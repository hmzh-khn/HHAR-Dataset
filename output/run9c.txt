
LOOCV TRAINING INFO - is_lstm? True
LOOCV? -  True
-------------
TRAINING USERS -  ['a', 'b', 'c', 'e', 'g', 'i']
LEFT OUT -  h
-------------
actions ['bike', 'sit']
devices ['samsungold_1', 'samsungold_2']
step size 10
num_epochs 1000
batch size 12
feature size (x,y,z) 3
hidden size 20
number recurrent layers 2
number of classes 2
writing pickle to run9_model.p
writing accuracy + pickle to acc_run9_model.p
------------------------------------------------
0	 steps: training loss - 0.69002	, testing loss - 0.70014	
1	 steps: training loss - 0.70720	, testing loss - 0.69866	
2	 steps: training loss - 0.68961	, testing loss - 0.69733	
3	 steps: training loss - 0.68585	, testing loss - 0.69610	
4	 steps: training loss - 0.69131	, testing loss - 0.69498	
5	 steps: training loss - 0.71670	, testing loss - 0.69393	
6	 steps: training loss - 0.70463	, testing loss - 0.69284	
7	 steps: training loss - 0.69940	, testing loss - 0.69175	
8	 steps: training loss - 0.68786	, testing loss - 0.69067	
9	 steps: training loss - 0.68770	, testing loss - 0.68972	
10	 steps: training loss - 0.69300	, testing loss - 0.68888	
11	 steps: training loss - 0.69343	, testing loss - 0.68804	
12	 steps: training loss - 0.70352	, testing loss - 0.68721	
13	 steps: training loss - 0.69884	, testing loss - 0.68636	
14	 steps: training loss - 0.68832	, testing loss - 0.68555	
15	 steps: training loss - 0.69251	, testing loss - 0.68478	
16	 steps: training loss - 0.67798	, testing loss - 0.68407	
17	 steps: training loss - 0.68765	, testing loss - 0.68352	
18	 steps: training loss - 0.67560	, testing loss - 0.68311	
19	 steps: training loss - 0.68447	, testing loss - 0.68272	
20	 steps: training loss - 0.68216	, testing loss - 0.68238	
21	 steps: training loss - 0.67790	, testing loss - 0.68208	
22	 steps: training loss - 0.68030	, testing loss - 0.68178	
23	 steps: training loss - 0.67761	, testing loss - 0.68151	
24	 steps: training loss - 0.68056	, testing loss - 0.68127	
25	 steps: training loss - 0.67059	, testing loss - 0.68105	
26	 steps: training loss - 0.68235	, testing loss - 0.68084	
27	 steps: training loss - 0.66705	, testing loss - 0.68065	
28	 steps: training loss - 0.67119	, testing loss - 0.68047	
29	 steps: training loss - 0.66044	, testing loss - 0.68032	
30	 steps: training loss - 0.66172	, testing loss - 0.68019	
31	 steps: training loss - 0.66428	, testing loss - 0.68011	
32	 steps: training loss - 0.67628	, testing loss - 0.68008	
33	 steps: training loss - 0.66112	, testing loss - 0.68009	
34	 steps: training loss - 0.68594	, testing loss - 0.68013	
35	 steps: training loss - 0.66111	, testing loss - 0.68018	
36	 steps: training loss - 0.64302	, testing loss - 0.68024	
37	 steps: training loss - 0.66648	, testing loss - 0.68038	
38	 steps: training loss - 0.66229	, testing loss - 0.68053	
39	 steps: training loss - 0.66537	, testing loss - 0.68068	
40	 steps: training loss - 0.63196	, testing loss - 0.68082	
41	 steps: training loss - 0.62737	, testing loss - 0.68104	
42	 steps: training loss - 0.71012	, testing loss - 0.68136	
43	 steps: training loss - 0.64130	, testing loss - 0.68157	
44	 steps: training loss - 0.68096	, testing loss - 0.68178	
45	 steps: training loss - 0.68260	, testing loss - 0.68193	
46	 steps: training loss - 0.67335	, testing loss - 0.68196	
47	 steps: training loss - 0.62069	, testing loss - 0.68196	
48	 steps: training loss - 0.66886	, testing loss - 0.68208	
49	 steps: training loss - 0.66223	, testing loss - 0.68220	
50	 steps: training loss - 0.66625	, testing loss - 0.68229	
51	 steps: training loss - 0.63883	, testing loss - 0.68235	
52	 steps: training loss - 0.63844	, testing loss - 0.68247	
53	 steps: training loss - 0.68076	, testing loss - 0.68268	
54	 steps: training loss - 0.67191	, testing loss - 0.68280	
55	 steps: training loss - 0.70468	, testing loss - 0.68287	
56	 steps: training loss - 0.70258	, testing loss - 0.68278	
57	 steps: training loss - 0.66461	, testing loss - 0.68250	
58	 steps: training loss - 0.65390	, testing loss - 0.68223	
59	 steps: training loss - 0.69403	, testing loss - 0.68202	
60	 steps: training loss - 0.62134	, testing loss - 0.68177	
61	 steps: training loss - 0.68445	, testing loss - 0.68169	
62	 steps: training loss - 0.69222	, testing loss - 0.68161	
63	 steps: training loss - 0.67722	, testing loss - 0.68142	
64	 steps: training loss - 0.62723	, testing loss - 0.68119	
65	 steps: training loss - 0.61789	, testing loss - 0.68110	
66	 steps: training loss - 0.68658	, testing loss - 0.68119	
67	 steps: training loss - 0.61599	, testing loss - 0.68124	
68	 steps: training loss - 0.61719	, testing loss - 0.68140	
69	 steps: training loss - 0.61659	, testing loss - 0.68173	
70	 steps: training loss - 0.59628	, testing loss - 0.68222	
71	 steps: training loss - 0.66040	, testing loss - 0.68291	
72	 steps: training loss - 0.65357	, testing loss - 0.68356	
73	 steps: training loss - 0.68851	, testing loss - 0.68412	
74	 steps: training loss - 0.65229	, testing loss - 0.68448	
75	 steps: training loss - 0.68551	, testing loss - 0.68473	
76	 steps: training loss - 0.67614	, testing loss - 0.68481	
77	 steps: training loss - 0.68121	, testing loss - 0.68473	
78	 steps: training loss - 0.68598	, testing loss - 0.68452	
79	 steps: training loss - 0.67242	, testing loss - 0.68420	
80	 steps: training loss - 0.63071	, testing loss - 0.68381	
81	 steps: training loss - 0.65745	, testing loss - 0.68355	
82	 steps: training loss - 0.63137	, testing loss - 0.68333	
83	 steps: training loss - 0.62651	, testing loss - 0.68323	
84	 steps: training loss - 0.65235	, testing loss - 0.68327	
85	 steps: training loss - 0.64131	, testing loss - 0.68332	
86	 steps: training loss - 0.60325	, testing loss - 0.68339	
87	 steps: training loss - 0.71368	, testing loss - 0.68364	
88	 steps: training loss - 0.65187	, testing loss - 0.68367	
89	 steps: training loss - 0.63016	, testing loss - 0.68360	
90	 steps: training loss - 0.69416	, testing loss - 0.68365	
91	 steps: training loss - 0.68724	, testing loss - 0.68358	
92	 steps: training loss - 0.66553	, testing loss - 0.68333	
93	 steps: training loss - 0.68152	, testing loss - 0.68303	
94	 steps: training loss - 0.65614	, testing loss - 0.68266	
95	 steps: training loss - 0.59284	, testing loss - 0.68231	
96	 steps: training loss - 0.58934	, testing loss - 0.68223	
97	 steps: training loss - 0.66780	, testing loss - 0.68241	
98	 steps: training loss - 0.68724	, testing loss - 0.68256	
99	 steps: training loss - 0.68584	, testing loss - 0.68252	
100	 steps: training loss - 0.67319	, testing loss - 0.68231	
101	 steps: training loss - 0.70853	, testing loss - 0.68199	
102	 steps: training loss - 0.68152	, testing loss - 0.68146	
103	 steps: training loss - 0.61472	, testing loss - 0.68085	
104	 steps: training loss - 0.60766	, testing loss - 0.68045	
105	 steps: training loss - 0.67419	, testing loss - 0.68034	
106	 steps: training loss - 0.68586	, testing loss - 0.68021	
107	 steps: training loss - 0.59283	, testing loss - 0.67997	
108	 steps: training loss - 0.67960	, testing loss - 0.67995	
109	 steps: training loss - 0.65069	, testing loss - 0.67987	
110	 steps: training loss - 0.60199	, testing loss - 0.67979	
111	 steps: training loss - 0.69661	, testing loss - 0.67993	
112	 steps: training loss - 0.60935	, testing loss - 0.67998	
113	 steps: training loss - 0.64032	, testing loss - 0.68014	
114	 steps: training loss - 0.68522	, testing loss - 0.68040	
115	 steps: training loss - 0.63317	, testing loss - 0.68049	
116	 steps: training loss - 0.71779	, testing loss - 0.68061	
117	 steps: training loss - 0.61967	, testing loss - 0.68049	
118	 steps: training loss - 0.73043	, testing loss - 0.68039	
119	 steps: training loss - 0.57198	, testing loss - 0.67999	
120	 steps: training loss - 0.66035	, testing loss - 0.67983	
121	 steps: training loss - 0.63280	, testing loss - 0.67979	
122	 steps: training loss - 0.65693	, testing loss - 0.67979	
123	 steps: training loss - 0.65651	, testing loss - 0.67978	
124	 steps: training loss - 0.64218	, testing loss - 0.67972	
125	 steps: training loss - 0.64747	, testing loss - 0.67966	
126	 steps: training loss - 0.60498	, testing loss - 0.67963	
127	 steps: training loss - 0.74381	, testing loss - 0.67978	
128	 steps: training loss - 0.64407	, testing loss - 0.67960	
129	 steps: training loss - 0.69543	, testing loss - 0.67935	
130	 steps: training loss - 0.57974	, testing loss - 0.67894	
131	 steps: training loss - 0.71834	, testing loss - 0.67876	
132	 steps: training loss - 0.69804	, testing loss - 0.67846	
133	 steps: training loss - 0.65689	, testing loss - 0.67799	
134	 steps: training loss - 0.59821	, testing loss - 0.67756	
135	 steps: training loss - 0.69121	, testing loss - 0.67734	
136	 steps: training loss - 0.59526	, testing loss - 0.67704	
137	 steps: training loss - 0.61490	, testing loss - 0.67695	
138	 steps: training loss - 0.67532	, testing loss - 0.67705	
139	 steps: training loss - 0.71614	, testing loss - 0.67713	
140	 steps: training loss - 0.73031	, testing loss - 0.67694	
141	 steps: training loss - 0.61520	, testing loss - 0.67642	
142	 steps: training loss - 0.61628	, testing loss - 0.67600	
143	 steps: training loss - 0.69010	, testing loss - 0.67584	
144	 steps: training loss - 0.66052	, testing loss - 0.67564	
145	 steps: training loss - 0.68143	, testing loss - 0.67536	
146	 steps: training loss - 0.67237	, testing loss - 0.67502	
147	 steps: training loss - 0.62605	, testing loss - 0.67461	
148	 steps: training loss - 0.67037	, testing loss - 0.67424	
149	 steps: training loss - 0.71348	, testing loss - 0.67389	
150	 steps: training loss - 0.64240	, testing loss - 0.67342	
151	 steps: training loss - 0.70620	, testing loss - 0.67299	
152	 steps: training loss - 0.67892	, testing loss - 0.67241	
153	 steps: training loss - 0.62798	, testing loss - 0.67184	
154	 steps: training loss - 0.63444	, testing loss - 0.67145	
155	 steps: training loss - 0.63649	, testing loss - 0.67122	
156	 steps: training loss - 0.64297	, testing loss - 0.67112	
157	 steps: training loss - 0.66347	, testing loss - 0.67114	
158	 steps: training loss - 0.64179	, testing loss - 0.67118	
159	 steps: training loss - 0.70547	, testing loss - 0.67124	
160	 steps: training loss - 0.62243	, testing loss - 0.67122	
161	 steps: training loss - 0.67530	, testing loss - 0.67125	
162	 steps: training loss - 0.60109	, testing loss - 0.67116	
163	 steps: training loss - 0.63399	, testing loss - 0.67118	
164	 steps: training loss - 0.59809	, testing loss - 0.67126	
165	 steps: training loss - 0.63458	, testing loss - 0.67149	
166	 steps: training loss - 0.60787	, testing loss - 0.67184	
167	 steps: training loss - 0.64408	, testing loss - 0.67234	
168	 steps: training loss - 0.67822	, testing loss - 0.67284	
169	 steps: training loss - 0.62389	, testing loss - 0.67308	
170	 steps: training loss - 0.65339	, testing loss - 0.67324	
171	 steps: training loss - 0.65329	, testing loss - 0.67330	
172	 steps: training loss - 0.66741	, testing loss - 0.67330	
173	 steps: training loss - 0.60961	, testing loss - 0.67327	
174	 steps: training loss - 0.63321	, testing loss - 0.67335	
175	 steps: training loss - 0.60862	, testing loss - 0.67347	
176	 steps: training loss - 0.64893	, testing loss - 0.67368	
177	 steps: training loss - 0.69909	, testing loss - 0.67388	
178	 steps: training loss - 0.64049	, testing loss - 0.67383	
179	 steps: training loss - 0.63688	, testing loss - 0.67369	
180	 steps: training loss - 0.70058	, testing loss - 0.67357	
181	 steps: training loss - 0.60069	, testing loss - 0.67332	
182	 steps: training loss - 0.67619	, testing loss - 0.67320	
183	 steps: training loss - 0.63047	, testing loss - 0.67302	
184	 steps: training loss - 0.63040	, testing loss - 0.67285	
185	 steps: training loss - 0.61271	, testing loss - 0.67273	
186	 steps: training loss - 0.63777	, testing loss - 0.67274	
187	 steps: training loss - 0.61433	, testing loss - 0.67289	
188	 steps: training loss - 0.65869	, testing loss - 0.67305	
189	 steps: training loss - 0.67458	, testing loss - 0.67307	
190	 steps: training loss - 0.65691	, testing loss - 0.67289	
191	 steps: training loss - 0.60391	, testing loss - 0.67267	
192	 steps: training loss - 0.58659	, testing loss - 0.67261	
193	 steps: training loss - 0.60544	, testing loss - 0.67279	
194	 steps: training loss - 0.61267	, testing loss - 0.67310	
195	 steps: training loss - 0.69705	, testing loss - 0.67349	
196	 steps: training loss - 0.67306	, testing loss - 0.67355	
197	 steps: training loss - 0.60583	, testing loss - 0.67337	
198	 steps: training loss - 0.64644	, testing loss - 0.67338	
199	 steps: training loss - 0.71295	, testing loss - 0.67340	
200	 steps: training loss - 0.61019	, testing loss - 0.67316	
201	 steps: training loss - 0.60625	, testing loss - 0.67293	
202	 steps: training loss - 0.64628	, testing loss - 0.67283	
203	 steps: training loss - 0.65191	, testing loss - 0.67282	
204	 steps: training loss - 0.64601	, testing loss - 0.67279	
205	 steps: training loss - 0.62624	, testing loss - 0.67277	
206	 steps: training loss - 0.66605	, testing loss - 0.67283	
207	 steps: training loss - 0.71319	, testing loss - 0.67278	
208	 steps: training loss - 0.58943	, testing loss - 0.67241	
209	 steps: training loss - 0.61921	, testing loss - 0.67222	
210	 steps: training loss - 0.62788	, testing loss - 0.67225	
211	 steps: training loss - 0.63688	, testing loss - 0.67230	
212	 steps: training loss - 0.62537	, testing loss - 0.67236	
213	 steps: training loss - 0.62119	, testing loss - 0.67243	
214	 steps: training loss - 0.63060	, testing loss - 0.67252	
215	 steps: training loss - 0.62378	, testing loss - 0.67260	
216	 steps: training loss - 0.61169	, testing loss - 0.67264	
217	 steps: training loss - 0.61012	, testing loss - 0.67271	
218	 steps: training loss - 0.63854	, testing loss - 0.67279	
219	 steps: training loss - 0.66589	, testing loss - 0.67285	
220	 steps: training loss - 0.64112	, testing loss - 0.67275	
221	 steps: training loss - 0.59880	, testing loss - 0.67252	
222	 steps: training loss - 0.61853	, testing loss - 0.67242	
223	 steps: training loss - 0.60293	, testing loss - 0.67248	
224	 steps: training loss - 0.64299	, testing loss - 0.67271	
225	 steps: training loss - 0.63010	, testing loss - 0.67288	
226	 steps: training loss - 0.65069	, testing loss - 0.67299	
227	 steps: training loss - 0.62643	, testing loss - 0.67294	
228	 steps: training loss - 0.64694	, testing loss - 0.67295	
229	 steps: training loss - 0.62003	, testing loss - 0.67288	
230	 steps: training loss - 0.62165	, testing loss - 0.67287	
231	 steps: training loss - 0.76934	, testing loss - 0.67287	
232	 steps: training loss - 0.66154	, testing loss - 0.67225	
233	 steps: training loss - 0.70134	, testing loss - 0.67133	
234	 steps: training loss - 0.59755	, testing loss - 0.67027	
235	 steps: training loss - 0.60849	, testing loss - 0.66948	
236	 steps: training loss - 0.58632	, testing loss - 0.66898	
237	 steps: training loss - 0.61277	, testing loss - 0.66884	
238	 steps: training loss - 0.67558	, testing loss - 0.66887	
239	 steps: training loss - 0.67515	, testing loss - 0.66878	
240	 steps: training loss - 0.69722	, testing loss - 0.66853	
241	 steps: training loss - 0.66945	, testing loss - 0.66803	
242	 steps: training loss - 0.58937	, testing loss - 0.66739	
243	 steps: training loss - 0.62096	, testing loss - 0.66694	
244	 steps: training loss - 0.64343	, testing loss - 0.66678	
245	 steps: training loss - 0.62838	, testing loss - 0.66670	
246	 steps: training loss - 0.67424	, testing loss - 0.66666	
247	 steps: training loss - 0.64617	, testing loss - 0.66645	
248	 steps: training loss - 0.62155	, testing loss - 0.66611	
249	 steps: training loss - 0.62919	, testing loss - 0.66584	
250	 steps: training loss - 0.63779	, testing loss - 0.66552	
251	 steps: training loss - 0.62322	, testing loss - 0.66524	
252	 steps: training loss - 0.68210	, testing loss - 0.66513	
253	 steps: training loss - 0.63212	, testing loss - 0.66488	
254	 steps: training loss - 0.54065	, testing loss - 0.66460	
255	 steps: training loss - 0.66312	, testing loss - 0.66474	
256	 steps: training loss - 0.64813	, testing loss - 0.66486	
257	 steps: training loss - 0.67067	, testing loss - 0.66484	
258	 steps: training loss - 0.64847	, testing loss - 0.66460	
259	 steps: training loss - 0.64259	, testing loss - 0.66427	
260	 steps: training loss - 0.67807	, testing loss - 0.66398	
261	 steps: training loss - 0.57972	, testing loss - 0.66348	
262	 steps: training loss - 0.64550	, testing loss - 0.66320	
263	 steps: training loss - 0.66300	, testing loss - 0.66296	
264	 steps: training loss - 0.63448	, testing loss - 0.66265	
265	 steps: training loss - 0.60901	, testing loss - 0.66228	
266	 steps: training loss - 0.63109	, testing loss - 0.66198	
267	 steps: training loss - 0.66112	, testing loss - 0.66176	
268	 steps: training loss - 0.61334	, testing loss - 0.66135	
269	 steps: training loss - 0.60209	, testing loss - 0.66104	
270	 steps: training loss - 0.59761	, testing loss - 0.66091	
271	 steps: training loss - 0.59261	, testing loss - 0.66089	
272	 steps: training loss - 0.63318	, testing loss - 0.66102	
273	 steps: training loss - 0.61958	, testing loss - 0.66117	
274	 steps: training loss - 0.60860	, testing loss - 0.66142	
275	 steps: training loss - 0.59834	, testing loss - 0.66169	
276	 steps: training loss - 0.66773	, testing loss - 0.66194	
277	 steps: training loss - 0.59409	, testing loss - 0.66197	
278	 steps: training loss - 0.63073	, testing loss - 0.66203	
279	 steps: training loss - 0.65665	, testing loss - 0.66214	
280	 steps: training loss - 0.58939	, testing loss - 0.66213	
281	 steps: training loss - 0.60828	, testing loss - 0.66219	
282	 steps: training loss - 0.62818	, testing loss - 0.66241	
283	 steps: training loss - 0.63716	, testing loss - 0.66260	
284	 steps: training loss - 0.58612	, testing loss - 0.66277	
285	 steps: training loss - 0.61553	, testing loss - 0.66296	
286	 steps: training loss - 0.68084	, testing loss - 0.66325	
287	 steps: training loss - 0.59993	, testing loss - 0.66333	
288	 steps: training loss - 0.64123	, testing loss - 0.66355	
289	 steps: training loss - 0.70050	, testing loss - 0.66368	
290	 steps: training loss - 0.62195	, testing loss - 0.66348	
291	 steps: training loss - 0.67336	, testing loss - 0.66332	
292	 steps: training loss - 0.62066	, testing loss - 0.66311	
293	 steps: training loss - 0.64339	, testing loss - 0.66300	
294	 steps: training loss - 0.69999	, testing loss - 0.66275	
295	 steps: training loss - 0.64488	, testing loss - 0.66236	
296	 steps: training loss - 0.58926	, testing loss - 0.66193	
297	 steps: training loss - 0.68642	, testing loss - 0.66165	
298	 steps: training loss - 0.62038	, testing loss - 0.66131	
299	 steps: training loss - 0.63113	, testing loss - 0.66107	
300	 steps: training loss - 0.61003	, testing loss - 0.66082	
301	 steps: training loss - 0.60416	, testing loss - 0.66072	
302	 steps: training loss - 0.62873	, testing loss - 0.66081	
303	 steps: training loss - 0.64362	, testing loss - 0.66101	
304	 steps: training loss - 0.61644	, testing loss - 0.66121	
305	 steps: training loss - 0.66402	, testing loss - 0.66149	
306	 steps: training loss - 0.65618	, testing loss - 0.66174	
307	 steps: training loss - 0.62150	, testing loss - 0.66179	
308	 steps: training loss - 0.60286	, testing loss - 0.66179	
309	 steps: training loss - 0.68856	, testing loss - 0.66182	
310	 steps: training loss - 0.57784	, testing loss - 0.66169	
311	 steps: training loss - 0.68325	, testing loss - 0.66178	
312	 steps: training loss - 0.61106	, testing loss - 0.66179	
313	 steps: training loss - 0.56929	, testing loss - 0.66188	
314	 steps: training loss - 0.62912	, testing loss - 0.66223	
315	 steps: training loss - 0.62091	, testing loss - 0.66271	
316	 steps: training loss - 0.58906	, testing loss - 0.66325	
317	 steps: training loss - 0.70693	, testing loss - 0.66385	
318	 steps: training loss - 0.67064	, testing loss - 0.66406	
319	 steps: training loss - 0.59478	, testing loss - 0.66398	
320	 steps: training loss - 0.60068	, testing loss - 0.66397	
321	 steps: training loss - 0.60421	, testing loss - 0.66399	
322	 steps: training loss - 0.63630	, testing loss - 0.66404	
323	 steps: training loss - 0.67990	, testing loss - 0.66406	
324	 steps: training loss - 0.64311	, testing loss - 0.66376	
325	 steps: training loss - 0.59031	, testing loss - 0.66338	
326	 steps: training loss - 0.55965	, testing loss - 0.66320	
327	 steps: training loss - 0.70906	, testing loss - 0.66332	
328	 steps: training loss - 0.62462	, testing loss - 0.66313	
329	 steps: training loss - 0.63855	, testing loss - 0.66290	
330	 steps: training loss - 0.60114	, testing loss - 0.66270	
331	 steps: training loss - 0.61481	, testing loss - 0.66251	
332	 steps: training loss - 0.63208	, testing loss - 0.66234	
333	 steps: training loss - 0.63018	, testing loss - 0.66206	
334	 steps: training loss - 0.63100	, testing loss - 0.66168	
335	 steps: training loss - 0.69231	, testing loss - 0.66130	
336	 steps: training loss - 0.54974	, testing loss - 0.66080	
337	 steps: training loss - 0.67671	, testing loss - 0.66058	
338	 steps: training loss - 0.59362	, testing loss - 0.66022	
339	 steps: training loss - 0.63483	, testing loss - 0.65986	
340	 steps: training loss - 0.59387	, testing loss - 0.65946	
341	 steps: training loss - 0.63338	, testing loss - 0.65924	
342	 steps: training loss - 0.65240	, testing loss - 0.65901	
343	 steps: training loss - 0.61994	, testing loss - 0.65858	
344	 steps: training loss - 0.60637	, testing loss - 0.65807	
345	 steps: training loss - 0.62882	, testing loss - 0.65776	
346	 steps: training loss - 0.61562	, testing loss - 0.65766	
347	 steps: training loss - 0.61493	, testing loss - 0.65774	
348	 steps: training loss - 0.61770	, testing loss - 0.65772	
349	 steps: training loss - 0.62426	, testing loss - 0.65768	
350	 steps: training loss - 0.54761	, testing loss - 0.65775	
351	 steps: training loss - 0.66031	, testing loss - 0.65810	
352	 steps: training loss - 0.58351	, testing loss - 0.65840	
353	 steps: training loss - 0.58342	, testing loss - 0.65890	
354	 steps: training loss - 0.58004	, testing loss - 0.65956	
355	 steps: training loss - 0.58776	, testing loss - 0.66039	
356	 steps: training loss - 0.64657	, testing loss - 0.66130	
357	 steps: training loss - 0.64227	, testing loss - 0.66208	
358	 steps: training loss - 0.56927	, testing loss - 0.66264	
359	 steps: training loss - 0.60688	, testing loss - 0.66324	
360	 steps: training loss - 0.63007	, testing loss - 0.66376	
361	 steps: training loss - 0.62874	, testing loss - 0.66424	
362	 steps: training loss - 0.61831	, testing loss - 0.66466	
363	 steps: training loss - 0.64383	, testing loss - 0.66491	
364	 steps: training loss - 0.56178	, testing loss - 0.66490	
365	 steps: training loss - 0.63399	, testing loss - 0.66499	
366	 steps: training loss - 0.60863	, testing loss - 0.66517	
367	 steps: training loss - 0.63371	, testing loss - 0.66518	
368	 steps: training loss - 0.66034	, testing loss - 0.66496	
369	 steps: training loss - 0.68301	, testing loss - 0.66440	
370	 steps: training loss - 0.59102	, testing loss - 0.66358	
371	 steps: training loss - 0.65658	, testing loss - 0.66291	
372	 steps: training loss - 0.63396	, testing loss - 0.66229	
373	 steps: training loss - 0.61718	, testing loss - 0.66158	
374	 steps: training loss - 0.59379	, testing loss - 0.66091	
375	 steps: training loss - 0.64390	, testing loss - 0.66033	
376	 steps: training loss - 0.58125	, testing loss - 0.65953	
377	 steps: training loss - 0.67793	, testing loss - 0.65894	
378	 steps: training loss - 0.59499	, testing loss - 0.65808	
379	 steps: training loss - 0.68902	, testing loss - 0.65718	
380	 steps: training loss - 0.64501	, testing loss - 0.65631	
381	 steps: training loss - 0.56278	, testing loss - 0.65546	
382	 steps: training loss - 0.64923	, testing loss - 0.65501	
383	 steps: training loss - 0.65880	, testing loss - 0.65470	
384	 steps: training loss - 0.60093	, testing loss - 0.65422	
385	 steps: training loss - 0.62527	, testing loss - 0.65373	
386	 steps: training loss - 0.59335	, testing loss - 0.65334	
387	 steps: training loss - 0.63809	, testing loss - 0.65321	
388	 steps: training loss - 0.62111	, testing loss - 0.65314	
389	 steps: training loss - 0.64144	, testing loss - 0.65310	
390	 steps: training loss - 0.61145	, testing loss - 0.65297	
391	 steps: training loss - 0.68747	, testing loss - 0.65290	
392	 steps: training loss - 0.61330	, testing loss - 0.65264	
393	 steps: training loss - 0.62797	, testing loss - 0.65249	
394	 steps: training loss - 0.67986	, testing loss - 0.65242	
395	 steps: training loss - 0.59404	, testing loss - 0.65213	
396	 steps: training loss - 0.61318	, testing loss - 0.65195	
397	 steps: training loss - 0.64373	, testing loss - 0.65174	
398	 steps: training loss - 0.63855	, testing loss - 0.65155	
399	 steps: training loss - 0.66777	, testing loss - 0.65118	
400	 steps: training loss - 0.59901	, testing loss - 0.65059	
401	 steps: training loss - 0.61650	, testing loss - 0.64991	
402	 steps: training loss - 0.67502	, testing loss - 0.64934	
403	 steps: training loss - 0.61421	, testing loss - 0.64871	
404	 steps: training loss - 0.64920	, testing loss - 0.64827	
405	 steps: training loss - 0.61578	, testing loss - 0.64769	
406	 steps: training loss - 0.58179	, testing loss - 0.64719	
407	 steps: training loss - 0.60049	, testing loss - 0.64686	
408	 steps: training loss - 0.57886	, testing loss - 0.64665	
409	 steps: training loss - 0.63145	, testing loss - 0.64660	
410	 steps: training loss - 0.64703	, testing loss - 0.64665	
411	 steps: training loss - 0.57745	, testing loss - 0.64672	
412	 steps: training loss - 0.58460	, testing loss - 0.64683	
413	 steps: training loss - 0.61476	, testing loss - 0.64699	
414	 steps: training loss - 0.62545	, testing loss - 0.64717	
415	 steps: training loss - 0.59199	, testing loss - 0.64723	
416	 steps: training loss - 0.66212	, testing loss - 0.64729	
417	 steps: training loss - 0.59652	, testing loss - 0.64730	
418	 steps: training loss - 0.58499	, testing loss - 0.64741	
419	 steps: training loss - 0.66289	, testing loss - 0.64767	
420	 steps: training loss - 0.62278	, testing loss - 0.64786	
421	 steps: training loss - 0.63508	, testing loss - 0.64802	
422	 steps: training loss - 0.61772	, testing loss - 0.64827	
423	 steps: training loss - 0.63437	, testing loss - 0.64852	
424	 steps: training loss - 0.60262	, testing loss - 0.64866	
425	 steps: training loss - 0.61621	, testing loss - 0.64870	
426	 steps: training loss - 0.60552	, testing loss - 0.64896	
427	 steps: training loss - 0.58199	, testing loss - 0.64929	
428	 steps: training loss - 0.67139	, testing loss - 0.64958	
429	 steps: training loss - 0.58917	, testing loss - 0.64937	
430	 steps: training loss - 0.69035	, testing loss - 0.64926	
431	 steps: training loss - 0.61324	, testing loss - 0.64900	
432	 steps: training loss - 0.63101	, testing loss - 0.64882	
433	 steps: training loss - 0.59395	, testing loss - 0.64849	
434	 steps: training loss - 0.69004	, testing loss - 0.64817	
435	 steps: training loss - 0.63182	, testing loss - 0.64766	
436	 steps: training loss - 0.60413	, testing loss - 0.64717	
437	 steps: training loss - 0.58189	, testing loss - 0.64682	
438	 steps: training loss - 0.60027	, testing loss - 0.64671	
439	 steps: training loss - 0.64623	, testing loss - 0.64671	
440	 steps: training loss - 0.59208	, testing loss - 0.64666	
441	 steps: training loss - 0.65419	, testing loss - 0.64652	
442	 steps: training loss - 0.62325	, testing loss - 0.64638	
443	 steps: training loss - 0.57169	, testing loss - 0.64620	
444	 steps: training loss - 0.60922	, testing loss - 0.64621	
445	 steps: training loss - 0.64466	, testing loss - 0.64638	
446	 steps: training loss - 0.57806	, testing loss - 0.64643	
447	 steps: training loss - 0.62585	, testing loss - 0.64666	
448	 steps: training loss - 0.59987	, testing loss - 0.64670	
449	 steps: training loss - 0.61535	, testing loss - 0.64671	
450	 steps: training loss - 0.58720	, testing loss - 0.64679	
451	 steps: training loss - 0.60809	, testing loss - 0.64676	
452	 steps: training loss - 0.63073	, testing loss - 0.64674	
453	 steps: training loss - 0.61470	, testing loss - 0.64672	
454	 steps: training loss - 0.59822	, testing loss - 0.64680	
455	 steps: training loss - 0.59616	, testing loss - 0.64691	
456	 steps: training loss - 0.63100	, testing loss - 0.64711	
457	 steps: training loss - 0.67021	, testing loss - 0.64731	
458	 steps: training loss - 0.70978	, testing loss - 0.64726	
459	 steps: training loss - 0.58053	, testing loss - 0.64675	
460	 steps: training loss - 0.57549	, testing loss - 0.64643	
461	 steps: training loss - 0.63226	, testing loss - 0.64635	
462	 steps: training loss - 0.55945	, testing loss - 0.64643	
463	 steps: training loss - 0.61001	, testing loss - 0.64670	
464	 steps: training loss - 0.59390	, testing loss - 0.64707	
465	 steps: training loss - 0.57145	, testing loss - 0.64754	
466	 steps: training loss - 0.60089	, testing loss - 0.64820	
467	 steps: training loss - 0.63296	, testing loss - 0.64880	
468	 steps: training loss - 0.61980	, testing loss - 0.64917	
469	 steps: training loss - 0.58811	, testing loss - 0.64935	
470	 steps: training loss - 0.60078	, testing loss - 0.64958	
471	 steps: training loss - 0.61302	, testing loss - 0.64979	
472	 steps: training loss - 0.62059	, testing loss - 0.65005	
473	 steps: training loss - 0.55703	, testing loss - 0.65017	
474	 steps: training loss - 0.68820	, testing loss - 0.65048	
475	 steps: training loss - 0.57837	, testing loss - 0.65046	
476	 steps: training loss - 0.60222	, testing loss - 0.65050	
477	 steps: training loss - 0.59623	, testing loss - 0.65046	
478	 steps: training loss - 0.63491	, testing loss - 0.65031	
479	 steps: training loss - 0.64920	, testing loss - 0.64996	
480	 steps: training loss - 0.62533	, testing loss - 0.64956	
481	 steps: training loss - 0.64680	, testing loss - 0.64923	
482	 steps: training loss - 0.65080	, testing loss - 0.64879	
483	 steps: training loss - 0.66196	, testing loss - 0.64806	
484	 steps: training loss - 0.56394	, testing loss - 0.64723	
485	 steps: training loss - 0.63074	, testing loss - 0.64655	
486	 steps: training loss - 0.61454	, testing loss - 0.64605	
487	 steps: training loss - 0.57083	, testing loss - 0.64578	
488	 steps: training loss - 0.64454	, testing loss - 0.64571	
489	 steps: training loss - 0.53818	, testing loss - 0.64544	
490	 steps: training loss - 0.55812	, testing loss - 0.64529	
491	 steps: training loss - 0.55139	, testing loss - 0.64537	
492	 steps: training loss - 0.56859	, testing loss - 0.64575	
493	 steps: training loss - 0.64126	, testing loss - 0.64642	
494	 steps: training loss - 0.60112	, testing loss - 0.64693	
495	 steps: training loss - 0.53348	, testing loss - 0.64736	
496	 steps: training loss - 0.57654	, testing loss - 0.64815	
497	 steps: training loss - 0.63440	, testing loss - 0.64899	
498	 steps: training loss - 0.56208	, testing loss - 0.64949	
499	 steps: training loss - 0.54318	, testing loss - 0.64998	
500	 steps: training loss - 0.62529	, testing loss - 0.65052	
501	 steps: training loss - 0.63517	, testing loss - 0.65098	
502	 steps: training loss - 0.53080	, testing loss - 0.65137	
503	 steps: training loss - 0.65041	, testing loss - 0.65182	
504	 steps: training loss - 0.57969	, testing loss - 0.65220	
505	 steps: training loss - 0.62353	, testing loss - 0.65238	
506	 steps: training loss - 0.65548	, testing loss - 0.65242	
507	 steps: training loss - 0.56216	, testing loss - 0.65231	
508	 steps: training loss - 0.61362	, testing loss - 0.65247	
509	 steps: training loss - 0.56430	, testing loss - 0.65268	
510	 steps: training loss - 0.60400	, testing loss - 0.65284	
511	 steps: training loss - 0.64303	, testing loss - 0.65307	
512	 steps: training loss - 0.60193	, testing loss - 0.65312	
513	 steps: training loss - 0.52648	, testing loss - 0.65303	
514	 steps: training loss - 0.57479	, testing loss - 0.65312	
515	 steps: training loss - 0.60088	, testing loss - 0.65320	
516	 steps: training loss - 0.62087	, testing loss - 0.65332	
517	 steps: training loss - 0.58395	, testing loss - 0.65339	
518	 steps: training loss - 0.51941	, testing loss - 0.65328	
519	 steps: training loss - 0.56538	, testing loss - 0.65371	
520	 steps: training loss - 0.48427	, testing loss - 0.65434	
521	 steps: training loss - 0.65761	, testing loss - 0.65541	
522	 steps: training loss - 0.54474	, testing loss - 0.65631	
523	 steps: training loss - 0.61121	, testing loss - 0.65726	
524	 steps: training loss - 0.65567	, testing loss - 0.65821	
525	 steps: training loss - 0.64099	, testing loss - 0.65871	
526	 steps: training loss - 0.60847	, testing loss - 0.65881	
527	 steps: training loss - 0.68476	, testing loss - 0.65876	
528	 steps: training loss - 0.59144	, testing loss - 0.65832	
529	 steps: training loss - 0.69542	, testing loss - 0.65799	
530	 steps: training loss - 0.66372	, testing loss - 0.65729	
531	 steps: training loss - 0.71805	, testing loss - 0.65618	
532	 steps: training loss - 0.62179	, testing loss - 0.65470	
533	 steps: training loss - 0.55997	, testing loss - 0.65318	
534	 steps: training loss - 0.66482	, testing loss - 0.65193	
535	 steps: training loss - 0.58743	, testing loss - 0.65057	
536	 steps: training loss - 0.62593	, testing loss - 0.64921	
537	 steps: training loss - 0.68245	, testing loss - 0.64806	
538	 steps: training loss - 0.67477	, testing loss - 0.64682	
539	 steps: training loss - 0.60251	, testing loss - 0.64566	
540	 steps: training loss - 0.63700	, testing loss - 0.64483	
541	 steps: training loss - 0.58187	, testing loss - 0.64414	
542	 steps: training loss - 0.57630	, testing loss - 0.64357	
543	 steps: training loss - 0.57858	, testing loss - 0.64303	
544	 steps: training loss - 0.58761	, testing loss - 0.64256	
545	 steps: training loss - 0.62606	, testing loss - 0.64226	
546	 steps: training loss - 0.56556	, testing loss - 0.64217	
547	 steps: training loss - 0.58779	, testing loss - 0.64217	
548	 steps: training loss - 0.67643	, testing loss - 0.64220	
549	 steps: training loss - 0.58918	, testing loss - 0.64219	
550	 steps: training loss - 0.56995	, testing loss - 0.64229	
551	 steps: training loss - 0.57029	, testing loss - 0.64249	
552	 steps: training loss - 0.62352	, testing loss - 0.64287	
553	 steps: training loss - 0.72188	, testing loss - 0.64301	
554	 steps: training loss - 0.63606	, testing loss - 0.64255	
555	 steps: training loss - 0.60383	, testing loss - 0.64201	
556	 steps: training loss - 0.57212	, testing loss - 0.64174	
557	 steps: training loss - 0.56868	, testing loss - 0.64150	
558	 steps: training loss - 0.58883	, testing loss - 0.64140	
559	 steps: training loss - 0.63913	, testing loss - 0.64125	
560	 steps: training loss - 0.54826	, testing loss - 0.64108	
561	 steps: training loss - 0.65510	, testing loss - 0.64095	
562	 steps: training loss - 0.56014	, testing loss - 0.64040	
563	 steps: training loss - 0.58680	, testing loss - 0.64004	
564	 steps: training loss - 0.54399	, testing loss - 0.63968	
565	 steps: training loss - 0.65448	, testing loss - 0.63969	
566	 steps: training loss - 0.54652	, testing loss - 0.63983	
567	 steps: training loss - 0.58835	, testing loss - 0.64013	
568	 steps: training loss - 0.62015	, testing loss - 0.64058	
569	 steps: training loss - 0.60447	, testing loss - 0.64113	
570	 steps: training loss - 0.64983	, testing loss - 0.64174	
571	 steps: training loss - 0.63977	, testing loss - 0.64195	
572	 steps: training loss - 0.59411	, testing loss - 0.64185	
573	 steps: training loss - 0.61691	, testing loss - 0.64181	
574	 steps: training loss - 0.63900	, testing loss - 0.64196	
575	 steps: training loss - 0.57395	, testing loss - 0.64209	
576	 steps: training loss - 0.63030	, testing loss - 0.64239	
577	 steps: training loss - 0.59170	, testing loss - 0.64263	
578	 steps: training loss - 0.58307	, testing loss - 0.64267	
579	 steps: training loss - 0.54903	, testing loss - 0.64267	
580	 steps: training loss - 0.58074	, testing loss - 0.64285	
581	 steps: training loss - 0.61848	, testing loss - 0.64290	
582	 steps: training loss - 0.63105	, testing loss - 0.64261	
583	 steps: training loss - 0.61671	, testing loss - 0.64208	
584	 steps: training loss - 0.64743	, testing loss - 0.64143	
585	 steps: training loss - 0.69370	, testing loss - 0.64066	
586	 steps: training loss - 0.59427	, testing loss - 0.63963	
587	 steps: training loss - 0.56231	, testing loss - 0.63863	
588	 steps: training loss - 0.62333	, testing loss - 0.63798	
589	 steps: training loss - 0.54862	, testing loss - 0.63752	
590	 steps: training loss - 0.59671	, testing loss - 0.63747	
591	 steps: training loss - 0.58644	, testing loss - 0.63763	
592	 steps: training loss - 0.53532	, testing loss - 0.63806	
593	 steps: training loss - 0.66438	, testing loss - 0.63869	
594	 steps: training loss - 0.60333	, testing loss - 0.63911	
595	 steps: training loss - 0.52692	, testing loss - 0.63909	
596	 steps: training loss - 0.61257	, testing loss - 0.63907	
597	 steps: training loss - 0.57638	, testing loss - 0.63890	
598	 steps: training loss - 0.57126	, testing loss - 0.63894	
599	 steps: training loss - 0.62400	, testing loss - 0.63922	
600	 steps: training loss - 0.61967	, testing loss - 0.63946	
601	 steps: training loss - 0.62871	, testing loss - 0.63950	
602	 steps: training loss - 0.63583	, testing loss - 0.63932	
603	 steps: training loss - 0.56117	, testing loss - 0.63884	
604	 steps: training loss - 0.56256	, testing loss - 0.63841	
605	 steps: training loss - 0.54929	, testing loss - 0.63808	
606	 steps: training loss - 0.56944	, testing loss - 0.63812	
607	 steps: training loss - 0.58071	, testing loss - 0.63847	
608	 steps: training loss - 0.57648	, testing loss - 0.63895	
609	 steps: training loss - 0.55404	, testing loss - 0.63951	
610	 steps: training loss - 0.58704	, testing loss - 0.64017	
611	 steps: training loss - 0.57647	, testing loss - 0.64095	
612	 steps: training loss - 0.57592	, testing loss - 0.64164	
613	 steps: training loss - 0.54089	, testing loss - 0.64222	
614	 steps: training loss - 0.63226	, testing loss - 0.64261	
615	 steps: training loss - 0.54804	, testing loss - 0.64262	
616	 steps: training loss - 0.64396	, testing loss - 0.64293	
617	 steps: training loss - 0.64139	, testing loss - 0.64315	
618	 steps: training loss - 0.59086	, testing loss - 0.64287	
619	 steps: training loss - 0.60667	, testing loss - 0.64240	
620	 steps: training loss - 0.65023	, testing loss - 0.64182	
621	 steps: training loss - 0.61649	, testing loss - 0.64093	
622	 steps: training loss - 0.56712	, testing loss - 0.63990	
623	 steps: training loss - 0.70985	, testing loss - 0.63907	
624	 steps: training loss - 0.62333	, testing loss - 0.63790	
625	 steps: training loss - 0.67545	, testing loss - 0.63661	
626	 steps: training loss - 0.53858	, testing loss - 0.63549	
627	 steps: training loss - 0.53860	, testing loss - 0.63466	
628	 steps: training loss - 0.59097	, testing loss - 0.63427	
629	 steps: training loss - 0.56847	, testing loss - 0.63429	
630	 steps: training loss - 0.57075	, testing loss - 0.63463	
631	 steps: training loss - 0.64477	, testing loss - 0.63483	
632	 steps: training loss - 0.58840	, testing loss - 0.63481	
633	 steps: training loss - 0.54387	, testing loss - 0.63472	
634	 steps: training loss - 0.60378	, testing loss - 0.63481	
635	 steps: training loss - 0.48297	, testing loss - 0.63495	
636	 steps: training loss - 0.59545	, testing loss - 0.63540	
637	 steps: training loss - 0.56885	, testing loss - 0.63614	
638	 steps: training loss - 0.55940	, testing loss - 0.63707	
639	 steps: training loss - 0.61191	, testing loss - 0.63786	
640	 steps: training loss - 0.47732	, testing loss - 0.63846	
641	 steps: training loss - 0.65815	, testing loss - 0.63914	
642	 steps: training loss - 0.60558	, testing loss - 0.63956	
643	 steps: training loss - 0.56838	, testing loss - 0.63961	
644	 steps: training loss - 0.61764	, testing loss - 0.63953	
645	 steps: training loss - 0.58197	, testing loss - 0.63950	
646	 steps: training loss - 0.52552	, testing loss - 0.63971	
647	 steps: training loss - 0.61555	, testing loss - 0.64027	
648	 steps: training loss - 0.54133	, testing loss - 0.64061	
649	 steps: training loss - 0.57506	, testing loss - 0.64113	
650	 steps: training loss - 0.57336	, testing loss - 0.64173	
651	 steps: training loss - 0.60555	, testing loss - 0.64239	
652	 steps: training loss - 0.64113	, testing loss - 0.64309	
653	 steps: training loss - 0.61472	, testing loss - 0.64341	
654	 steps: training loss - 0.62311	, testing loss - 0.64334	
655	 steps: training loss - 0.61746	, testing loss - 0.64321	
656	 steps: training loss - 0.60216	, testing loss - 0.64310	
657	 steps: training loss - 0.60655	, testing loss - 0.64284	
658	 steps: training loss - 0.66757	, testing loss - 0.64240	
659	 steps: training loss - 0.55240	, testing loss - 0.64179	
660	 steps: training loss - 0.56720	, testing loss - 0.64150	
661	 steps: training loss - 0.59275	, testing loss - 0.64150	
662	 steps: training loss - 0.50263	, testing loss - 0.64132	
663	 steps: training loss - 0.55409	, testing loss - 0.64132	
664	 steps: training loss - 0.61648	, testing loss - 0.64160	
665	 steps: training loss - 0.59844	, testing loss - 0.64180	
666	 steps: training loss - 0.55169	, testing loss - 0.64200	
667	 steps: training loss - 0.62948	, testing loss - 0.64221	
668	 steps: training loss - 0.66186	, testing loss - 0.64198	
669	 steps: training loss - 0.53349	, testing loss - 0.64127	
670	 steps: training loss - 0.54184	, testing loss - 0.64083	
671	 steps: training loss - 0.57472	, testing loss - 0.64085	
672	 steps: training loss - 0.57884	, testing loss - 0.64112	
673	 steps: training loss - 0.54026	, testing loss - 0.64141	
674	 steps: training loss - 0.57763	, testing loss - 0.64174	
675	 steps: training loss - 0.62621	, testing loss - 0.64193	
676	 steps: training loss - 0.59079	, testing loss - 0.64198	
677	 steps: training loss - 0.62718	, testing loss - 0.64217	
678	 steps: training loss - 0.66598	, testing loss - 0.64240	
679	 steps: training loss - 0.56093	, testing loss - 0.64230	
680	 steps: training loss - 0.58609	, testing loss - 0.64239	
681	 steps: training loss - 0.56970	, testing loss - 0.64252	
682	 steps: training loss - 0.62814	, testing loss - 0.64252	
683	 steps: training loss - 0.65138	, testing loss - 0.64208	
684	 steps: training loss - 0.57307	, testing loss - 0.64131	
685	 steps: training loss - 0.56727	, testing loss - 0.64069	
686	 steps: training loss - 0.61747	, testing loss - 0.64043	
687	 steps: training loss - 0.65131	, testing loss - 0.64002	
688	 steps: training loss - 0.59373	, testing loss - 0.63930	
689	 steps: training loss - 0.56352	, testing loss - 0.63862	
690	 steps: training loss - 0.56030	, testing loss - 0.63772	
691	 steps: training loss - 0.59128	, testing loss - 0.63680	
692	 steps: training loss - 0.64066	, testing loss - 0.63601	
693	 steps: training loss - 0.59143	, testing loss - 0.63528	
694	 steps: training loss - 0.59488	, testing loss - 0.63453	
695	 steps: training loss - 0.62030	, testing loss - 0.63398	
696	 steps: training loss - 0.59459	, testing loss - 0.63373	
697	 steps: training loss - 0.50849	, testing loss - 0.63373	
698	 steps: training loss - 0.59169	, testing loss - 0.63413	
699	 steps: training loss - 0.58849	, testing loss - 0.63450	
700	 steps: training loss - 0.58015	, testing loss - 0.63476	
701	 steps: training loss - 0.53800	, testing loss - 0.63481	
702	 steps: training loss - 0.62505	, testing loss - 0.63494	
703	 steps: training loss - 0.58204	, testing loss - 0.63487	
704	 steps: training loss - 0.52648	, testing loss - 0.63496	
705	 steps: training loss - 0.59512	, testing loss - 0.63529	
706	 steps: training loss - 0.61538	, testing loss - 0.63551	
707	 steps: training loss - 0.61625	, testing loss - 0.63550	
708	 steps: training loss - 0.55003	, testing loss - 0.63542	
709	 steps: training loss - 0.57488	, testing loss - 0.63546	
710	 steps: training loss - 0.59666	, testing loss - 0.63571	
711	 steps: training loss - 0.50785	, testing loss - 0.63587	
712	 steps: training loss - 0.48385	, testing loss - 0.63633	
713	 steps: training loss - 0.60450	, testing loss - 0.63705	
714	 steps: training loss - 0.54002	, testing loss - 0.63775	
715	 steps: training loss - 0.54765	, testing loss - 0.63833	
716	 steps: training loss - 0.52416	, testing loss - 0.63874	
717	 steps: training loss - 0.54467	, testing loss - 0.63930	
718	 steps: training loss - 0.61244	, testing loss - 0.64006	
719	 steps: training loss - 0.56931	, testing loss - 0.64095	
720	 steps: training loss - 0.54946	, testing loss - 0.64187	
721	 steps: training loss - 0.65439	, testing loss - 0.64245	
722	 steps: training loss - 0.61180	, testing loss - 0.64243	
723	 steps: training loss - 0.60869	, testing loss - 0.64233	
724	 steps: training loss - 0.61423	, testing loss - 0.64216	
725	 steps: training loss - 0.63354	, testing loss - 0.64201	
726	 steps: training loss - 0.63157	, testing loss - 0.64178	
727	 steps: training loss - 0.64874	, testing loss - 0.64123	
728	 steps: training loss - 0.51301	, testing loss - 0.64058	
729	 steps: training loss - 0.61484	, testing loss - 0.64023	
730	 steps: training loss - 0.55784	, testing loss - 0.63965	
731	 steps: training loss - 0.57311	, testing loss - 0.63923	
732	 steps: training loss - 0.65790	, testing loss - 0.63904	
733	 steps: training loss - 0.52860	, testing loss - 0.63836	
734	 steps: training loss - 0.54881	, testing loss - 0.63807	
735	 steps: training loss - 0.56008	, testing loss - 0.63805	
736	 steps: training loss - 0.54580	, testing loss - 0.63786	
737	 steps: training loss - 0.59006	, testing loss - 0.63760	
738	 steps: training loss - 0.59607	, testing loss - 0.63702	
739	 steps: training loss - 0.54648	, testing loss - 0.63664	
740	 steps: training loss - 0.54159	, testing loss - 0.63664	
741	 steps: training loss - 0.57069	, testing loss - 0.63710	
742	 steps: training loss - 0.62757	, testing loss - 0.63768	
743	 steps: training loss - 0.59293	, testing loss - 0.63775	
744	 steps: training loss - 0.59685	, testing loss - 0.63746	
745	 steps: training loss - 0.54884	, testing loss - 0.63702	
746	 steps: training loss - 0.53925	, testing loss - 0.63661	
747	 steps: training loss - 0.61292	, testing loss - 0.63617	
748	 steps: training loss - 0.65868	, testing loss - 0.63589	
749	 steps: training loss - 0.56965	, testing loss - 0.63537	
750	 steps: training loss - 0.55062	, testing loss - 0.63487	
751	 steps: training loss - 0.56918	, testing loss - 0.63441	
752	 steps: training loss - 0.63520	, testing loss - 0.63422	
753	 steps: training loss - 0.54933	, testing loss - 0.63382	
754	 steps: training loss - 0.56788	, testing loss - 0.63345	
755	 steps: training loss - 0.56414	, testing loss - 0.63304	
756	 steps: training loss - 0.54058	, testing loss - 0.63276	
757	 steps: training loss - 0.61487	, testing loss - 0.63252	
758	 steps: training loss - 0.59248	, testing loss - 0.63222	
759	 steps: training loss - 0.54784	, testing loss - 0.63174	
760	 steps: training loss - 0.54974	, testing loss - 0.63147	
761	 steps: training loss - 0.56996	, testing loss - 0.63163	
762	 steps: training loss - 0.48380	, testing loss - 0.63207	
763	 steps: training loss - 0.57782	, testing loss - 0.63292	
764	 steps: training loss - 0.55807	, testing loss - 0.63385	
765	 steps: training loss - 0.66562	, testing loss - 0.63479	
766	 steps: training loss - 0.55126	, testing loss - 0.63528	
767	 steps: training loss - 0.51468	, testing loss - 0.63562	
768	 steps: training loss - 0.60765	, testing loss - 0.63619	
769	 steps: training loss - 0.56030	, testing loss - 0.63647	
770	 steps: training loss - 0.61205	, testing loss - 0.63626	
771	 steps: training loss - 0.55814	, testing loss - 0.63588	
772	 steps: training loss - 0.64168	, testing loss - 0.63553	
773	 steps: training loss - 0.55014	, testing loss - 0.63496	
774	 steps: training loss - 0.50314	, testing loss - 0.63437	
775	 steps: training loss - 0.67167	, testing loss - 0.63392	
776	 steps: training loss - 0.64202	, testing loss - 0.63317	
777	 steps: training loss - 0.60287	, testing loss - 0.63189	
778	 steps: training loss - 0.52103	, testing loss - 0.63052	
779	 steps: training loss - 0.53519	, testing loss - 0.62952	
780	 steps: training loss - 0.58426	, testing loss - 0.62910	
781	 steps: training loss - 0.51809	, testing loss - 0.62905	
782	 steps: training loss - 0.60882	, testing loss - 0.62930	
783	 steps: training loss - 0.59135	, testing loss - 0.62957	
784	 steps: training loss - 0.57875	, testing loss - 0.62974	
785	 steps: training loss - 0.59552	, testing loss - 0.62973	
786	 steps: training loss - 0.51711	, testing loss - 0.62950	
787	 steps: training loss - 0.56073	, testing loss - 0.62954	
788	 steps: training loss - 0.58604	, testing loss - 0.62975	
789	 steps: training loss - 0.51745	, testing loss - 0.62992	
790	 steps: training loss - 0.57442	, testing loss - 0.63038	
791	 steps: training loss - 0.54704	, testing loss - 0.63109	
792	 steps: training loss - 0.53862	, testing loss - 0.63174	
793	 steps: training loss - 0.55533	, testing loss - 0.63236	
794	 steps: training loss - 0.66605	, testing loss - 0.63294	
795	 steps: training loss - 0.68775	, testing loss - 0.63335	
796	 steps: training loss - 0.58254	, testing loss - 0.63296	
797	 steps: training loss - 0.67442	, testing loss - 0.63242	
798	 steps: training loss - 0.55799	, testing loss - 0.63155	
799	 steps: training loss - 0.58390	, testing loss - 0.63079	
800	 steps: training loss - 0.62192	, testing loss - 0.62988	
801	 steps: training loss - 0.48641	, testing loss - 0.62900	
802	 steps: training loss - 0.54381	, testing loss - 0.62867	
803	 steps: training loss - 0.53033	, testing loss - 0.62874	
804	 steps: training loss - 0.64015	, testing loss - 0.62889	
805	 steps: training loss - 0.55001	, testing loss - 0.62854	
806	 steps: training loss - 0.57336	, testing loss - 0.62802	
807	 steps: training loss - 0.53948	, testing loss - 0.62755	
808	 steps: training loss - 0.60099	, testing loss - 0.62749	
809	 steps: training loss - 0.55813	, testing loss - 0.62738	
810	 steps: training loss - 0.55138	, testing loss - 0.62751	
811	 steps: training loss - 0.54040	, testing loss - 0.62770	
812	 steps: training loss - 0.63556	, testing loss - 0.62822	
813	 steps: training loss - 0.60940	, testing loss - 0.62852	
814	 steps: training loss - 0.60229	, testing loss - 0.62859	
815	 steps: training loss - 0.57222	, testing loss - 0.62879	
816	 steps: training loss - 0.55260	, testing loss - 0.62902	
817	 steps: training loss - 0.58720	, testing loss - 0.62911	
818	 steps: training loss - 0.68962	, testing loss - 0.62909	
819	 steps: training loss - 0.57441	, testing loss - 0.62877	
820	 steps: training loss - 0.66280	, testing loss - 0.62819	
821	 steps: training loss - 0.53784	, testing loss - 0.62719	
822	 steps: training loss - 0.53334	, testing loss - 0.62644	
823	 steps: training loss - 0.59393	, testing loss - 0.62624	
824	 steps: training loss - 0.59720	, testing loss - 0.62635	
825	 steps: training loss - 0.53190	, testing loss - 0.62634	
826	 steps: training loss - 0.46539	, testing loss - 0.62667	
827	 steps: training loss - 0.62229	, testing loss - 0.62736	
828	 steps: training loss - 0.65409	, testing loss - 0.62782	
829	 steps: training loss - 0.65172	, testing loss - 0.62794	
830	 steps: training loss - 0.60943	, testing loss - 0.62788	
831	 steps: training loss - 0.56488	, testing loss - 0.62774	
832	 steps: training loss - 0.52557	, testing loss - 0.62762	
833	 steps: training loss - 0.60011	, testing loss - 0.62772	
834	 steps: training loss - 0.63304	, testing loss - 0.62792	
835	 steps: training loss - 0.55849	, testing loss - 0.62773	
836	 steps: training loss - 0.64815	, testing loss - 0.62745	
837	 steps: training loss - 0.62768	, testing loss - 0.62718	
838	 steps: training loss - 0.54150	, testing loss - 0.62691	
839	 steps: training loss - 0.47771	, testing loss - 0.62660	
840	 steps: training loss - 0.58470	, testing loss - 0.62670	
841	 steps: training loss - 0.60888	, testing loss - 0.62645	
842	 steps: training loss - 0.59514	, testing loss - 0.62609	
843	 steps: training loss - 0.63433	, testing loss - 0.62581	
844	 steps: training loss - 0.59024	, testing loss - 0.62543	
845	 steps: training loss - 0.64995	, testing loss - 0.62530	
846	 steps: training loss - 0.59585	, testing loss - 0.62481	
847	 steps: training loss - 0.58980	, testing loss - 0.62427	
848	 steps: training loss - 0.53398	, testing loss - 0.62414	
849	 steps: training loss - 0.58133	, testing loss - 0.62436	
850	 steps: training loss - 0.50891	, testing loss - 0.62460	
851	 steps: training loss - 0.59463	, testing loss - 0.62482	
852	 steps: training loss - 0.56773	, testing loss - 0.62531	
853	 steps: training loss - 0.53180	, testing loss - 0.62566	
854	 steps: training loss - 0.47901	, testing loss - 0.62623	
855	 steps: training loss - 0.50148	, testing loss - 0.62701	
856	 steps: training loss - 0.63086	, testing loss - 0.62783	
857	 steps: training loss - 0.57054	, testing loss - 0.62835	
858	 steps: training loss - 0.59357	, testing loss - 0.62884	
859	 steps: training loss - 0.59265	, testing loss - 0.62903	
860	 steps: training loss - 0.54935	, testing loss - 0.62905	
861	 steps: training loss - 0.50154	, testing loss - 0.62929	
862	 steps: training loss - 0.57740	, testing loss - 0.62982	
863	 steps: training loss - 0.65279	, testing loss - 0.63018	
864	 steps: training loss - 0.64823	, testing loss - 0.62996	
865	 steps: training loss - 0.62844	, testing loss - 0.62934	
866	 steps: training loss - 0.59371	, testing loss - 0.62823	
867	 steps: training loss - 0.60081	, testing loss - 0.62705	
868	 steps: training loss - 0.49466	, testing loss - 0.62592	
869	 steps: training loss - 0.59689	, testing loss - 0.62514	
870	 steps: training loss - 0.59306	, testing loss - 0.62441	
871	 steps: training loss - 0.70229	, testing loss - 0.62374	
872	 steps: training loss - 0.59311	, testing loss - 0.62292	
873	 steps: training loss - 0.49083	, testing loss - 0.62198	
874	 steps: training loss - 0.61050	, testing loss - 0.62119	
875	 steps: training loss - 0.53926	, testing loss - 0.62041	
876	 steps: training loss - 0.53991	, testing loss - 0.61960	
877	 steps: training loss - 0.61239	, testing loss - 0.61902	
878	 steps: training loss - 0.62093	, testing loss - 0.61843	
879	 steps: training loss - 0.56912	, testing loss - 0.61771	
880	 steps: training loss - 0.56530	, testing loss - 0.61717	
881	 steps: training loss - 0.56621	, testing loss - 0.61665	
882	 steps: training loss - 0.59563	, testing loss - 0.61637	
883	 steps: training loss - 0.58425	, testing loss - 0.61622	
884	 steps: training loss - 0.49906	, testing loss - 0.61588	
885	 steps: training loss - 0.60307	, testing loss - 0.61559	
886	 steps: training loss - 0.53243	, testing loss - 0.61542	
887	 steps: training loss - 0.57536	, testing loss - 0.61542	
888	 steps: training loss - 0.47929	, testing loss - 0.61555	
889	 steps: training loss - 0.59887	, testing loss - 0.61605	
890	 steps: training loss - 0.56424	, testing loss - 0.61661	
891	 steps: training loss - 0.64696	, testing loss - 0.61723	
892	 steps: training loss - 0.61003	, testing loss - 0.61767	
893	 steps: training loss - 0.57932	, testing loss - 0.61807	
894	 steps: training loss - 0.51239	, testing loss - 0.61822	
895	 steps: training loss - 0.61743	, testing loss - 0.61866	
896	 steps: training loss - 0.57627	, testing loss - 0.61900	
897	 steps: training loss - 0.55953	, testing loss - 0.61900	
898	 steps: training loss - 0.64746	, testing loss - 0.61900	
899	 steps: training loss - 0.52483	, testing loss - 0.61877	
900	 steps: training loss - 0.53523	, testing loss - 0.61876	
901	 steps: training loss - 0.60463	, testing loss - 0.61901	
902	 steps: training loss - 0.60463	, testing loss - 0.61882	
903	 steps: training loss - 0.62216	, testing loss - 0.61860	
904	 steps: training loss - 0.55002	, testing loss - 0.61825	
905	 steps: training loss - 0.53968	, testing loss - 0.61793	
906	 steps: training loss - 0.48356	, testing loss - 0.61773	
907	 steps: training loss - 0.56108	, testing loss - 0.61803	
908	 steps: training loss - 0.56574	, testing loss - 0.61869	
909	 steps: training loss - 0.58488	, testing loss - 0.61944	
910	 steps: training loss - 0.56410	, testing loss - 0.62003	
911	 steps: training loss - 0.55873	, testing loss - 0.62061	
912	 steps: training loss - 0.55399	, testing loss - 0.62105	
913	 steps: training loss - 0.51887	, testing loss - 0.62122	
914	 steps: training loss - 0.55773	, testing loss - 0.62162	
915	 steps: training loss - 0.49344	, testing loss - 0.62244	
916	 steps: training loss - 0.56208	, testing loss - 0.62341	
917	 steps: training loss - 0.59853	, testing loss - 0.62436	
918	 steps: training loss - 0.56156	, testing loss - 0.62509	
919	 steps: training loss - 0.46610	, testing loss - 0.62595	
920	 steps: training loss - 0.53544	, testing loss - 0.62718	
921	 steps: training loss - 0.53838	, testing loss - 0.62878	
922	 steps: training loss - 0.61499	, testing loss - 0.63044	
923	 steps: training loss - 0.48085	, testing loss - 0.63141	
924	 steps: training loss - 0.70866	, testing loss - 0.63224	
925	 steps: training loss - 0.65226	, testing loss - 0.63252	
926	 steps: training loss - 0.59270	, testing loss - 0.63174	
927	 steps: training loss - 0.54946	, testing loss - 0.63056	
928	 steps: training loss - 0.57764	, testing loss - 0.62992	
929	 steps: training loss - 0.46944	, testing loss - 0.62981	
930	 steps: training loss - 0.56793	, testing loss - 0.62985	
931	 steps: training loss - 0.57956	, testing loss - 0.62984	
932	 steps: training loss - 0.50711	, testing loss - 0.62976	
933	 steps: training loss - 0.44836	, testing loss - 0.62989	
934	 steps: training loss - 0.57705	, testing loss - 0.63023	
935	 steps: training loss - 0.61792	, testing loss - 0.63062	
936	 steps: training loss - 0.54012	, testing loss - 0.63078	
937	 steps: training loss - 0.51738	, testing loss - 0.63126	
938	 steps: training loss - 0.65375	, testing loss - 0.63214	
939	 steps: training loss - 0.52129	, testing loss - 0.63264	
940	 steps: training loss - 0.56792	, testing loss - 0.63307	
941	 steps: training loss - 0.65683	, testing loss - 0.63316	
942	 steps: training loss - 0.58858	, testing loss - 0.63287	
943	 steps: training loss - 0.59124	, testing loss - 0.63250	
944	 steps: training loss - 0.55889	, testing loss - 0.63201	
945	 steps: training loss - 0.64504	, testing loss - 0.63156	
946	 steps: training loss - 0.55558	, testing loss - 0.63103	
947	 steps: training loss - 0.66224	, testing loss - 0.63058	
948	 steps: training loss - 0.61951	, testing loss - 0.62977	
949	 steps: training loss - 0.57751	, testing loss - 0.62892	
950	 steps: training loss - 0.63156	, testing loss - 0.62829	
951	 steps: training loss - 0.45375	, testing loss - 0.62739	
952	 steps: training loss - 0.58131	, testing loss - 0.62700	
953	 steps: training loss - 0.57281	, testing loss - 0.62656	
954	 steps: training loss - 0.60702	, testing loss - 0.62600	
955	 steps: training loss - 0.57454	, testing loss - 0.62531	
956	 steps: training loss - 0.61408	, testing loss - 0.62495	
957	 steps: training loss - 0.68112	, testing loss - 0.62465	
958	 steps: training loss - 0.57157	, testing loss - 0.62379	
959	 steps: training loss - 0.47151	, testing loss - 0.62252	
960	 steps: training loss - 0.55591	, testing loss - 0.62220	
961	 steps: training loss - 0.61600	, testing loss - 0.62223	
962	 steps: training loss - 0.59925	, testing loss - 0.62207	
963	 steps: training loss - 0.68873	, testing loss - 0.62167	
964	 steps: training loss - 0.53404	, testing loss - 0.62073	
965	 steps: training loss - 0.61738	, testing loss - 0.61986	
966	 steps: training loss - 0.61118	, testing loss - 0.61917	
967	 steps: training loss - 0.56501	, testing loss - 0.61861	
968	 steps: training loss - 0.64125	, testing loss - 0.61830	
969	 steps: training loss - 0.52163	, testing loss - 0.61784	
970	 steps: training loss - 0.59453	, testing loss - 0.61780	
971	 steps: training loss - 0.59890	, testing loss - 0.61785	
972	 steps: training loss - 0.48675	, testing loss - 0.61759	
973	 steps: training loss - 0.59476	, testing loss - 0.61769	
974	 steps: training loss - 0.57530	, testing loss - 0.61797	
975	 steps: training loss - 0.57639	, testing loss - 0.61827	
976	 steps: training loss - 0.57595	, testing loss - 0.61825	
977	 steps: training loss - 0.57831	, testing loss - 0.61838	
978	 steps: training loss - 0.57056	, testing loss - 0.61845	
979	 steps: training loss - 0.52847	, testing loss - 0.61858	
980	 steps: training loss - 0.60633	, testing loss - 0.61873	
981	 steps: training loss - 0.56310	, testing loss - 0.61850	
982	 steps: training loss - 0.61976	, testing loss - 0.61815	
983	 steps: training loss - 0.65815	, testing loss - 0.61743	
984	 steps: training loss - 0.60217	, testing loss - 0.61639	
985	 steps: training loss - 0.64996	, testing loss - 0.61523	
986	 steps: training loss - 0.53644	, testing loss - 0.61391	
987	 steps: training loss - 0.56557	, testing loss - 0.61296	
988	 steps: training loss - 0.49468	, testing loss - 0.61227	
989	 steps: training loss - 0.58040	, testing loss - 0.61191	
990	 steps: training loss - 0.56533	, testing loss - 0.61176	
991	 steps: training loss - 0.65718	, testing loss - 0.61200	
992	 steps: training loss - 0.57354	, testing loss - 0.61170	
993	 steps: training loss - 0.57674	, testing loss - 0.61144	
994	 steps: training loss - 0.52959	, testing loss - 0.61132	
995	 steps: training loss - 0.53967	, testing loss - 0.61149	
996	 steps: training loss - 0.55552	, testing loss - 0.61162	
997	 steps: training loss - 0.63066	, testing loss - 0.61144	
998	 steps: training loss - 0.56176	, testing loss - 0.61097	
999	 steps: training loss - 0.59506	, testing loss - 0.61077	
EVALUATION
----------
Test loss: 0.73881
MIMO Accuracies: 0.78955

LOOCV TRAINING INFO - is_lstm? True
LOOCV? -  True
-------------
TRAINING USERS -  ['a', 'b', 'c', 'e', 'g', 'h']
LEFT OUT -  i
-------------
actions ['bike', 'sit']
devices ['samsungold_1', 'samsungold_2']
step size 10
num_epochs 1000
batch size 12
feature size (x,y,z) 3
hidden size 20
number recurrent layers 2
number of classes 2
writing pickle to run9_model.p
writing accuracy + pickle to acc_run9_model.p
------------------------------------------------
0	 steps: training loss - 0.69963	, testing loss - 0.70599	
1	 steps: training loss - 0.69759	, testing loss - 0.70410	
2	 steps: training loss - 0.69617	, testing loss - 0.70223	
3	 steps: training loss - 0.69280	, testing loss - 0.70050	
4	 steps: training loss - 0.69310	, testing loss - 0.69904	
5	 steps: training loss - 0.69115	, testing loss - 0.69761	
6	 steps: training loss - 0.69175	, testing loss - 0.69630	
7	 steps: training loss - 0.69108	, testing loss - 0.69489	
8	 steps: training loss - 0.68945	, testing loss - 0.69352	
9	 steps: training loss - 0.68882	, testing loss - 0.69219	
10	 steps: training loss - 0.69013	, testing loss - 0.69114	
11	 steps: training loss - 0.68868	, testing loss - 0.68998	
12	 steps: training loss - 0.68733	, testing loss - 0.68879	
13	 steps: training loss - 0.68998	, testing loss - 0.68768	
14	 steps: training loss - 0.68399	, testing loss - 0.68642	
15	 steps: training loss - 0.68861	, testing loss - 0.68522	
16	 steps: training loss - 0.68543	, testing loss - 0.68437	
17	 steps: training loss - 0.68632	, testing loss - 0.68347	
18	 steps: training loss - 0.68290	, testing loss - 0.68239	
19	 steps: training loss - 0.69044	, testing loss - 0.68111	
20	 steps: training loss - 0.68683	, testing loss - 0.67993	
21	 steps: training loss - 0.67637	, testing loss - 0.67888	
22	 steps: training loss - 0.67950	, testing loss - 0.67769	
23	 steps: training loss - 0.68926	, testing loss - 0.67640	
24	 steps: training loss - 0.69027	, testing loss - 0.67525	
25	 steps: training loss - 0.67742	, testing loss - 0.67423	
26	 steps: training loss - 0.68172	, testing loss - 0.67311	
27	 steps: training loss - 0.68468	, testing loss - 0.67197	
28	 steps: training loss - 0.67160	, testing loss - 0.67095	
29	 steps: training loss - 0.67278	, testing loss - 0.66980	
30	 steps: training loss - 0.67493	, testing loss - 0.66855	
31	 steps: training loss - 0.67585	, testing loss - 0.66722	
32	 steps: training loss - 0.67541	, testing loss - 0.66592	
33	 steps: training loss - 0.67742	, testing loss - 0.66470	
34	 steps: training loss - 0.67540	, testing loss - 0.66355	
35	 steps: training loss - 0.66403	, testing loss - 0.66242	
36	 steps: training loss - 0.67151	, testing loss - 0.66121	
37	 steps: training loss - 0.67723	, testing loss - 0.66001	
38	 steps: training loss - 0.67340	, testing loss - 0.65888	
39	 steps: training loss - 0.67517	, testing loss - 0.65775	
40	 steps: training loss - 0.67574	, testing loss - 0.65671	
41	 steps: training loss - 0.68411	, testing loss - 0.65573	
42	 steps: training loss - 0.65532	, testing loss - 0.65490	
43	 steps: training loss - 0.68507	, testing loss - 0.65401	
44	 steps: training loss - 0.67560	, testing loss - 0.65317	
45	 steps: training loss - 0.68113	, testing loss - 0.65234	
46	 steps: training loss - 0.66627	, testing loss - 0.65158	
47	 steps: training loss - 0.66346	, testing loss - 0.65081	
48	 steps: training loss - 0.65899	, testing loss - 0.64996	
49	 steps: training loss - 0.66959	, testing loss - 0.64902	
50	 steps: training loss - 0.66205	, testing loss - 0.64805	
51	 steps: training loss - 0.68907	, testing loss - 0.64708	
52	 steps: training loss - 0.68418	, testing loss - 0.64621	
53	 steps: training loss - 0.65807	, testing loss - 0.64549	
54	 steps: training loss - 0.69397	, testing loss - 0.64474	
55	 steps: training loss - 0.66380	, testing loss - 0.64411	
56	 steps: training loss - 0.68676	, testing loss - 0.64345	
57	 steps: training loss - 0.66288	, testing loss - 0.64286	
58	 steps: training loss - 0.64491	, testing loss - 0.64221	
59	 steps: training loss - 0.67926	, testing loss - 0.64137	
60	 steps: training loss - 0.65191	, testing loss - 0.64058	
61	 steps: training loss - 0.67769	, testing loss - 0.63974	
62	 steps: training loss - 0.67271	, testing loss - 0.63897	
63	 steps: training loss - 0.64392	, testing loss - 0.63828	
64	 steps: training loss - 0.68619	, testing loss - 0.63746	
65	 steps: training loss - 0.66499	, testing loss - 0.63669	
66	 steps: training loss - 0.66369	, testing loss - 0.63591	
67	 steps: training loss - 0.66868	, testing loss - 0.63513	
68	 steps: training loss - 0.66164	, testing loss - 0.63435	
69	 steps: training loss - 0.62422	, testing loss - 0.63352	
70	 steps: training loss - 0.64759	, testing loss - 0.63247	
71	 steps: training loss - 0.65447	, testing loss - 0.63135	
72	 steps: training loss - 0.67115	, testing loss - 0.63023	
73	 steps: training loss - 0.66884	, testing loss - 0.62918	
74	 steps: training loss - 0.67377	, testing loss - 0.62821	
75	 steps: training loss - 0.63237	, testing loss - 0.62729	
76	 steps: training loss - 0.67965	, testing loss - 0.62632	
77	 steps: training loss - 0.68079	, testing loss - 0.62543	
78	 steps: training loss - 0.66242	, testing loss - 0.62465	
79	 steps: training loss - 0.66458	, testing loss - 0.62392	
80	 steps: training loss - 0.63207	, testing loss - 0.62319	
81	 steps: training loss - 0.65837	, testing loss - 0.62236	
82	 steps: training loss - 0.64704	, testing loss - 0.62150	
83	 steps: training loss - 0.65068	, testing loss - 0.62064	
84	 steps: training loss - 0.61614	, testing loss - 0.61977	
85	 steps: training loss - 0.61957	, testing loss - 0.61873	
86	 steps: training loss - 0.62460	, testing loss - 0.61757	
87	 steps: training loss - 0.64573	, testing loss - 0.61636	
88	 steps: training loss - 0.66780	, testing loss - 0.61521	
89	 steps: training loss - 0.64471	, testing loss - 0.61420	
90	 steps: training loss - 0.67936	, testing loss - 0.61322	
91	 steps: training loss - 0.63781	, testing loss - 0.61230	
92	 steps: training loss - 0.62632	, testing loss - 0.61137	
93	 steps: training loss - 0.63848	, testing loss - 0.61043	
94	 steps: training loss - 0.67268	, testing loss - 0.60947	
95	 steps: training loss - 0.66126	, testing loss - 0.60860	
96	 steps: training loss - 0.62800	, testing loss - 0.60778	
97	 steps: training loss - 0.70136	, testing loss - 0.60692	
98	 steps: training loss - 0.61798	, testing loss - 0.60616	
99	 steps: training loss - 0.65474	, testing loss - 0.60536	
100	 steps: training loss - 0.63752	, testing loss - 0.60459	
101	 steps: training loss - 0.62385	, testing loss - 0.60384	
102	 steps: training loss - 0.67336	, testing loss - 0.60302	
103	 steps: training loss - 0.64004	, testing loss - 0.60229	
104	 steps: training loss - 0.63592	, testing loss - 0.60154	
105	 steps: training loss - 0.59695	, testing loss - 0.60074	
106	 steps: training loss - 0.63672	, testing loss - 0.59988	
107	 steps: training loss - 0.61094	, testing loss - 0.59894	
108	 steps: training loss - 0.65980	, testing loss - 0.59796	
109	 steps: training loss - 0.62228	, testing loss - 0.59707	
110	 steps: training loss - 0.67654	, testing loss - 0.59617	
111	 steps: training loss - 0.63528	, testing loss - 0.59541	
112	 steps: training loss - 0.62212	, testing loss - 0.59474	
113	 steps: training loss - 0.64897	, testing loss - 0.59399	
114	 steps: training loss - 0.66979	, testing loss - 0.59324	
115	 steps: training loss - 0.70192	, testing loss - 0.59256	
116	 steps: training loss - 0.61953	, testing loss - 0.59197	
117	 steps: training loss - 0.67534	, testing loss - 0.59135	
118	 steps: training loss - 0.65261	, testing loss - 0.59075	
119	 steps: training loss - 0.62688	, testing loss - 0.59018	
120	 steps: training loss - 0.63092	, testing loss - 0.58960	
121	 steps: training loss - 0.65013	, testing loss - 0.58897	
122	 steps: training loss - 0.62766	, testing loss - 0.58837	
123	 steps: training loss - 0.62372	, testing loss - 0.58775	
124	 steps: training loss - 0.62963	, testing loss - 0.58707	
125	 steps: training loss - 0.62556	, testing loss - 0.58636	
126	 steps: training loss - 0.64764	, testing loss - 0.58563	
127	 steps: training loss - 0.64258	, testing loss - 0.58490	
128	 steps: training loss - 0.64387	, testing loss - 0.58419	
129	 steps: training loss - 0.65132	, testing loss - 0.58355	
130	 steps: training loss - 0.59507	, testing loss - 0.58296	
131	 steps: training loss - 0.60329	, testing loss - 0.58227	
132	 steps: training loss - 0.58688	, testing loss - 0.58147	
133	 steps: training loss - 0.59151	, testing loss - 0.58062	
134	 steps: training loss - 0.62884	, testing loss - 0.57969	
135	 steps: training loss - 0.61345	, testing loss - 0.57881	
136	 steps: training loss - 0.62298	, testing loss - 0.57797	
137	 steps: training loss - 0.64194	, testing loss - 0.57714	
138	 steps: training loss - 0.62851	, testing loss - 0.57631	
139	 steps: training loss - 0.66634	, testing loss - 0.57548	
140	 steps: training loss - 0.61012	, testing loss - 0.57469	
141	 steps: training loss - 0.68314	, testing loss - 0.57391	
142	 steps: training loss - 0.61585	, testing loss - 0.57324	
143	 steps: training loss - 0.65443	, testing loss - 0.57261	
144	 steps: training loss - 0.64465	, testing loss - 0.57207	
145	 steps: training loss - 0.64915	, testing loss - 0.57156	
146	 steps: training loss - 0.65372	, testing loss - 0.57103	
147	 steps: training loss - 0.62779	, testing loss - 0.57051	
148	 steps: training loss - 0.62387	, testing loss - 0.56995	
149	 steps: training loss - 0.62547	, testing loss - 0.56930	
150	 steps: training loss - 0.64090	, testing loss - 0.56863	
151	 steps: training loss - 0.57385	, testing loss - 0.56799	
152	 steps: training loss - 0.64928	, testing loss - 0.56727	
153	 steps: training loss - 0.67142	, testing loss - 0.56655	
154	 steps: training loss - 0.65861	, testing loss - 0.56595	
155	 steps: training loss - 0.59419	, testing loss - 0.56540	
156	 steps: training loss - 0.62017	, testing loss - 0.56474	
157	 steps: training loss - 0.62713	, testing loss - 0.56396	
158	 steps: training loss - 0.65108	, testing loss - 0.56317	
159	 steps: training loss - 0.62367	, testing loss - 0.56248	
160	 steps: training loss - 0.58717	, testing loss - 0.56181	
161	 steps: training loss - 0.57292	, testing loss - 0.56109	
162	 steps: training loss - 0.59888	, testing loss - 0.56030	
163	 steps: training loss - 0.65344	, testing loss - 0.55947	
164	 steps: training loss - 0.65173	, testing loss - 0.55874	
165	 steps: training loss - 0.63400	, testing loss - 0.55809	
166	 steps: training loss - 0.68190	, testing loss - 0.55747	
167	 steps: training loss - 0.65139	, testing loss - 0.55691	
168	 steps: training loss - 0.62011	, testing loss - 0.55640	
169	 steps: training loss - 0.59400	, testing loss - 0.55589	
170	 steps: training loss - 0.59645	, testing loss - 0.55532	
171	 steps: training loss - 0.62051	, testing loss - 0.55469	
172	 steps: training loss - 0.62940	, testing loss - 0.55403	
173	 steps: training loss - 0.61850	, testing loss - 0.55336	
174	 steps: training loss - 0.58031	, testing loss - 0.55271	
175	 steps: training loss - 0.59413	, testing loss - 0.55198	
176	 steps: training loss - 0.65414	, testing loss - 0.55118	
177	 steps: training loss - 0.59250	, testing loss - 0.55048	
178	 steps: training loss - 0.59174	, testing loss - 0.54977	
179	 steps: training loss - 0.59653	, testing loss - 0.54899	
180	 steps: training loss - 0.57774	, testing loss - 0.54816	
181	 steps: training loss - 0.63531	, testing loss - 0.54729	
182	 steps: training loss - 0.59431	, testing loss - 0.54646	
183	 steps: training loss - 0.56948	, testing loss - 0.54565	
184	 steps: training loss - 0.54374	, testing loss - 0.54479	
185	 steps: training loss - 0.69238	, testing loss - 0.54381	
186	 steps: training loss - 0.64146	, testing loss - 0.54301	
187	 steps: training loss - 0.64896	, testing loss - 0.54237	
188	 steps: training loss - 0.61467	, testing loss - 0.54178	
189	 steps: training loss - 0.57981	, testing loss - 0.54117	
190	 steps: training loss - 0.60053	, testing loss - 0.54051	
191	 steps: training loss - 0.64970	, testing loss - 0.53980	
192	 steps: training loss - 0.71376	, testing loss - 0.53911	
193	 steps: training loss - 0.65715	, testing loss - 0.53860	
194	 steps: training loss - 0.61683	, testing loss - 0.53819	
195	 steps: training loss - 0.66351	, testing loss - 0.53775	
196	 steps: training loss - 0.56150	, testing loss - 0.53739	
197	 steps: training loss - 0.67797	, testing loss - 0.53693	
198	 steps: training loss - 0.59210	, testing loss - 0.53653	
199	 steps: training loss - 0.59742	, testing loss - 0.53608	
200	 steps: training loss - 0.60186	, testing loss - 0.53553	
201	 steps: training loss - 0.69602	, testing loss - 0.53497	
202	 steps: training loss - 0.66845	, testing loss - 0.53459	
203	 steps: training loss - 0.58219	, testing loss - 0.53435	
204	 steps: training loss - 0.62199	, testing loss - 0.53400	
205	 steps: training loss - 0.65643	, testing loss - 0.53361	
206	 steps: training loss - 0.58697	, testing loss - 0.53330	
207	 steps: training loss - 0.52158	, testing loss - 0.53293	
208	 steps: training loss - 0.61538	, testing loss - 0.53225	
209	 steps: training loss - 0.61150	, testing loss - 0.53151	
210	 steps: training loss - 0.67234	, testing loss - 0.53081	
211	 steps: training loss - 0.58625	, testing loss - 0.53022	
212	 steps: training loss - 0.60314	, testing loss - 0.52958	
213	 steps: training loss - 0.60427	, testing loss - 0.52885	
214	 steps: training loss - 0.57759	, testing loss - 0.52812	
215	 steps: training loss - 0.59842	, testing loss - 0.52734	
216	 steps: training loss - 0.68144	, testing loss - 0.52656	
217	 steps: training loss - 0.62345	, testing loss - 0.52596	
218	 steps: training loss - 0.64208	, testing loss - 0.52545	
219	 steps: training loss - 0.57480	, testing loss - 0.52502	
220	 steps: training loss - 0.59522	, testing loss - 0.52450	
221	 steps: training loss - 0.60345	, testing loss - 0.52394	
222	 steps: training loss - 0.63328	, testing loss - 0.52335	
223	 steps: training loss - 0.56379	, testing loss - 0.52278	
224	 steps: training loss - 0.60018	, testing loss - 0.52214	
225	 steps: training loss - 0.52294	, testing loss - 0.52146	
226	 steps: training loss - 0.57250	, testing loss - 0.52067	
227	 steps: training loss - 0.63185	, testing loss - 0.51984	
228	 steps: training loss - 0.62304	, testing loss - 0.51910	
229	 steps: training loss - 0.56996	, testing loss - 0.51843	
230	 steps: training loss - 0.58089	, testing loss - 0.51771	
231	 steps: training loss - 0.60031	, testing loss - 0.51696	
232	 steps: training loss - 0.60464	, testing loss - 0.51623	
233	 steps: training loss - 0.59584	, testing loss - 0.51558	
234	 steps: training loss - 0.62174	, testing loss - 0.51496	
235	 steps: training loss - 0.58452	, testing loss - 0.51441	
236	 steps: training loss - 0.60119	, testing loss - 0.51384	
237	 steps: training loss - 0.64434	, testing loss - 0.51325	
238	 steps: training loss - 0.64382	, testing loss - 0.51273	
239	 steps: training loss - 0.58733	, testing loss - 0.51229	
240	 steps: training loss - 0.60367	, testing loss - 0.51183	
241	 steps: training loss - 0.64952	, testing loss - 0.51136	
242	 steps: training loss - 0.57721	, testing loss - 0.51095	
243	 steps: training loss - 0.55973	, testing loss - 0.51051	
244	 steps: training loss - 0.61760	, testing loss - 0.50998	
245	 steps: training loss - 0.57217	, testing loss - 0.50947	
246	 steps: training loss - 0.53920	, testing loss - 0.50894	
247	 steps: training loss - 0.63506	, testing loss - 0.50832	
248	 steps: training loss - 0.57013	, testing loss - 0.50774	
249	 steps: training loss - 0.53117	, testing loss - 0.50712	
250	 steps: training loss - 0.60042	, testing loss - 0.50641	
251	 steps: training loss - 0.56010	, testing loss - 0.50571	
252	 steps: training loss - 0.59929	, testing loss - 0.50501	
253	 steps: training loss - 0.57644	, testing loss - 0.50430	
254	 steps: training loss - 0.61104	, testing loss - 0.50357	
255	 steps: training loss - 0.61955	, testing loss - 0.50290	
256	 steps: training loss - 0.59012	, testing loss - 0.50231	
257	 steps: training loss - 0.69433	, testing loss - 0.50173	
258	 steps: training loss - 0.55552	, testing loss - 0.50129	
259	 steps: training loss - 0.59927	, testing loss - 0.50081	
260	 steps: training loss - 0.58979	, testing loss - 0.50029	
261	 steps: training loss - 0.56901	, testing loss - 0.49976	
262	 steps: training loss - 0.58209	, testing loss - 0.49919	
263	 steps: training loss - 0.59509	, testing loss - 0.49863	
264	 steps: training loss - 0.55363	, testing loss - 0.49807	
265	 steps: training loss - 0.60567	, testing loss - 0.49746	
266	 steps: training loss - 0.58299	, testing loss - 0.49687	
267	 steps: training loss - 0.61463	, testing loss - 0.49626	
268	 steps: training loss - 0.69189	, testing loss - 0.49570	
269	 steps: training loss - 0.60653	, testing loss - 0.49531	
270	 steps: training loss - 0.52246	, testing loss - 0.49494	
271	 steps: training loss - 0.63631	, testing loss - 0.49446	
272	 steps: training loss - 0.61180	, testing loss - 0.49400	
273	 steps: training loss - 0.61101	, testing loss - 0.49356	
274	 steps: training loss - 0.56472	, testing loss - 0.49316	
275	 steps: training loss - 0.66368	, testing loss - 0.49273	
276	 steps: training loss - 0.60338	, testing loss - 0.49237	
277	 steps: training loss - 0.56743	, testing loss - 0.49201	
278	 steps: training loss - 0.60369	, testing loss - 0.49160	
279	 steps: training loss - 0.56078	, testing loss - 0.49118	
280	 steps: training loss - 0.58377	, testing loss - 0.49070	
281	 steps: training loss - 0.57864	, testing loss - 0.49019	
282	 steps: training loss - 0.59781	, testing loss - 0.48969	
283	 steps: training loss - 0.63129	, testing loss - 0.48921	
284	 steps: training loss - 0.63862	, testing loss - 0.48876	
285	 steps: training loss - 0.61998	, testing loss - 0.48836	
286	 steps: training loss - 0.57358	, testing loss - 0.48801	
287	 steps: training loss - 0.62328	, testing loss - 0.48765	
288	 steps: training loss - 0.63599	, testing loss - 0.48728	
289	 steps: training loss - 0.58708	, testing loss - 0.48700	
290	 steps: training loss - 0.58245	, testing loss - 0.48669	
291	 steps: training loss - 0.57731	, testing loss - 0.48631	
292	 steps: training loss - 0.52744	, testing loss - 0.48591	
293	 steps: training loss - 0.61937	, testing loss - 0.48539	
294	 steps: training loss - 0.61626	, testing loss - 0.48488	
295	 steps: training loss - 0.60207	, testing loss - 0.48445	
296	 steps: training loss - 0.58057	, testing loss - 0.48405	
297	 steps: training loss - 0.67327	, testing loss - 0.48364	
298	 steps: training loss - 0.58964	, testing loss - 0.48336	
299	 steps: training loss - 0.59158	, testing loss - 0.48312	
300	 steps: training loss - 0.53318	, testing loss - 0.48284	
301	 steps: training loss - 0.61516	, testing loss - 0.48244	
302	 steps: training loss - 0.62918	, testing loss - 0.48206	
303	 steps: training loss - 0.53199	, testing loss - 0.48172	
304	 steps: training loss - 0.64527	, testing loss - 0.48128	
305	 steps: training loss - 0.60764	, testing loss - 0.48088	
306	 steps: training loss - 0.59056	, testing loss - 0.48053	
307	 steps: training loss - 0.52571	, testing loss - 0.48018	
308	 steps: training loss - 0.58506	, testing loss - 0.47975	
309	 steps: training loss - 0.68583	, testing loss - 0.47926	
310	 steps: training loss - 0.62748	, testing loss - 0.47892	
311	 steps: training loss - 0.63188	, testing loss - 0.47866	
312	 steps: training loss - 0.61490	, testing loss - 0.47847	
313	 steps: training loss - 0.58498	, testing loss - 0.47830	
314	 steps: training loss - 0.55899	, testing loss - 0.47806	
315	 steps: training loss - 0.59280	, testing loss - 0.47772	
316	 steps: training loss - 0.62242	, testing loss - 0.47736	
317	 steps: training loss - 0.50411	, testing loss - 0.47703	
318	 steps: training loss - 0.63037	, testing loss - 0.47657	
319	 steps: training loss - 0.60165	, testing loss - 0.47615	
320	 steps: training loss - 0.52468	, testing loss - 0.47580	
321	 steps: training loss - 0.55916	, testing loss - 0.47539	
322	 steps: training loss - 0.54094	, testing loss - 0.47494	
323	 steps: training loss - 0.64126	, testing loss - 0.47441	
324	 steps: training loss - 0.62798	, testing loss - 0.47394	
325	 steps: training loss - 0.53594	, testing loss - 0.47357	
326	 steps: training loss - 0.55970	, testing loss - 0.47312	
327	 steps: training loss - 0.58097	, testing loss - 0.47261	
328	 steps: training loss - 0.57732	, testing loss - 0.47212	
329	 steps: training loss - 0.60771	, testing loss - 0.47161	
330	 steps: training loss - 0.53411	, testing loss - 0.47113	
331	 steps: training loss - 0.60167	, testing loss - 0.47056	
332	 steps: training loss - 0.61972	, testing loss - 0.47001	
333	 steps: training loss - 0.60156	, testing loss - 0.46953	
334	 steps: training loss - 0.58576	, testing loss - 0.46908	
335	 steps: training loss - 0.57045	, testing loss - 0.46862	
336	 steps: training loss - 0.63268	, testing loss - 0.46820	
337	 steps: training loss - 0.53381	, testing loss - 0.46791	
338	 steps: training loss - 0.63697	, testing loss - 0.46756	
339	 steps: training loss - 0.59624	, testing loss - 0.46727	
340	 steps: training loss - 0.61940	, testing loss - 0.46696	
341	 steps: training loss - 0.54406	, testing loss - 0.46673	
342	 steps: training loss - 0.58250	, testing loss - 0.46645	
343	 steps: training loss - 0.58575	, testing loss - 0.46615	
344	 steps: training loss - 0.60673	, testing loss - 0.46590	
345	 steps: training loss - 0.58658	, testing loss - 0.46571	
346	 steps: training loss - 0.63295	, testing loss - 0.46549	
347	 steps: training loss - 0.59676	, testing loss - 0.46542	
348	 steps: training loss - 0.66286	, testing loss - 0.46533	
349	 steps: training loss - 0.63112	, testing loss - 0.46531	
350	 steps: training loss - 0.59882	, testing loss - 0.46535	
351	 steps: training loss - 0.52535	, testing loss - 0.46532	
352	 steps: training loss - 0.68704	, testing loss - 0.46511	
353	 steps: training loss - 0.61527	, testing loss - 0.46498	
354	 steps: training loss - 0.55242	, testing loss - 0.46491	
355	 steps: training loss - 0.61648	, testing loss - 0.46475	
356	 steps: training loss - 0.54320	, testing loss - 0.46458	
357	 steps: training loss - 0.59210	, testing loss - 0.46427	
358	 steps: training loss - 0.65194	, testing loss - 0.46395	
359	 steps: training loss - 0.57978	, testing loss - 0.46368	
360	 steps: training loss - 0.64953	, testing loss - 0.46339	
361	 steps: training loss - 0.55180	, testing loss - 0.46318	
362	 steps: training loss - 0.50529	, testing loss - 0.46288	
363	 steps: training loss - 0.63787	, testing loss - 0.46241	
364	 steps: training loss - 0.54507	, testing loss - 0.46205	
365	 steps: training loss - 0.66846	, testing loss - 0.46173	
366	 steps: training loss - 0.59168	, testing loss - 0.46160	
367	 steps: training loss - 0.56206	, testing loss - 0.46151	
368	 steps: training loss - 0.66787	, testing loss - 0.46130	
369	 steps: training loss - 0.59204	, testing loss - 0.46108	
370	 steps: training loss - 0.69037	, testing loss - 0.46088	
371	 steps: training loss - 0.57764	, testing loss - 0.46084	
372	 steps: training loss - 0.55139	, testing loss - 0.46073	
373	 steps: training loss - 0.52742	, testing loss - 0.46053	
374	 steps: training loss - 0.62190	, testing loss - 0.46018	
375	 steps: training loss - 0.50452	, testing loss - 0.45986	
376	 steps: training loss - 0.53527	, testing loss - 0.45937	
377	 steps: training loss - 0.55107	, testing loss - 0.45877	
378	 steps: training loss - 0.62649	, testing loss - 0.45817	
379	 steps: training loss - 0.57894	, testing loss - 0.45770	
380	 steps: training loss - 0.66000	, testing loss - 0.45727	
381	 steps: training loss - 0.68652	, testing loss - 0.45704	
382	 steps: training loss - 0.65381	, testing loss - 0.45696	
383	 steps: training loss - 0.60998	, testing loss - 0.45702	
384	 steps: training loss - 0.58732	, testing loss - 0.45716	
385	 steps: training loss - 0.65326	, testing loss - 0.45719	
386	 steps: training loss - 0.54190	, testing loss - 0.45714	
387	 steps: training loss - 0.51406	, testing loss - 0.45698	
388	 steps: training loss - 0.59335	, testing loss - 0.45661	
389	 steps: training loss - 0.58550	, testing loss - 0.45610	
390	 steps: training loss - 0.59324	, testing loss - 0.45556	
391	 steps: training loss - 0.62135	, testing loss - 0.45510	
392	 steps: training loss - 0.61071	, testing loss - 0.45465	
393	 steps: training loss - 0.59141	, testing loss - 0.45418	
394	 steps: training loss - 0.60011	, testing loss - 0.45373	
395	 steps: training loss - 0.62691	, testing loss - 0.45335	
396	 steps: training loss - 0.62529	, testing loss - 0.45302	
397	 steps: training loss - 0.58941	, testing loss - 0.45270	
398	 steps: training loss - 0.58782	, testing loss - 0.45245	
399	 steps: training loss - 0.62855	, testing loss - 0.45215	
400	 steps: training loss - 0.56287	, testing loss - 0.45186	
401	 steps: training loss - 0.55455	, testing loss - 0.45160	
402	 steps: training loss - 0.48887	, testing loss - 0.45127	
403	 steps: training loss - 0.57996	, testing loss - 0.45075	
404	 steps: training loss - 0.55992	, testing loss - 0.45025	
405	 steps: training loss - 0.61710	, testing loss - 0.44972	
406	 steps: training loss - 0.53832	, testing loss - 0.44940	
407	 steps: training loss - 0.50198	, testing loss - 0.44905	
408	 steps: training loss - 0.58266	, testing loss - 0.44849	
409	 steps: training loss - 0.56399	, testing loss - 0.44789	
410	 steps: training loss - 0.52189	, testing loss - 0.44733	
411	 steps: training loss - 0.57978	, testing loss - 0.44673	
412	 steps: training loss - 0.55438	, testing loss - 0.44619	
413	 steps: training loss - 0.63392	, testing loss - 0.44564	
414	 steps: training loss - 0.55325	, testing loss - 0.44519	
415	 steps: training loss - 0.53573	, testing loss - 0.44479	
416	 steps: training loss - 0.67480	, testing loss - 0.44427	
417	 steps: training loss - 0.66259	, testing loss - 0.44394	
418	 steps: training loss - 0.52581	, testing loss - 0.44372	
419	 steps: training loss - 0.63508	, testing loss - 0.44343	
420	 steps: training loss - 0.52683	, testing loss - 0.44324	
421	 steps: training loss - 0.59357	, testing loss - 0.44298	
422	 steps: training loss - 0.57030	, testing loss - 0.44276	
423	 steps: training loss - 0.57805	, testing loss - 0.44248	
424	 steps: training loss - 0.54965	, testing loss - 0.44215	
425	 steps: training loss - 0.60864	, testing loss - 0.44186	
426	 steps: training loss - 0.60222	, testing loss - 0.44168	
427	 steps: training loss - 0.51191	, testing loss - 0.44152	
428	 steps: training loss - 0.62980	, testing loss - 0.44130	
429	 steps: training loss - 0.56679	, testing loss - 0.44114	
430	 steps: training loss - 0.61685	, testing loss - 0.44094	
431	 steps: training loss - 0.66636	, testing loss - 0.44082	
432	 steps: training loss - 0.52861	, testing loss - 0.44085	
433	 steps: training loss - 0.51835	, testing loss - 0.44073	
434	 steps: training loss - 0.51521	, testing loss - 0.44061	
435	 steps: training loss - 0.55245	, testing loss - 0.44040	
436	 steps: training loss - 0.55025	, testing loss - 0.44012	
437	 steps: training loss - 0.58424	, testing loss - 0.43976	
438	 steps: training loss - 0.52847	, testing loss - 0.43952	
439	 steps: training loss - 0.53392	, testing loss - 0.43923	
440	 steps: training loss - 0.50991	, testing loss - 0.43888	
441	 steps: training loss - 0.57633	, testing loss - 0.43844	
442	 steps: training loss - 0.54349	, testing loss - 0.43794	
443	 steps: training loss - 0.58553	, testing loss - 0.43729	
444	 steps: training loss - 0.62198	, testing loss - 0.43664	
445	 steps: training loss - 0.59458	, testing loss - 0.43613	
446	 steps: training loss - 0.53794	, testing loss - 0.43578	
447	 steps: training loss - 0.55441	, testing loss - 0.43537	
448	 steps: training loss - 0.52040	, testing loss - 0.43492	
449	 steps: training loss - 0.60560	, testing loss - 0.43434	
450	 steps: training loss - 0.57458	, testing loss - 0.43376	
451	 steps: training loss - 0.62893	, testing loss - 0.43322	
452	 steps: training loss - 0.61117	, testing loss - 0.43279	
453	 steps: training loss - 0.55143	, testing loss - 0.43240	
454	 steps: training loss - 0.58986	, testing loss - 0.43198	
455	 steps: training loss - 0.55297	, testing loss - 0.43165	
456	 steps: training loss - 0.60311	, testing loss - 0.43119	
457	 steps: training loss - 0.56196	, testing loss - 0.43088	
458	 steps: training loss - 0.58000	, testing loss - 0.43056	
459	 steps: training loss - 0.59840	, testing loss - 0.43021	
460	 steps: training loss - 0.52900	, testing loss - 0.42994	
461	 steps: training loss - 0.51337	, testing loss - 0.42956	
462	 steps: training loss - 0.48052	, testing loss - 0.42907	
463	 steps: training loss - 0.52767	, testing loss - 0.42844	
464	 steps: training loss - 0.62172	, testing loss - 0.42772	
465	 steps: training loss - 0.60491	, testing loss - 0.42701	
466	 steps: training loss - 0.57591	, testing loss - 0.42636	
467	 steps: training loss - 0.64236	, testing loss - 0.42576	
468	 steps: training loss - 0.49385	, testing loss - 0.42532	
469	 steps: training loss - 0.52983	, testing loss - 0.42478	
470	 steps: training loss - 0.60661	, testing loss - 0.42419	
471	 steps: training loss - 0.58704	, testing loss - 0.42370	
472	 steps: training loss - 0.53489	, testing loss - 0.42327	
473	 steps: training loss - 0.62170	, testing loss - 0.42282	
474	 steps: training loss - 0.58316	, testing loss - 0.42251	
475	 steps: training loss - 0.57862	, testing loss - 0.42233	
476	 steps: training loss - 0.57416	, testing loss - 0.42213	
477	 steps: training loss - 0.57999	, testing loss - 0.42199	
478	 steps: training loss - 0.59365	, testing loss - 0.42182	
479	 steps: training loss - 0.67696	, testing loss - 0.42163	
480	 steps: training loss - 0.64886	, testing loss - 0.42153	
481	 steps: training loss - 0.52605	, testing loss - 0.42164	
482	 steps: training loss - 0.59804	, testing loss - 0.42168	
483	 steps: training loss - 0.47345	, testing loss - 0.42173	
484	 steps: training loss - 0.58031	, testing loss - 0.42168	
485	 steps: training loss - 0.59468	, testing loss - 0.42153	
486	 steps: training loss - 0.53942	, testing loss - 0.42141	
487	 steps: training loss - 0.57511	, testing loss - 0.42120	
488	 steps: training loss - 0.57147	, testing loss - 0.42085	
489	 steps: training loss - 0.50817	, testing loss - 0.42051	
490	 steps: training loss - 0.51036	, testing loss - 0.42010	
491	 steps: training loss - 0.60203	, testing loss - 0.41965	
492	 steps: training loss - 0.51067	, testing loss - 0.41921	
493	 steps: training loss - 0.61137	, testing loss - 0.41866	
494	 steps: training loss - 0.58508	, testing loss - 0.41816	
495	 steps: training loss - 0.57109	, testing loss - 0.41781	
496	 steps: training loss - 0.44478	, testing loss - 0.41750	
497	 steps: training loss - 0.53895	, testing loss - 0.41708	
498	 steps: training loss - 0.54691	, testing loss - 0.41662	
499	 steps: training loss - 0.54546	, testing loss - 0.41622	
500	 steps: training loss - 0.60592	, testing loss - 0.41586	
501	 steps: training loss - 0.53698	, testing loss - 0.41548	
502	 steps: training loss - 0.55903	, testing loss - 0.41505	
503	 steps: training loss - 0.49558	, testing loss - 0.41460	
504	 steps: training loss - 0.53608	, testing loss - 0.41403	
505	 steps: training loss - 0.52135	, testing loss - 0.41335	
506	 steps: training loss - 0.47564	, testing loss - 0.41264	
507	 steps: training loss - 0.59534	, testing loss - 0.41187	
508	 steps: training loss - 0.64890	, testing loss - 0.41123	
509	 steps: training loss - 0.51001	, testing loss - 0.41081	
510	 steps: training loss - 0.58933	, testing loss - 0.41049	
511	 steps: training loss - 0.57330	, testing loss - 0.41020	
512	 steps: training loss - 0.65513	, testing loss - 0.40986	
513	 steps: training loss - 0.65687	, testing loss - 0.40963	
514	 steps: training loss - 0.52644	, testing loss - 0.40951	
515	 steps: training loss - 0.60427	, testing loss - 0.40931	
516	 steps: training loss - 0.44868	, testing loss - 0.40918	
517	 steps: training loss - 0.55381	, testing loss - 0.40894	
518	 steps: training loss - 0.55574	, testing loss - 0.40861	
519	 steps: training loss - 0.50943	, testing loss - 0.40819	
520	 steps: training loss - 0.60877	, testing loss - 0.40770	
521	 steps: training loss - 0.48017	, testing loss - 0.40724	
522	 steps: training loss - 0.58399	, testing loss - 0.40683	
523	 steps: training loss - 0.58296	, testing loss - 0.40647	
524	 steps: training loss - 0.57858	, testing loss - 0.40618	
525	 steps: training loss - 0.44929	, testing loss - 0.40598	
526	 steps: training loss - 0.48842	, testing loss - 0.40571	
527	 steps: training loss - 0.52938	, testing loss - 0.40544	
528	 steps: training loss - 0.49496	, testing loss - 0.40515	
529	 steps: training loss - 0.56295	, testing loss - 0.40477	
530	 steps: training loss - 0.63649	, testing loss - 0.40435	
531	 steps: training loss - 0.55998	, testing loss - 0.40399	
532	 steps: training loss - 0.51123	, testing loss - 0.40361	
533	 steps: training loss - 0.49250	, testing loss - 0.40319	
534	 steps: training loss - 0.52970	, testing loss - 0.40273	
535	 steps: training loss - 0.54061	, testing loss - 0.40235	
536	 steps: training loss - 0.56587	, testing loss - 0.40190	
537	 steps: training loss - 0.60007	, testing loss - 0.40140	
538	 steps: training loss - 0.55643	, testing loss - 0.40101	
539	 steps: training loss - 0.54151	, testing loss - 0.40064	
540	 steps: training loss - 0.49926	, testing loss - 0.40027	
541	 steps: training loss - 0.48333	, testing loss - 0.39985	
542	 steps: training loss - 0.53138	, testing loss - 0.39937	
543	 steps: training loss - 0.56462	, testing loss - 0.39891	
544	 steps: training loss - 0.70042	, testing loss - 0.39844	
545	 steps: training loss - 0.53166	, testing loss - 0.39816	
546	 steps: training loss - 0.49336	, testing loss - 0.39785	
547	 steps: training loss - 0.51232	, testing loss - 0.39754	
548	 steps: training loss - 0.62037	, testing loss - 0.39719	
549	 steps: training loss - 0.67448	, testing loss - 0.39690	
550	 steps: training loss - 0.54852	, testing loss - 0.39678	
551	 steps: training loss - 0.53027	, testing loss - 0.39673	
552	 steps: training loss - 0.57223	, testing loss - 0.39667	
553	 steps: training loss - 0.54459	, testing loss - 0.39665	
554	 steps: training loss - 0.58422	, testing loss - 0.39662	
555	 steps: training loss - 0.60252	, testing loss - 0.39660	
556	 steps: training loss - 0.64206	, testing loss - 0.39660	
557	 steps: training loss - 0.58101	, testing loss - 0.39655	
558	 steps: training loss - 0.54122	, testing loss - 0.39640	
559	 steps: training loss - 0.56323	, testing loss - 0.39619	
560	 steps: training loss - 0.59947	, testing loss - 0.39603	
561	 steps: training loss - 0.60427	, testing loss - 0.39608	
562	 steps: training loss - 0.62405	, testing loss - 0.39609	
563	 steps: training loss - 0.63757	, testing loss - 0.39608	
564	 steps: training loss - 0.57405	, testing loss - 0.39617	
565	 steps: training loss - 0.62820	, testing loss - 0.39624	
566	 steps: training loss - 0.49922	, testing loss - 0.39631	
567	 steps: training loss - 0.49273	, testing loss - 0.39617	
568	 steps: training loss - 0.64220	, testing loss - 0.39588	
569	 steps: training loss - 0.48456	, testing loss - 0.39569	
570	 steps: training loss - 0.59442	, testing loss - 0.39543	
571	 steps: training loss - 0.54848	, testing loss - 0.39521	
572	 steps: training loss - 0.60780	, testing loss - 0.39505	
573	 steps: training loss - 0.58072	, testing loss - 0.39507	
574	 steps: training loss - 0.58614	, testing loss - 0.39507	
575	 steps: training loss - 0.49542	, testing loss - 0.39507	
576	 steps: training loss - 0.53352	, testing loss - 0.39506	
577	 steps: training loss - 0.56076	, testing loss - 0.39498	
578	 steps: training loss - 0.52987	, testing loss - 0.39473	
579	 steps: training loss - 0.47829	, testing loss - 0.39450	
580	 steps: training loss - 0.50528	, testing loss - 0.39411	
581	 steps: training loss - 0.64741	, testing loss - 0.39367	
582	 steps: training loss - 0.56388	, testing loss - 0.39339	
583	 steps: training loss - 0.52915	, testing loss - 0.39317	
584	 steps: training loss - 0.51986	, testing loss - 0.39300	
585	 steps: training loss - 0.61068	, testing loss - 0.39273	
586	 steps: training loss - 0.56264	, testing loss - 0.39247	
587	 steps: training loss - 0.60587	, testing loss - 0.39236	
588	 steps: training loss - 0.55405	, testing loss - 0.39230	
589	 steps: training loss - 0.50209	, testing loss - 0.39221	
590	 steps: training loss - 0.55624	, testing loss - 0.39202	
591	 steps: training loss - 0.65110	, testing loss - 0.39179	
592	 steps: training loss - 0.58413	, testing loss - 0.39166	
593	 steps: training loss - 0.64220	, testing loss - 0.39155	
594	 steps: training loss - 0.54834	, testing loss - 0.39159	
595	 steps: training loss - 0.53589	, testing loss - 0.39161	
596	 steps: training loss - 0.56176	, testing loss - 0.39166	
597	 steps: training loss - 0.43393	, testing loss - 0.39172	
598	 steps: training loss - 0.51712	, testing loss - 0.39162	
599	 steps: training loss - 0.46755	, testing loss - 0.39145	
600	 steps: training loss - 0.60293	, testing loss - 0.39122	
601	 steps: training loss - 0.58825	, testing loss - 0.39111	
602	 steps: training loss - 0.56753	, testing loss - 0.39100	
603	 steps: training loss - 0.52358	, testing loss - 0.39088	
604	 steps: training loss - 0.54999	, testing loss - 0.39067	
605	 steps: training loss - 0.54891	, testing loss - 0.39041	
606	 steps: training loss - 0.56428	, testing loss - 0.39010	
607	 steps: training loss - 0.50677	, testing loss - 0.38984	
608	 steps: training loss - 0.59508	, testing loss - 0.38946	
609	 steps: training loss - 0.54666	, testing loss - 0.38914	
610	 steps: training loss - 0.58700	, testing loss - 0.38885	
611	 steps: training loss - 0.66454	, testing loss - 0.38859	
612	 steps: training loss - 0.56835	, testing loss - 0.38842	
613	 steps: training loss - 0.53474	, testing loss - 0.38844	
614	 steps: training loss - 0.54686	, testing loss - 0.38841	
615	 steps: training loss - 0.48145	, testing loss - 0.38827	
616	 steps: training loss - 0.57009	, testing loss - 0.38802	
617	 steps: training loss - 0.58907	, testing loss - 0.38776	
618	 steps: training loss - 0.60007	, testing loss - 0.38761	
619	 steps: training loss - 0.50461	, testing loss - 0.38761	
620	 steps: training loss - 0.62511	, testing loss - 0.38762	
621	 steps: training loss - 0.50818	, testing loss - 0.38763	
622	 steps: training loss - 0.59668	, testing loss - 0.38761	
623	 steps: training loss - 0.47703	, testing loss - 0.38753	
624	 steps: training loss - 0.65158	, testing loss - 0.38729	
625	 steps: training loss - 0.59475	, testing loss - 0.38714	
626	 steps: training loss - 0.64489	, testing loss - 0.38704	
627	 steps: training loss - 0.61320	, testing loss - 0.38708	
628	 steps: training loss - 0.48183	, testing loss - 0.38711	
629	 steps: training loss - 0.54873	, testing loss - 0.38710	
630	 steps: training loss - 0.53586	, testing loss - 0.38696	
631	 steps: training loss - 0.58486	, testing loss - 0.38678	
632	 steps: training loss - 0.53409	, testing loss - 0.38659	
633	 steps: training loss - 0.50578	, testing loss - 0.38629	
634	 steps: training loss - 0.59119	, testing loss - 0.38582	
635	 steps: training loss - 0.56964	, testing loss - 0.38538	
636	 steps: training loss - 0.50804	, testing loss - 0.38495	
637	 steps: training loss - 0.57737	, testing loss - 0.38443	
638	 steps: training loss - 0.55518	, testing loss - 0.38403	
639	 steps: training loss - 0.57063	, testing loss - 0.38372	
640	 steps: training loss - 0.49789	, testing loss - 0.38342	
641	 steps: training loss - 0.66118	, testing loss - 0.38315	
642	 steps: training loss - 0.60689	, testing loss - 0.38291	
643	 steps: training loss - 0.53737	, testing loss - 0.38277	
644	 steps: training loss - 0.53557	, testing loss - 0.38266	
645	 steps: training loss - 0.46475	, testing loss - 0.38250	
646	 steps: training loss - 0.55822	, testing loss - 0.38227	
647	 steps: training loss - 0.60288	, testing loss - 0.38202	
648	 steps: training loss - 0.61035	, testing loss - 0.38194	
649	 steps: training loss - 0.52851	, testing loss - 0.38197	
650	 steps: training loss - 0.53018	, testing loss - 0.38203	
651	 steps: training loss - 0.57959	, testing loss - 0.38199	
652	 steps: training loss - 0.48424	, testing loss - 0.38183	
653	 steps: training loss - 0.44761	, testing loss - 0.38148	
654	 steps: training loss - 0.57053	, testing loss - 0.38105	
655	 steps: training loss - 0.51215	, testing loss - 0.38067	
656	 steps: training loss - 0.60299	, testing loss - 0.38034	
657	 steps: training loss - 0.61496	, testing loss - 0.38011	
658	 steps: training loss - 0.59693	, testing loss - 0.37993	
659	 steps: training loss - 0.54351	, testing loss - 0.37968	
660	 steps: training loss - 0.53806	, testing loss - 0.37937	
661	 steps: training loss - 0.57037	, testing loss - 0.37918	
662	 steps: training loss - 0.69569	, testing loss - 0.37911	
663	 steps: training loss - 0.61298	, testing loss - 0.37921	
664	 steps: training loss - 0.54083	, testing loss - 0.37940	
665	 steps: training loss - 0.48975	, testing loss - 0.37956	
666	 steps: training loss - 0.59658	, testing loss - 0.37960	
667	 steps: training loss - 0.51452	, testing loss - 0.37961	
668	 steps: training loss - 0.59867	, testing loss - 0.37958	
669	 steps: training loss - 0.55137	, testing loss - 0.37955	
670	 steps: training loss - 0.63790	, testing loss - 0.37963	
671	 steps: training loss - 0.57443	, testing loss - 0.37967	
672	 steps: training loss - 0.61888	, testing loss - 0.37965	
673	 steps: training loss - 0.64064	, testing loss - 0.37976	
674	 steps: training loss - 0.55024	, testing loss - 0.37989	
675	 steps: training loss - 0.46057	, testing loss - 0.38001	
676	 steps: training loss - 0.52388	, testing loss - 0.38000	
677	 steps: training loss - 0.56374	, testing loss - 0.37990	
678	 steps: training loss - 0.56456	, testing loss - 0.37973	
679	 steps: training loss - 0.45146	, testing loss - 0.37960	
680	 steps: training loss - 0.55221	, testing loss - 0.37935	
681	 steps: training loss - 0.52950	, testing loss - 0.37909	
682	 steps: training loss - 0.52343	, testing loss - 0.37878	
683	 steps: training loss - 0.65545	, testing loss - 0.37833	
684	 steps: training loss - 0.54284	, testing loss - 0.37813	
685	 steps: training loss - 0.52137	, testing loss - 0.37801	
686	 steps: training loss - 0.59322	, testing loss - 0.37789	
687	 steps: training loss - 0.52769	, testing loss - 0.37775	
688	 steps: training loss - 0.67146	, testing loss - 0.37748	
689	 steps: training loss - 0.49995	, testing loss - 0.37719	
690	 steps: training loss - 0.51868	, testing loss - 0.37693	
691	 steps: training loss - 0.55027	, testing loss - 0.37663	
692	 steps: training loss - 0.52496	, testing loss - 0.37627	
693	 steps: training loss - 0.53288	, testing loss - 0.37587	
694	 steps: training loss - 0.39844	, testing loss - 0.37560	
695	 steps: training loss - 0.44121	, testing loss - 0.37522	
696	 steps: training loss - 0.55675	, testing loss - 0.37476	
697	 steps: training loss - 0.69073	, testing loss - 0.37440	
698	 steps: training loss - 0.67791	, testing loss - 0.37422	
699	 steps: training loss - 0.46874	, testing loss - 0.37421	
700	 steps: training loss - 0.51009	, testing loss - 0.37408	
701	 steps: training loss - 0.57532	, testing loss - 0.37390	
702	 steps: training loss - 0.51412	, testing loss - 0.37377	
703	 steps: training loss - 0.55531	, testing loss - 0.37358	
704	 steps: training loss - 0.62532	, testing loss - 0.37335	
705	 steps: training loss - 0.47806	, testing loss - 0.37316	
706	 steps: training loss - 0.51830	, testing loss - 0.37287	
707	 steps: training loss - 0.56120	, testing loss - 0.37265	
708	 steps: training loss - 0.52809	, testing loss - 0.37236	
709	 steps: training loss - 0.57132	, testing loss - 0.37199	
710	 steps: training loss - 0.56630	, testing loss - 0.37167	
711	 steps: training loss - 0.53056	, testing loss - 0.37136	
712	 steps: training loss - 0.72889	, testing loss - 0.37113	
713	 steps: training loss - 0.61549	, testing loss - 0.37108	
714	 steps: training loss - 0.51587	, testing loss - 0.37112	
715	 steps: training loss - 0.54917	, testing loss - 0.37102	
716	 steps: training loss - 0.56308	, testing loss - 0.37087	
717	 steps: training loss - 0.43134	, testing loss - 0.37071	
718	 steps: training loss - 0.53388	, testing loss - 0.37046	
719	 steps: training loss - 0.59058	, testing loss - 0.37012	
720	 steps: training loss - 0.48239	, testing loss - 0.36979	
721	 steps: training loss - 0.57764	, testing loss - 0.36950	
722	 steps: training loss - 0.56429	, testing loss - 0.36927	
723	 steps: training loss - 0.53409	, testing loss - 0.36912	
724	 steps: training loss - 0.56239	, testing loss - 0.36902	
725	 steps: training loss - 0.44216	, testing loss - 0.36901	
726	 steps: training loss - 0.64019	, testing loss - 0.36885	
727	 steps: training loss - 0.53363	, testing loss - 0.36873	
728	 steps: training loss - 0.56701	, testing loss - 0.36862	
729	 steps: training loss - 0.50091	, testing loss - 0.36844	
730	 steps: training loss - 0.40899	, testing loss - 0.36822	
731	 steps: training loss - 0.53308	, testing loss - 0.36784	
732	 steps: training loss - 0.58838	, testing loss - 0.36750	
733	 steps: training loss - 0.59533	, testing loss - 0.36731	
734	 steps: training loss - 0.54760	, testing loss - 0.36714	
735	 steps: training loss - 0.58974	, testing loss - 0.36692	
736	 steps: training loss - 0.46673	, testing loss - 0.36678	
737	 steps: training loss - 0.61282	, testing loss - 0.36665	
738	 steps: training loss - 0.60100	, testing loss - 0.36655	
739	 steps: training loss - 0.64184	, testing loss - 0.36649	
740	 steps: training loss - 0.47155	, testing loss - 0.36655	
741	 steps: training loss - 0.52932	, testing loss - 0.36649	
742	 steps: training loss - 0.53254	, testing loss - 0.36634	
743	 steps: training loss - 0.51297	, testing loss - 0.36632	
744	 steps: training loss - 0.52728	, testing loss - 0.36618	
745	 steps: training loss - 0.47685	, testing loss - 0.36601	
746	 steps: training loss - 0.47605	, testing loss - 0.36575	
747	 steps: training loss - 0.52335	, testing loss - 0.36538	
748	 steps: training loss - 0.47360	, testing loss - 0.36494	
749	 steps: training loss - 0.38956	, testing loss - 0.36454	
750	 steps: training loss - 0.60026	, testing loss - 0.36416	
751	 steps: training loss - 0.50052	, testing loss - 0.36385	
752	 steps: training loss - 0.43037	, testing loss - 0.36360	
753	 steps: training loss - 0.52937	, testing loss - 0.36325	
754	 steps: training loss - 0.50000	, testing loss - 0.36294	
755	 steps: training loss - 0.64010	, testing loss - 0.36259	
756	 steps: training loss - 0.41998	, testing loss - 0.36231	
757	 steps: training loss - 0.47309	, testing loss - 0.36198	
758	 steps: training loss - 0.50137	, testing loss - 0.36163	
759	 steps: training loss - 0.50525	, testing loss - 0.36128	
760	 steps: training loss - 0.60437	, testing loss - 0.36090	
761	 steps: training loss - 0.54860	, testing loss - 0.36062	
762	 steps: training loss - 0.47837	, testing loss - 0.36045	
763	 steps: training loss - 0.63114	, testing loss - 0.36022	
764	 steps: training loss - 0.51873	, testing loss - 0.36000	
765	 steps: training loss - 0.49068	, testing loss - 0.35978	
766	 steps: training loss - 0.42873	, testing loss - 0.35944	
767	 steps: training loss - 0.61270	, testing loss - 0.35893	
768	 steps: training loss - 0.47692	, testing loss - 0.35851	
769	 steps: training loss - 0.58002	, testing loss - 0.35804	
770	 steps: training loss - 0.47041	, testing loss - 0.35760	
771	 steps: training loss - 0.53737	, testing loss - 0.35715	
772	 steps: training loss - 0.59803	, testing loss - 0.35675	
773	 steps: training loss - 0.56354	, testing loss - 0.35645	
774	 steps: training loss - 0.69361	, testing loss - 0.35617	
775	 steps: training loss - 0.53312	, testing loss - 0.35612	
776	 steps: training loss - 0.46573	, testing loss - 0.35625	
777	 steps: training loss - 0.57205	, testing loss - 0.35626	
778	 steps: training loss - 0.57262	, testing loss - 0.35631	
779	 steps: training loss - 0.41383	, testing loss - 0.35638	
780	 steps: training loss - 0.45903	, testing loss - 0.35639	
781	 steps: training loss - 0.48528	, testing loss - 0.35634	
782	 steps: training loss - 0.61445	, testing loss - 0.35621	
783	 steps: training loss - 0.56299	, testing loss - 0.35607	
784	 steps: training loss - 0.57779	, testing loss - 0.35597	
785	 steps: training loss - 0.49878	, testing loss - 0.35580	
786	 steps: training loss - 0.48775	, testing loss - 0.35552	
787	 steps: training loss - 0.65615	, testing loss - 0.35513	
788	 steps: training loss - 0.55314	, testing loss - 0.35490	
789	 steps: training loss - 0.52569	, testing loss - 0.35474	
790	 steps: training loss - 0.56157	, testing loss - 0.35453	
791	 steps: training loss - 0.66088	, testing loss - 0.35435	
792	 steps: training loss - 0.44189	, testing loss - 0.35424	
793	 steps: training loss - 0.57734	, testing loss - 0.35408	
794	 steps: training loss - 0.58600	, testing loss - 0.35389	
795	 steps: training loss - 0.56983	, testing loss - 0.35372	
796	 steps: training loss - 0.49167	, testing loss - 0.35354	
797	 steps: training loss - 0.61753	, testing loss - 0.35335	
798	 steps: training loss - 0.55696	, testing loss - 0.35315	
799	 steps: training loss - 0.45900	, testing loss - 0.35312	
800	 steps: training loss - 0.50169	, testing loss - 0.35300	
801	 steps: training loss - 0.52616	, testing loss - 0.35274	
802	 steps: training loss - 0.48978	, testing loss - 0.35242	
803	 steps: training loss - 0.59490	, testing loss - 0.35203	
804	 steps: training loss - 0.60209	, testing loss - 0.35174	
805	 steps: training loss - 0.51249	, testing loss - 0.35151	
806	 steps: training loss - 0.49615	, testing loss - 0.35132	
807	 steps: training loss - 0.43735	, testing loss - 0.35120	
808	 steps: training loss - 0.57305	, testing loss - 0.35095	
809	 steps: training loss - 0.46876	, testing loss - 0.35063	
810	 steps: training loss - 0.53061	, testing loss - 0.35030	
811	 steps: training loss - 0.50688	, testing loss - 0.34998	
812	 steps: training loss - 0.41617	, testing loss - 0.34960	
813	 steps: training loss - 0.48797	, testing loss - 0.34911	
814	 steps: training loss - 0.53159	, testing loss - 0.34860	
815	 steps: training loss - 0.50853	, testing loss - 0.34811	
816	 steps: training loss - 0.73240	, testing loss - 0.34769	
817	 steps: training loss - 0.56808	, testing loss - 0.34760	
818	 steps: training loss - 0.54606	, testing loss - 0.34765	
819	 steps: training loss - 0.47976	, testing loss - 0.34776	
820	 steps: training loss - 0.61110	, testing loss - 0.34780	
821	 steps: training loss - 0.61249	, testing loss - 0.34782	
822	 steps: training loss - 0.56620	, testing loss - 0.34786	
823	 steps: training loss - 0.47423	, testing loss - 0.34784	
824	 steps: training loss - 0.49383	, testing loss - 0.34773	
825	 steps: training loss - 0.54811	, testing loss - 0.34759	
826	 steps: training loss - 0.53254	, testing loss - 0.34749	
827	 steps: training loss - 0.49005	, testing loss - 0.34746	
828	 steps: training loss - 0.49070	, testing loss - 0.34732	
829	 steps: training loss - 0.46464	, testing loss - 0.34706	
830	 steps: training loss - 0.48127	, testing loss - 0.34678	
831	 steps: training loss - 0.46558	, testing loss - 0.34650	
832	 steps: training loss - 0.53037	, testing loss - 0.34610	
833	 steps: training loss - 0.51200	, testing loss - 0.34571	
834	 steps: training loss - 0.49073	, testing loss - 0.34531	
835	 steps: training loss - 0.54283	, testing loss - 0.34490	
836	 steps: training loss - 0.59505	, testing loss - 0.34449	
837	 steps: training loss - 0.43488	, testing loss - 0.34422	
838	 steps: training loss - 0.48172	, testing loss - 0.34389	
839	 steps: training loss - 0.54138	, testing loss - 0.34358	
840	 steps: training loss - 0.60823	, testing loss - 0.34339	
841	 steps: training loss - 0.35962	, testing loss - 0.34325	
842	 steps: training loss - 0.48140	, testing loss - 0.34296	
843	 steps: training loss - 0.56352	, testing loss - 0.34264	
844	 steps: training loss - 0.61311	, testing loss - 0.34243	
845	 steps: training loss - 0.51097	, testing loss - 0.34243	
846	 steps: training loss - 0.59253	, testing loss - 0.34252	
847	 steps: training loss - 0.50427	, testing loss - 0.34262	
848	 steps: training loss - 0.52037	, testing loss - 0.34265	
849	 steps: training loss - 0.49934	, testing loss - 0.34263	
850	 steps: training loss - 0.60393	, testing loss - 0.34255	
851	 steps: training loss - 0.51795	, testing loss - 0.34248	
852	 steps: training loss - 0.50323	, testing loss - 0.34247	
853	 steps: training loss - 0.51747	, testing loss - 0.34234	
854	 steps: training loss - 0.56178	, testing loss - 0.34214	
855	 steps: training loss - 0.54438	, testing loss - 0.34194	
856	 steps: training loss - 0.52965	, testing loss - 0.34173	
857	 steps: training loss - 0.52766	, testing loss - 0.34154	
858	 steps: training loss - 0.51992	, testing loss - 0.34135	
859	 steps: training loss - 0.53865	, testing loss - 0.34122	
860	 steps: training loss - 0.61154	, testing loss - 0.34103	
861	 steps: training loss - 0.63421	, testing loss - 0.34089	
862	 steps: training loss - 0.37886	, testing loss - 0.34090	
863	 steps: training loss - 0.63120	, testing loss - 0.34075	
864	 steps: training loss - 0.42668	, testing loss - 0.34060	
865	 steps: training loss - 0.51691	, testing loss - 0.34036	
866	 steps: training loss - 0.51270	, testing loss - 0.34004	
867	 steps: training loss - 0.58573	, testing loss - 0.33967	
868	 steps: training loss - 0.65061	, testing loss - 0.33936	
869	 steps: training loss - 0.64461	, testing loss - 0.33922	
870	 steps: training loss - 0.56266	, testing loss - 0.33918	
871	 steps: training loss - 0.50888	, testing loss - 0.33918	
872	 steps: training loss - 0.57733	, testing loss - 0.33915	
873	 steps: training loss - 0.57081	, testing loss - 0.33910	
874	 steps: training loss - 0.48174	, testing loss - 0.33903	
875	 steps: training loss - 0.57865	, testing loss - 0.33900	
876	 steps: training loss - 0.49551	, testing loss - 0.33911	
877	 steps: training loss - 0.66592	, testing loss - 0.33918	
878	 steps: training loss - 0.55595	, testing loss - 0.33936	
879	 steps: training loss - 0.56884	, testing loss - 0.33953	
880	 steps: training loss - 0.40547	, testing loss - 0.33964	
881	 steps: training loss - 0.49706	, testing loss - 0.33964	
882	 steps: training loss - 0.68054	, testing loss - 0.33961	
883	 steps: training loss - 0.51620	, testing loss - 0.33970	
884	 steps: training loss - 0.54651	, testing loss - 0.33973	
885	 steps: training loss - 0.49386	, testing loss - 0.33964	
886	 steps: training loss - 0.59061	, testing loss - 0.33951	
887	 steps: training loss - 0.51810	, testing loss - 0.33946	
888	 steps: training loss - 0.59550	, testing loss - 0.33939	
889	 steps: training loss - 0.55251	, testing loss - 0.33934	
890	 steps: training loss - 0.50306	, testing loss - 0.33934	
891	 steps: training loss - 0.53335	, testing loss - 0.33929	
892	 steps: training loss - 0.55720	, testing loss - 0.33919	
893	 steps: training loss - 0.60193	, testing loss - 0.33911	
894	 steps: training loss - 0.54131	, testing loss - 0.33922	
895	 steps: training loss - 0.44566	, testing loss - 0.33929	
896	 steps: training loss - 0.36667	, testing loss - 0.33930	
897	 steps: training loss - 0.55427	, testing loss - 0.33917	
898	 steps: training loss - 0.47807	, testing loss - 0.33904	
899	 steps: training loss - 0.51730	, testing loss - 0.33885	
900	 steps: training loss - 0.52360	, testing loss - 0.33862	
901	 steps: training loss - 0.54026	, testing loss - 0.33839	
902	 steps: training loss - 0.46820	, testing loss - 0.33823	
903	 steps: training loss - 0.55543	, testing loss - 0.33808	
904	 steps: training loss - 0.49696	, testing loss - 0.33794	
905	 steps: training loss - 0.62754	, testing loss - 0.33768	
906	 steps: training loss - 0.69566	, testing loss - 0.33742	
907	 steps: training loss - 0.47512	, testing loss - 0.33733	
908	 steps: training loss - 0.46668	, testing loss - 0.33731	
909	 steps: training loss - 0.57372	, testing loss - 0.33722	
910	 steps: training loss - 0.64718	, testing loss - 0.33711	
911	 steps: training loss - 0.54977	, testing loss - 0.33707	
912	 steps: training loss - 0.59603	, testing loss - 0.33699	
913	 steps: training loss - 0.54882	, testing loss - 0.33695	
914	 steps: training loss - 0.49584	, testing loss - 0.33695	
915	 steps: training loss - 0.47172	, testing loss - 0.33695	
916	 steps: training loss - 0.57959	, testing loss - 0.33693	
917	 steps: training loss - 0.53501	, testing loss - 0.33690	
918	 steps: training loss - 0.64989	, testing loss - 0.33700	
919	 steps: training loss - 0.55620	, testing loss - 0.33727	
920	 steps: training loss - 0.66610	, testing loss - 0.33760	
921	 steps: training loss - 0.44796	, testing loss - 0.33802	
922	 steps: training loss - 0.42544	, testing loss - 0.33826	
923	 steps: training loss - 0.62457	, testing loss - 0.33833	
924	 steps: training loss - 0.49780	, testing loss - 0.33842	
925	 steps: training loss - 0.52328	, testing loss - 0.33847	
926	 steps: training loss - 0.54609	, testing loss - 0.33851	
927	 steps: training loss - 0.66774	, testing loss - 0.33844	
928	 steps: training loss - 0.66159	, testing loss - 0.33845	
929	 steps: training loss - 0.42019	, testing loss - 0.33854	
930	 steps: training loss - 0.47954	, testing loss - 0.33857	
931	 steps: training loss - 0.60781	, testing loss - 0.33857	
932	 steps: training loss - 0.63753	, testing loss - 0.33861	
933	 steps: training loss - 0.56452	, testing loss - 0.33867	
934	 steps: training loss - 0.46569	, testing loss - 0.33868	
935	 steps: training loss - 0.48309	, testing loss - 0.33871	
936	 steps: training loss - 0.57031	, testing loss - 0.33856	
937	 steps: training loss - 0.48216	, testing loss - 0.33828	
938	 steps: training loss - 0.56554	, testing loss - 0.33798	
939	 steps: training loss - 0.54228	, testing loss - 0.33775	
940	 steps: training loss - 0.55197	, testing loss - 0.33763	
941	 steps: training loss - 0.49027	, testing loss - 0.33773	
942	 steps: training loss - 0.67073	, testing loss - 0.33775	
943	 steps: training loss - 0.48576	, testing loss - 0.33788	
944	 steps: training loss - 0.45402	, testing loss - 0.33794	
945	 steps: training loss - 0.34260	, testing loss - 0.33792	
946	 steps: training loss - 0.57328	, testing loss - 0.33775	
947	 steps: training loss - 0.49293	, testing loss - 0.33742	
948	 steps: training loss - 0.46369	, testing loss - 0.33701	
949	 steps: training loss - 0.54350	, testing loss - 0.33659	
950	 steps: training loss - 0.55696	, testing loss - 0.33621	
951	 steps: training loss - 0.48423	, testing loss - 0.33597	
952	 steps: training loss - 0.55059	, testing loss - 0.33566	
953	 steps: training loss - 0.42055	, testing loss - 0.33542	
954	 steps: training loss - 0.53889	, testing loss - 0.33521	
955	 steps: training loss - 0.56305	, testing loss - 0.33510	
956	 steps: training loss - 0.61925	, testing loss - 0.33501	
957	 steps: training loss - 0.61134	, testing loss - 0.33502	
958	 steps: training loss - 0.56625	, testing loss - 0.33505	
959	 steps: training loss - 0.45130	, testing loss - 0.33505	
960	 steps: training loss - 0.45031	, testing loss - 0.33494	
961	 steps: training loss - 0.39723	, testing loss - 0.33473	
962	 steps: training loss - 0.54872	, testing loss - 0.33444	
963	 steps: training loss - 0.54996	, testing loss - 0.33411	
964	 steps: training loss - 0.64241	, testing loss - 0.33380	
965	 steps: training loss - 0.57185	, testing loss - 0.33367	
966	 steps: training loss - 0.77311	, testing loss - 0.33366	
967	 steps: training loss - 0.48393	, testing loss - 0.33383	
968	 steps: training loss - 0.54818	, testing loss - 0.33398	
969	 steps: training loss - 0.57691	, testing loss - 0.33407	
970	 steps: training loss - 0.45058	, testing loss - 0.33416	
971	 steps: training loss - 0.61770	, testing loss - 0.33419	
972	 steps: training loss - 0.57711	, testing loss - 0.33430	
973	 steps: training loss - 0.39590	, testing loss - 0.33447	
974	 steps: training loss - 0.49524	, testing loss - 0.33440	
975	 steps: training loss - 0.50694	, testing loss - 0.33425	
976	 steps: training loss - 0.44728	, testing loss - 0.33406	
977	 steps: training loss - 0.62784	, testing loss - 0.33377	
978	 steps: training loss - 0.62470	, testing loss - 0.33356	
979	 steps: training loss - 0.54591	, testing loss - 0.33347	
980	 steps: training loss - 0.49183	, testing loss - 0.33346	
981	 steps: training loss - 0.52714	, testing loss - 0.33341	
982	 steps: training loss - 0.68829	, testing loss - 0.33344	
983	 steps: training loss - 0.67613	, testing loss - 0.33362	
984	 steps: training loss - 0.44775	, testing loss - 0.33401	
985	 steps: training loss - 0.47378	, testing loss - 0.33438	
986	 steps: training loss - 0.69832	, testing loss - 0.33457	
987	 steps: training loss - 0.58178	, testing loss - 0.33481	
988	 steps: training loss - 0.44976	, testing loss - 0.33498	
989	 steps: training loss - 0.52941	, testing loss - 0.33498	
990	 steps: training loss - 0.38734	, testing loss - 0.33495	
991	 steps: training loss - 0.51918	, testing loss - 0.33483	
992	 steps: training loss - 0.57383	, testing loss - 0.33476	
993	 steps: training loss - 0.54616	, testing loss - 0.33473	
994	 steps: training loss - 0.41944	, testing loss - 0.33472	
995	 steps: training loss - 0.45741	, testing loss - 0.33464	
996	 steps: training loss - 0.52143	, testing loss - 0.33458	
997	 steps: training loss - 0.55247	, testing loss - 0.33440	
998	 steps: training loss - 0.59048	, testing loss - 0.33420	
999	 steps: training loss - 0.50489	, testing loss - 0.33417	
EVALUATION
----------
Test loss: 0.56095
MIMO Accuracies: 0.99978

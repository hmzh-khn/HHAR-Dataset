0	 steps: training loss - 141053.59375	, testing loss - 450464.31250	
1	 steps: training loss - 149683.00000	, testing loss - 447525.18750	
2	 steps: training loss - 168743.21875	, testing loss - 444561.93750	
3	 steps: training loss - 119407.50000	, testing loss - 443047.06250	
4	 steps: training loss - 154096.71875	, testing loss - 442216.75000	
5	 steps: training loss - 126706.72656	, testing loss - 441417.09375	
6	 steps: training loss - 149520.56250	, testing loss - 440351.71875	
7	 steps: training loss - 157686.70312	, testing loss - 439196.65625	
8	 steps: training loss - 143738.45312	, testing loss - 438174.18750	
9	 steps: training loss - 162327.90625	, testing loss - 437117.53125	
10	 steps: training loss - 139394.45312	, testing loss - 435356.78125	
11	 steps: training loss - 134614.89062	, testing loss - 433311.15625	
12	 steps: training loss - 126715.76562	, testing loss - 431588.84375	
13	 steps: training loss - 119170.46875	, testing loss - 429238.81250	
14	 steps: training loss - 150485.70312	, testing loss - 427070.65625	
15	 steps: training loss - 171534.06250	, testing loss - 425288.81250	
16	 steps: training loss - 129412.48438	, testing loss - 424553.50000	
17	 steps: training loss - 147561.82812	, testing loss - 424379.28125	
18	 steps: training loss - 150200.73438	, testing loss - 424675.43750	
19	 steps: training loss - 140262.39062	, testing loss - 425630.18750	
20	 steps: training loss - 128773.16406	, testing loss - 426683.15625	
21	 steps: training loss - 132970.93750	, testing loss - 427721.06250	
22	 steps: training loss - 161767.40625	, testing loss - 428386.75000	
23	 steps: training loss - 144378.46875	, testing loss - 429021.78125	
24	 steps: training loss - 163126.73438	, testing loss - 429918.75000	
25	 steps: training loss - 136123.76562	, testing loss - 430809.62500	
26	 steps: training loss - 140905.12500	, testing loss - 430684.81250	
27	 steps: training loss - 133351.50000	, testing loss - 428286.96875	
28	 steps: training loss - 134073.48438	, testing loss - 425866.03125	
29	 steps: training loss - 140451.28125	, testing loss - 424030.00000	
30	 steps: training loss - 142702.85938	, testing loss - 422735.06250	
31	 steps: training loss - 123838.75000	, testing loss - 421372.18750	
32	 steps: training loss - 140909.93750	, testing loss - 419715.78125	
33	 steps: training loss - 146724.48438	, testing loss - 417287.40625	
34	 steps: training loss - 145135.71875	, testing loss - 414988.84375	
35	 steps: training loss - 134703.95312	, testing loss - 413236.28125	
36	 steps: training loss - 131399.85938	, testing loss - 411775.93750	
37	 steps: training loss - 141241.84375	, testing loss - 410546.53125	
38	 steps: training loss - 126288.13281	, testing loss - 408659.53125	
39	 steps: training loss - 116248.88281	, testing loss - 407385.12500	
40	 steps: training loss - 141742.06250	, testing loss - 406562.09375	
41	 steps: training loss - 107158.25000	, testing loss - 406437.96875	
42	 steps: training loss - 131047.01562	, testing loss - 406539.93750	
43	 steps: training loss - 139787.65625	, testing loss - 407516.18750	
44	 steps: training loss - 117391.32031	, testing loss - 409933.46875	
45	 steps: training loss - 116755.20312	, testing loss - 411389.68750	
46	 steps: training loss - 126064.71875	, testing loss - 412523.87500	
47	 steps: training loss - 155225.98438	, testing loss - 413245.93750	
48	 steps: training loss - 114169.57812	, testing loss - 412854.37500	
49	 steps: training loss - 113737.98438	, testing loss - 411094.46875	
50	 steps: training loss - 133588.04688	, testing loss - 408367.53125	
51	 steps: training loss - 103816.64844	, testing loss - 406638.12500	
52	 steps: training loss - 137282.92188	, testing loss - 405893.31250	
53	 steps: training loss - 128020.69531	, testing loss - 404965.21875	
54	 steps: training loss - 129551.68750	, testing loss - 403472.71875	
55	 steps: training loss - 138844.07812	, testing loss - 401574.53125	
56	 steps: training loss - 135750.20312	, testing loss - 399436.46875	
57	 steps: training loss - 151035.79688	, testing loss - 398714.56250	
58	 steps: training loss - 119953.60156	, testing loss - 399442.71875	
59	 steps: training loss - 129915.05469	, testing loss - 399941.09375	
60	 steps: training loss - 134189.87500	, testing loss - 400645.12500	
61	 steps: training loss - 103504.10938	, testing loss - 400833.96875	
62	 steps: training loss - 144220.43750	, testing loss - 400333.84375	
63	 steps: training loss - 118989.37500	, testing loss - 400244.96875	
64	 steps: training loss - 118202.53125	, testing loss - 400514.90625	
65	 steps: training loss - 123711.62500	, testing loss - 399853.71875	
66	 steps: training loss - 122744.67969	, testing loss - 398401.00000	
67	 steps: training loss - 140377.60938	, testing loss - 397588.96875	
68	 steps: training loss - 138951.21875	, testing loss - 397002.90625	
69	 steps: training loss - 118521.93750	, testing loss - 397157.46875	
70	 steps: training loss - 137745.90625	, testing loss - 397453.75000	
71	 steps: training loss - 118755.92188	, testing loss - 398205.12500	
72	 steps: training loss - 122131.06250	, testing loss - 398804.09375	
73	 steps: training loss - 138435.15625	, testing loss - 400291.06250	
74	 steps: training loss - 132311.90625	, testing loss - 401612.50000	
75	 steps: training loss - 131627.54688	, testing loss - 402793.96875	
76	 steps: training loss - 144759.87500	, testing loss - 403240.50000	
77	 steps: training loss - 129850.69531	, testing loss - 402359.90625	
78	 steps: training loss - 111308.18750	, testing loss - 400546.25000	
79	 steps: training loss - 101650.25000	, testing loss - 398721.37500	
80	 steps: training loss - 127426.35938	, testing loss - 396157.18750	
81	 steps: training loss - 137037.39062	, testing loss - 393059.59375	
82	 steps: training loss - 108388.87500	, testing loss - 390645.21875	
83	 steps: training loss - 121672.56250	, testing loss - 389367.56250	
84	 steps: training loss - 140879.95312	, testing loss - 388016.31250	
85	 steps: training loss - 131903.34375	, testing loss - 387431.03125	
86	 steps: training loss - 113019.51562	, testing loss - 387411.06250	
87	 steps: training loss - 131553.00000	, testing loss - 387045.21875	
88	 steps: training loss - 143418.57812	, testing loss - 387674.31250	
89	 steps: training loss - 132956.84375	, testing loss - 387869.12500	
90	 steps: training loss - 121837.07031	, testing loss - 388114.03125	
91	 steps: training loss - 128253.14844	, testing loss - 388372.59375	
92	 steps: training loss - 142602.71875	, testing loss - 388184.21875	
93	 steps: training loss - 135599.87500	, testing loss - 387389.12500	
94	 steps: training loss - 130652.69531	, testing loss - 386330.87500	
95	 steps: training loss - 116848.75000	, testing loss - 384946.40625	
96	 steps: training loss - 140967.29688	, testing loss - 384454.06250	
97	 steps: training loss - 119452.85938	, testing loss - 384812.09375	
98	 steps: training loss - 102337.83594	, testing loss - 385159.31250	
99	 steps: training loss - 159101.14062	, testing loss - 385092.12500	
100	 steps: training loss - 131674.87500	, testing loss - 385138.59375	
101	 steps: training loss - 121169.72656	, testing loss - 384795.06250	
102	 steps: training loss - 116036.03906	, testing loss - 384020.75000	
103	 steps: training loss - 107560.56250	, testing loss - 383018.53125	
104	 steps: training loss - 136479.51562	, testing loss - 383416.56250	
105	 steps: training loss - 132101.31250	, testing loss - 385571.59375	
106	 steps: training loss - 117583.32812	, testing loss - 388147.68750	
107	 steps: training loss - 124493.81250	, testing loss - 390717.03125	
108	 steps: training loss - 122084.26562	, testing loss - 392919.59375	
109	 steps: training loss - 143765.76562	, testing loss - 394813.43750	
110	 steps: training loss - 125408.02344	, testing loss - 395437.71875	
111	 steps: training loss - 133127.87500	, testing loss - 395627.62500	
112	 steps: training loss - 108216.41406	, testing loss - 395483.56250	
113	 steps: training loss - 133788.20312	, testing loss - 394907.75000	
114	 steps: training loss - 143701.93750	, testing loss - 393858.03125	
115	 steps: training loss - 111650.60938	, testing loss - 392139.37500	
116	 steps: training loss - 111999.08594	, testing loss - 389668.31250	
117	 steps: training loss - 103897.83594	, testing loss - 386846.46875	
118	 steps: training loss - 154251.53125	, testing loss - 384968.62500	
119	 steps: training loss - 157491.25000	, testing loss - 382717.43750	
120	 steps: training loss - 124928.64844	, testing loss - 381172.59375	
121	 steps: training loss - 105915.66406	, testing loss - 380433.12500	
122	 steps: training loss - 139792.90625	, testing loss - 379845.53125	
123	 steps: training loss - 157084.43750	, testing loss - 380123.93750	
124	 steps: training loss - 93037.82812	, testing loss - 381021.71875	
125	 steps: training loss - 114447.68750	, testing loss - 382469.25000	
126	 steps: training loss - 119536.93750	, testing loss - 383394.43750	
127	 steps: training loss - 139946.39062	, testing loss - 384463.56250	
128	 steps: training loss - 128077.42969	, testing loss - 385951.78125	
129	 steps: training loss - 138974.40625	, testing loss - 387111.15625	
130	 steps: training loss - 127374.12500	, testing loss - 387104.28125	
131	 steps: training loss - 119479.18750	, testing loss - 386524.31250	
132	 steps: training loss - 123507.98438	, testing loss - 385840.25000	
133	 steps: training loss - 116502.92969	, testing loss - 386143.00000	
134	 steps: training loss - 122378.83594	, testing loss - 386083.96875	
135	 steps: training loss - 132380.65625	, testing loss - 385654.43750	
136	 steps: training loss - 106686.05469	, testing loss - 385300.53125	
137	 steps: training loss - 126528.19531	, testing loss - 385511.68750	
138	 steps: training loss - 141644.93750	, testing loss - 384686.15625	
139	 steps: training loss - 139233.17188	, testing loss - 382877.87500	
140	 steps: training loss - 139150.87500	, testing loss - 380975.03125	
141	 steps: training loss - 96020.14844	, testing loss - 379708.93750	
142	 steps: training loss - 117098.72656	, testing loss - 378520.21875	
143	 steps: training loss - 120645.11719	, testing loss - 376904.40625	
144	 steps: training loss - 112587.86719	, testing loss - 375574.90625	
145	 steps: training loss - 125492.22656	, testing loss - 374867.87500	
146	 steps: training loss - 139342.04688	, testing loss - 374394.81250	
147	 steps: training loss - 134681.46875	, testing loss - 374295.62500	
148	 steps: training loss - 118357.80469	, testing loss - 375352.78125	
149	 steps: training loss - 122484.51562	, testing loss - 376691.37500	
150	 steps: training loss - 159295.04688	, testing loss - 378169.12500	
151	 steps: training loss - 112548.52344	, testing loss - 379162.56250	
152	 steps: training loss - 134184.92188	, testing loss - 379762.68750	
153	 steps: training loss - 125773.21875	, testing loss - 380908.53125	
154	 steps: training loss - 122273.44531	, testing loss - 381372.09375	
155	 steps: training loss - 132293.70312	, testing loss - 381302.68750	
156	 steps: training loss - 128593.03906	, testing loss - 380714.84375	
157	 steps: training loss - 116196.32812	, testing loss - 380769.90625	
158	 steps: training loss - 113954.92188	, testing loss - 381031.56250	
159	 steps: training loss - 117704.53125	, testing loss - 381779.50000	
160	 steps: training loss - 131784.76562	, testing loss - 382378.93750	
161	 steps: training loss - 128446.19531	, testing loss - 382450.87500	
162	 steps: training loss - 118793.59375	, testing loss - 383029.65625	
163	 steps: training loss - 135659.40625	, testing loss - 383617.75000	
164	 steps: training loss - 123585.75781	, testing loss - 384443.31250	
165	 steps: training loss - 142083.96875	, testing loss - 385868.96875	
166	 steps: training loss - 128352.91406	, testing loss - 386545.40625	
167	 steps: training loss - 100159.58594	, testing loss - 386744.71875	
168	 steps: training loss - 149409.42188	, testing loss - 386909.68750	
169	 steps: training loss - 154656.76562	, testing loss - 386928.03125	
170	 steps: training loss - 147963.21875	, testing loss - 385852.65625	
171	 steps: training loss - 116956.87500	, testing loss - 383977.78125	
172	 steps: training loss - 133304.15625	, testing loss - 381841.50000	
173	 steps: training loss - 113798.72656	, testing loss - 379800.21875	
174	 steps: training loss - 121181.24219	, testing loss - 378728.68750	
175	 steps: training loss - 122188.01562	, testing loss - 378167.15625	
176	 steps: training loss - 129395.63281	, testing loss - 377712.81250	
177	 steps: training loss - 115337.12500	, testing loss - 377533.53125	
178	 steps: training loss - 126900.07031	, testing loss - 377099.00000	
179	 steps: training loss - 141026.96875	, testing loss - 375876.90625	
180	 steps: training loss - 111718.86719	, testing loss - 375058.59375	
181	 steps: training loss - 139099.79688	, testing loss - 374380.81250	
182	 steps: training loss - 141834.51562	, testing loss - 374349.18750	
183	 steps: training loss - 138620.51562	, testing loss - 375393.03125	
184	 steps: training loss - 139300.79688	, testing loss - 377177.06250	
185	 steps: training loss - 142908.43750	, testing loss - 379600.43750	
186	 steps: training loss - 119485.35938	, testing loss - 381713.15625	
187	 steps: training loss - 136539.39062	, testing loss - 383285.31250	
188	 steps: training loss - 95763.01562	, testing loss - 385198.00000	
189	 steps: training loss - 95190.36719	, testing loss - 387376.00000	
190	 steps: training loss - 117811.70312	, testing loss - 389966.28125	
191	 steps: training loss - 118950.32031	, testing loss - 393506.25000	
192	 steps: training loss - 127709.13281	, testing loss - 395900.84375	
193	 steps: training loss - 129198.09375	, testing loss - 397044.09375	
194	 steps: training loss - 109139.10938	, testing loss - 398191.28125	
195	 steps: training loss - 104155.92188	, testing loss - 398741.06250	
196	 steps: training loss - 138092.90625	, testing loss - 399800.87500	
197	 steps: training loss - 114931.90625	, testing loss - 400207.90625	
198	 steps: training loss - 115012.53125	, testing loss - 400844.90625	
199	 steps: training loss - 123827.40625	, testing loss - 399941.15625	
200	 steps: training loss - 144581.21875	, testing loss - 397573.78125	
201	 steps: training loss - 140428.20312	, testing loss - 394407.56250	
202	 steps: training loss - 127898.03906	, testing loss - 393046.25000	
203	 steps: training loss - 131502.32812	, testing loss - 393099.68750	
204	 steps: training loss - 115859.02344	, testing loss - 392383.84375	
205	 steps: training loss - 124894.23438	, testing loss - 390436.37500	
206	 steps: training loss - 132286.29688	, testing loss - 388895.25000	
207	 steps: training loss - 123543.84375	, testing loss - 388498.06250	
208	 steps: training loss - 120342.40625	, testing loss - 388121.53125	
209	 steps: training loss - 118983.71875	, testing loss - 387626.37500	
210	 steps: training loss - 122864.17969	, testing loss - 386049.78125	
211	 steps: training loss - 127210.13281	, testing loss - 384201.71875	
212	 steps: training loss - 114914.20312	, testing loss - 381865.31250	
213	 steps: training loss - 126390.14062	, testing loss - 381481.12500	
214	 steps: training loss - 121872.42188	, testing loss - 380911.40625	
215	 steps: training loss - 155111.26562	, testing loss - 379491.12500	
216	 steps: training loss - 125057.82031	, testing loss - 378648.68750	
217	 steps: training loss - 141494.45312	, testing loss - 378393.62500	
218	 steps: training loss - 125606.90625	, testing loss - 378315.00000	
219	 steps: training loss - 122458.22656	, testing loss - 379086.28125	
220	 steps: training loss - 125344.19531	, testing loss - 379603.06250	
221	 steps: training loss - 136873.51562	, testing loss - 380115.15625	
222	 steps: training loss - 125964.11719	, testing loss - 380904.90625	
223	 steps: training loss - 121620.32812	, testing loss - 381870.53125	
224	 steps: training loss - 127591.43750	, testing loss - 382881.81250	
225	 steps: training loss - 122699.00000	, testing loss - 383260.59375	
226	 steps: training loss - 112848.92188	, testing loss - 382638.93750	
227	 steps: training loss - 117017.89844	, testing loss - 381095.53125	
228	 steps: training loss - 135220.60938	, testing loss - 379882.65625	
229	 steps: training loss - 128550.39062	, testing loss - 379451.62500	
230	 steps: training loss - 105869.14844	, testing loss - 378215.96875	
231	 steps: training loss - 110546.10156	, testing loss - 376397.68750	
232	 steps: training loss - 124630.14062	, testing loss - 374906.46875	
233	 steps: training loss - 131791.00000	, testing loss - 374078.34375	
234	 steps: training loss - 103813.32812	, testing loss - 373216.50000	
235	 steps: training loss - 136168.57812	, testing loss - 372616.78125	
236	 steps: training loss - 125169.46875	, testing loss - 372549.59375	
237	 steps: training loss - 80248.21094	, testing loss - 373126.31250	
238	 steps: training loss - 131849.15625	, testing loss - 374146.53125	
239	 steps: training loss - 120525.96875	, testing loss - 375357.90625	
240	 steps: training loss - 123823.92969	, testing loss - 376575.93750	
241	 steps: training loss - 113003.93750	, testing loss - 377296.71875	
242	 steps: training loss - 142285.10938	, testing loss - 377577.09375	
243	 steps: training loss - 127623.92188	, testing loss - 377891.06250	
244	 steps: training loss - 108522.95312	, testing loss - 378920.09375	
245	 steps: training loss - 137779.03125	, testing loss - 379602.96875	
246	 steps: training loss - 117302.11719	, testing loss - 380196.06250	
247	 steps: training loss - 138341.32812	, testing loss - 380592.75000	
248	 steps: training loss - 125310.99219	, testing loss - 380763.25000	
249	 steps: training loss - 114457.11719	, testing loss - 380472.87500	
250	 steps: training loss - 118466.47656	, testing loss - 380480.71875	
251	 steps: training loss - 148145.12500	, testing loss - 380575.03125	
252	 steps: training loss - 138647.68750	, testing loss - 380368.71875	
253	 steps: training loss - 160156.29688	, testing loss - 381397.87500	
254	 steps: training loss - 135320.70312	, testing loss - 382963.00000	
255	 steps: training loss - 156675.85938	, testing loss - 383971.18750	
256	 steps: training loss - 139670.48438	, testing loss - 384095.87500	
257	 steps: training loss - 115572.48438	, testing loss - 383158.25000	
258	 steps: training loss - 117123.75781	, testing loss - 382924.53125	
259	 steps: training loss - 114423.87500	, testing loss - 383458.00000	
260	 steps: training loss - 113722.28906	, testing loss - 385053.75000	
261	 steps: training loss - 121444.52344	, testing loss - 385894.84375	
262	 steps: training loss - 107899.88281	, testing loss - 386660.40625	
263	 steps: training loss - 130739.44531	, testing loss - 387507.18750	
264	 steps: training loss - 120417.96875	, testing loss - 386826.84375	
265	 steps: training loss - 125244.33594	, testing loss - 385935.46875	
266	 steps: training loss - 138638.64062	, testing loss - 384602.71875	
267	 steps: training loss - 109736.18750	, testing loss - 383067.84375	
268	 steps: training loss - 133650.81250	, testing loss - 381338.65625	
269	 steps: training loss - 103309.43750	, testing loss - 379372.71875	
270	 steps: training loss - 138792.17188	, testing loss - 377013.84375	
271	 steps: training loss - 130696.67188	, testing loss - 374764.96875	
272	 steps: training loss - 116097.27344	, testing loss - 373519.78125	
273	 steps: training loss - 157603.50000	, testing loss - 373632.90625	
274	 steps: training loss - 99959.52344	, testing loss - 375036.93750	
275	 steps: training loss - 127838.78125	, testing loss - 377676.90625	
276	 steps: training loss - 129770.99219	, testing loss - 381023.21875	
277	 steps: training loss - 118096.70312	, testing loss - 384233.68750	
278	 steps: training loss - 125341.76562	, testing loss - 386253.46875	
279	 steps: training loss - 109695.50000	, testing loss - 386928.34375	
280	 steps: training loss - 142681.35938	, testing loss - 387223.68750	
281	 steps: training loss - 108653.71094	, testing loss - 387629.25000	
282	 steps: training loss - 106953.92969	, testing loss - 387380.75000	
283	 steps: training loss - 108775.53906	, testing loss - 386540.00000	
284	 steps: training loss - 135014.39062	, testing loss - 386397.15625	
285	 steps: training loss - 118339.67969	, testing loss - 386103.50000	
286	 steps: training loss - 133628.82812	, testing loss - 384147.03125	
287	 steps: training loss - 152890.50000	, testing loss - 381761.00000	
288	 steps: training loss - 142722.09375	, testing loss - 379559.12500	
289	 steps: training loss - 135418.84375	, testing loss - 378094.50000	
290	 steps: training loss - 126888.48438	, testing loss - 376936.46875	
291	 steps: training loss - 124096.28906	, testing loss - 376841.56250	
292	 steps: training loss - 116312.83594	, testing loss - 377751.84375	
293	 steps: training loss - 137004.68750	, testing loss - 379049.06250	
294	 steps: training loss - 118881.39844	, testing loss - 381047.87500	
295	 steps: training loss - 123628.51562	, testing loss - 382220.96875	
296	 steps: training loss - 118578.45312	, testing loss - 383684.40625	
297	 steps: training loss - 120842.87500	, testing loss - 384721.09375	
298	 steps: training loss - 104782.71094	, testing loss - 385275.28125	
299	 steps: training loss - 121818.01562	, testing loss - 385686.00000	
300	 steps: training loss - 120257.71875	, testing loss - 386402.56250	
301	 steps: training loss - 143417.06250	, testing loss - 386644.28125	
302	 steps: training loss - 116818.42188	, testing loss - 387915.93750	
303	 steps: training loss - 133823.53125	, testing loss - 389029.62500	
304	 steps: training loss - 131034.98438	, testing loss - 389429.21875	
305	 steps: training loss - 108836.96094	, testing loss - 389973.00000	
306	 steps: training loss - 109938.54688	, testing loss - 389670.84375	
307	 steps: training loss - 140854.40625	, testing loss - 388583.90625	
308	 steps: training loss - 149826.70312	, testing loss - 387888.31250	
309	 steps: training loss - 128610.94531	, testing loss - 388147.71875	
310	 steps: training loss - 118524.04688	, testing loss - 388256.50000	
311	 steps: training loss - 120858.26562	, testing loss - 388017.53125	
312	 steps: training loss - 133597.79688	, testing loss - 387557.65625	
313	 steps: training loss - 133870.15625	, testing loss - 388156.28125	
314	 steps: training loss - 124334.30469	, testing loss - 389206.34375	
315	 steps: training loss - 118363.87500	, testing loss - 389215.12500	
316	 steps: training loss - 124340.28125	, testing loss - 388000.81250	
317	 steps: training loss - 142069.57812	, testing loss - 387391.93750	
318	 steps: training loss - 124342.29688	, testing loss - 386279.34375	
319	 steps: training loss - 117273.07031	, testing loss - 384974.21875	
320	 steps: training loss - 118117.62500	, testing loss - 383498.53125	
321	 steps: training loss - 152830.34375	, testing loss - 381931.50000	
322	 steps: training loss - 135084.17188	, testing loss - 380139.75000	
323	 steps: training loss - 120120.37500	, testing loss - 378961.31250	
324	 steps: training loss - 112111.02344	, testing loss - 378296.75000	
325	 steps: training loss - 124193.55469	, testing loss - 378176.78125	
326	 steps: training loss - 118591.89062	, testing loss - 377430.09375	
327	 steps: training loss - 120268.73438	, testing loss - 375726.75000	
328	 steps: training loss - 143774.50000	, testing loss - 374147.12500	
329	 steps: training loss - 138862.89062	, testing loss - 373342.71875	
330	 steps: training loss - 110904.03906	, testing loss - 373810.56250	
331	 steps: training loss - 104554.98438	, testing loss - 374353.78125	
332	 steps: training loss - 125943.74219	, testing loss - 374456.46875	
333	 steps: training loss - 90910.87500	, testing loss - 374911.46875	
334	 steps: training loss - 124229.68750	, testing loss - 375692.62500	
335	 steps: training loss - 107024.19531	, testing loss - 376549.71875	
336	 steps: training loss - 94619.71875	, testing loss - 377123.21875	
337	 steps: training loss - 127703.31250	, testing loss - 377890.65625	
338	 steps: training loss - 119156.91406	, testing loss - 379166.03125	
339	 steps: training loss - 128751.10156	, testing loss - 379744.40625	
340	 steps: training loss - 124780.02344	, testing loss - 379820.78125	
341	 steps: training loss - 140399.76562	, testing loss - 379607.81250	
342	 steps: training loss - 117732.63281	, testing loss - 378370.06250	
343	 steps: training loss - 132526.64062	, testing loss - 377545.09375	
344	 steps: training loss - 129879.45312	, testing loss - 377508.84375	
345	 steps: training loss - 101014.36719	, testing loss - 377167.40625	
346	 steps: training loss - 116423.96875	, testing loss - 376517.53125	
347	 steps: training loss - 125783.06250	, testing loss - 375885.37500	
348	 steps: training loss - 119039.31250	, testing loss - 375333.40625	
349	 steps: training loss - 145935.89062	, testing loss - 374991.31250	
350	 steps: training loss - 112170.14844	, testing loss - 374580.15625	
351	 steps: training loss - 98639.76562	, testing loss - 374652.34375	
352	 steps: training loss - 122912.78125	, testing loss - 374615.81250	
353	 steps: training loss - 112295.20312	, testing loss - 374378.90625	
354	 steps: training loss - 109240.60938	, testing loss - 374275.37500	
355	 steps: training loss - 127713.35938	, testing loss - 374402.84375	
356	 steps: training loss - 94224.01562	, testing loss - 374045.46875	
357	 steps: training loss - 129233.38281	, testing loss - 373223.21875	
358	 steps: training loss - 123180.04688	, testing loss - 372798.15625	
359	 steps: training loss - 134927.43750	, testing loss - 372594.21875	
360	 steps: training loss - 114416.92969	, testing loss - 372664.46875	
361	 steps: training loss - 141492.07812	, testing loss - 372884.34375	
362	 steps: training loss - 105622.71094	, testing loss - 372967.43750	
363	 steps: training loss - 124712.14062	, testing loss - 373352.96875	
364	 steps: training loss - 123942.60156	, testing loss - 374365.06250	
365	 steps: training loss - 131906.04688	, testing loss - 375113.21875	
366	 steps: training loss - 113644.24219	, testing loss - 375005.59375	
367	 steps: training loss - 146038.01562	, testing loss - 375259.87500	
368	 steps: training loss - 133654.32812	, testing loss - 375005.18750	
369	 steps: training loss - 148210.93750	, testing loss - 374626.75000	
370	 steps: training loss - 99730.92188	, testing loss - 374305.78125	
371	 steps: training loss - 100136.22656	, testing loss - 374548.56250	
372	 steps: training loss - 125425.67188	, testing loss - 375239.62500	
373	 steps: training loss - 112048.52344	, testing loss - 376705.40625	
374	 steps: training loss - 154458.90625	, testing loss - 378694.75000	
375	 steps: training loss - 127182.52344	, testing loss - 380287.96875	
376	 steps: training loss - 123361.48438	, testing loss - 381208.31250	
377	 steps: training loss - 110935.76562	, testing loss - 380850.56250	
378	 steps: training loss - 117978.85156	, testing loss - 380926.06250	
379	 steps: training loss - 131467.07812	, testing loss - 382555.00000	
380	 steps: training loss - 114859.86719	, testing loss - 384590.12500	
381	 steps: training loss - 126060.92969	, testing loss - 387269.84375	
382	 steps: training loss - 127873.78906	, testing loss - 389252.84375	
383	 steps: training loss - 107141.79688	, testing loss - 390836.06250	
384	 steps: training loss - 117734.62500	, testing loss - 392076.71875	
385	 steps: training loss - 128439.00000	, testing loss - 392990.50000	
386	 steps: training loss - 119704.35156	, testing loss - 392204.62500	
387	 steps: training loss - 111052.42969	, testing loss - 390799.12500	
388	 steps: training loss - 122379.95312	, testing loss - 389782.68750	
389	 steps: training loss - 112090.47656	, testing loss - 388464.93750	
390	 steps: training loss - 156020.60938	, testing loss - 386917.18750	
391	 steps: training loss - 106435.93750	, testing loss - 384548.84375	
392	 steps: training loss - 138854.64062	, testing loss - 382945.06250	
393	 steps: training loss - 132237.82812	, testing loss - 382167.40625	
394	 steps: training loss - 147545.62500	, testing loss - 381767.12500	
395	 steps: training loss - 128702.05469	, testing loss - 382016.03125	
396	 steps: training loss - 117195.39844	, testing loss - 383286.15625	
397	 steps: training loss - 111181.49219	, testing loss - 384308.68750	
398	 steps: training loss - 126011.00781	, testing loss - 385988.59375	
399	 steps: training loss - 132138.54688	, testing loss - 388024.56250	
400	 steps: training loss - 136194.04688	, testing loss - 391001.31250	
401	 steps: training loss - 117709.52344	, testing loss - 393314.78125	
402	 steps: training loss - 109494.74219	, testing loss - 393582.53125	
403	 steps: training loss - 101625.06250	, testing loss - 393934.78125	
404	 steps: training loss - 119404.61719	, testing loss - 393969.34375	
405	 steps: training loss - 143398.71875	, testing loss - 394143.18750	
406	 steps: training loss - 136121.81250	, testing loss - 393981.81250	
407	 steps: training loss - 133534.50000	, testing loss - 393131.06250	
408	 steps: training loss - 121078.82031	, testing loss - 391934.34375	
409	 steps: training loss - 118921.65625	, testing loss - 390212.06250	
410	 steps: training loss - 141931.18750	, testing loss - 387149.12500	
411	 steps: training loss - 125105.73438	, testing loss - 383919.56250	
412	 steps: training loss - 112537.35156	, testing loss - 381224.53125	
413	 steps: training loss - 131324.03125	, testing loss - 379000.78125	
414	 steps: training loss - 140127.12500	, testing loss - 377123.12500	
415	 steps: training loss - 141484.26562	, testing loss - 375856.37500	
416	 steps: training loss - 146853.29688	, testing loss - 374388.03125	
417	 steps: training loss - 143376.93750	, testing loss - 372910.25000	
418	 steps: training loss - 107457.70312	, testing loss - 373064.06250	
419	 steps: training loss - 120762.28906	, testing loss - 373639.40625	
420	 steps: training loss - 104882.20312	, testing loss - 374090.84375	
421	 steps: training loss - 127695.83594	, testing loss - 374685.25000	
422	 steps: training loss - 121044.86719	, testing loss - 374858.37500	
423	 steps: training loss - 110311.58594	, testing loss - 375218.59375	
424	 steps: training loss - 119923.50781	, testing loss - 376375.84375	
425	 steps: training loss - 139973.42188	, testing loss - 376532.53125	
426	 steps: training loss - 137800.39062	, testing loss - 376283.40625	
427	 steps: training loss - 120574.70312	, testing loss - 376738.90625	
428	 steps: training loss - 132198.87500	, testing loss - 378343.21875	
429	 steps: training loss - 125051.70312	, testing loss - 379492.40625	
430	 steps: training loss - 128022.38281	, testing loss - 379646.37500	
431	 steps: training loss - 146975.82812	, testing loss - 379302.21875	
432	 steps: training loss - 134943.42188	, testing loss - 377515.00000	
433	 steps: training loss - 126877.92969	, testing loss - 376144.53125	
434	 steps: training loss - 117205.97656	, testing loss - 375209.59375	
435	 steps: training loss - 126021.33594	, testing loss - 374459.28125	
436	 steps: training loss - 144936.31250	, testing loss - 374019.46875	
437	 steps: training loss - 113690.53125	, testing loss - 374838.15625	
438	 steps: training loss - 106631.65625	, testing loss - 376723.12500	
439	 steps: training loss - 104637.47656	, testing loss - 378878.31250	
440	 steps: training loss - 112690.38281	, testing loss - 380316.78125	
441	 steps: training loss - 132887.93750	, testing loss - 381284.96875	
442	 steps: training loss - 144998.68750	, testing loss - 381968.56250	
443	 steps: training loss - 114266.93750	, testing loss - 382982.18750	
444	 steps: training loss - 124869.60938	, testing loss - 384415.62500	
445	 steps: training loss - 107548.35938	, testing loss - 386624.93750	
446	 steps: training loss - 120332.46094	, testing loss - 388146.71875	
447	 steps: training loss - 108589.19531	, testing loss - 388719.15625	
448	 steps: training loss - 133161.25000	, testing loss - 390501.53125	
449	 steps: training loss - 124534.44531	, testing loss - 391067.09375	
450	 steps: training loss - 125604.77344	, testing loss - 390992.03125	
451	 steps: training loss - 126556.85938	, testing loss - 390077.21875	
452	 steps: training loss - 155349.67188	, testing loss - 389353.06250	
453	 steps: training loss - 138378.35938	, testing loss - 388342.12500	
454	 steps: training loss - 125006.82031	, testing loss - 387875.43750	
455	 steps: training loss - 126423.61719	, testing loss - 386011.09375	
456	 steps: training loss - 116647.01562	, testing loss - 383509.03125	
457	 steps: training loss - 113611.65625	, testing loss - 380856.68750	
458	 steps: training loss - 122359.77344	, testing loss - 378765.28125	
459	 steps: training loss - 128063.96094	, testing loss - 378018.93750	
460	 steps: training loss - 127946.21875	, testing loss - 377665.75000	
461	 steps: training loss - 137226.93750	, testing loss - 378485.37500	
462	 steps: training loss - 110179.28125	, testing loss - 379254.84375	
463	 steps: training loss - 106469.65625	, testing loss - 379664.06250	
464	 steps: training loss - 128313.20312	, testing loss - 379843.37500	
465	 steps: training loss - 114775.02344	, testing loss - 379471.75000	
466	 steps: training loss - 126847.73438	, testing loss - 378522.78125	
467	 steps: training loss - 123526.34375	, testing loss - 378744.68750	
468	 steps: training loss - 128731.62500	, testing loss - 378881.09375	
469	 steps: training loss - 125273.37500	, testing loss - 379118.37500	
470	 steps: training loss - 127686.56250	, testing loss - 378987.90625	
471	 steps: training loss - 106140.42969	, testing loss - 378827.68750	
472	 steps: training loss - 139400.20312	, testing loss - 378481.43750	
473	 steps: training loss - 132189.34375	, testing loss - 377389.81250	
474	 steps: training loss - 109995.85156	, testing loss - 376554.15625	
475	 steps: training loss - 119404.35156	, testing loss - 376869.43750	
476	 steps: training loss - 124179.87500	, testing loss - 377072.18750	
477	 steps: training loss - 117610.21094	, testing loss - 377181.28125	
478	 steps: training loss - 109804.50781	, testing loss - 377076.75000	
479	 steps: training loss - 110868.75781	, testing loss - 377230.34375	
480	 steps: training loss - 131759.23438	, testing loss - 377078.53125	
481	 steps: training loss - 140862.53125	, testing loss - 376749.84375	
482	 steps: training loss - 130394.00781	, testing loss - 376659.31250	
483	 steps: training loss - 130156.50000	, testing loss - 377031.18750	
484	 steps: training loss - 135497.37500	, testing loss - 378501.87500	
485	 steps: training loss - 109237.60938	, testing loss - 381068.75000	
486	 steps: training loss - 108120.99219	, testing loss - 382479.84375	
487	 steps: training loss - 125462.52344	, testing loss - 383386.06250	
488	 steps: training loss - 115175.89844	, testing loss - 383608.71875	
489	 steps: training loss - 128904.69531	, testing loss - 383626.12500	
490	 steps: training loss - 117335.28906	, testing loss - 384865.12500	
491	 steps: training loss - 140163.29688	, testing loss - 385980.71875	
492	 steps: training loss - 127994.02344	, testing loss - 386516.43750	
493	 steps: training loss - 116259.92188	, testing loss - 386037.28125	
494	 steps: training loss - 118591.37500	, testing loss - 384517.12500	
495	 steps: training loss - 129449.67188	, testing loss - 383773.43750	
496	 steps: training loss - 118275.25000	, testing loss - 382546.37500	
497	 steps: training loss - 126034.78125	, testing loss - 381826.56250	
498	 steps: training loss - 114156.78906	, testing loss - 380795.31250	
499	 steps: training loss - 111527.60938	, testing loss - 379504.18750	
500	 steps: training loss - 127955.08594	, testing loss - 377578.53125	
501	 steps: training loss - 112782.90625	, testing loss - 376302.40625	
502	 steps: training loss - 125421.25781	, testing loss - 375233.50000	
503	 steps: training loss - 131295.48438	, testing loss - 374738.59375	
504	 steps: training loss - 113451.29688	, testing loss - 374994.56250	
505	 steps: training loss - 122569.21094	, testing loss - 375243.21875	
506	 steps: training loss - 144359.78125	, testing loss - 375677.18750	
507	 steps: training loss - 152551.76562	, testing loss - 376532.65625	
508	 steps: training loss - 156821.00000	, testing loss - 376781.00000	
509	 steps: training loss - 135172.14062	, testing loss - 377518.37500	
510	 steps: training loss - 96419.77344	, testing loss - 378874.75000	
511	 steps: training loss - 132812.00000	, testing loss - 380035.71875	
512	 steps: training loss - 132692.89062	, testing loss - 380198.93750	
513	 steps: training loss - 124234.53906	, testing loss - 379798.25000	
514	 steps: training loss - 119197.03906	, testing loss - 379109.12500	
515	 steps: training loss - 108371.87500	, testing loss - 378720.65625	
516	 steps: training loss - 135666.57812	, testing loss - 378586.31250	
517	 steps: training loss - 140206.14062	, testing loss - 378949.75000	
518	 steps: training loss - 132412.39062	, testing loss - 380523.68750	
519	 steps: training loss - 123650.46094	, testing loss - 381774.18750	
520	 steps: training loss - 119371.92188	, testing loss - 384609.12500	
521	 steps: training loss - 123933.54688	, testing loss - 387254.28125	
522	 steps: training loss - 134506.92188	, testing loss - 389111.43750	
523	 steps: training loss - 115942.37500	, testing loss - 389435.12500	
524	 steps: training loss - 133224.35938	, testing loss - 388327.34375	
525	 steps: training loss - 129299.37500	, testing loss - 387035.28125	
526	 steps: training loss - 129025.32031	, testing loss - 385865.37500	
527	 steps: training loss - 99643.96094	, testing loss - 383830.59375	
528	 steps: training loss - 124638.44531	, testing loss - 381969.46875	
529	 steps: training loss - 117575.67188	, testing loss - 380670.43750	
530	 steps: training loss - 150841.73438	, testing loss - 379259.43750	
531	 steps: training loss - 138814.75000	, testing loss - 377856.25000	
532	 steps: training loss - 151695.93750	, testing loss - 375478.68750	
533	 steps: training loss - 131288.20312	, testing loss - 372655.68750	
534	 steps: training loss - 115759.26562	, testing loss - 370459.09375	
535	 steps: training loss - 116083.82812	, testing loss - 369318.81250	
536	 steps: training loss - 123866.23438	, testing loss - 368607.75000	
537	 steps: training loss - 128015.88281	, testing loss - 367721.59375	
538	 steps: training loss - 131674.03125	, testing loss - 367133.71875	
539	 steps: training loss - 119101.23438	, testing loss - 367349.03125	
540	 steps: training loss - 121685.07812	, testing loss - 368396.59375	
541	 steps: training loss - 119822.68750	, testing loss - 369500.09375	
542	 steps: training loss - 133194.14062	, testing loss - 370398.53125	
543	 steps: training loss - 119543.92969	, testing loss - 371222.18750	
544	 steps: training loss - 117815.04688	, testing loss - 371459.81250	
545	 steps: training loss - 126289.89062	, testing loss - 372437.65625	
546	 steps: training loss - 146567.18750	, testing loss - 374865.15625	
547	 steps: training loss - 128642.27344	, testing loss - 377262.34375	
548	 steps: training loss - 127624.00000	, testing loss - 379052.31250	
549	 steps: training loss - 126048.21875	, testing loss - 379561.28125	
550	 steps: training loss - 121310.80469	, testing loss - 379676.09375	
551	 steps: training loss - 103725.84375	, testing loss - 379416.31250	
552	 steps: training loss - 123629.09375	, testing loss - 378974.56250	
553	 steps: training loss - 120005.53906	, testing loss - 378706.31250	
554	 steps: training loss - 103519.43750	, testing loss - 378839.78125	
555	 steps: training loss - 107093.33594	, testing loss - 379344.65625	
556	 steps: training loss - 139778.00000	, testing loss - 380009.31250	
557	 steps: training loss - 107560.40625	, testing loss - 379223.56250	
558	 steps: training loss - 94926.10938	, testing loss - 378170.78125	
559	 steps: training loss - 123949.28906	, testing loss - 377590.15625	
560	 steps: training loss - 97614.44531	, testing loss - 376748.96875	
561	 steps: training loss - 137339.59375	, testing loss - 375988.53125	
562	 steps: training loss - 106819.42969	, testing loss - 376003.50000	
563	 steps: training loss - 115647.48438	, testing loss - 376796.12500	
564	 steps: training loss - 119152.39844	, testing loss - 376908.81250	
565	 steps: training loss - 120504.09375	, testing loss - 376352.62500	
566	 steps: training loss - 121735.29688	, testing loss - 376229.25000	
567	 steps: training loss - 120159.85156	, testing loss - 376468.50000	
568	 steps: training loss - 133463.98438	, testing loss - 377381.75000	
569	 steps: training loss - 100812.21094	, testing loss - 377994.50000	
570	 steps: training loss - 107597.12500	, testing loss - 378563.90625	
571	 steps: training loss - 119849.49219	, testing loss - 379863.96875	
572	 steps: training loss - 113452.52344	, testing loss - 380566.50000	
573	 steps: training loss - 123203.27344	, testing loss - 380437.59375	
574	 steps: training loss - 133401.17188	, testing loss - 380224.15625	
575	 steps: training loss - 134064.67188	, testing loss - 380006.18750	
576	 steps: training loss - 128470.18750	, testing loss - 379441.25000	
577	 steps: training loss - 107341.32812	, testing loss - 379015.09375	
578	 steps: training loss - 109438.41406	, testing loss - 377982.03125	
579	 steps: training loss - 131925.89062	, testing loss - 377044.53125	
580	 steps: training loss - 115286.09375	, testing loss - 376817.96875	
581	 steps: training loss - 127385.46094	, testing loss - 375890.75000	
582	 steps: training loss - 139923.53125	, testing loss - 374500.53125	
583	 steps: training loss - 125315.01562	, testing loss - 373154.65625	
584	 steps: training loss - 90674.59375	, testing loss - 372875.75000	
585	 steps: training loss - 132747.09375	, testing loss - 373428.34375	
586	 steps: training loss - 115393.88281	, testing loss - 374115.68750	
587	 steps: training loss - 110844.20312	, testing loss - 374758.59375	
588	 steps: training loss - 101663.27344	, testing loss - 375917.71875	
589	 steps: training loss - 106638.73438	, testing loss - 377090.09375	
590	 steps: training loss - 114506.27344	, testing loss - 377443.12500	
591	 steps: training loss - 93248.67188	, testing loss - 377347.53125	
592	 steps: training loss - 125643.19531	, testing loss - 377584.75000	
593	 steps: training loss - 113826.41406	, testing loss - 377928.09375	
594	 steps: training loss - 147916.25000	, testing loss - 378904.31250	
595	 steps: training loss - 121923.85938	, testing loss - 379573.59375	
596	 steps: training loss - 154085.92188	, testing loss - 381010.50000	
597	 steps: training loss - 101865.04688	, testing loss - 380545.90625	
598	 steps: training loss - 107518.14844	, testing loss - 378765.93750	
599	 steps: training loss - 137738.31250	, testing loss - 377125.81250	
600	 steps: training loss - 87354.96094	, testing loss - 375983.06250	
601	 steps: training loss - 125753.43750	, testing loss - 375288.96875	
602	 steps: training loss - 114068.46875	, testing loss - 375126.46875	
603	 steps: training loss - 115392.80469	, testing loss - 374784.50000	
604	 steps: training loss - 135248.89062	, testing loss - 375265.65625	
605	 steps: training loss - 112428.64844	, testing loss - 375538.65625	
606	 steps: training loss - 115523.07031	, testing loss - 375535.93750	
607	 steps: training loss - 118272.56250	, testing loss - 376738.21875	
608	 steps: training loss - 130379.39844	, testing loss - 379067.93750	
609	 steps: training loss - 122332.96875	, testing loss - 381530.68750	
610	 steps: training loss - 136458.68750	, testing loss - 383379.46875	
611	 steps: training loss - 105628.32031	, testing loss - 383937.28125	
612	 steps: training loss - 114450.78906	, testing loss - 385002.59375	
613	 steps: training loss - 121262.25000	, testing loss - 386384.84375	
614	 steps: training loss - 134080.78125	, testing loss - 386137.59375	
615	 steps: training loss - 133238.31250	, testing loss - 385164.37500	
616	 steps: training loss - 132039.35938	, testing loss - 384840.46875	
617	 steps: training loss - 121497.04688	, testing loss - 382950.15625	
618	 steps: training loss - 145869.84375	, testing loss - 381165.84375	
619	 steps: training loss - 142746.75000	, testing loss - 379279.90625	
620	 steps: training loss - 131271.04688	, testing loss - 377617.09375	
621	 steps: training loss - 117535.12500	, testing loss - 375426.68750	
622	 steps: training loss - 115240.96094	, testing loss - 373940.28125	
623	 steps: training loss - 119943.34375	, testing loss - 373667.59375	
624	 steps: training loss - 111345.78906	, testing loss - 373770.65625	
625	 steps: training loss - 104905.04688	, testing loss - 373996.09375	
626	 steps: training loss - 118749.03906	, testing loss - 374408.31250	
627	 steps: training loss - 125296.06250	, testing loss - 375083.59375	
628	 steps: training loss - 109993.06250	, testing loss - 375922.50000	
629	 steps: training loss - 115426.89844	, testing loss - 377301.87500	
630	 steps: training loss - 139042.43750	, testing loss - 378700.03125	
631	 steps: training loss - 107499.00000	, testing loss - 379082.65625	
632	 steps: training loss - 99648.67969	, testing loss - 379231.56250	
633	 steps: training loss - 132052.17188	, testing loss - 379004.09375	
634	 steps: training loss - 123085.09375	, testing loss - 378684.90625	
635	 steps: training loss - 112255.84375	, testing loss - 378223.25000	
636	 steps: training loss - 111363.07812	, testing loss - 377266.78125	
637	 steps: training loss - 111508.89844	, testing loss - 376327.46875	
638	 steps: training loss - 101626.50000	, testing loss - 375601.50000	
639	 steps: training loss - 121568.68750	, testing loss - 375481.06250	
640	 steps: training loss - 133944.20312	, testing loss - 375081.21875	
641	 steps: training loss - 133441.76562	, testing loss - 374244.90625	
642	 steps: training loss - 109566.14844	, testing loss - 373154.37500	
643	 steps: training loss - 127538.95312	, testing loss - 372439.62500	
644	 steps: training loss - 142959.21875	, testing loss - 372338.43750	
645	 steps: training loss - 103975.31250	, testing loss - 372447.37500	
646	 steps: training loss - 117774.44531	, testing loss - 372572.15625	
647	 steps: training loss - 147055.10938	, testing loss - 372350.18750	
648	 steps: training loss - 116207.91406	, testing loss - 372232.37500	
649	 steps: training loss - 146819.56250	, testing loss - 372083.62500	
650	 steps: training loss - 98793.04688	, testing loss - 372806.78125	
651	 steps: training loss - 116984.98438	, testing loss - 373314.00000	
652	 steps: training loss - 113576.13281	, testing loss - 373962.09375	
653	 steps: training loss - 129533.28125	, testing loss - 374771.68750	
654	 steps: training loss - 124251.09375	, testing loss - 375205.50000	
655	 steps: training loss - 104931.84375	, testing loss - 376370.25000	
656	 steps: training loss - 118804.75781	, testing loss - 377942.12500	
657	 steps: training loss - 109552.31250	, testing loss - 378357.00000	
658	 steps: training loss - 92910.67188	, testing loss - 379047.15625	
659	 steps: training loss - 105737.75781	, testing loss - 379663.28125	
660	 steps: training loss - 108218.42188	, testing loss - 380877.84375	
661	 steps: training loss - 109799.38281	, testing loss - 381247.65625	
662	 steps: training loss - 119343.41406	, testing loss - 381993.21875	
663	 steps: training loss - 113850.62500	, testing loss - 382022.87500	
664	 steps: training loss - 122785.08594	, testing loss - 381293.59375	
665	 steps: training loss - 120336.62500	, testing loss - 380400.96875	
666	 steps: training loss - 128028.77344	, testing loss - 379928.21875	
667	 steps: training loss - 104032.35156	, testing loss - 379823.25000	
668	 steps: training loss - 112138.31250	, testing loss - 380814.71875	
669	 steps: training loss - 104374.75000	, testing loss - 382779.06250	
670	 steps: training loss - 97904.02344	, testing loss - 384434.90625	
671	 steps: training loss - 123873.20312	, testing loss - 385306.40625	
672	 steps: training loss - 103851.71875	, testing loss - 385615.12500	
673	 steps: training loss - 138582.96875	, testing loss - 385453.09375	
674	 steps: training loss - 112062.50000	, testing loss - 384805.75000	
675	 steps: training loss - 103103.10156	, testing loss - 384164.18750	
676	 steps: training loss - 124222.34375	, testing loss - 384121.09375	
677	 steps: training loss - 94017.14844	, testing loss - 383796.50000	
678	 steps: training loss - 114973.32031	, testing loss - 384061.53125	
679	 steps: training loss - 115181.11719	, testing loss - 383735.00000	
680	 steps: training loss - 88962.61719	, testing loss - 383873.21875	
681	 steps: training loss - 121441.21875	, testing loss - 384689.25000	
682	 steps: training loss - 105098.79688	, testing loss - 384777.75000	
683	 steps: training loss - 135778.37500	, testing loss - 384738.84375	
684	 steps: training loss - 97996.07812	, testing loss - 385633.21875	
685	 steps: training loss - 116061.75000	, testing loss - 386362.34375	
686	 steps: training loss - 113919.02344	, testing loss - 386366.34375	
687	 steps: training loss - 138671.15625	, testing loss - 386879.43750	
688	 steps: training loss - 140236.54688	, testing loss - 386187.65625	
689	 steps: training loss - 102248.35156	, testing loss - 384919.15625	
690	 steps: training loss - 111523.07812	, testing loss - 382988.75000	
691	 steps: training loss - 126635.08594	, testing loss - 381547.34375	
692	 steps: training loss - 114393.34375	, testing loss - 381629.71875	
693	 steps: training loss - 127338.31250	, testing loss - 382581.71875	
694	 steps: training loss - 101635.49219	, testing loss - 384097.46875	
695	 steps: training loss - 106047.54688	, testing loss - 384537.43750	
696	 steps: training loss - 121526.52344	, testing loss - 383752.56250	
697	 steps: training loss - 113379.92969	, testing loss - 382872.71875	
698	 steps: training loss - 121531.89062	, testing loss - 381390.18750	
699	 steps: training loss - 115363.72656	, testing loss - 379805.18750	
700	 steps: training loss - 134553.26562	, testing loss - 378366.71875	
701	 steps: training loss - 126312.66406	, testing loss - 376893.25000	
702	 steps: training loss - 125162.69531	, testing loss - 375730.25000	
703	 steps: training loss - 131076.42188	, testing loss - 374931.46875	
704	 steps: training loss - 116107.28125	, testing loss - 373486.71875	
705	 steps: training loss - 128277.60938	, testing loss - 372203.65625	
706	 steps: training loss - 126626.75000	, testing loss - 371113.50000	
707	 steps: training loss - 155764.89062	, testing loss - 371129.90625	
708	 steps: training loss - 116254.66406	, testing loss - 372129.15625	
709	 steps: training loss - 123224.95312	, testing loss - 373325.06250	
710	 steps: training loss - 111223.95312	, testing loss - 375520.34375	
711	 steps: training loss - 125817.67188	, testing loss - 377366.71875	
712	 steps: training loss - 108545.55469	, testing loss - 378043.31250	
713	 steps: training loss - 148198.40625	, testing loss - 378373.90625	
714	 steps: training loss - 107357.25000	, testing loss - 377700.59375	
715	 steps: training loss - 121818.00781	, testing loss - 377139.75000	
716	 steps: training loss - 111257.19531	, testing loss - 377036.75000	
717	 steps: training loss - 99840.13281	, testing loss - 377054.40625	
718	 steps: training loss - 122915.83594	, testing loss - 376769.15625	
719	 steps: training loss - 110305.24219	, testing loss - 376260.31250	
720	 steps: training loss - 116852.04688	, testing loss - 376495.00000	
721	 steps: training loss - 105956.84375	, testing loss - 376537.87500	
722	 steps: training loss - 142809.87500	, testing loss - 376968.81250	
723	 steps: training loss - 142899.23438	, testing loss - 377573.87500	
724	 steps: training loss - 128090.32031	, testing loss - 378936.96875	
725	 steps: training loss - 114752.53906	, testing loss - 380969.59375	
726	 steps: training loss - 118222.85156	, testing loss - 381587.71875	
727	 steps: training loss - 123053.46094	, testing loss - 380453.87500	
728	 steps: training loss - 114445.40625	, testing loss - 379196.78125	
729	 steps: training loss - 116342.64062	, testing loss - 378429.62500	
730	 steps: training loss - 101047.40625	, testing loss - 377966.96875	
731	 steps: training loss - 102658.83594	, testing loss - 377927.78125	
732	 steps: training loss - 107088.74219	, testing loss - 377886.40625	
733	 steps: training loss - 118909.82812	, testing loss - 377637.59375	
734	 steps: training loss - 131827.29688	, testing loss - 377571.56250	
735	 steps: training loss - 120963.95312	, testing loss - 376495.15625	
736	 steps: training loss - 102673.91406	, testing loss - 375023.43750	
737	 steps: training loss - 109366.10938	, testing loss - 373717.25000	
738	 steps: training loss - 123211.38281	, testing loss - 372638.31250	
739	 steps: training loss - 120890.41406	, testing loss - 371879.68750	
740	 steps: training loss - 106862.30469	, testing loss - 370871.87500	
741	 steps: training loss - 135467.93750	, testing loss - 370065.96875	
742	 steps: training loss - 131675.87500	, testing loss - 369540.18750	
743	 steps: training loss - 116965.07812	, testing loss - 370177.37500	
744	 steps: training loss - 120387.14844	, testing loss - 370444.96875	
745	 steps: training loss - 117479.62500	, testing loss - 371462.53125	
746	 steps: training loss - 95618.39844	, testing loss - 373056.68750	
747	 steps: training loss - 115222.51562	, testing loss - 374363.78125	
748	 steps: training loss - 135555.42188	, testing loss - 375300.81250	
749	 steps: training loss - 124339.79688	, testing loss - 376815.37500	
750	 steps: training loss - 107092.45312	, testing loss - 377624.90625	
751	 steps: training loss - 98102.09375	, testing loss - 377251.28125	
752	 steps: training loss - 126942.96094	, testing loss - 376591.81250	
753	 steps: training loss - 103162.80469	, testing loss - 376091.09375	
754	 steps: training loss - 97232.72656	, testing loss - 376504.62500	
755	 steps: training loss - 122583.08594	, testing loss - 377456.87500	
756	 steps: training loss - 122952.11719	, testing loss - 378139.56250	
757	 steps: training loss - 102796.21094	, testing loss - 379418.09375	
758	 steps: training loss - 124274.52344	, testing loss - 380238.75000	
759	 steps: training loss - 77007.07031	, testing loss - 382310.53125	
760	 steps: training loss - 127635.43750	, testing loss - 384557.53125	
761	 steps: training loss - 110097.50000	, testing loss - 387068.03125	
762	 steps: training loss - 128484.39844	, testing loss - 387366.43750	
763	 steps: training loss - 106443.53906	, testing loss - 387293.93750	
764	 steps: training loss - 110838.16406	, testing loss - 386611.43750	
765	 steps: training loss - 122009.00781	, testing loss - 384651.81250	
766	 steps: training loss - 104413.31250	, testing loss - 383172.78125	
767	 steps: training loss - 126881.44531	, testing loss - 381231.93750	
768	 steps: training loss - 98929.73438	, testing loss - 379288.93750	
769	 steps: training loss - 111827.42188	, testing loss - 377648.34375	
770	 steps: training loss - 117787.45312	, testing loss - 376376.12500	
771	 steps: training loss - 118515.63281	, testing loss - 375056.37500	
772	 steps: training loss - 116051.58594	, testing loss - 373561.59375	
773	 steps: training loss - 111270.81250	, testing loss - 372793.12500	
774	 steps: training loss - 133644.65625	, testing loss - 372929.40625	
775	 steps: training loss - 104213.14062	, testing loss - 372687.46875	
776	 steps: training loss - 124272.89062	, testing loss - 372847.56250	
777	 steps: training loss - 140317.50000	, testing loss - 373182.68750	
778	 steps: training loss - 91915.96875	, testing loss - 373118.68750	
779	 steps: training loss - 132416.78125	, testing loss - 373314.15625	
780	 steps: training loss - 107618.70312	, testing loss - 372420.37500	
781	 steps: training loss - 127055.29688	, testing loss - 371402.40625	
782	 steps: training loss - 147006.45312	, testing loss - 370918.06250	
783	 steps: training loss - 108874.37500	, testing loss - 371564.50000	
784	 steps: training loss - 117782.68750	, testing loss - 372951.43750	
785	 steps: training loss - 112672.80469	, testing loss - 374940.31250	
786	 steps: training loss - 139112.21875	, testing loss - 376717.62500	
787	 steps: training loss - 97446.32031	, testing loss - 378291.40625	
788	 steps: training loss - 128187.86719	, testing loss - 379292.00000	
789	 steps: training loss - 103306.34375	, testing loss - 381161.31250	
790	 steps: training loss - 106557.57031	, testing loss - 382846.96875	
791	 steps: training loss - 107952.57812	, testing loss - 383487.46875	
792	 steps: training loss - 136462.84375	, testing loss - 383032.37500	
793	 steps: training loss - 125482.52344	, testing loss - 381666.09375	
794	 steps: training loss - 124910.52344	, testing loss - 380474.06250	
795	 steps: training loss - 148416.84375	, testing loss - 380352.53125	
796	 steps: training loss - 151716.87500	, testing loss - 382013.34375	
797	 steps: training loss - 127657.31250	, testing loss - 382755.31250	
798	 steps: training loss - 113565.72656	, testing loss - 383061.96875	
799	 steps: training loss - 136083.32812	, testing loss - 382903.18750	
800	 steps: training loss - 141738.62500	, testing loss - 380943.37500	
801	 steps: training loss - 104576.32812	, testing loss - 378993.06250	
802	 steps: training loss - 115444.42188	, testing loss - 377966.84375	
803	 steps: training loss - 102173.56250	, testing loss - 377292.12500	
804	 steps: training loss - 135877.32812	, testing loss - 376511.46875	
805	 steps: training loss - 105142.12500	, testing loss - 375983.50000	
806	 steps: training loss - 107931.50781	, testing loss - 375455.37500	
807	 steps: training loss - 138092.89062	, testing loss - 374863.65625	
808	 steps: training loss - 114713.75000	, testing loss - 374888.34375	
809	 steps: training loss - 126504.82031	, testing loss - 374798.84375	
810	 steps: training loss - 145941.42188	, testing loss - 374373.96875	
811	 steps: training loss - 126150.84375	, testing loss - 374006.68750	
812	 steps: training loss - 102838.56250	, testing loss - 373648.62500	
813	 steps: training loss - 97282.89062	, testing loss - 373181.59375	
814	 steps: training loss - 106623.22656	, testing loss - 372531.87500	
815	 steps: training loss - 154603.54688	, testing loss - 371539.12500	
816	 steps: training loss - 129114.35938	, testing loss - 370751.03125	
817	 steps: training loss - 118578.47656	, testing loss - 369950.12500	
818	 steps: training loss - 127362.20312	, testing loss - 370560.18750	
819	 steps: training loss - 133985.68750	, testing loss - 372269.21875	
820	 steps: training loss - 133224.84375	, testing loss - 374425.18750	
821	 steps: training loss - 138752.73438	, testing loss - 375976.43750	
822	 steps: training loss - 95111.09375	, testing loss - 376809.81250	
823	 steps: training loss - 115349.97656	, testing loss - 377535.62500	
824	 steps: training loss - 132663.35938	, testing loss - 378961.81250	
825	 steps: training loss - 125289.82031	, testing loss - 380150.03125	
826	 steps: training loss - 112443.84375	, testing loss - 380728.93750	
827	 steps: training loss - 120239.25000	, testing loss - 381074.65625	
828	 steps: training loss - 149342.07812	, testing loss - 380275.65625	
829	 steps: training loss - 95319.84375	, testing loss - 378203.00000	
830	 steps: training loss - 138981.78125	, testing loss - 376072.65625	
831	 steps: training loss - 118914.27344	, testing loss - 373921.71875	
832	 steps: training loss - 130656.66406	, testing loss - 372051.15625	
833	 steps: training loss - 108954.31250	, testing loss - 371189.59375	
834	 steps: training loss - 122037.68750	, testing loss - 370867.78125	
835	 steps: training loss - 128412.50781	, testing loss - 370750.68750	
836	 steps: training loss - 99328.73438	, testing loss - 370300.59375	
837	 steps: training loss - 126735.63281	, testing loss - 369818.50000	
838	 steps: training loss - 106181.67969	, testing loss - 369755.03125	
839	 steps: training loss - 131964.81250	, testing loss - 370285.15625	
840	 steps: training loss - 135268.34375	, testing loss - 371472.34375	
841	 steps: training loss - 129185.56250	, testing loss - 372423.96875	
842	 steps: training loss - 97350.56250	, testing loss - 373851.50000	
843	 steps: training loss - 108956.30469	, testing loss - 375426.37500	
844	 steps: training loss - 100576.57031	, testing loss - 376710.50000	
845	 steps: training loss - 111583.99219	, testing loss - 376972.96875	
846	 steps: training loss - 114356.71875	, testing loss - 376785.31250	
847	 steps: training loss - 111855.18750	, testing loss - 377173.71875	
848	 steps: training loss - 115498.35938	, testing loss - 377203.21875	
849	 steps: training loss - 129500.75000	, testing loss - 377248.78125	
850	 steps: training loss - 102094.79688	, testing loss - 377148.00000	
851	 steps: training loss - 117422.91406	, testing loss - 376351.90625	
852	 steps: training loss - 124446.08594	, testing loss - 375539.12500	
853	 steps: training loss - 114669.75781	, testing loss - 374273.28125	
854	 steps: training loss - 111294.40625	, testing loss - 372192.15625	
855	 steps: training loss - 131840.71875	, testing loss - 370911.84375	
856	 steps: training loss - 118103.00781	, testing loss - 369951.28125	
857	 steps: training loss - 114348.69531	, testing loss - 369118.71875	
858	 steps: training loss - 110624.52344	, testing loss - 369466.75000	
859	 steps: training loss - 123274.57031	, testing loss - 370029.03125	
860	 steps: training loss - 118735.60938	, testing loss - 370095.28125	
861	 steps: training loss - 96110.92969	, testing loss - 370972.09375	
862	 steps: training loss - 124877.57031	, testing loss - 371850.56250	
863	 steps: training loss - 121039.00000	, testing loss - 372858.68750	
864	 steps: training loss - 127736.04688	, testing loss - 373588.06250	
865	 steps: training loss - 116287.44531	, testing loss - 374105.40625	
866	 steps: training loss - 128862.52344	, testing loss - 374581.34375	
867	 steps: training loss - 149435.48438	, testing loss - 374772.18750	
868	 steps: training loss - 111845.28906	, testing loss - 374918.68750	
869	 steps: training loss - 130466.75000	, testing loss - 374047.31250	
870	 steps: training loss - 119021.63281	, testing loss - 372561.71875	
871	 steps: training loss - 134281.43750	, testing loss - 371281.90625	
872	 steps: training loss - 139769.09375	, testing loss - 371776.18750	
873	 steps: training loss - 126251.65625	, testing loss - 372513.00000	
874	 steps: training loss - 149766.56250	, testing loss - 373914.15625	
875	 steps: training loss - 127607.43750	, testing loss - 375295.46875	
876	 steps: training loss - 115900.03125	, testing loss - 376955.87500	
877	 steps: training loss - 140310.39062	, testing loss - 378695.31250	
878	 steps: training loss - 112526.50000	, testing loss - 379606.81250	
879	 steps: training loss - 119841.56250	, testing loss - 380118.81250	
880	 steps: training loss - 133570.51562	, testing loss - 380502.46875	
881	 steps: training loss - 151922.53125	, testing loss - 379870.87500	
882	 steps: training loss - 139984.56250	, testing loss - 379009.65625	
883	 steps: training loss - 125783.96875	, testing loss - 377458.06250	
884	 steps: training loss - 113925.64844	, testing loss - 374590.53125	
885	 steps: training loss - 110529.64844	, testing loss - 372165.68750	
886	 steps: training loss - 98893.92969	, testing loss - 369336.15625	
887	 steps: training loss - 108705.85156	, testing loss - 367272.00000	
888	 steps: training loss - 87345.85938	, testing loss - 365870.68750	
889	 steps: training loss - 135754.95312	, testing loss - 364685.71875	
890	 steps: training loss - 136031.40625	, testing loss - 364280.75000	
891	 steps: training loss - 105907.54688	, testing loss - 364117.12500	
892	 steps: training loss - 105533.82031	, testing loss - 364137.00000	
893	 steps: training loss - 134015.54688	, testing loss - 364319.93750	
894	 steps: training loss - 140908.53125	, testing loss - 364450.81250	
895	 steps: training loss - 129009.39844	, testing loss - 364686.96875	
896	 steps: training loss - 145786.59375	, testing loss - 365076.40625	
897	 steps: training loss - 120809.16406	, testing loss - 366172.75000	
898	 steps: training loss - 108575.03125	, testing loss - 367395.50000	
899	 steps: training loss - 121478.95312	, testing loss - 368816.93750	
900	 steps: training loss - 118190.36719	, testing loss - 369869.68750	
901	 steps: training loss - 90998.13281	, testing loss - 371498.50000	
902	 steps: training loss - 111810.79688	, testing loss - 372848.81250	
903	 steps: training loss - 95220.85156	, testing loss - 373669.31250	
904	 steps: training loss - 101772.06250	, testing loss - 374378.46875	
905	 steps: training loss - 134529.56250	, testing loss - 374346.09375	
906	 steps: training loss - 113872.26562	, testing loss - 374669.09375	
907	 steps: training loss - 117010.95312	, testing loss - 374857.12500	
908	 steps: training loss - 108724.38281	, testing loss - 373994.56250	
909	 steps: training loss - 138826.35938	, testing loss - 372404.25000	
910	 steps: training loss - 114572.77344	, testing loss - 370932.00000	
911	 steps: training loss - 135497.23438	, testing loss - 369015.06250	
912	 steps: training loss - 123214.23438	, testing loss - 367048.34375	
913	 steps: training loss - 110311.53125	, testing loss - 365846.96875	
914	 steps: training loss - 107515.71094	, testing loss - 364853.34375	
915	 steps: training loss - 130464.99219	, testing loss - 363831.40625	
916	 steps: training loss - 129317.33594	, testing loss - 363209.18750	
917	 steps: training loss - 120557.52344	, testing loss - 363790.56250	
918	 steps: training loss - 129805.99219	, testing loss - 364925.25000	
919	 steps: training loss - 119572.31250	, testing loss - 367452.78125	
920	 steps: training loss - 110925.49219	, testing loss - 370549.90625	
921	 steps: training loss - 119458.16406	, testing loss - 373494.90625	
922	 steps: training loss - 139144.82812	, testing loss - 376882.46875	
923	 steps: training loss - 112349.37500	, testing loss - 380581.21875	
924	 steps: training loss - 101633.89062	, testing loss - 383310.59375	
925	 steps: training loss - 136605.26562	, testing loss - 385881.68750	
926	 steps: training loss - 129886.03125	, testing loss - 386960.06250	
927	 steps: training loss - 133870.46875	, testing loss - 386089.34375	
928	 steps: training loss - 128561.02344	, testing loss - 384396.87500	
929	 steps: training loss - 111371.80469	, testing loss - 381385.68750	
930	 steps: training loss - 105408.78125	, testing loss - 378565.43750	
931	 steps: training loss - 98644.10938	, testing loss - 375035.81250	
932	 steps: training loss - 121585.38281	, testing loss - 372511.34375	
933	 steps: training loss - 106509.80469	, testing loss - 370587.03125	
934	 steps: training loss - 122703.60156	, testing loss - 369139.81250	
935	 steps: training loss - 100949.37500	, testing loss - 368157.81250	
936	 steps: training loss - 131686.46875	, testing loss - 367977.28125	
937	 steps: training loss - 139745.04688	, testing loss - 368060.18750	
938	 steps: training loss - 105802.81250	, testing loss - 369068.46875	
939	 steps: training loss - 152289.65625	, testing loss - 369061.87500	
940	 steps: training loss - 136976.12500	, testing loss - 369251.28125	
941	 steps: training loss - 122822.12500	, testing loss - 369501.87500	
942	 steps: training loss - 122349.03125	, testing loss - 369439.84375	
943	 steps: training loss - 95887.76562	, testing loss - 370834.06250	
944	 steps: training loss - 123974.20312	, testing loss - 372543.59375	
945	 steps: training loss - 113038.58594	, testing loss - 372900.40625	
946	 steps: training loss - 132610.37500	, testing loss - 372921.21875	
947	 steps: training loss - 116760.25000	, testing loss - 372579.03125	
948	 steps: training loss - 151360.39062	, testing loss - 372545.12500	
949	 steps: training loss - 132952.42188	, testing loss - 372944.37500	
950	 steps: training loss - 126528.03906	, testing loss - 372494.21875	
951	 steps: training loss - 96507.52344	, testing loss - 371504.37500	
952	 steps: training loss - 107203.99219	, testing loss - 370318.43750	
953	 steps: training loss - 100740.76562	, testing loss - 369786.43750	
954	 steps: training loss - 119022.57812	, testing loss - 369140.15625	
955	 steps: training loss - 104516.28906	, testing loss - 369115.59375	
956	 steps: training loss - 126568.35938	, testing loss - 368729.06250	
957	 steps: training loss - 119198.37500	, testing loss - 367734.65625	
958	 steps: training loss - 111225.67969	, testing loss - 366905.34375	
959	 steps: training loss - 133673.06250	, testing loss - 366088.62500	
960	 steps: training loss - 127764.16406	, testing loss - 365946.12500	
961	 steps: training loss - 125620.38281	, testing loss - 366344.81250	
962	 steps: training loss - 109986.25781	, testing loss - 366829.68750	
963	 steps: training loss - 127210.85938	, testing loss - 367519.93750	
964	 steps: training loss - 129340.53125	, testing loss - 367966.87500	
965	 steps: training loss - 92858.73438	, testing loss - 368841.25000	
966	 steps: training loss - 126798.71094	, testing loss - 370006.21875	
967	 steps: training loss - 83519.79688	, testing loss - 371719.03125	
968	 steps: training loss - 138077.73438	, testing loss - 373459.12500	
969	 steps: training loss - 102314.21875	, testing loss - 374076.21875	
970	 steps: training loss - 118167.46094	, testing loss - 374697.93750	
971	 steps: training loss - 106660.50000	, testing loss - 374953.34375	
972	 steps: training loss - 115767.51562	, testing loss - 374787.59375	
973	 steps: training loss - 103917.28906	, testing loss - 375529.56250	
974	 steps: training loss - 115649.14844	, testing loss - 375932.06250	
975	 steps: training loss - 141606.34375	, testing loss - 375491.96875	
976	 steps: training loss - 130947.28906	, testing loss - 375611.81250	
977	 steps: training loss - 106447.94531	, testing loss - 375421.50000	
978	 steps: training loss - 133331.56250	, testing loss - 375431.40625	
979	 steps: training loss - 107625.17969	, testing loss - 374887.43750	
980	 steps: training loss - 123101.87500	, testing loss - 374352.75000	
981	 steps: training loss - 143442.50000	, testing loss - 374401.00000	
982	 steps: training loss - 118470.72656	, testing loss - 374984.96875	
983	 steps: training loss - 136027.93750	, testing loss - 376243.56250	
984	 steps: training loss - 111127.78906	, testing loss - 377599.93750	
985	 steps: training loss - 123396.88281	, testing loss - 378975.15625	
986	 steps: training loss - 115346.70312	, testing loss - 379232.53125	
987	 steps: training loss - 92346.17188	, testing loss - 379022.65625	
988	 steps: training loss - 98394.62500	, testing loss - 378959.87500	
989	 steps: training loss - 118672.17188	, testing loss - 378339.56250	
990	 steps: training loss - 102490.12500	, testing loss - 378701.31250	
991	 steps: training loss - 120986.77344	, testing loss - 378312.68750	
992	 steps: training loss - 99747.79688	, testing loss - 376573.50000	
993	 steps: training loss - 110077.77344	, testing loss - 374904.53125	
994	 steps: training loss - 110409.25781	, testing loss - 373918.62500	
995	 steps: training loss - 128988.54688	, testing loss - 372919.46875	
996	 steps: training loss - 127267.32031	, testing loss - 372659.46875	
997	 steps: training loss - 102367.32812	, testing loss - 372717.15625	
998	 steps: training loss - 123614.46875	, testing loss - 373235.75000	
999	 steps: training loss - 105118.92969	, testing loss - 373871.50000	
1000	 steps: training loss - 131921.87500	, testing loss - 374510.53125	
1001	 steps: training loss - 113383.74219	, testing loss - 374947.68750	
1002	 steps: training loss - 124594.25000	, testing loss - 374755.62500	
1003	 steps: training loss - 120635.54688	, testing loss - 373993.31250	
1004	 steps: training loss - 132330.67188	, testing loss - 373190.34375	
1005	 steps: training loss - 103244.57812	, testing loss - 372980.68750	
1006	 steps: training loss - 117191.71094	, testing loss - 372804.50000	
1007	 steps: training loss - 99364.47656	, testing loss - 372717.43750	
1008	 steps: training loss - 125433.87500	, testing loss - 373331.46875	
1009	 steps: training loss - 126324.85938	, testing loss - 374323.12500	
1010	 steps: training loss - 135523.40625	, testing loss - 374994.18750	
1011	 steps: training loss - 128166.86719	, testing loss - 374405.62500	
1012	 steps: training loss - 138220.06250	, testing loss - 374174.87500	
1013	 steps: training loss - 145885.92188	, testing loss - 374136.53125	
1014	 steps: training loss - 133714.73438	, testing loss - 375319.78125	
1015	 steps: training loss - 129009.16406	, testing loss - 376882.40625	
1016	 steps: training loss - 106183.04688	, testing loss - 378908.68750	
1017	 steps: training loss - 105903.89844	, testing loss - 382040.90625	
1018	 steps: training loss - 122508.80469	, testing loss - 385983.31250	
1019	 steps: training loss - 128424.54688	, testing loss - 389114.59375	
1020	 steps: training loss - 139584.56250	, testing loss - 390148.65625	
1021	 steps: training loss - 130411.82031	, testing loss - 389863.62500	
1022	 steps: training loss - 102124.77344	, testing loss - 389388.84375	
1023	 steps: training loss - 113275.17188	, testing loss - 389139.12500	
1024	 steps: training loss - 116805.06250	, testing loss - 388238.84375	
1025	 steps: training loss - 112026.15625	, testing loss - 388722.25000	
1026	 steps: training loss - 94626.08594	, testing loss - 388850.59375	
1027	 steps: training loss - 128017.24219	, testing loss - 387801.75000	
1028	 steps: training loss - 110831.28125	, testing loss - 385424.25000	
1029	 steps: training loss - 100647.24219	, testing loss - 382546.37500	
1030	 steps: training loss - 135811.17188	, testing loss - 380257.18750	
1031	 steps: training loss - 135111.40625	, testing loss - 379674.31250	
1032	 steps: training loss - 108178.25781	, testing loss - 379363.40625	
1033	 steps: training loss - 81895.73438	, testing loss - 379053.34375	
1034	 steps: training loss - 115202.79688	, testing loss - 378590.59375	
1035	 steps: training loss - 111742.92188	, testing loss - 377922.28125	
1036	 steps: training loss - 112035.53906	, testing loss - 377458.56250	
1037	 steps: training loss - 113236.55469	, testing loss - 376698.18750	
1038	 steps: training loss - 122616.96875	, testing loss - 376109.28125	
1039	 steps: training loss - 99870.45312	, testing loss - 375664.12500	
1040	 steps: training loss - 127056.68750	, testing loss - 374958.25000	
1041	 steps: training loss - 125173.93750	, testing loss - 373578.46875	
1042	 steps: training loss - 136587.84375	, testing loss - 372179.90625	
1043	 steps: training loss - 119319.64844	, testing loss - 372241.03125	
1044	 steps: training loss - 125979.32812	, testing loss - 372815.81250	
1045	 steps: training loss - 122666.18750	, testing loss - 372828.84375	
1046	 steps: training loss - 86287.85938	, testing loss - 372496.75000	
1047	 steps: training loss - 103433.99219	, testing loss - 371624.18750	
1048	 steps: training loss - 119394.96875	, testing loss - 371146.03125	
1049	 steps: training loss - 92555.29688	, testing loss - 369804.12500	
1050	 steps: training loss - 106635.10938	, testing loss - 368023.31250	
1051	 steps: training loss - 107283.00000	, testing loss - 366685.40625	
1052	 steps: training loss - 117636.75000	, testing loss - 365215.90625	
1053	 steps: training loss - 108681.35938	, testing loss - 364493.81250	
1054	 steps: training loss - 94414.89844	, testing loss - 363880.15625	
1055	 steps: training loss - 156943.89062	, testing loss - 363334.31250	
1056	 steps: training loss - 121463.96875	, testing loss - 363406.06250	
1057	 steps: training loss - 126467.40625	, testing loss - 363693.84375	
1058	 steps: training loss - 108334.82031	, testing loss - 364070.59375	
1059	 steps: training loss - 115171.57812	, testing loss - 364516.43750	
1060	 steps: training loss - 99222.61719	, testing loss - 365366.59375	
1061	 steps: training loss - 109041.43750	, testing loss - 366793.31250	
1062	 steps: training loss - 123090.29688	, testing loss - 368744.00000	
1063	 steps: training loss - 110062.45312	, testing loss - 371435.15625	
1064	 steps: training loss - 123866.11719	, testing loss - 373687.31250	
1065	 steps: training loss - 122970.69531	, testing loss - 376338.50000	
1066	 steps: training loss - 93073.56250	, testing loss - 378296.68750	
1067	 steps: training loss - 122070.92188	, testing loss - 379665.53125	
1068	 steps: training loss - 125142.38281	, testing loss - 380609.96875	
1069	 steps: training loss - 112638.84375	, testing loss - 381250.06250	
1070	 steps: training loss - 113619.81250	, testing loss - 381718.06250	
1071	 steps: training loss - 110444.76562	, testing loss - 381320.15625	
1072	 steps: training loss - 136735.57812	, testing loss - 380429.40625	
1073	 steps: training loss - 143153.12500	, testing loss - 379180.93750	
1074	 steps: training loss - 106644.17188	, testing loss - 377908.28125	
1075	 steps: training loss - 106996.23438	, testing loss - 376283.62500	
1076	 steps: training loss - 130133.76562	, testing loss - 374346.81250	
1077	 steps: training loss - 143011.46875	, testing loss - 372994.18750	
1078	 steps: training loss - 123646.50781	, testing loss - 372113.03125	
1079	 steps: training loss - 112904.25000	, testing loss - 372035.21875	
1080	 steps: training loss - 111735.85938	, testing loss - 371695.65625	
1081	 steps: training loss - 124580.36719	, testing loss - 371128.93750	
1082	 steps: training loss - 101388.35156	, testing loss - 370163.71875	
1083	 steps: training loss - 131866.03125	, testing loss - 368993.09375	
1084	 steps: training loss - 116241.15625	, testing loss - 367661.68750	
1085	 steps: training loss - 136024.59375	, testing loss - 366386.71875	
1086	 steps: training loss - 100180.78906	, testing loss - 365210.53125	
1087	 steps: training loss - 142291.65625	, testing loss - 364560.12500	
1088	 steps: training loss - 111482.78906	, testing loss - 364070.03125	
1089	 steps: training loss - 144355.10938	, testing loss - 364257.18750	
1090	 steps: training loss - 124483.81250	, testing loss - 365656.84375	
1091	 steps: training loss - 106614.45312	, testing loss - 367793.84375	
1092	 steps: training loss - 162426.43750	, testing loss - 369693.31250	
1093	 steps: training loss - 116937.87500	, testing loss - 371143.15625	
1094	 steps: training loss - 132005.95312	, testing loss - 373328.12500	
1095	 steps: training loss - 120519.89062	, testing loss - 374068.40625	
1096	 steps: training loss - 117539.28906	, testing loss - 374619.87500	
1097	 steps: training loss - 124588.33594	, testing loss - 374539.50000	
1098	 steps: training loss - 141082.06250	, testing loss - 373736.50000	
1099	 steps: training loss - 134537.35938	, testing loss - 372678.09375	
1100	 steps: training loss - 120418.76562	, testing loss - 372556.62500	
1101	 steps: training loss - 116826.04688	, testing loss - 371514.71875	
1102	 steps: training loss - 129238.79688	, testing loss - 370599.18750	
1103	 steps: training loss - 121517.85156	, testing loss - 369354.46875	
1104	 steps: training loss - 135473.81250	, testing loss - 368261.68750	
1105	 steps: training loss - 123844.93750	, testing loss - 367897.68750	
1106	 steps: training loss - 105841.37500	, testing loss - 367689.46875	
1107	 steps: training loss - 132326.18750	, testing loss - 367977.71875	
1108	 steps: training loss - 124724.50000	, testing loss - 367711.50000	
1109	 steps: training loss - 107479.55469	, testing loss - 366999.65625	
1110	 steps: training loss - 101105.39844	, testing loss - 365802.00000	
1111	 steps: training loss - 128732.22656	, testing loss - 364565.50000	
1112	 steps: training loss - 97258.39844	, testing loss - 363854.87500	
1113	 steps: training loss - 132665.15625	, testing loss - 363926.50000	
1114	 steps: training loss - 114881.48438	, testing loss - 364747.15625	
1115	 steps: training loss - 117311.89062	, testing loss - 366805.87500	
1116	 steps: training loss - 132374.40625	, testing loss - 368971.40625	
1117	 steps: training loss - 140692.84375	, testing loss - 371003.78125	
1118	 steps: training loss - 120431.00000	, testing loss - 372598.03125	
1119	 steps: training loss - 129263.50781	, testing loss - 373846.18750	
1120	 steps: training loss - 114584.21094	, testing loss - 375643.50000	
1121	 steps: training loss - 98204.28906	, testing loss - 378552.06250	
1122	 steps: training loss - 106708.26562	, testing loss - 381843.93750	
1123	 steps: training loss - 115159.45312	, testing loss - 384429.34375	
1124	 steps: training loss - 106253.53906	, testing loss - 386996.71875	
1125	 steps: training loss - 111832.88281	, testing loss - 387719.87500	
1126	 steps: training loss - 151259.71875	, testing loss - 387939.90625	
1127	 steps: training loss - 112119.99219	, testing loss - 386535.96875	
1128	 steps: training loss - 109659.28125	, testing loss - 385902.37500	
1129	 steps: training loss - 123957.86719	, testing loss - 384729.00000	
1130	 steps: training loss - 116631.65625	, testing loss - 381719.75000	
1131	 steps: training loss - 115422.60156	, testing loss - 377871.56250	
1132	 steps: training loss - 97260.31250	, testing loss - 374751.71875	
1133	 steps: training loss - 131256.53125	, testing loss - 373077.37500	
1134	 steps: training loss - 123893.00000	, testing loss - 372165.75000	
1135	 steps: training loss - 131853.26562	, testing loss - 371476.71875	
1136	 steps: training loss - 106960.85938	, testing loss - 371796.53125	
1137	 steps: training loss - 136462.89062	, testing loss - 372422.75000	
1138	 steps: training loss - 121685.51562	, testing loss - 372743.62500	
1139	 steps: training loss - 126757.71094	, testing loss - 373293.15625	
1140	 steps: training loss - 116115.78125	, testing loss - 372732.21875	
1141	 steps: training loss - 102992.89844	, testing loss - 372685.40625	
1142	 steps: training loss - 123765.60938	, testing loss - 372796.40625	
1143	 steps: training loss - 108869.12500	, testing loss - 373498.56250	
1144	 steps: training loss - 126863.75000	, testing loss - 374186.96875	
1145	 steps: training loss - 117740.11719	, testing loss - 374663.53125	
1146	 steps: training loss - 131341.62500	, testing loss - 376157.78125	
1147	 steps: training loss - 123000.57031	, testing loss - 377517.15625	
1148	 steps: training loss - 108462.23438	, testing loss - 377440.71875	
1149	 steps: training loss - 142881.54688	, testing loss - 376134.03125	
1150	 steps: training loss - 112355.15625	, testing loss - 374529.90625	
1151	 steps: training loss - 116993.23438	, testing loss - 372808.06250	
1152	 steps: training loss - 101798.51562	, testing loss - 370855.87500	
1153	 steps: training loss - 108632.47656	, testing loss - 368593.75000	
1154	 steps: training loss - 120256.07031	, testing loss - 365919.62500	
1155	 steps: training loss - 136101.28125	, testing loss - 363791.78125	
1156	 steps: training loss - 121453.08594	, testing loss - 362501.46875	
1157	 steps: training loss - 108376.20312	, testing loss - 361671.71875	
1158	 steps: training loss - 107315.82031	, testing loss - 361571.34375	
1159	 steps: training loss - 138236.87500	, testing loss - 361816.25000	
1160	 steps: training loss - 141104.48438	, testing loss - 362558.15625	
1161	 steps: training loss - 130713.12500	, testing loss - 362673.62500	
1162	 steps: training loss - 117613.21875	, testing loss - 363210.00000	
1163	 steps: training loss - 126763.68750	, testing loss - 363693.09375	
1164	 steps: training loss - 115720.32812	, testing loss - 363917.65625	
1165	 steps: training loss - 91613.77344	, testing loss - 363673.71875	
1166	 steps: training loss - 109322.00000	, testing loss - 363955.78125	
1167	 steps: training loss - 113216.77344	, testing loss - 364472.62500	
1168	 steps: training loss - 113664.48438	, testing loss - 364505.46875	
1169	 steps: training loss - 109098.93750	, testing loss - 364309.28125	
1170	 steps: training loss - 121603.22656	, testing loss - 364334.96875	
1171	 steps: training loss - 111605.10156	, testing loss - 364524.25000	
1172	 steps: training loss - 132775.23438	, testing loss - 364368.28125	
1173	 steps: training loss - 116652.59375	, testing loss - 364855.37500	
1174	 steps: training loss - 146434.00000	, testing loss - 365792.46875	
1175	 steps: training loss - 117716.57812	, testing loss - 367250.46875	
1176	 steps: training loss - 118111.44531	, testing loss - 368608.75000	
1177	 steps: training loss - 114387.67969	, testing loss - 369477.12500	
1178	 steps: training loss - 127608.78125	, testing loss - 370641.53125	
1179	 steps: training loss - 117131.13281	, testing loss - 371949.28125	
1180	 steps: training loss - 115079.10156	, testing loss - 372527.62500	
1181	 steps: training loss - 124941.77344	, testing loss - 372890.21875	
1182	 steps: training loss - 116119.64062	, testing loss - 372588.65625	
1183	 steps: training loss - 132882.10938	, testing loss - 371218.81250	
1184	 steps: training loss - 115292.64844	, testing loss - 369579.15625	
1185	 steps: training loss - 117804.29688	, testing loss - 368871.96875	
1186	 steps: training loss - 109296.18750	, testing loss - 368126.90625	
1187	 steps: training loss - 141887.76562	, testing loss - 367473.21875	
1188	 steps: training loss - 87031.60156	, testing loss - 367270.75000	
1189	 steps: training loss - 116368.42969	, testing loss - 366957.78125	
1190	 steps: training loss - 129139.10156	, testing loss - 365715.09375	
1191	 steps: training loss - 108758.54688	, testing loss - 365330.65625	
1192	 steps: training loss - 131539.43750	, testing loss - 365403.34375	
1193	 steps: training loss - 116176.46094	, testing loss - 365346.46875	
1194	 steps: training loss - 134185.14062	, testing loss - 365555.31250	
1195	 steps: training loss - 114007.06250	, testing loss - 366050.15625	
1196	 steps: training loss - 115477.97656	, testing loss - 367227.34375	
1197	 steps: training loss - 109811.18750	, testing loss - 368229.50000	
1198	 steps: training loss - 106845.00000	, testing loss - 368905.96875	
1199	 steps: training loss - 104569.64844	, testing loss - 370004.12500	
1200	 steps: training loss - 115225.00000	, testing loss - 370201.31250	
1201	 steps: training loss - 113414.78906	, testing loss - 370472.37500	
1202	 steps: training loss - 101782.14062	, testing loss - 370910.15625	
1203	 steps: training loss - 99798.89062	, testing loss - 371977.90625	
1204	 steps: training loss - 138647.43750	, testing loss - 373723.31250	
1205	 steps: training loss - 113863.92969	, testing loss - 375319.59375	
1206	 steps: training loss - 115789.14062	, testing loss - 375728.34375	
1207	 steps: training loss - 98433.17969	, testing loss - 376529.75000	
1208	 steps: training loss - 136750.43750	, testing loss - 377126.40625	
1209	 steps: training loss - 122369.53125	, testing loss - 378128.56250	
1210	 steps: training loss - 112525.00000	, testing loss - 378432.40625	
1211	 steps: training loss - 117371.32812	, testing loss - 378076.18750	
1212	 steps: training loss - 117981.98438	, testing loss - 377807.09375	
1213	 steps: training loss - 115655.97656	, testing loss - 377798.40625	
1214	 steps: training loss - 127101.17969	, testing loss - 377642.21875	
1215	 steps: training loss - 121357.76562	, testing loss - 376797.62500	
1216	 steps: training loss - 132751.89062	, testing loss - 375743.81250	
1217	 steps: training loss - 133518.57812	, testing loss - 374293.28125	
1218	 steps: training loss - 129004.92969	, testing loss - 373803.65625	
1219	 steps: training loss - 121881.99219	, testing loss - 373855.46875	
1220	 steps: training loss - 129307.50000	, testing loss - 373686.65625	
1221	 steps: training loss - 118127.40625	, testing loss - 373131.62500	
1222	 steps: training loss - 93864.46875	, testing loss - 372906.12500	
1223	 steps: training loss - 120792.12500	, testing loss - 372339.34375	
1224	 steps: training loss - 121247.79688	, testing loss - 371547.40625	
1225	 steps: training loss - 132050.82812	, testing loss - 370276.59375	
1226	 steps: training loss - 121530.65625	, testing loss - 368989.50000	
1227	 steps: training loss - 128623.93750	, testing loss - 367979.12500	
1228	 steps: training loss - 130327.93750	, testing loss - 368063.65625	
1229	 steps: training loss - 141694.76562	, testing loss - 368184.53125	
1230	 steps: training loss - 117997.33594	, testing loss - 367950.34375	
1231	 steps: training loss - 117613.60156	, testing loss - 367857.87500	
1232	 steps: training loss - 136915.54688	, testing loss - 367995.84375	
1233	 steps: training loss - 138068.54688	, testing loss - 367665.81250	
1234	 steps: training loss - 116149.10938	, testing loss - 367301.37500	
1235	 steps: training loss - 123229.78125	, testing loss - 367708.71875	
1236	 steps: training loss - 144354.14062	, testing loss - 368992.90625	
1237	 steps: training loss - 113599.04688	, testing loss - 370050.40625	
1238	 steps: training loss - 129153.51562	, testing loss - 370963.40625	
1239	 steps: training loss - 85436.90625	, testing loss - 371198.31250	
1240	 steps: training loss - 109112.64062	, testing loss - 371580.78125	
1241	 steps: training loss - 100879.94531	, testing loss - 371397.12500	
1242	 steps: training loss - 114920.82812	, testing loss - 370919.12500	
1243	 steps: training loss - 107531.89844	, testing loss - 370701.65625	
1244	 steps: training loss - 106418.41406	, testing loss - 369697.06250	
1245	 steps: training loss - 137794.14062	, testing loss - 368798.31250	
1246	 steps: training loss - 111839.67969	, testing loss - 368243.18750	
1247	 steps: training loss - 108050.38281	, testing loss - 367873.15625	
1248	 steps: training loss - 115442.56250	, testing loss - 367914.09375	
1249	 steps: training loss - 136300.81250	, testing loss - 367923.09375	
1250	 steps: training loss - 105193.94531	, testing loss - 368984.53125	
1251	 steps: training loss - 114473.28906	, testing loss - 371059.15625	
1252	 steps: training loss - 132679.62500	, testing loss - 372937.06250	
1253	 steps: training loss - 121905.55469	, testing loss - 374336.53125	
1254	 steps: training loss - 116730.14844	, testing loss - 375425.50000	
1255	 steps: training loss - 100451.00000	, testing loss - 375516.12500	
1256	 steps: training loss - 101750.46875	, testing loss - 375556.68750	
1257	 steps: training loss - 115355.98438	, testing loss - 376068.09375	
1258	 steps: training loss - 120506.61719	, testing loss - 376576.90625	
1259	 steps: training loss - 104445.39844	, testing loss - 378483.40625	
1260	 steps: training loss - 123227.33594	, testing loss - 380072.84375	
1261	 steps: training loss - 102726.33594	, testing loss - 381486.56250	
1262	 steps: training loss - 121558.70312	, testing loss - 382516.18750	
1263	 steps: training loss - 131663.26562	, testing loss - 382672.81250	
1264	 steps: training loss - 128409.78906	, testing loss - 381986.06250	
1265	 steps: training loss - 111066.05469	, testing loss - 380738.18750	
1266	 steps: training loss - 103440.59375	, testing loss - 380031.12500	
1267	 steps: training loss - 94241.03125	, testing loss - 380930.46875	
1268	 steps: training loss - 114764.78125	, testing loss - 381411.90625	
1269	 steps: training loss - 103820.67188	, testing loss - 380392.46875	
1270	 steps: training loss - 110972.16406	, testing loss - 378387.53125	
1271	 steps: training loss - 107967.28906	, testing loss - 376536.00000	
1272	 steps: training loss - 105697.92969	, testing loss - 374869.50000	
1273	 steps: training loss - 100455.82812	, testing loss - 373437.40625	
1274	 steps: training loss - 122024.16406	, testing loss - 372323.34375	
1275	 steps: training loss - 110311.53906	, testing loss - 371607.65625	
1276	 steps: training loss - 111036.01562	, testing loss - 371199.59375	
1277	 steps: training loss - 109204.30469	, testing loss - 371141.53125	
1278	 steps: training loss - 110289.68750	, testing loss - 370851.81250	
1279	 steps: training loss - 123328.47656	, testing loss - 371084.06250	
1280	 steps: training loss - 122472.60938	, testing loss - 371195.06250	
1281	 steps: training loss - 115337.03125	, testing loss - 370519.31250	
1282	 steps: training loss - 106025.96094	, testing loss - 369350.84375	
1283	 steps: training loss - 116100.89062	, testing loss - 368461.84375	
1284	 steps: training loss - 120768.89844	, testing loss - 368053.31250	
1285	 steps: training loss - 108367.59375	, testing loss - 367964.43750	
1286	 steps: training loss - 113237.00000	, testing loss - 367458.62500	
1287	 steps: training loss - 113386.25000	, testing loss - 366887.43750	
1288	 steps: training loss - 133983.18750	, testing loss - 366680.87500	
1289	 steps: training loss - 113605.04688	, testing loss - 366678.53125	
1290	 steps: training loss - 117619.12500	, testing loss - 366995.43750	
1291	 steps: training loss - 122138.26562	, testing loss - 367455.12500	
1292	 steps: training loss - 116639.22656	, testing loss - 367758.40625	
1293	 steps: training loss - 115073.17188	, testing loss - 368124.03125	
1294	 steps: training loss - 96654.17188	, testing loss - 368264.71875	
1295	 steps: training loss - 112752.82812	, testing loss - 369144.00000	
1296	 steps: training loss - 113121.54688	, testing loss - 369408.50000	
1297	 steps: training loss - 112701.70312	, testing loss - 368788.00000	
1298	 steps: training loss - 122622.45312	, testing loss - 368242.28125	
1299	 steps: training loss - 117804.29688	, testing loss - 368068.06250	
1300	 steps: training loss - 98823.60156	, testing loss - 367659.00000	
1301	 steps: training loss - 140327.48438	, testing loss - 367536.75000	
1302	 steps: training loss - 133578.46875	, testing loss - 368271.53125	
1303	 steps: training loss - 123837.23438	, testing loss - 369036.37500	
1304	 steps: training loss - 105768.53125	, testing loss - 369003.18750	
1305	 steps: training loss - 135601.90625	, testing loss - 369219.90625	
1306	 steps: training loss - 142301.57812	, testing loss - 371078.59375	
1307	 steps: training loss - 119293.17188	, testing loss - 374271.00000	
1308	 steps: training loss - 128594.10938	, testing loss - 377769.65625	
1309	 steps: training loss - 143962.06250	, testing loss - 381248.50000	
1310	 steps: training loss - 134822.85938	, testing loss - 384338.46875	
1311	 steps: training loss - 158694.07812	, testing loss - 387548.53125	
1312	 steps: training loss - 126129.80469	, testing loss - 391022.71875	
1313	 steps: training loss - 130228.31250	, testing loss - 393117.90625	
1314	 steps: training loss - 130897.14062	, testing loss - 394191.28125	
1315	 steps: training loss - 107042.84375	, testing loss - 395055.87500	
1316	 steps: training loss - 124774.87500	, testing loss - 394493.37500	
1317	 steps: training loss - 90337.90625	, testing loss - 392433.50000	
1318	 steps: training loss - 102668.75781	, testing loss - 390867.46875	
1319	 steps: training loss - 119161.33594	, testing loss - 390085.06250	
1320	 steps: training loss - 107666.89062	, testing loss - 388924.43750	
1321	 steps: training loss - 112479.59375	, testing loss - 387057.40625	
1322	 steps: training loss - 96365.93750	, testing loss - 386806.50000	
1323	 steps: training loss - 131829.67188	, testing loss - 385450.93750	
1324	 steps: training loss - 88851.45312	, testing loss - 382655.21875	
1325	 steps: training loss - 106693.72656	, testing loss - 379591.09375	
1326	 steps: training loss - 124002.09375	, testing loss - 377756.37500	
1327	 steps: training loss - 125771.70312	, testing loss - 375732.53125	
1328	 steps: training loss - 80647.63281	, testing loss - 374772.18750	
1329	 steps: training loss - 114510.66406	, testing loss - 374174.37500	
1330	 steps: training loss - 113560.15625	, testing loss - 373582.75000	
1331	 steps: training loss - 116021.67188	, testing loss - 372517.59375	
1332	 steps: training loss - 118643.88281	, testing loss - 371788.50000	
1333	 steps: training loss - 139264.00000	, testing loss - 371674.03125	
1334	 steps: training loss - 147417.12500	, testing loss - 372863.00000	
1335	 steps: training loss - 110591.55469	, testing loss - 374956.12500	
1336	 steps: training loss - 94106.82031	, testing loss - 377515.34375	
1337	 steps: training loss - 122975.47656	, testing loss - 379884.40625	
1338	 steps: training loss - 124182.46094	, testing loss - 380770.12500	
1339	 steps: training loss - 97620.21875	, testing loss - 382502.87500	
1340	 steps: training loss - 136957.84375	, testing loss - 384000.71875	
1341	 steps: training loss - 132723.78125	, testing loss - 382915.25000	
1342	 steps: training loss - 97145.31250	, testing loss - 381033.12500	
1343	 steps: training loss - 126039.91406	, testing loss - 379010.25000	
1344	 steps: training loss - 103256.00781	, testing loss - 378234.68750	
1345	 steps: training loss - 116357.10156	, testing loss - 379515.56250	
1346	 steps: training loss - 141898.00000	, testing loss - 380724.50000	
1347	 steps: training loss - 111212.19531	, testing loss - 381854.34375	
1348	 steps: training loss - 99866.23438	, testing loss - 382709.84375	
1349	 steps: training loss - 108204.34375	, testing loss - 382500.46875	
1350	 steps: training loss - 106978.27344	, testing loss - 380917.06250	
1351	 steps: training loss - 130762.50000	, testing loss - 378888.56250	
1352	 steps: training loss - 93608.00781	, testing loss - 377555.96875	
1353	 steps: training loss - 86893.07031	, testing loss - 376426.96875	
1354	 steps: training loss - 128443.82812	, testing loss - 375929.09375	
1355	 steps: training loss - 113568.42969	, testing loss - 375796.75000	
1356	 steps: training loss - 120605.75000	, testing loss - 375681.37500	
1357	 steps: training loss - 112255.54688	, testing loss - 375845.87500	
1358	 steps: training loss - 126437.89844	, testing loss - 375915.71875	
1359	 steps: training loss - 93076.55469	, testing loss - 376344.09375	
1360	 steps: training loss - 108188.84375	, testing loss - 376146.75000	
1361	 steps: training loss - 119716.33594	, testing loss - 375708.71875	
1362	 steps: training loss - 114324.69531	, testing loss - 374109.21875	
1363	 steps: training loss - 118576.52344	, testing loss - 372554.40625	
1364	 steps: training loss - 104859.10156	, testing loss - 370897.15625	
1365	 steps: training loss - 136712.82812	, testing loss - 369688.84375	
1366	 steps: training loss - 110168.34375	, testing loss - 369350.21875	
1367	 steps: training loss - 113156.40625	, testing loss - 368999.40625	
1368	 steps: training loss - 121874.87500	, testing loss - 368729.53125	
1369	 steps: training loss - 134064.75000	, testing loss - 368926.43750	
1370	 steps: training loss - 102445.29688	, testing loss - 369030.09375	
1371	 steps: training loss - 115587.31250	, testing loss - 368851.28125	
1372	 steps: training loss - 119736.46094	, testing loss - 369495.50000	
1373	 steps: training loss - 85448.50781	, testing loss - 369963.15625	
1374	 steps: training loss - 125320.35938	, testing loss - 369764.06250	
1375	 steps: training loss - 104390.40625	, testing loss - 370422.71875	
1376	 steps: training loss - 142157.10938	, testing loss - 371281.87500	
1377	 steps: training loss - 143336.29688	, testing loss - 372151.46875	
1378	 steps: training loss - 92829.05469	, testing loss - 372608.18750	
1379	 steps: training loss - 100292.46094	, testing loss - 372233.84375	
1380	 steps: training loss - 120679.65625	, testing loss - 371731.84375	
1381	 steps: training loss - 93065.17969	, testing loss - 371717.53125	
1382	 steps: training loss - 121398.38281	, testing loss - 371479.68750	
1383	 steps: training loss - 113293.29688	, testing loss - 370941.71875	
1384	 steps: training loss - 100719.53906	, testing loss - 371188.68750	
1385	 steps: training loss - 119335.39844	, testing loss - 371588.75000	
1386	 steps: training loss - 112192.80469	, testing loss - 372305.96875	
1387	 steps: training loss - 91683.01562	, testing loss - 372929.43750	
1388	 steps: training loss - 138874.31250	, testing loss - 373389.96875	
1389	 steps: training loss - 82076.45312	, testing loss - 374003.37500	
1390	 steps: training loss - 128684.92188	, testing loss - 374583.90625	
1391	 steps: training loss - 142690.29688	, testing loss - 374678.21875	
1392	 steps: training loss - 130029.18750	, testing loss - 374151.00000	
1393	 steps: training loss - 121565.70312	, testing loss - 373960.18750	
1394	 steps: training loss - 98771.47656	, testing loss - 373395.15625	
1395	 steps: training loss - 104550.92188	, testing loss - 372505.87500	
1396	 steps: training loss - 119505.95312	, testing loss - 371974.90625	
1397	 steps: training loss - 90472.90625	, testing loss - 371234.90625	
1398	 steps: training loss - 122378.35156	, testing loss - 370574.06250	
1399	 steps: training loss - 110794.89062	, testing loss - 369660.00000	
1400	 steps: training loss - 90701.43750	, testing loss - 369195.06250	
1401	 steps: training loss - 92856.08594	, testing loss - 368879.12500	
1402	 steps: training loss - 105673.78906	, testing loss - 367987.43750	
1403	 steps: training loss - 96269.61719	, testing loss - 367918.50000	
1404	 steps: training loss - 129395.99219	, testing loss - 368596.84375	
1405	 steps: training loss - 113907.40625	, testing loss - 369348.28125	
1406	 steps: training loss - 115011.63281	, testing loss - 370659.37500	
1407	 steps: training loss - 129314.33594	, testing loss - 372045.34375	
1408	 steps: training loss - 121847.63281	, testing loss - 373846.46875	
1409	 steps: training loss - 96202.07812	, testing loss - 376416.31250	
1410	 steps: training loss - 100929.67188	, testing loss - 377756.53125	
1411	 steps: training loss - 98014.98438	, testing loss - 379388.50000	
1412	 steps: training loss - 142181.73438	, testing loss - 380814.46875	
1413	 steps: training loss - 136562.87500	, testing loss - 381221.00000	
1414	 steps: training loss - 117905.96875	, testing loss - 381747.59375	
1415	 steps: training loss - 140286.96875	, testing loss - 381727.37500	
1416	 steps: training loss - 150710.56250	, testing loss - 381737.31250	
1417	 steps: training loss - 130784.81250	, testing loss - 379861.93750	
1418	 steps: training loss - 140897.75000	, testing loss - 377563.68750	
1419	 steps: training loss - 111597.49219	, testing loss - 374027.21875	
1420	 steps: training loss - 126388.88281	, testing loss - 369504.40625	
1421	 steps: training loss - 129449.42188	, testing loss - 365870.78125	
1422	 steps: training loss - 119194.11719	, testing loss - 363257.71875	
1423	 steps: training loss - 104628.73438	, testing loss - 362003.03125	
1424	 steps: training loss - 114196.46875	, testing loss - 361664.65625	
1425	 steps: training loss - 134294.75000	, testing loss - 361493.21875	
1426	 steps: training loss - 107459.16406	, testing loss - 361998.81250	
1427	 steps: training loss - 123142.89062	, testing loss - 363501.25000	
1428	 steps: training loss - 113967.67969	, testing loss - 366364.21875	
1429	 steps: training loss - 112666.79688	, testing loss - 369453.62500	
1430	 steps: training loss - 124354.50781	, testing loss - 372747.31250	
1431	 steps: training loss - 122108.57031	, testing loss - 375750.93750	
1432	 steps: training loss - 125760.86719	, testing loss - 377740.34375	
1433	 steps: training loss - 141778.00000	, testing loss - 380231.46875	
1434	 steps: training loss - 109994.82812	, testing loss - 382724.87500	
1435	 steps: training loss - 108347.07031	, testing loss - 386214.15625	
1436	 steps: training loss - 101920.71094	, testing loss - 387852.71875	
1437	 steps: training loss - 90042.90625	, testing loss - 389492.90625	
1438	 steps: training loss - 113263.09375	, testing loss - 392168.34375	
1439	 steps: training loss - 115287.40625	, testing loss - 393571.15625	
1440	 steps: training loss - 122732.81250	, testing loss - 394430.31250	
1441	 steps: training loss - 107924.49219	, testing loss - 395385.00000	
1442	 steps: training loss - 136326.35938	, testing loss - 395953.78125	
1443	 steps: training loss - 127803.23438	, testing loss - 393911.37500	
1444	 steps: training loss - 122149.07812	, testing loss - 389641.00000	
1445	 steps: training loss - 99793.16406	, testing loss - 384914.21875	
1446	 steps: training loss - 116956.67188	, testing loss - 381170.00000	
1447	 steps: training loss - 120936.29688	, testing loss - 377601.34375	
1448	 steps: training loss - 109724.76562	, testing loss - 375015.12500	
1449	 steps: training loss - 129896.01562	, testing loss - 372106.15625	
1450	 steps: training loss - 117192.05469	, testing loss - 369588.56250	
1451	 steps: training loss - 103558.86719	, testing loss - 366832.06250	
1452	 steps: training loss - 125093.81250	, testing loss - 364798.93750	
1453	 steps: training loss - 101060.72656	, testing loss - 363847.12500	
1454	 steps: training loss - 111155.40625	, testing loss - 364075.53125	
1455	 steps: training loss - 115405.45312	, testing loss - 364213.21875	
1456	 steps: training loss - 119392.97656	, testing loss - 364077.03125	
1457	 steps: training loss - 98292.96875	, testing loss - 364417.81250	
1458	 steps: training loss - 131251.78125	, testing loss - 365236.40625	
1459	 steps: training loss - 118638.89844	, testing loss - 366847.12500	
1460	 steps: training loss - 138168.07812	, testing loss - 368527.78125	
1461	 steps: training loss - 122460.03125	, testing loss - 370020.53125	
1462	 steps: training loss - 112155.70312	, testing loss - 369943.56250	
1463	 steps: training loss - 122158.88281	, testing loss - 370584.78125	
1464	 steps: training loss - 114944.96875	, testing loss - 370501.12500	
1465	 steps: training loss - 124434.89062	, testing loss - 370578.03125	
1466	 steps: training loss - 129820.79688	, testing loss - 371400.50000	
1467	 steps: training loss - 129624.53906	, testing loss - 372155.87500	
1468	 steps: training loss - 132546.59375	, testing loss - 372741.71875	
1469	 steps: training loss - 133237.25000	, testing loss - 372170.65625	
1470	 steps: training loss - 111002.07031	, testing loss - 371319.34375	
1471	 steps: training loss - 97748.35938	, testing loss - 370077.43750	
1472	 steps: training loss - 110407.92969	, testing loss - 369713.71875	
1473	 steps: training loss - 89398.54688	, testing loss - 369544.56250	
1474	 steps: training loss - 94513.21094	, testing loss - 369168.56250	
1475	 steps: training loss - 118569.74219	, testing loss - 368702.37500	
1476	 steps: training loss - 133796.17188	, testing loss - 369182.40625	
1477	 steps: training loss - 123061.23438	, testing loss - 370540.34375	
1478	 steps: training loss - 110666.54688	, testing loss - 371186.50000	
1479	 steps: training loss - 121482.23438	, testing loss - 370611.21875	
1480	 steps: training loss - 129180.28906	, testing loss - 370185.46875	
1481	 steps: training loss - 124672.95312	, testing loss - 369869.62500	
1482	 steps: training loss - 122068.90625	, testing loss - 369014.93750	
1483	 steps: training loss - 111219.88281	, testing loss - 368388.43750	
1484	 steps: training loss - 108020.29688	, testing loss - 367582.78125	
1485	 steps: training loss - 104742.79688	, testing loss - 367271.09375	
1486	 steps: training loss - 129172.01562	, testing loss - 367099.59375	
1487	 steps: training loss - 127109.60938	, testing loss - 366647.43750	
1488	 steps: training loss - 140088.03125	, testing loss - 365663.03125	
1489	 steps: training loss - 140672.54688	, testing loss - 365502.75000	
1490	 steps: training loss - 115397.55469	, testing loss - 366624.18750	
1491	 steps: training loss - 138041.65625	, testing loss - 367748.03125	
1492	 steps: training loss - 106077.89844	, testing loss - 368861.50000	
1493	 steps: training loss - 112111.42969	, testing loss - 369916.65625	
1494	 steps: training loss - 126512.96875	, testing loss - 370888.37500	
1495	 steps: training loss - 126962.64844	, testing loss - 371679.75000	
1496	 steps: training loss - 137079.98438	, testing loss - 371446.00000	
1497	 steps: training loss - 111663.42188	, testing loss - 370157.78125	
1498	 steps: training loss - 128927.54688	, testing loss - 368061.31250	
1499	 steps: training loss - 120682.25781	, testing loss - 366045.34375	
1500	 steps: training loss - 108697.71094	, testing loss - 365105.50000	
1501	 steps: training loss - 144607.65625	, testing loss - 365591.59375	
1502	 steps: training loss - 121739.75000	, testing loss - 366823.31250	
1503	 steps: training loss - 108038.37500	, testing loss - 368156.12500	
1504	 steps: training loss - 106346.79688	, testing loss - 369253.34375	
1505	 steps: training loss - 100779.86719	, testing loss - 371029.15625	
1506	 steps: training loss - 108734.99219	, testing loss - 372603.28125	
1507	 steps: training loss - 108990.65625	, testing loss - 373005.62500	
1508	 steps: training loss - 101913.11719	, testing loss - 372543.09375	
1509	 steps: training loss - 90546.05469	, testing loss - 372436.78125	
1510	 steps: training loss - 92714.03125	, testing loss - 372179.78125	
1511	 steps: training loss - 126551.15625	, testing loss - 371974.40625	
1512	 steps: training loss - 115501.98438	, testing loss - 372027.96875	
1513	 steps: training loss - 113645.14844	, testing loss - 372123.68750	
1514	 steps: training loss - 94920.71875	, testing loss - 371347.75000	
1515	 steps: training loss - 123132.78125	, testing loss - 370575.68750	
1516	 steps: training loss - 113123.72656	, testing loss - 370428.71875	
1517	 steps: training loss - 125167.39062	, testing loss - 370487.84375	
1518	 steps: training loss - 105499.54688	, testing loss - 370898.78125	
1519	 steps: training loss - 135636.01562	, testing loss - 370314.78125	
1520	 steps: training loss - 94557.82812	, testing loss - 369662.87500	
1521	 steps: training loss - 125063.87500	, testing loss - 369008.56250	
1522	 steps: training loss - 125725.59375	, testing loss - 367723.03125	
1523	 steps: training loss - 124181.82031	, testing loss - 365937.53125	
1524	 steps: training loss - 100383.74219	, testing loss - 364820.78125	
1525	 steps: training loss - 111818.92188	, testing loss - 364038.53125	
1526	 steps: training loss - 109289.77344	, testing loss - 362752.28125	
1527	 steps: training loss - 112150.29688	, testing loss - 362056.96875	
1528	 steps: training loss - 109508.55469	, testing loss - 360900.87500	
1529	 steps: training loss - 104756.91406	, testing loss - 360066.06250	
1530	 steps: training loss - 116854.72656	, testing loss - 359868.56250	
1531	 steps: training loss - 123920.93750	, testing loss - 359625.78125	
1532	 steps: training loss - 137747.15625	, testing loss - 359318.00000	
1533	 steps: training loss - 130939.06250	, testing loss - 359134.62500	
1534	 steps: training loss - 131418.28125	, testing loss - 358722.03125	
1535	 steps: training loss - 108482.57812	, testing loss - 358301.50000	
1536	 steps: training loss - 125569.41406	, testing loss - 358160.56250	
1537	 steps: training loss - 145810.57812	, testing loss - 357933.59375	
1538	 steps: training loss - 124784.79688	, testing loss - 358636.96875	
1539	 steps: training loss - 93993.52344	, testing loss - 360533.62500	
1540	 steps: training loss - 137085.53125	, testing loss - 362692.25000	
1541	 steps: training loss - 113937.41406	, testing loss - 365618.50000	
1542	 steps: training loss - 127724.11719	, testing loss - 368596.21875	
1543	 steps: training loss - 124455.62500	, testing loss - 372618.53125	
1544	 steps: training loss - 118861.66406	, testing loss - 376594.40625	
1545	 steps: training loss - 105418.39062	, testing loss - 379267.43750	
1546	 steps: training loss - 113153.88281	, testing loss - 380810.68750	
1547	 steps: training loss - 110059.96094	, testing loss - 382134.53125	
1548	 steps: training loss - 116780.58594	, testing loss - 382800.37500	
1549	 steps: training loss - 129028.19531	, testing loss - 382816.15625	
1550	 steps: training loss - 124275.45312	, testing loss - 382467.31250	
1551	 steps: training loss - 106144.21875	, testing loss - 380921.93750	
1552	 steps: training loss - 104713.01562	, testing loss - 379875.75000	
1553	 steps: training loss - 127538.21094	, testing loss - 379329.46875	
1554	 steps: training loss - 137151.67188	, testing loss - 377942.40625	
1555	 steps: training loss - 139919.40625	, testing loss - 375312.96875	
1556	 steps: training loss - 103827.53906	, testing loss - 373459.43750	
1557	 steps: training loss - 119418.11719	, testing loss - 372593.78125	
1558	 steps: training loss - 112565.18750	, testing loss - 372763.87500	
1559	 steps: training loss - 100210.15625	, testing loss - 373510.84375	
1560	 steps: training loss - 124829.36719	, testing loss - 373896.59375	
1561	 steps: training loss - 102789.65625	, testing loss - 374293.87500	
1562	 steps: training loss - 110358.25781	, testing loss - 374828.90625	
1563	 steps: training loss - 97952.95312	, testing loss - 374983.15625	
1564	 steps: training loss - 122343.60156	, testing loss - 375360.93750	
1565	 steps: training loss - 98220.63281	, testing loss - 374250.96875	
1566	 steps: training loss - 119448.25000	, testing loss - 372842.12500	
1567	 steps: training loss - 111647.74219	, testing loss - 371916.37500	
1568	 steps: training loss - 108342.25000	, testing loss - 372434.12500	
1569	 steps: training loss - 133999.81250	, testing loss - 373068.90625	
1570	 steps: training loss - 110562.53125	, testing loss - 373369.00000	
1571	 steps: training loss - 132195.50000	, testing loss - 373623.59375	
1572	 steps: training loss - 103535.82031	, testing loss - 373185.90625	
1573	 steps: training loss - 133032.04688	, testing loss - 372790.31250	
1574	 steps: training loss - 111677.74219	, testing loss - 371930.09375	
1575	 steps: training loss - 121193.10156	, testing loss - 371287.37500	
1576	 steps: training loss - 117196.46875	, testing loss - 370532.81250	
1577	 steps: training loss - 94994.17969	, testing loss - 369820.31250	
1578	 steps: training loss - 127008.16406	, testing loss - 369104.90625	
1579	 steps: training loss - 112542.65625	, testing loss - 368481.59375	
1580	 steps: training loss - 119534.87500	, testing loss - 368874.84375	
1581	 steps: training loss - 112641.97656	, testing loss - 369573.68750	
1582	 steps: training loss - 145424.25000	, testing loss - 370499.87500	
1583	 steps: training loss - 146629.54688	, testing loss - 372203.15625	
1584	 steps: training loss - 117233.67969	, testing loss - 374639.03125	
1585	 steps: training loss - 109499.50781	, testing loss - 377232.90625	
1586	 steps: training loss - 125989.03906	, testing loss - 379316.75000	
1587	 steps: training loss - 120478.53906	, testing loss - 382426.03125	
1588	 steps: training loss - 85054.48438	, testing loss - 384559.96875	
1589	 steps: training loss - 109326.16406	, testing loss - 384575.93750	
1590	 steps: training loss - 116716.67969	, testing loss - 384700.37500	
1591	 steps: training loss - 137406.92188	, testing loss - 384252.03125	
1592	 steps: training loss - 125512.93750	, testing loss - 382293.90625	
1593	 steps: training loss - 124684.46875	, testing loss - 380493.31250	
1594	 steps: training loss - 95088.12500	, testing loss - 377753.75000	
1595	 steps: training loss - 111219.21875	, testing loss - 376011.09375	
1596	 steps: training loss - 100343.28125	, testing loss - 373913.34375	
1597	 steps: training loss - 104763.00000	, testing loss - 371235.12500	
1598	 steps: training loss - 91906.78906	, testing loss - 369200.25000	
1599	 steps: training loss - 126761.91406	, testing loss - 367437.59375	
1600	 steps: training loss - 131451.62500	, testing loss - 365961.43750	
1601	 steps: training loss - 96645.82812	, testing loss - 363913.81250	
1602	 steps: training loss - 116811.11719	, testing loss - 362131.12500	
1603	 steps: training loss - 105372.91406	, testing loss - 360377.12500	
1604	 steps: training loss - 116115.23438	, testing loss - 359351.68750	
1605	 steps: training loss - 110618.96875	, testing loss - 359443.71875	
1606	 steps: training loss - 122635.71875	, testing loss - 360311.25000	
1607	 steps: training loss - 116726.95312	, testing loss - 362017.53125	
1608	 steps: training loss - 112448.98438	, testing loss - 364131.34375	
1609	 steps: training loss - 112881.93750	, testing loss - 365702.15625	
1610	 steps: training loss - 102730.75781	, testing loss - 366460.50000	
1611	 steps: training loss - 109485.12500	, testing loss - 366998.37500	
1612	 steps: training loss - 93542.99219	, testing loss - 367252.93750	
1613	 steps: training loss - 122776.40625	, testing loss - 367666.87500	
1614	 steps: training loss - 129247.72656	, testing loss - 367466.62500	
1615	 steps: training loss - 117545.57031	, testing loss - 367551.78125	
1616	 steps: training loss - 87863.70312	, testing loss - 368207.56250	
1617	 steps: training loss - 110765.64062	, testing loss - 369657.90625	
1618	 steps: training loss - 107953.88281	, testing loss - 370809.09375	
1619	 steps: training loss - 131440.81250	, testing loss - 370675.46875	
1620	 steps: training loss - 113251.96094	, testing loss - 369732.40625	
1621	 steps: training loss - 100490.62500	, testing loss - 368991.87500	
1622	 steps: training loss - 126683.02344	, testing loss - 368480.03125	
1623	 steps: training loss - 82702.20312	, testing loss - 367734.96875	
1624	 steps: training loss - 125886.67969	, testing loss - 367697.03125	
1625	 steps: training loss - 116597.81250	, testing loss - 367774.50000	
1626	 steps: training loss - 106797.40625	, testing loss - 368015.68750	
1627	 steps: training loss - 125769.10938	, testing loss - 368629.25000	
1628	 steps: training loss - 112584.92188	, testing loss - 369280.50000	
1629	 steps: training loss - 135432.95312	, testing loss - 369538.75000	
1630	 steps: training loss - 150197.35938	, testing loss - 369865.93750	
1631	 steps: training loss - 93890.71094	, testing loss - 370495.75000	
1632	 steps: training loss - 114291.93750	, testing loss - 370855.75000	
1633	 steps: training loss - 113005.39062	, testing loss - 370744.03125	
1634	 steps: training loss - 112835.31250	, testing loss - 369923.62500	
1635	 steps: training loss - 139579.07812	, testing loss - 368362.68750	
1636	 steps: training loss - 110803.82812	, testing loss - 366680.34375	
1637	 steps: training loss - 122025.46875	, testing loss - 365069.46875	
1638	 steps: training loss - 131339.90625	, testing loss - 363770.34375	
1639	 steps: training loss - 112961.10938	, testing loss - 362279.78125	
1640	 steps: training loss - 116772.64062	, testing loss - 360573.28125	
1641	 steps: training loss - 112663.95312	, testing loss - 359848.00000	
1642	 steps: training loss - 111870.67188	, testing loss - 360057.37500	
1643	 steps: training loss - 109204.14062	, testing loss - 360701.53125	
1644	 steps: training loss - 125898.71875	, testing loss - 361127.90625	
1645	 steps: training loss - 108480.68750	, testing loss - 361809.81250	
1646	 steps: training loss - 115829.10156	, testing loss - 362315.43750	
1647	 steps: training loss - 104713.37500	, testing loss - 363019.21875	
1648	 steps: training loss - 115374.29688	, testing loss - 363196.87500	
1649	 steps: training loss - 100641.14844	, testing loss - 363239.31250	
1650	 steps: training loss - 121910.65625	, testing loss - 363658.15625	
1651	 steps: training loss - 123849.30469	, testing loss - 364309.53125	
1652	 steps: training loss - 116617.95312	, testing loss - 364680.37500	
1653	 steps: training loss - 118478.57031	, testing loss - 365374.56250	
1654	 steps: training loss - 124418.84375	, testing loss - 366024.40625	
1655	 steps: training loss - 124127.26562	, testing loss - 366069.40625	
1656	 steps: training loss - 112937.73438	, testing loss - 366237.71875	
1657	 steps: training loss - 140934.50000	, testing loss - 367432.31250	
1658	 steps: training loss - 111856.75781	, testing loss - 369116.09375	
1659	 steps: training loss - 108955.95312	, testing loss - 370493.40625	
1660	 steps: training loss - 124706.96875	, testing loss - 371996.43750	
1661	 steps: training loss - 105243.10156	, testing loss - 374066.68750	
1662	 steps: training loss - 107316.11719	, testing loss - 375522.62500	
1663	 steps: training loss - 111906.97656	, testing loss - 376626.40625	
1664	 steps: training loss - 131670.03125	, testing loss - 377205.71875	
1665	 steps: training loss - 129632.60938	, testing loss - 376697.65625	
1666	 steps: training loss - 104278.92188	, testing loss - 375961.31250	
1667	 steps: training loss - 85085.07031	, testing loss - 375181.34375	
1668	 steps: training loss - 106596.25000	, testing loss - 374221.28125	
1669	 steps: training loss - 132625.15625	, testing loss - 373685.62500	
1670	 steps: training loss - 114299.39062	, testing loss - 374165.71875	
1671	 steps: training loss - 105561.66406	, testing loss - 374276.31250	
1672	 steps: training loss - 103995.72656	, testing loss - 374671.59375	
1673	 steps: training loss - 108926.90625	, testing loss - 374131.87500	
1674	 steps: training loss - 101537.28125	, testing loss - 373698.31250	
1675	 steps: training loss - 137252.70312	, testing loss - 374030.93750	
1676	 steps: training loss - 103020.49219	, testing loss - 374341.06250	
1677	 steps: training loss - 115681.64062	, testing loss - 373824.87500	
1678	 steps: training loss - 142408.76562	, testing loss - 372859.62500	
1679	 steps: training loss - 129597.77344	, testing loss - 372406.31250	
1680	 steps: training loss - 90129.96094	, testing loss - 372010.96875	
1681	 steps: training loss - 126606.71094	, testing loss - 370586.03125	
1682	 steps: training loss - 121918.33594	, testing loss - 370419.53125	
1683	 steps: training loss - 112974.88281	, testing loss - 371429.34375	
1684	 steps: training loss - 110087.51562	, testing loss - 371365.84375	
1685	 steps: training loss - 127733.56250	, testing loss - 370693.81250	
1686	 steps: training loss - 108190.39844	, testing loss - 370822.68750	
1687	 steps: training loss - 105019.22656	, testing loss - 371640.37500	
1688	 steps: training loss - 117663.17969	, testing loss - 371844.34375	
1689	 steps: training loss - 100533.67969	, testing loss - 372340.53125	
1690	 steps: training loss - 105287.00000	, testing loss - 371872.31250	
1691	 steps: training loss - 120782.51562	, testing loss - 370789.75000	
1692	 steps: training loss - 126162.38281	, testing loss - 370406.75000	
1693	 steps: training loss - 108469.50000	, testing loss - 369917.09375	
1694	 steps: training loss - 110629.49219	, testing loss - 368957.25000	
1695	 steps: training loss - 142313.35938	, testing loss - 368254.68750	
1696	 steps: training loss - 105224.40625	, testing loss - 367775.59375	
1697	 steps: training loss - 118748.42969	, testing loss - 366874.78125	
1698	 steps: training loss - 98495.00781	, testing loss - 365508.78125	
1699	 steps: training loss - 123256.89062	, testing loss - 364262.90625	
1700	 steps: training loss - 112152.40625	, testing loss - 363636.50000	
1701	 steps: training loss - 120348.39844	, testing loss - 362559.37500	
1702	 steps: training loss - 103230.61719	, testing loss - 362114.90625	
1703	 steps: training loss - 97923.31250	, testing loss - 361727.62500	
1704	 steps: training loss - 132981.10938	, testing loss - 361066.09375	
1705	 steps: training loss - 123506.21094	, testing loss - 360623.34375	
1706	 steps: training loss - 108936.29688	, testing loss - 360542.31250	
1707	 steps: training loss - 126833.71094	, testing loss - 360479.93750	
1708	 steps: training loss - 154684.76562	, testing loss - 360056.68750	
1709	 steps: training loss - 121238.40625	, testing loss - 359793.15625	
1710	 steps: training loss - 97846.85156	, testing loss - 360261.59375	
1711	 steps: training loss - 103363.15625	, testing loss - 361065.43750	
1712	 steps: training loss - 129220.49219	, testing loss - 362604.40625	
1713	 steps: training loss - 106328.70312	, testing loss - 364606.81250	
1714	 steps: training loss - 102120.85938	, testing loss - 365450.93750	
1715	 steps: training loss - 106652.91406	, testing loss - 365814.03125	
1716	 steps: training loss - 116672.09375	, testing loss - 365924.09375	
1717	 steps: training loss - 117825.19531	, testing loss - 365694.87500	
1718	 steps: training loss - 119251.28906	, testing loss - 365550.18750	
1719	 steps: training loss - 108353.59375	, testing loss - 366698.34375	
1720	 steps: training loss - 117331.49219	, testing loss - 367664.37500	
1721	 steps: training loss - 123535.17188	, testing loss - 368022.50000	
1722	 steps: training loss - 133469.93750	, testing loss - 368088.28125	
1723	 steps: training loss - 122006.54688	, testing loss - 368588.25000	
1724	 steps: training loss - 130315.96094	, testing loss - 368882.37500	
1725	 steps: training loss - 143550.20312	, testing loss - 369083.62500	
1726	 steps: training loss - 98613.00781	, testing loss - 369363.18750	
1727	 steps: training loss - 121341.51562	, testing loss - 369279.37500	
1728	 steps: training loss - 141515.93750	, testing loss - 368866.87500	
1729	 steps: training loss - 129275.42969	, testing loss - 368820.84375	
1730	 steps: training loss - 113389.52344	, testing loss - 367982.40625	
1731	 steps: training loss - 113789.20312	, testing loss - 367294.78125	
1732	 steps: training loss - 121205.66406	, testing loss - 367409.28125	
1733	 steps: training loss - 121033.85156	, testing loss - 368404.68750	
1734	 steps: training loss - 111609.39062	, testing loss - 368726.96875	
1735	 steps: training loss - 109247.85938	, testing loss - 368498.18750	
1736	 steps: training loss - 96943.11719	, testing loss - 368029.12500	
1737	 steps: training loss - 123178.56250	, testing loss - 367972.18750	
1738	 steps: training loss - 127820.46875	, testing loss - 367994.78125	
1739	 steps: training loss - 105286.07031	, testing loss - 368131.12500	
1740	 steps: training loss - 122023.51562	, testing loss - 368701.40625	
1741	 steps: training loss - 107012.08594	, testing loss - 369896.93750	
1742	 steps: training loss - 101227.85156	, testing loss - 370070.90625	
1743	 steps: training loss - 128481.34375	, testing loss - 369679.03125	
1744	 steps: training loss - 155578.68750	, testing loss - 369078.68750	
1745	 steps: training loss - 108058.40625	, testing loss - 368247.81250	
1746	 steps: training loss - 117437.21094	, testing loss - 366409.96875	
1747	 steps: training loss - 118230.93750	, testing loss - 365111.59375	
1748	 steps: training loss - 143370.79688	, testing loss - 364439.78125	
1749	 steps: training loss - 108317.85156	, testing loss - 364584.18750	
1750	 steps: training loss - 97309.00781	, testing loss - 365250.90625	
1751	 steps: training loss - 106350.32812	, testing loss - 366194.93750	
1752	 steps: training loss - 132884.96875	, testing loss - 366476.50000	
1753	 steps: training loss - 108369.75781	, testing loss - 366212.50000	
1754	 steps: training loss - 104316.74219	, testing loss - 365881.68750	
1755	 steps: training loss - 130582.78125	, testing loss - 365359.75000	
1756	 steps: training loss - 126337.03906	, testing loss - 364624.21875	
1757	 steps: training loss - 94840.81250	, testing loss - 363900.03125	
1758	 steps: training loss - 121781.53906	, testing loss - 363565.37500	
1759	 steps: training loss - 119165.85938	, testing loss - 363037.68750	
1760	 steps: training loss - 109248.97656	, testing loss - 363089.78125	
1761	 steps: training loss - 114483.07031	, testing loss - 363505.28125	
1762	 steps: training loss - 113638.85938	, testing loss - 364097.56250	
1763	 steps: training loss - 112735.98438	, testing loss - 365541.12500	
1764	 steps: training loss - 102584.04688	, testing loss - 367214.84375	
1765	 steps: training loss - 127450.53906	, testing loss - 368388.62500	
1766	 steps: training loss - 123597.98438	, testing loss - 369110.87500	
1767	 steps: training loss - 127599.16406	, testing loss - 369304.90625	
1768	 steps: training loss - 126534.92969	, testing loss - 369125.78125	
1769	 steps: training loss - 118411.46094	, testing loss - 368553.87500	
1770	 steps: training loss - 104857.71094	, testing loss - 367748.84375	
1771	 steps: training loss - 125016.74219	, testing loss - 367528.21875	
1772	 steps: training loss - 113290.59375	, testing loss - 367634.78125	
1773	 steps: training loss - 122889.18750	, testing loss - 368730.43750	
1774	 steps: training loss - 115041.01562	, testing loss - 370043.90625	
1775	 steps: training loss - 109956.64844	, testing loss - 370901.84375	
1776	 steps: training loss - 103165.07031	, testing loss - 371243.71875	
1777	 steps: training loss - 138176.64062	, testing loss - 371093.12500	
1778	 steps: training loss - 121351.51562	, testing loss - 370369.18750	
1779	 steps: training loss - 115987.58594	, testing loss - 369668.56250	
1780	 steps: training loss - 126586.82812	, testing loss - 368802.31250	
1781	 steps: training loss - 120535.32031	, testing loss - 367124.03125	
1782	 steps: training loss - 111182.52344	, testing loss - 366069.21875	
1783	 steps: training loss - 116134.17969	, testing loss - 366232.34375	
1784	 steps: training loss - 137662.68750	, testing loss - 366696.21875	
1785	 steps: training loss - 125717.13281	, testing loss - 367347.03125	
1786	 steps: training loss - 119006.07812	, testing loss - 367287.12500	
1787	 steps: training loss - 106664.75781	, testing loss - 366948.40625	
1788	 steps: training loss - 119285.91406	, testing loss - 366647.96875	
1789	 steps: training loss - 123785.49219	, testing loss - 367359.87500	
1790	 steps: training loss - 102637.78906	, testing loss - 368318.71875	
1791	 steps: training loss - 127314.89062	, testing loss - 369380.31250	
1792	 steps: training loss - 132170.34375	, testing loss - 370796.53125	
1793	 steps: training loss - 141453.12500	, testing loss - 371169.43750	
1794	 steps: training loss - 133183.29688	, testing loss - 370997.87500	
1795	 steps: training loss - 94631.39062	, testing loss - 372189.40625	
1796	 steps: training loss - 124471.46875	, testing loss - 372467.40625	
1797	 steps: training loss - 110072.20312	, testing loss - 372863.21875	
1798	 steps: training loss - 127193.70312	, testing loss - 373498.43750	
1799	 steps: training loss - 109502.97656	, testing loss - 374044.25000	
1800	 steps: training loss - 110350.71875	, testing loss - 374813.75000	
1801	 steps: training loss - 122637.76562	, testing loss - 374870.28125	
1802	 steps: training loss - 112878.65625	, testing loss - 374166.09375	
1803	 steps: training loss - 113617.19531	, testing loss - 373314.03125	
1804	 steps: training loss - 111887.35156	, testing loss - 372452.25000	
1805	 steps: training loss - 113127.97656	, testing loss - 372640.90625	
1806	 steps: training loss - 115310.22656	, testing loss - 373024.28125	
1807	 steps: training loss - 140339.64062	, testing loss - 373512.56250	
1808	 steps: training loss - 101521.01562	, testing loss - 374247.65625	
1809	 steps: training loss - 136106.03125	, testing loss - 373730.25000	
1810	 steps: training loss - 100450.46094	, testing loss - 372535.56250	
1811	 steps: training loss - 127397.78906	, testing loss - 370951.21875	
1812	 steps: training loss - 122382.89062	, testing loss - 368448.21875	
1813	 steps: training loss - 126510.11719	, testing loss - 366011.25000	
1814	 steps: training loss - 138897.34375	, testing loss - 365059.84375	
1815	 steps: training loss - 100860.35156	, testing loss - 365121.81250	
1816	 steps: training loss - 123615.78906	, testing loss - 366225.43750	
1817	 steps: training loss - 114931.74219	, testing loss - 366966.43750	
1818	 steps: training loss - 99685.46094	, testing loss - 368398.96875	
1819	 steps: training loss - 107586.67188	, testing loss - 369995.75000	
1820	 steps: training loss - 103112.79688	, testing loss - 371711.87500	
1821	 steps: training loss - 123023.10938	, testing loss - 373425.53125	
1822	 steps: training loss - 128149.32031	, testing loss - 375146.25000	
1823	 steps: training loss - 121388.54688	, testing loss - 375791.34375	
1824	 steps: training loss - 102867.18750	, testing loss - 375341.87500	
1825	 steps: training loss - 120058.70312	, testing loss - 374990.90625	
1826	 steps: training loss - 105448.30469	, testing loss - 374548.00000	
1827	 steps: training loss - 106118.67969	, testing loss - 372994.65625	
1828	 steps: training loss - 130120.92969	, testing loss - 372006.25000	
1829	 steps: training loss - 96098.88281	, testing loss - 371814.25000	
1830	 steps: training loss - 126505.95312	, testing loss - 371507.37500	
1831	 steps: training loss - 109275.84375	, testing loss - 371229.75000	
1832	 steps: training loss - 126111.28906	, testing loss - 370271.34375	
1833	 steps: training loss - 110368.65625	, testing loss - 369318.71875	
1834	 steps: training loss - 122558.71875	, testing loss - 368348.65625	
1835	 steps: training loss - 148158.96875	, testing loss - 368168.40625	
1836	 steps: training loss - 119744.45312	, testing loss - 368867.87500	
1837	 steps: training loss - 114895.08594	, testing loss - 371026.43750	
1838	 steps: training loss - 108225.78125	, testing loss - 372855.59375	
1839	 steps: training loss - 114295.07031	, testing loss - 375096.96875	
1840	 steps: training loss - 125654.91406	, testing loss - 378095.65625	
1841	 steps: training loss - 114243.11719	, testing loss - 379354.62500	
1842	 steps: training loss - 116216.34375	, testing loss - 378538.84375	
1843	 steps: training loss - 127563.78125	, testing loss - 376909.34375	
1844	 steps: training loss - 106948.70312	, testing loss - 375433.71875	
1845	 steps: training loss - 122447.91406	, testing loss - 373863.03125	
1846	 steps: training loss - 106916.11719	, testing loss - 371790.93750	
1847	 steps: training loss - 98172.67188	, testing loss - 370469.21875	
1848	 steps: training loss - 126888.64844	, testing loss - 370017.59375	
1849	 steps: training loss - 111773.10938	, testing loss - 370172.25000	
1850	 steps: training loss - 138642.73438	, testing loss - 371323.59375	
1851	 steps: training loss - 109328.91406	, testing loss - 372100.93750	
1852	 steps: training loss - 112453.98438	, testing loss - 373053.18750	
1853	 steps: training loss - 81530.29688	, testing loss - 373942.25000	
1854	 steps: training loss - 121562.67188	, testing loss - 374640.84375	
1855	 steps: training loss - 113374.10938	, testing loss - 375397.03125	
1856	 steps: training loss - 123406.68750	, testing loss - 376083.03125	
1857	 steps: training loss - 129320.14062	, testing loss - 376229.71875	
1858	 steps: training loss - 109010.18750	, testing loss - 375319.34375	
1859	 steps: training loss - 116150.42969	, testing loss - 373527.50000	
1860	 steps: training loss - 136407.78125	, testing loss - 372201.21875	
1861	 steps: training loss - 128467.60156	, testing loss - 370839.06250	
1862	 steps: training loss - 106396.58594	, testing loss - 369456.03125	
1863	 steps: training loss - 123745.09375	, testing loss - 368498.81250	
1864	 steps: training loss - 120703.53906	, testing loss - 368504.46875	
1865	 steps: training loss - 123157.90625	, testing loss - 368880.46875	
1866	 steps: training loss - 137374.92188	, testing loss - 369519.84375	
1867	 steps: training loss - 100220.52344	, testing loss - 369762.84375	
1868	 steps: training loss - 122031.36719	, testing loss - 369825.12500	
1869	 steps: training loss - 104636.05469	, testing loss - 369605.90625	
1870	 steps: training loss - 94359.89844	, testing loss - 369717.68750	
1871	 steps: training loss - 134691.90625	, testing loss - 369138.12500	
1872	 steps: training loss - 112024.78125	, testing loss - 368764.40625	
1873	 steps: training loss - 117392.10156	, testing loss - 368859.50000	
1874	 steps: training loss - 122687.83594	, testing loss - 369124.81250	
1875	 steps: training loss - 142458.68750	, testing loss - 369309.06250	
1876	 steps: training loss - 150447.89062	, testing loss - 369803.12500	
1877	 steps: training loss - 121742.32812	, testing loss - 370404.75000	
1878	 steps: training loss - 111023.55469	, testing loss - 370803.00000	
1879	 steps: training loss - 132715.53125	, testing loss - 371676.53125	
1880	 steps: training loss - 111350.46094	, testing loss - 372683.37500	
1881	 steps: training loss - 106716.00000	, testing loss - 372825.50000	
1882	 steps: training loss - 122824.39062	, testing loss - 371927.15625	
1883	 steps: training loss - 104770.10156	, testing loss - 371356.65625	
1884	 steps: training loss - 125587.11719	, testing loss - 370649.31250	
1885	 steps: training loss - 98081.69531	, testing loss - 369868.12500	
1886	 steps: training loss - 120196.81250	, testing loss - 368390.84375	
1887	 steps: training loss - 105800.78906	, testing loss - 368091.31250	
1888	 steps: training loss - 101162.55469	, testing loss - 368098.03125	
1889	 steps: training loss - 122845.23438	, testing loss - 368536.40625	
1890	 steps: training loss - 106009.77344	, testing loss - 369743.06250	
1891	 steps: training loss - 116248.77344	, testing loss - 370347.25000	
1892	 steps: training loss - 144648.12500	, testing loss - 369978.09375	
1893	 steps: training loss - 105555.75781	, testing loss - 369780.53125	
1894	 steps: training loss - 113036.17188	, testing loss - 369617.21875	
1895	 steps: training loss - 113044.25781	, testing loss - 369113.62500	
1896	 steps: training loss - 116719.74219	, testing loss - 369447.93750	
1897	 steps: training loss - 106146.42969	, testing loss - 369990.62500	
1898	 steps: training loss - 105628.10156	, testing loss - 370464.59375	
1899	 steps: training loss - 119433.70312	, testing loss - 370967.62500	
1900	 steps: training loss - 127805.00781	, testing loss - 370525.59375	
1901	 steps: training loss - 133854.37500	, testing loss - 369709.18750	
1902	 steps: training loss - 113575.78906	, testing loss - 369542.53125	
1903	 steps: training loss - 150412.21875	, testing loss - 368086.90625	
1904	 steps: training loss - 98915.61719	, testing loss - 366610.46875	
1905	 steps: training loss - 93446.02344	, testing loss - 365359.03125	
1906	 steps: training loss - 110794.53125	, testing loss - 364519.15625	
1907	 steps: training loss - 123475.50000	, testing loss - 364105.68750	
1908	 steps: training loss - 132544.23438	, testing loss - 364505.00000	
1909	 steps: training loss - 109800.92188	, testing loss - 364989.43750	
1910	 steps: training loss - 111006.52344	, testing loss - 365953.06250	
1911	 steps: training loss - 111823.91406	, testing loss - 367405.84375	
1912	 steps: training loss - 91601.67188	, testing loss - 368856.68750	
1913	 steps: training loss - 127042.26562	, testing loss - 370812.25000	
1914	 steps: training loss - 99043.79688	, testing loss - 371534.84375	
1915	 steps: training loss - 110535.57031	, testing loss - 370959.53125	
1916	 steps: training loss - 98226.37500	, testing loss - 369295.50000	
1917	 steps: training loss - 114927.50781	, testing loss - 367841.15625	
1918	 steps: training loss - 121549.72656	, testing loss - 366216.31250	
1919	 steps: training loss - 125689.93750	, testing loss - 365565.93750	
1920	 steps: training loss - 101264.42188	, testing loss - 364659.46875	
1921	 steps: training loss - 95510.49219	, testing loss - 364017.78125	
1922	 steps: training loss - 122961.46094	, testing loss - 363596.81250	
1923	 steps: training loss - 112914.49219	, testing loss - 363709.12500	
1924	 steps: training loss - 116674.48438	, testing loss - 364100.62500	
1925	 steps: training loss - 99316.33594	, testing loss - 364402.62500	
1926	 steps: training loss - 125452.06250	, testing loss - 364900.81250	
1927	 steps: training loss - 129263.36719	, testing loss - 365914.28125	
1928	 steps: training loss - 113429.63281	, testing loss - 366970.09375	
1929	 steps: training loss - 115085.82812	, testing loss - 368767.28125	
1930	 steps: training loss - 120826.71094	, testing loss - 372212.56250	
1931	 steps: training loss - 113700.52344	, testing loss - 374718.84375	
1932	 steps: training loss - 106845.89844	, testing loss - 375399.68750	
1933	 steps: training loss - 97113.33594	, testing loss - 375492.09375	
1934	 steps: training loss - 117540.12500	, testing loss - 375148.87500	
1935	 steps: training loss - 93673.38281	, testing loss - 375228.31250	
1936	 steps: training loss - 113012.17969	, testing loss - 375811.56250	
1937	 steps: training loss - 112511.27344	, testing loss - 375731.50000	
1938	 steps: training loss - 110324.50000	, testing loss - 374163.06250	
1939	 steps: training loss - 120049.14844	, testing loss - 372401.12500	
1940	 steps: training loss - 128657.56250	, testing loss - 371512.65625	
1941	 steps: training loss - 148062.82812	, testing loss - 370782.25000	
1942	 steps: training loss - 122199.49219	, testing loss - 370300.28125	
1943	 steps: training loss - 117140.36719	, testing loss - 369269.15625	
1944	 steps: training loss - 130965.01562	, testing loss - 368870.00000	
1945	 steps: training loss - 137116.39062	, testing loss - 368871.78125	
1946	 steps: training loss - 106996.67188	, testing loss - 368496.21875	
1947	 steps: training loss - 118044.66406	, testing loss - 367499.90625	
1948	 steps: training loss - 108000.96875	, testing loss - 366505.65625	
1949	 steps: training loss - 113439.66406	, testing loss - 365822.21875	
1950	 steps: training loss - 106110.10156	, testing loss - 365149.84375	
1951	 steps: training loss - 94638.25781	, testing loss - 365250.31250	
1952	 steps: training loss - 124219.39062	, testing loss - 366147.53125	
1953	 steps: training loss - 129365.70312	, testing loss - 366078.50000	
1954	 steps: training loss - 143642.12500	, testing loss - 365283.34375	
1955	 steps: training loss - 114870.96094	, testing loss - 364968.21875	
1956	 steps: training loss - 88684.68750	, testing loss - 364941.75000	
1957	 steps: training loss - 125513.50781	, testing loss - 365660.34375	
1958	 steps: training loss - 126454.40625	, testing loss - 366753.62500	
1959	 steps: training loss - 108216.63281	, testing loss - 366910.81250	
1960	 steps: training loss - 134072.17188	, testing loss - 367102.68750	
1961	 steps: training loss - 141606.67188	, testing loss - 367954.96875	
1962	 steps: training loss - 116699.99219	, testing loss - 369077.21875	
1963	 steps: training loss - 130518.63281	, testing loss - 370279.78125	
1964	 steps: training loss - 104407.31250	, testing loss - 371572.28125	
1965	 steps: training loss - 129269.05469	, testing loss - 372059.28125	
1966	 steps: training loss - 107023.69531	, testing loss - 372180.31250	
1967	 steps: training loss - 109892.71094	, testing loss - 372588.71875	
1968	 steps: training loss - 107253.99219	, testing loss - 371721.87500	
1969	 steps: training loss - 123087.76562	, testing loss - 370242.40625	
1970	 steps: training loss - 104123.12500	, testing loss - 368798.81250	
1971	 steps: training loss - 115610.42969	, testing loss - 368082.21875	
1972	 steps: training loss - 106083.06250	, testing loss - 368044.40625	
1973	 steps: training loss - 117491.93750	, testing loss - 368325.68750	
1974	 steps: training loss - 111620.76562	, testing loss - 369473.06250	
1975	 steps: training loss - 113774.86719	, testing loss - 369949.34375	
1976	 steps: training loss - 109752.13281	, testing loss - 370371.78125	
1977	 steps: training loss - 113000.22656	, testing loss - 370837.65625	
1978	 steps: training loss - 116669.48438	, testing loss - 370099.28125	
1979	 steps: training loss - 123292.70312	, testing loss - 370506.46875	
1980	 steps: training loss - 98884.97656	, testing loss - 371690.25000	
1981	 steps: training loss - 127163.98438	, testing loss - 372912.28125	
1982	 steps: training loss - 99623.57031	, testing loss - 373632.09375	
1983	 steps: training loss - 113208.52344	, testing loss - 374337.87500	
1984	 steps: training loss - 120701.17969	, testing loss - 374272.25000	
1985	 steps: training loss - 118625.35156	, testing loss - 373837.56250	
1986	 steps: training loss - 125330.71875	, testing loss - 373445.50000	
1987	 steps: training loss - 120121.05469	, testing loss - 372806.84375	
1988	 steps: training loss - 124466.52344	, testing loss - 372237.59375	
1989	 steps: training loss - 110852.29688	, testing loss - 371359.31250	
1990	 steps: training loss - 100469.85938	, testing loss - 369908.90625	
1991	 steps: training loss - 119508.85156	, testing loss - 368835.96875	
1992	 steps: training loss - 114869.08594	, testing loss - 368552.68750	
1993	 steps: training loss - 115078.30469	, testing loss - 367290.40625	
1994	 steps: training loss - 128357.46875	, testing loss - 366574.25000	
1995	 steps: training loss - 93507.49219	, testing loss - 365836.21875	
1996	 steps: training loss - 101176.49219	, testing loss - 365168.62500	
1997	 steps: training loss - 128555.62500	, testing loss - 364051.75000	
1998	 steps: training loss - 128530.03125	, testing loss - 362414.75000	
1999	 steps: training loss - 136718.10938	, testing loss - 361216.84375	
2000	 steps: training loss - 122460.34375	, testing loss - 360772.37500	
2001	 steps: training loss - 116197.33594	, testing loss - 360936.25000	
2002	 steps: training loss - 116543.14062	, testing loss - 361252.46875	
2003	 steps: training loss - 126794.07812	, testing loss - 362022.31250	
2004	 steps: training loss - 133326.56250	, testing loss - 362299.18750	
2005	 steps: training loss - 88577.10938	, testing loss - 362243.65625	
2006	 steps: training loss - 113504.42969	, testing loss - 362628.87500	
2007	 steps: training loss - 124515.55469	, testing loss - 362358.15625	
2008	 steps: training loss - 113221.96875	, testing loss - 362304.34375	
2009	 steps: training loss - 102730.44531	, testing loss - 363572.50000	
2010	 steps: training loss - 116102.00000	, testing loss - 364505.46875	
2011	 steps: training loss - 118859.04688	, testing loss - 365532.75000	
2012	 steps: training loss - 119527.31250	, testing loss - 366621.93750	
2013	 steps: training loss - 146201.23438	, testing loss - 367592.84375	
2014	 steps: training loss - 122523.37500	, testing loss - 368125.87500	
2015	 steps: training loss - 126419.73438	, testing loss - 369048.12500	
2016	 steps: training loss - 114687.18750	, testing loss - 370176.56250	
2017	 steps: training loss - 116726.14062	, testing loss - 370840.12500	
2018	 steps: training loss - 135595.59375	, testing loss - 371459.12500	
2019	 steps: training loss - 110250.86719	, testing loss - 371616.31250	
2020	 steps: training loss - 113377.89062	, testing loss - 373405.34375	
2021	 steps: training loss - 146295.12500	, testing loss - 375151.21875	
2022	 steps: training loss - 119040.91406	, testing loss - 376074.00000	
2023	 steps: training loss - 130288.87500	, testing loss - 375335.84375	
2024	 steps: training loss - 107761.36719	, testing loss - 373711.31250	
2025	 steps: training loss - 112124.75000	, testing loss - 371607.78125	
2026	 steps: training loss - 106775.53906	, testing loss - 369879.90625	
2027	 steps: training loss - 116614.79688	, testing loss - 368652.09375	
2028	 steps: training loss - 102665.30469	, testing loss - 367260.81250	
2029	 steps: training loss - 102752.61719	, testing loss - 366201.68750	
2030	 steps: training loss - 90764.90625	, testing loss - 365363.34375	
2031	 steps: training loss - 103246.05469	, testing loss - 364765.34375	
2032	 steps: training loss - 114246.10156	, testing loss - 363732.62500	
2033	 steps: training loss - 97343.79688	, testing loss - 363223.53125	
2034	 steps: training loss - 112567.28906	, testing loss - 362478.93750	
2035	 steps: training loss - 114155.44531	, testing loss - 361574.65625	
2036	 steps: training loss - 107552.55469	, testing loss - 360391.75000	
2037	 steps: training loss - 115562.00000	, testing loss - 359542.81250	
2038	 steps: training loss - 94279.25781	, testing loss - 359226.12500	
2039	 steps: training loss - 104134.20312	, testing loss - 358981.68750	
2040	 steps: training loss - 97467.25000	, testing loss - 359572.65625	
2041	 steps: training loss - 131287.70312	, testing loss - 360508.78125	
2042	 steps: training loss - 106645.35156	, testing loss - 361177.65625	
2043	 steps: training loss - 127220.99219	, testing loss - 362042.21875	
2044	 steps: training loss - 110289.39844	, testing loss - 362942.53125	
2045	 steps: training loss - 114096.03906	, testing loss - 363507.93750	
2046	 steps: training loss - 139952.37500	, testing loss - 363737.56250	
2047	 steps: training loss - 135321.56250	, testing loss - 363701.34375	
2048	 steps: training loss - 88261.71094	, testing loss - 363377.25000	
2049	 steps: training loss - 141034.35938	, testing loss - 363036.68750	
2050	 steps: training loss - 118487.96875	, testing loss - 363307.21875	
2051	 steps: training loss - 129206.43750	, testing loss - 363857.78125	
2052	 steps: training loss - 111979.35938	, testing loss - 364713.96875	
2053	 steps: training loss - 104818.48438	, testing loss - 364883.03125	
2054	 steps: training loss - 123967.32812	, testing loss - 364266.09375	
2055	 steps: training loss - 110238.25781	, testing loss - 363691.68750	
2056	 steps: training loss - 99700.49219	, testing loss - 363539.62500	
2057	 steps: training loss - 112608.76562	, testing loss - 363408.81250	
2058	 steps: training loss - 117928.74219	, testing loss - 363596.90625	
2059	 steps: training loss - 99610.71094	, testing loss - 363660.84375	
2060	 steps: training loss - 115146.89062	, testing loss - 363063.84375	
2061	 steps: training loss - 97857.96094	, testing loss - 362777.59375	
2062	 steps: training loss - 123977.85156	, testing loss - 362272.71875	
2063	 steps: training loss - 113752.88281	, testing loss - 360867.25000	
2064	 steps: training loss - 106146.70312	, testing loss - 359598.90625	
2065	 steps: training loss - 110518.32812	, testing loss - 358399.28125	
2066	 steps: training loss - 95889.09375	, testing loss - 357527.09375	
2067	 steps: training loss - 105845.80469	, testing loss - 356577.71875	
2068	 steps: training loss - 130944.78906	, testing loss - 355915.50000	
2069	 steps: training loss - 105017.92969	, testing loss - 355519.28125	
2070	 steps: training loss - 125755.03125	, testing loss - 355641.93750	
2071	 steps: training loss - 98537.61719	, testing loss - 355785.15625	
2072	 steps: training loss - 112148.33594	, testing loss - 355710.31250	
2073	 steps: training loss - 122249.00000	, testing loss - 355606.09375	
2074	 steps: training loss - 113235.46875	, testing loss - 355836.06250	
2075	 steps: training loss - 122702.17969	, testing loss - 356309.78125	
2076	 steps: training loss - 110774.61719	, testing loss - 356972.12500	
2077	 steps: training loss - 114383.39062	, testing loss - 357046.65625	
2078	 steps: training loss - 120648.54688	, testing loss - 357640.78125	
2079	 steps: training loss - 130019.58594	, testing loss - 359041.37500	
2080	 steps: training loss - 113013.16406	, testing loss - 359952.21875	
2081	 steps: training loss - 132267.92188	, testing loss - 360456.87500	
2082	 steps: training loss - 129911.51562	, testing loss - 360520.31250	
2083	 steps: training loss - 81993.09375	, testing loss - 360883.56250	
2084	 steps: training loss - 104504.81250	, testing loss - 361150.40625	
2085	 steps: training loss - 94829.60938	, testing loss - 360952.65625	
2086	 steps: training loss - 99388.43750	, testing loss - 360860.06250	
2087	 steps: training loss - 121024.82031	, testing loss - 361781.12500	
2088	 steps: training loss - 94566.03125	, testing loss - 363594.81250	
2089	 steps: training loss - 123880.53125	, testing loss - 365084.18750	
2090	 steps: training loss - 128934.35156	, testing loss - 366406.65625	
2091	 steps: training loss - 129975.86719	, testing loss - 367079.71875	
2092	 steps: training loss - 108106.27344	, testing loss - 366226.93750	
2093	 steps: training loss - 130266.10156	, testing loss - 364544.43750	
2094	 steps: training loss - 98292.19531	, testing loss - 363215.75000	
2095	 steps: training loss - 119189.88281	, testing loss - 363242.75000	
2096	 steps: training loss - 108875.64062	, testing loss - 363348.62500	
2097	 steps: training loss - 117625.41406	, testing loss - 363451.34375	
2098	 steps: training loss - 124817.73438	, testing loss - 363100.00000	
2099	 steps: training loss - 114031.91406	, testing loss - 362995.31250	
2100	 steps: training loss - 121849.64844	, testing loss - 364531.68750	
2101	 steps: training loss - 107659.76562	, testing loss - 365823.31250	
2102	 steps: training loss - 119682.25781	, testing loss - 367237.87500	
2103	 steps: training loss - 118328.15625	, testing loss - 368587.93750	
2104	 steps: training loss - 115723.04688	, testing loss - 368857.87500	
2105	 steps: training loss - 113366.13281	, testing loss - 368162.96875	
2106	 steps: training loss - 142450.79688	, testing loss - 366802.00000	
2107	 steps: training loss - 125705.37500	, testing loss - 365391.90625	
2108	 steps: training loss - 127766.39062	, testing loss - 363946.84375	
2109	 steps: training loss - 126028.35156	, testing loss - 362713.56250	
2110	 steps: training loss - 124452.89062	, testing loss - 361742.06250	
2111	 steps: training loss - 114837.17188	, testing loss - 361006.46875	
2112	 steps: training loss - 113756.79688	, testing loss - 360522.03125	
2113	 steps: training loss - 115244.99219	, testing loss - 361185.21875	
2114	 steps: training loss - 116196.33594	, testing loss - 362396.15625	
2115	 steps: training loss - 119149.39844	, testing loss - 363906.71875	
2116	 steps: training loss - 117077.76562	, testing loss - 365801.75000	
2117	 steps: training loss - 109282.71875	, testing loss - 366339.87500	
2118	 steps: training loss - 136033.57812	, testing loss - 365689.31250	
2119	 steps: training loss - 115847.69531	, testing loss - 365201.34375	
2120	 steps: training loss - 139695.29688	, testing loss - 364510.53125	
2121	 steps: training loss - 120208.66406	, testing loss - 364055.28125	
2122	 steps: training loss - 100493.50000	, testing loss - 364737.18750	
2123	 steps: training loss - 95324.63281	, testing loss - 365677.18750	
2124	 steps: training loss - 110366.26562	, testing loss - 366133.00000	
2125	 steps: training loss - 110638.20312	, testing loss - 365639.56250	
2126	 steps: training loss - 124596.33594	, testing loss - 365433.90625	
2127	 steps: training loss - 98058.22656	, testing loss - 365943.87500	
2128	 steps: training loss - 93077.71094	, testing loss - 366567.40625	
2129	 steps: training loss - 126010.84375	, testing loss - 367945.93750	
2130	 steps: training loss - 132473.73438	, testing loss - 368450.56250	
2131	 steps: training loss - 105088.72656	, testing loss - 367827.25000	
2132	 steps: training loss - 121546.74219	, testing loss - 366914.43750	
2133	 steps: training loss - 115671.32031	, testing loss - 366975.65625	
2134	 steps: training loss - 117880.05469	, testing loss - 367390.31250	
2135	 steps: training loss - 147158.71875	, testing loss - 368114.81250	
2136	 steps: training loss - 111622.28906	, testing loss - 368285.59375	
2137	 steps: training loss - 108188.31250	, testing loss - 368471.53125	
2138	 steps: training loss - 125076.65625	, testing loss - 368198.62500	
2139	 steps: training loss - 111016.38281	, testing loss - 367044.34375	
2140	 steps: training loss - 126873.21094	, testing loss - 365894.84375	
2141	 steps: training loss - 130393.13281	, testing loss - 364335.31250	
2142	 steps: training loss - 123964.09375	, testing loss - 361873.40625	
2143	 steps: training loss - 126752.97656	, testing loss - 359536.68750	
2144	 steps: training loss - 119677.10156	, testing loss - 357041.96875	
2145	 steps: training loss - 127111.20312	, testing loss - 354662.59375	
2146	 steps: training loss - 141085.26562	, testing loss - 353140.56250	
2147	 steps: training loss - 109320.00781	, testing loss - 352593.56250	
2148	 steps: training loss - 123203.03906	, testing loss - 352757.46875	
2149	 steps: training loss - 133150.59375	, testing loss - 353686.00000	
2150	 steps: training loss - 129262.85938	, testing loss - 354846.09375	
2151	 steps: training loss - 117632.84375	, testing loss - 356333.62500	
2152	 steps: training loss - 118584.65625	, testing loss - 357557.06250	
2153	 steps: training loss - 123822.60938	, testing loss - 358245.53125	
2154	 steps: training loss - 109691.96875	, testing loss - 359893.09375	
2155	 steps: training loss - 125353.25781	, testing loss - 361626.84375	
2156	 steps: training loss - 93421.41406	, testing loss - 362747.78125	
2157	 steps: training loss - 128554.28906	, testing loss - 364227.56250	
2158	 steps: training loss - 118573.81250	, testing loss - 365983.87500	
2159	 steps: training loss - 97412.13281	, testing loss - 367692.28125	
2160	 steps: training loss - 128261.99219	, testing loss - 368868.78125	
2161	 steps: training loss - 94221.92969	, testing loss - 369223.62500	
2162	 steps: training loss - 128837.17969	, testing loss - 368918.00000	
2163	 steps: training loss - 131949.00000	, testing loss - 368557.96875	
2164	 steps: training loss - 123266.25781	, testing loss - 367565.03125	
2165	 steps: training loss - 123319.10156	, testing loss - 366065.12500	
2166	 steps: training loss - 86486.59375	, testing loss - 364439.75000	
2167	 steps: training loss - 130491.58594	, testing loss - 363291.34375	
2168	 steps: training loss - 113905.57812	, testing loss - 362717.37500	
2169	 steps: training loss - 98095.64062	, testing loss - 362367.06250	
2170	 steps: training loss - 102070.63281	, testing loss - 362300.34375	
2171	 steps: training loss - 113229.37500	, testing loss - 362574.15625	
2172	 steps: training loss - 111913.25781	, testing loss - 363217.81250	
2173	 steps: training loss - 122692.32031	, testing loss - 364672.09375	
2174	 steps: training loss - 120085.22656	, testing loss - 366403.21875	
2175	 steps: training loss - 139002.06250	, testing loss - 368467.34375	
2176	 steps: training loss - 98708.67188	, testing loss - 369488.75000	
2177	 steps: training loss - 117636.92188	, testing loss - 368795.62500	
2178	 steps: training loss - 106644.37500	, testing loss - 367396.81250	
2179	 steps: training loss - 105029.66406	, testing loss - 366147.93750	
2180	 steps: training loss - 116037.02344	, testing loss - 365671.96875	
2181	 steps: training loss - 116334.10156	, testing loss - 365688.78125	
2182	 steps: training loss - 104001.60156	, testing loss - 365543.93750	
2183	 steps: training loss - 113761.51562	, testing loss - 365277.37500	
2184	 steps: training loss - 101337.82812	, testing loss - 365749.93750	
2185	 steps: training loss - 123564.54688	, testing loss - 365816.28125	
2186	 steps: training loss - 103794.35156	, testing loss - 364783.21875	
2187	 steps: training loss - 121109.78125	, testing loss - 363555.56250	
2188	 steps: training loss - 107927.28906	, testing loss - 362252.75000	
2189	 steps: training loss - 120975.52344	, testing loss - 361728.65625	
2190	 steps: training loss - 108387.89062	, testing loss - 360864.71875	
2191	 steps: training loss - 116664.25000	, testing loss - 360451.50000	
2192	 steps: training loss - 111045.80469	, testing loss - 360393.43750	
2193	 steps: training loss - 113742.19531	, testing loss - 360938.00000	
2194	 steps: training loss - 117013.00000	, testing loss - 362319.46875	
2195	 steps: training loss - 113672.26562	, testing loss - 362991.03125	
2196	 steps: training loss - 99597.80469	, testing loss - 363184.81250	
2197	 steps: training loss - 95043.03125	, testing loss - 362757.28125	
2198	 steps: training loss - 113750.16406	, testing loss - 362589.87500	
2199	 steps: training loss - 132112.93750	, testing loss - 362788.43750	
2200	 steps: training loss - 113198.67969	, testing loss - 362908.65625	
2201	 steps: training loss - 115249.52344	, testing loss - 362535.03125	
2202	 steps: training loss - 88356.53125	, testing loss - 361182.06250	
2203	 steps: training loss - 122041.10156	, testing loss - 360193.81250	
2204	 steps: training loss - 111625.55469	, testing loss - 359700.78125	
2205	 steps: training loss - 129712.42969	, testing loss - 359498.43750	
2206	 steps: training loss - 106100.73438	, testing loss - 359308.21875	
2207	 steps: training loss - 117710.64844	, testing loss - 359390.75000	
2208	 steps: training loss - 114404.57812	, testing loss - 360146.25000	
2209	 steps: training loss - 127204.03125	, testing loss - 360978.65625	
2210	 steps: training loss - 86206.53125	, testing loss - 362056.37500	
2211	 steps: training loss - 98248.14844	, testing loss - 362970.03125	
2212	 steps: training loss - 114608.46094	, testing loss - 363482.81250	
2213	 steps: training loss - 100704.22656	, testing loss - 363159.50000	
2214	 steps: training loss - 118101.85938	, testing loss - 362816.37500	
2215	 steps: training loss - 122841.82031	, testing loss - 363858.53125	
2216	 steps: training loss - 144284.10938	, testing loss - 365149.75000	
2217	 steps: training loss - 122171.51562	, testing loss - 364835.62500	
2218	 steps: training loss - 110777.97656	, testing loss - 363542.75000	
2219	 steps: training loss - 135137.20312	, testing loss - 362095.18750	
2220	 steps: training loss - 112881.27344	, testing loss - 360568.06250	
2221	 steps: training loss - 121619.97656	, testing loss - 360002.12500	
2222	 steps: training loss - 138053.37500	, testing loss - 359935.65625	
2223	 steps: training loss - 111448.02344	, testing loss - 359408.93750	
2224	 steps: training loss - 103897.58594	, testing loss - 359107.81250	
2225	 steps: training loss - 125667.82812	, testing loss - 359212.68750	
2226	 steps: training loss - 101646.72656	, testing loss - 359907.03125	
2227	 steps: training loss - 99541.80469	, testing loss - 360579.31250	
2228	 steps: training loss - 124394.85938	, testing loss - 360674.31250	
2229	 steps: training loss - 108549.57031	, testing loss - 360520.03125	
2230	 steps: training loss - 102028.35156	, testing loss - 361258.31250	
2231	 steps: training loss - 116293.81250	, testing loss - 362077.21875	
2232	 steps: training loss - 106470.15625	, testing loss - 363267.84375	
2233	 steps: training loss - 103338.17188	, testing loss - 364118.40625	
2234	 steps: training loss - 89521.19531	, testing loss - 365716.25000	
2235	 steps: training loss - 113449.37500	, testing loss - 366399.00000	
2236	 steps: training loss - 124258.52344	, testing loss - 366176.78125	
2237	 steps: training loss - 116461.62500	, testing loss - 365624.21875	
2238	 steps: training loss - 148833.10938	, testing loss - 364833.46875	
2239	 steps: training loss - 107824.35156	, testing loss - 363658.50000	
2240	 steps: training loss - 99188.90625	, testing loss - 362765.62500	
2241	 steps: training loss - 123171.78125	, testing loss - 362185.75000	
2242	 steps: training loss - 129400.68750	, testing loss - 361431.62500	
2243	 steps: training loss - 102403.47656	, testing loss - 360594.18750	
2244	 steps: training loss - 137901.46875	, testing loss - 360121.40625	
2245	 steps: training loss - 109424.14844	, testing loss - 359587.25000	
2246	 steps: training loss - 122442.27344	, testing loss - 359055.12500	
2247	 steps: training loss - 107053.09375	, testing loss - 358360.12500	
2248	 steps: training loss - 104642.84375	, testing loss - 358129.53125	
2249	 steps: training loss - 106038.26562	, testing loss - 357713.81250	
2250	 steps: training loss - 120705.40625	, testing loss - 357543.56250	
2251	 steps: training loss - 86230.46875	, testing loss - 358203.03125	
2252	 steps: training loss - 113607.03906	, testing loss - 358760.62500	
2253	 steps: training loss - 126763.21094	, testing loss - 360108.15625	
2254	 steps: training loss - 129302.78125	, testing loss - 362197.78125	
2255	 steps: training loss - 88619.34375	, testing loss - 363627.81250	
2256	 steps: training loss - 110767.65625	, testing loss - 364779.34375	
2257	 steps: training loss - 100974.09375	, testing loss - 366049.53125	
2258	 steps: training loss - 122660.90625	, testing loss - 366933.03125	
2259	 steps: training loss - 125468.09375	, testing loss - 366941.75000	
2260	 steps: training loss - 107353.17969	, testing loss - 366538.53125	
2261	 steps: training loss - 117066.02344	, testing loss - 365982.90625	
2262	 steps: training loss - 111007.05469	, testing loss - 364715.90625	
2263	 steps: training loss - 104436.32031	, testing loss - 363523.90625	
2264	 steps: training loss - 106226.72656	, testing loss - 363305.34375	
2265	 steps: training loss - 112645.57031	, testing loss - 364400.18750	
2266	 steps: training loss - 120818.66406	, testing loss - 365713.93750	
2267	 steps: training loss - 130073.14062	, testing loss - 367316.59375	
2268	 steps: training loss - 99130.47656	, testing loss - 368820.93750	
2269	 steps: training loss - 129813.82812	, testing loss - 370568.68750	
2270	 steps: training loss - 137081.57812	, testing loss - 372929.78125	
2271	 steps: training loss - 100930.65625	, testing loss - 374692.62500	
2272	 steps: training loss - 118865.62500	, testing loss - 376064.06250	
2273	 steps: training loss - 105303.61719	, testing loss - 378828.03125	
2274	 steps: training loss - 119022.60156	, testing loss - 381788.75000	
2275	 steps: training loss - 110662.35156	, testing loss - 383146.96875	
2276	 steps: training loss - 122675.88281	, testing loss - 383011.37500	
2277	 steps: training loss - 122713.96875	, testing loss - 381757.15625	
2278	 steps: training loss - 128920.26562	, testing loss - 378919.25000	
2279	 steps: training loss - 115538.32812	, testing loss - 375071.40625	
2280	 steps: training loss - 123859.67969	, testing loss - 372228.50000	
2281	 steps: training loss - 95726.71875	, testing loss - 369622.31250	
2282	 steps: training loss - 101263.96875	, testing loss - 367105.15625	
2283	 steps: training loss - 118257.50000	, testing loss - 363898.87500	
2284	 steps: training loss - 99200.86719	, testing loss - 362338.00000	
2285	 steps: training loss - 108738.74219	, testing loss - 361495.50000	
2286	 steps: training loss - 117157.85156	, testing loss - 361454.15625	
2287	 steps: training loss - 111586.07812	, testing loss - 361794.12500	
2288	 steps: training loss - 106549.42969	, testing loss - 362143.59375	
2289	 steps: training loss - 109738.24219	, testing loss - 361750.31250	
2290	 steps: training loss - 122734.30469	, testing loss - 361352.53125	
2291	 steps: training loss - 111294.80469	, testing loss - 360722.78125	
2292	 steps: training loss - 99543.65625	, testing loss - 360257.62500	
2293	 steps: training loss - 84413.37500	, testing loss - 360338.18750	
2294	 steps: training loss - 122253.78906	, testing loss - 360594.15625	
2295	 steps: training loss - 91987.22656	, testing loss - 361307.40625	
2296	 steps: training loss - 99435.43750	, testing loss - 362930.90625	
2297	 steps: training loss - 117000.09375	, testing loss - 363892.28125	
2298	 steps: training loss - 133025.67188	, testing loss - 365447.59375	
2299	 steps: training loss - 104664.38281	, testing loss - 367446.28125	
2300	 steps: training loss - 140931.29688	, testing loss - 369140.21875	
2301	 steps: training loss - 114595.86719	, testing loss - 369375.25000	
2302	 steps: training loss - 116437.33594	, testing loss - 369799.34375	
2303	 steps: training loss - 112521.21094	, testing loss - 370398.53125	
2304	 steps: training loss - 141295.75000	, testing loss - 370517.06250	
2305	 steps: training loss - 132350.70312	, testing loss - 370219.56250	
2306	 steps: training loss - 138581.73438	, testing loss - 369889.96875	
2307	 steps: training loss - 121606.67188	, testing loss - 369006.12500	
2308	 steps: training loss - 98560.50781	, testing loss - 367807.93750	
2309	 steps: training loss - 116443.64062	, testing loss - 366174.40625	
2310	 steps: training loss - 110859.36719	, testing loss - 364356.28125	
2311	 steps: training loss - 100471.35156	, testing loss - 362306.46875	
2312	 steps: training loss - 101840.02344	, testing loss - 360477.96875	
2313	 steps: training loss - 112506.12500	, testing loss - 359423.21875	
2314	 steps: training loss - 104158.13281	, testing loss - 358191.75000	
2315	 steps: training loss - 144124.14062	, testing loss - 357227.21875	
2316	 steps: training loss - 132626.85938	, testing loss - 356885.50000	
2317	 steps: training loss - 112200.06250	, testing loss - 356824.28125	
2318	 steps: training loss - 94328.12500	, testing loss - 356286.43750	
2319	 steps: training loss - 115192.54688	, testing loss - 355910.37500	
2320	 steps: training loss - 100695.01562	, testing loss - 355974.56250	
2321	 steps: training loss - 117181.00000	, testing loss - 356289.34375	
2322	 steps: training loss - 102371.45312	, testing loss - 356102.40625	
2323	 steps: training loss - 127134.47656	, testing loss - 355429.00000	
2324	 steps: training loss - 99411.62500	, testing loss - 354996.31250	
2325	 steps: training loss - 145358.68750	, testing loss - 355124.81250	
2326	 steps: training loss - 101726.00000	, testing loss - 355549.87500	
2327	 steps: training loss - 114083.40625	, testing loss - 355654.21875	
2328	 steps: training loss - 111497.83594	, testing loss - 355089.25000	
2329	 steps: training loss - 117976.75781	, testing loss - 354828.03125	
2330	 steps: training loss - 136973.57812	, testing loss - 354766.75000	
2331	 steps: training loss - 111735.48438	, testing loss - 354994.93750	
2332	 steps: training loss - 126180.34375	, testing loss - 355091.25000	
2333	 steps: training loss - 111719.35938	, testing loss - 355614.25000	
2334	 steps: training loss - 123021.67188	, testing loss - 356335.40625	
2335	 steps: training loss - 114563.76562	, testing loss - 357610.09375	
2336	 steps: training loss - 120559.92188	, testing loss - 359321.09375	
2337	 steps: training loss - 117182.23438	, testing loss - 362101.50000	
2338	 steps: training loss - 107271.53906	, testing loss - 365467.12500	
2339	 steps: training loss - 96089.57812	, testing loss - 368004.46875	
2340	 steps: training loss - 108465.58594	, testing loss - 369197.37500	
2341	 steps: training loss - 103697.67969	, testing loss - 370154.65625	
2342	 steps: training loss - 110448.39062	, testing loss - 370876.87500	
2343	 steps: training loss - 108460.97656	, testing loss - 372514.50000	
2344	 steps: training loss - 131704.92188	, testing loss - 373319.18750	
2345	 steps: training loss - 139437.46875	, testing loss - 373068.56250	
2346	 steps: training loss - 112930.25000	, testing loss - 372809.03125	
2347	 steps: training loss - 94464.09375	, testing loss - 372030.40625	
2348	 steps: training loss - 104266.63281	, testing loss - 370406.00000	
2349	 steps: training loss - 118460.23438	, testing loss - 369340.00000	
2350	 steps: training loss - 143584.37500	, testing loss - 368528.15625	
2351	 steps: training loss - 108829.64062	, testing loss - 365794.68750	
2352	 steps: training loss - 117530.59375	, testing loss - 363662.59375	
2353	 steps: training loss - 100690.92188	, testing loss - 361671.31250	
2354	 steps: training loss - 112788.35156	, testing loss - 359832.53125	
2355	 steps: training loss - 132775.10938	, testing loss - 358160.93750	
2356	 steps: training loss - 113316.00781	, testing loss - 356405.62500	
2357	 steps: training loss - 112770.72656	, testing loss - 355140.84375	
2358	 steps: training loss - 104510.35156	, testing loss - 354756.62500	
2359	 steps: training loss - 101524.71875	, testing loss - 354300.65625	
2360	 steps: training loss - 114488.10156	, testing loss - 354034.03125	
2361	 steps: training loss - 132481.62500	, testing loss - 353957.40625	
2362	 steps: training loss - 122666.47656	, testing loss - 353804.40625	
2363	 steps: training loss - 137444.46875	, testing loss - 354226.50000	
2364	 steps: training loss - 123558.49219	, testing loss - 355096.56250	
2365	 steps: training loss - 112470.63281	, testing loss - 356574.31250	
2366	 steps: training loss - 117377.38281	, testing loss - 357823.56250	
2367	 steps: training loss - 128608.98438	, testing loss - 359260.09375	
2368	 steps: training loss - 108479.46875	, testing loss - 361041.15625	
2369	 steps: training loss - 113145.10156	, testing loss - 363384.50000	
2370	 steps: training loss - 103703.39062	, testing loss - 365911.43750	
2371	 steps: training loss - 102042.08594	, testing loss - 368075.78125	
2372	 steps: training loss - 132625.25000	, testing loss - 369225.37500	
2373	 steps: training loss - 104479.42188	, testing loss - 369864.50000	
2374	 steps: training loss - 129483.55469	, testing loss - 369651.50000	
2375	 steps: training loss - 105916.74219	, testing loss - 369647.40625	
2376	 steps: training loss - 118698.87500	, testing loss - 369702.53125	
2377	 steps: training loss - 128534.53906	, testing loss - 368981.37500	
2378	 steps: training loss - 112183.15625	, testing loss - 368548.37500	
2379	 steps: training loss - 138387.23438	, testing loss - 367667.18750	
2380	 steps: training loss - 125071.85938	, testing loss - 367481.84375	
2381	 steps: training loss - 124190.80469	, testing loss - 367754.46875	
2382	 steps: training loss - 121868.79688	, testing loss - 367362.84375	
2383	 steps: training loss - 112986.90625	, testing loss - 367002.59375	
2384	 steps: training loss - 108254.38281	, testing loss - 366549.03125	
2385	 steps: training loss - 123078.30469	, testing loss - 366527.09375	
2386	 steps: training loss - 123555.59375	, testing loss - 365863.28125	
2387	 steps: training loss - 118008.03906	, testing loss - 365011.93750	
2388	 steps: training loss - 129584.77344	, testing loss - 364944.65625	
2389	 steps: training loss - 126700.71094	, testing loss - 365982.59375	
2390	 steps: training loss - 108166.02344	, testing loss - 366070.09375	
2391	 steps: training loss - 129542.45312	, testing loss - 365488.15625	
2392	 steps: training loss - 121959.44531	, testing loss - 365536.09375	
2393	 steps: training loss - 111122.94531	, testing loss - 364623.25000	
2394	 steps: training loss - 133146.60938	, testing loss - 363780.12500	
2395	 steps: training loss - 118721.93750	, testing loss - 363705.81250	
2396	 steps: training loss - 124239.02344	, testing loss - 363956.90625	
2397	 steps: training loss - 124787.57812	, testing loss - 363800.71875	
2398	 steps: training loss - 120301.67188	, testing loss - 363360.81250	
2399	 steps: training loss - 111001.43750	, testing loss - 362911.87500	
2400	 steps: training loss - 130671.60938	, testing loss - 363098.62500	
2401	 steps: training loss - 109849.04688	, testing loss - 364139.28125	
2402	 steps: training loss - 104115.21094	, testing loss - 365112.71875	
2403	 steps: training loss - 103794.22656	, testing loss - 365598.31250	
2404	 steps: training loss - 105180.06250	, testing loss - 365859.90625	
2405	 steps: training loss - 98222.78125	, testing loss - 366071.09375	
2406	 steps: training loss - 107474.51562	, testing loss - 366444.62500	
2407	 steps: training loss - 104786.82812	, testing loss - 366919.43750	
2408	 steps: training loss - 125878.22656	, testing loss - 366271.90625	
2409	 steps: training loss - 114308.96094	, testing loss - 364675.71875	
2410	 steps: training loss - 118401.36719	, testing loss - 363266.87500	
2411	 steps: training loss - 110683.98438	, testing loss - 362842.12500	
2412	 steps: training loss - 130949.78125	, testing loss - 362922.56250	
2413	 steps: training loss - 101547.10156	, testing loss - 362963.28125	
2414	 steps: training loss - 90010.78906	, testing loss - 363373.00000	
2415	 steps: training loss - 124370.85156	, testing loss - 363577.62500	
2416	 steps: training loss - 113557.28125	, testing loss - 363248.37500	
2417	 steps: training loss - 110240.95312	, testing loss - 361984.56250	
2418	 steps: training loss - 110112.96094	, testing loss - 360956.53125	
2419	 steps: training loss - 95772.10156	, testing loss - 360243.68750	
2420	 steps: training loss - 84690.17188	, testing loss - 359683.62500	
2421	 steps: training loss - 106958.35938	, testing loss - 359172.87500	
2422	 steps: training loss - 119974.73438	, testing loss - 359060.68750	
2423	 steps: training loss - 110377.31250	, testing loss - 358794.75000	
2424	 steps: training loss - 103163.83594	, testing loss - 359108.50000	
2425	 steps: training loss - 126452.58594	, testing loss - 359701.53125	
2426	 steps: training loss - 108505.49219	, testing loss - 360966.09375	
2427	 steps: training loss - 112798.46094	, testing loss - 361844.03125	
2428	 steps: training loss - 116764.60156	, testing loss - 361968.46875	
2429	 steps: training loss - 90668.65625	, testing loss - 361542.84375	
2430	 steps: training loss - 114905.79688	, testing loss - 360932.28125	
2431	 steps: training loss - 121749.67969	, testing loss - 360847.12500	
2432	 steps: training loss - 96404.21875	, testing loss - 362210.68750	
2433	 steps: training loss - 127121.85156	, testing loss - 363661.03125	
2434	 steps: training loss - 104130.56250	, testing loss - 365230.12500	
2435	 steps: training loss - 124004.42188	, testing loss - 366955.06250	
2436	 steps: training loss - 92359.99219	, testing loss - 369207.53125	
2437	 steps: training loss - 114778.64062	, testing loss - 370935.09375	
2438	 steps: training loss - 103371.44531	, testing loss - 371833.78125	
2439	 steps: training loss - 105048.73438	, testing loss - 372511.28125	
2440	 steps: training loss - 120162.39062	, testing loss - 372031.59375	
2441	 steps: training loss - 109581.07031	, testing loss - 370325.65625	
2442	 steps: training loss - 134980.87500	, testing loss - 368289.53125	
2443	 steps: training loss - 91984.24219	, testing loss - 366976.03125	
2444	 steps: training loss - 122642.78125	, testing loss - 365355.87500	
2445	 steps: training loss - 105246.45312	, testing loss - 363396.28125	
2446	 steps: training loss - 113942.96875	, testing loss - 361192.37500	
2447	 steps: training loss - 153966.67188	, testing loss - 359173.68750	
2448	 steps: training loss - 122808.50781	, testing loss - 357827.12500	
2449	 steps: training loss - 120582.32812	, testing loss - 357024.21875	
2450	 steps: training loss - 116830.13281	, testing loss - 355948.68750	
2451	 steps: training loss - 123710.84375	, testing loss - 355651.40625	
2452	 steps: training loss - 104507.82031	, testing loss - 355702.87500	
2453	 steps: training loss - 99578.67188	, testing loss - 356164.46875	
2454	 steps: training loss - 127144.23438	, testing loss - 356756.21875	
2455	 steps: training loss - 148478.10938	, testing loss - 358193.37500	
2456	 steps: training loss - 130800.57031	, testing loss - 360383.43750	
2457	 steps: training loss - 127315.14062	, testing loss - 363252.34375	
2458	 steps: training loss - 125361.75781	, testing loss - 366013.71875	
2459	 steps: training loss - 125697.23438	, testing loss - 369634.65625	
2460	 steps: training loss - 128967.85938	, testing loss - 373140.87500	
2461	 steps: training loss - 138735.37500	, testing loss - 376141.75000	
2462	 steps: training loss - 101620.28906	, testing loss - 377495.50000	
2463	 steps: training loss - 117437.21094	, testing loss - 377279.81250	
2464	 steps: training loss - 115560.64844	, testing loss - 377225.87500	
2465	 steps: training loss - 116061.95312	, testing loss - 377358.96875	
2466	 steps: training loss - 100566.83594	, testing loss - 376982.68750	
2467	 steps: training loss - 98946.78125	, testing loss - 375749.25000	
2468	 steps: training loss - 90070.22656	, testing loss - 374654.12500	
2469	 steps: training loss - 110338.31250	, testing loss - 373307.90625	
2470	 steps: training loss - 95045.04688	, testing loss - 372194.84375	
2471	 steps: training loss - 85867.28906	, testing loss - 371071.31250	
2472	 steps: training loss - 94925.76562	, testing loss - 369991.34375	
2473	 steps: training loss - 137122.90625	, testing loss - 369466.40625	
2474	 steps: training loss - 137804.54688	, testing loss - 369871.28125	
2475	 steps: training loss - 118619.49219	, testing loss - 370100.43750	
2476	 steps: training loss - 119960.46875	, testing loss - 369891.68750	
2477	 steps: training loss - 104316.74219	, testing loss - 370122.65625	
2478	 steps: training loss - 123636.85938	, testing loss - 371049.53125	
2479	 steps: training loss - 126143.39844	, testing loss - 372099.28125	
2480	 steps: training loss - 97808.71875	, testing loss - 372798.40625	
2481	 steps: training loss - 146689.93750	, testing loss - 373401.62500	
2482	 steps: training loss - 115647.55469	, testing loss - 373121.78125	
2483	 steps: training loss - 115373.03125	, testing loss - 373067.34375	
2484	 steps: training loss - 102513.28125	, testing loss - 373696.84375	
2485	 steps: training loss - 105067.61719	, testing loss - 374287.68750	
2486	 steps: training loss - 109419.26562	, testing loss - 373963.03125	
2487	 steps: training loss - 131919.32812	, testing loss - 374310.43750	
2488	 steps: training loss - 100100.52344	, testing loss - 374388.50000	
2489	 steps: training loss - 120709.46875	, testing loss - 372742.21875	
2490	 steps: training loss - 112164.47656	, testing loss - 370166.28125	
2491	 steps: training loss - 107502.92188	, testing loss - 367165.34375	
2492	 steps: training loss - 101666.35938	, testing loss - 363955.62500	
2493	 steps: training loss - 91531.10938	, testing loss - 361293.18750	
2494	 steps: training loss - 113137.62500	, testing loss - 358730.90625	
2495	 steps: training loss - 135501.21875	, testing loss - 356758.81250	
2496	 steps: training loss - 126529.75781	, testing loss - 355251.12500	
2497	 steps: training loss - 121861.19531	, testing loss - 354229.15625	
2498	 steps: training loss - 129831.60156	, testing loss - 354065.28125	
2499	 steps: training loss - 116727.17969	, testing loss - 354847.68750	
2500	 steps: training loss - 130920.46094	, testing loss - 356382.03125	
2501	 steps: training loss - 136884.07812	, testing loss - 358408.03125	
2502	 steps: training loss - 114516.32812	, testing loss - 360427.75000	
2503	 steps: training loss - 100553.32031	, testing loss - 362586.96875	
2504	 steps: training loss - 131617.40625	, testing loss - 364372.93750	
2505	 steps: training loss - 98841.49219	, testing loss - 365681.34375	
2506	 steps: training loss - 128056.04688	, testing loss - 366495.34375	
2507	 steps: training loss - 126114.35156	, testing loss - 367266.18750	
2508	 steps: training loss - 112661.96875	, testing loss - 368403.43750	
2509	 steps: training loss - 111494.37500	, testing loss - 368729.68750	
2510	 steps: training loss - 135297.84375	, testing loss - 368336.21875	
2511	 steps: training loss - 89190.99219	, testing loss - 367605.46875	
2512	 steps: training loss - 111722.39062	, testing loss - 366389.25000	
2513	 steps: training loss - 127681.97656	, testing loss - 365330.68750	
2514	 steps: training loss - 127215.13281	, testing loss - 364444.50000	
2515	 steps: training loss - 125177.67188	, testing loss - 363302.43750	
2516	 steps: training loss - 114881.66406	, testing loss - 362177.96875	
2517	 steps: training loss - 137608.20312	, testing loss - 361448.28125	
2518	 steps: training loss - 118540.86719	, testing loss - 361360.37500	
2519	 steps: training loss - 128386.20312	, testing loss - 361744.68750	
2520	 steps: training loss - 127088.56250	, testing loss - 362937.40625	
2521	 steps: training loss - 106873.46875	, testing loss - 364098.37500	
2522	 steps: training loss - 101811.17969	, testing loss - 364932.56250	
2523	 steps: training loss - 99775.68750	, testing loss - 365232.84375	
2524	 steps: training loss - 127511.42188	, testing loss - 366691.68750	
2525	 steps: training loss - 118529.25781	, testing loss - 367434.50000	
2526	 steps: training loss - 107276.61719	, testing loss - 367955.84375	
2527	 steps: training loss - 146970.73438	, testing loss - 369098.40625	
2528	 steps: training loss - 126014.78125	, testing loss - 370078.09375	
2529	 steps: training loss - 115375.15625	, testing loss - 370754.78125	
2530	 steps: training loss - 116186.05469	, testing loss - 370026.53125	
2531	 steps: training loss - 109897.53906	, testing loss - 370414.90625	
2532	 steps: training loss - 121570.48438	, testing loss - 370928.21875	
2533	 steps: training loss - 119990.03906	, testing loss - 371660.84375	
2534	 steps: training loss - 108087.78125	, testing loss - 371757.28125	
2535	 steps: training loss - 141941.65625	, testing loss - 372074.78125	
2536	 steps: training loss - 114785.57812	, testing loss - 371785.68750	
2537	 steps: training loss - 112176.10156	, testing loss - 372263.12500	
2538	 steps: training loss - 103546.93750	, testing loss - 372983.68750	
2539	 steps: training loss - 107539.10938	, testing loss - 373106.00000	
2540	 steps: training loss - 123986.18750	, testing loss - 372426.25000	
2541	 steps: training loss - 114672.67969	, testing loss - 370898.96875	
2542	 steps: training loss - 105184.25781	, testing loss - 369628.59375	
2543	 steps: training loss - 106595.85938	, testing loss - 369582.75000	
2544	 steps: training loss - 95624.31250	, testing loss - 370082.78125	
2545	 steps: training loss - 119127.28125	, testing loss - 369870.09375	
2546	 steps: training loss - 128362.37500	, testing loss - 369176.46875	
2547	 steps: training loss - 109091.51562	, testing loss - 368073.09375	
2548	 steps: training loss - 136786.95312	, testing loss - 366133.21875	
2549	 steps: training loss - 93371.14062	, testing loss - 363831.71875	
2550	 steps: training loss - 124858.91406	, testing loss - 361288.96875	
2551	 steps: training loss - 152066.59375	, testing loss - 358910.50000	
2552	 steps: training loss - 112587.45312	, testing loss - 358564.03125	
2553	 steps: training loss - 90021.73438	, testing loss - 358818.84375	
2554	 steps: training loss - 141375.82812	, testing loss - 359535.25000	
2555	 steps: training loss - 103633.18750	, testing loss - 360583.68750	
2556	 steps: training loss - 121665.84375	, testing loss - 361331.28125	
2557	 steps: training loss - 101745.03906	, testing loss - 361723.84375	
2558	 steps: training loss - 120530.41406	, testing loss - 361993.78125	
2559	 steps: training loss - 107162.23438	, testing loss - 362345.06250	
2560	 steps: training loss - 112715.39062	, testing loss - 362230.65625	
2561	 steps: training loss - 132152.14062	, testing loss - 362452.71875	
2562	 steps: training loss - 117823.65625	, testing loss - 361582.15625	
2563	 steps: training loss - 94505.87500	, testing loss - 360680.87500	
2564	 steps: training loss - 107084.21094	, testing loss - 359796.15625	
2565	 steps: training loss - 112539.51562	, testing loss - 359743.90625	
2566	 steps: training loss - 121897.77344	, testing loss - 359803.21875	
2567	 steps: training loss - 120261.36719	, testing loss - 360035.81250	
2568	 steps: training loss - 97196.04688	, testing loss - 360069.40625	
2569	 steps: training loss - 136359.89062	, testing loss - 360243.34375	
2570	 steps: training loss - 99758.82812	, testing loss - 360228.96875	
2571	 steps: training loss - 105786.63281	, testing loss - 360526.46875	
2572	 steps: training loss - 111831.24219	, testing loss - 361046.96875	
2573	 steps: training loss - 106097.17188	, testing loss - 361362.59375	
2574	 steps: training loss - 107459.29688	, testing loss - 361686.71875	
2575	 steps: training loss - 139115.21875	, testing loss - 361138.40625	
2576	 steps: training loss - 107443.35938	, testing loss - 361477.71875	
2577	 steps: training loss - 108250.62500	, testing loss - 360983.37500	
2578	 steps: training loss - 135568.32812	, testing loss - 360766.40625	
2579	 steps: training loss - 126097.07812	, testing loss - 360935.37500	
2580	 steps: training loss - 110547.79688	, testing loss - 362055.62500	
2581	 steps: training loss - 98478.18750	, testing loss - 363223.78125	
2582	 steps: training loss - 126301.08594	, testing loss - 363974.84375	
2583	 steps: training loss - 89349.39844	, testing loss - 364208.78125	
2584	 steps: training loss - 98798.82812	, testing loss - 363621.59375	
2585	 steps: training loss - 101040.57812	, testing loss - 363295.18750	
2586	 steps: training loss - 139046.12500	, testing loss - 362222.00000	
2587	 steps: training loss - 111405.85156	, testing loss - 360906.34375	
2588	 steps: training loss - 132163.03125	, testing loss - 360144.68750	
2589	 steps: training loss - 125231.80469	, testing loss - 360081.96875	
2590	 steps: training loss - 118411.61719	, testing loss - 359642.31250	
2591	 steps: training loss - 99868.11719	, testing loss - 358758.81250	
2592	 steps: training loss - 118081.25781	, testing loss - 357661.21875	
2593	 steps: training loss - 66210.83594	, testing loss - 357299.59375	
2594	 steps: training loss - 119207.17188	, testing loss - 356792.34375	
2595	 steps: training loss - 115854.12500	, testing loss - 356232.93750	
2596	 steps: training loss - 110000.73438	, testing loss - 355381.34375	
2597	 steps: training loss - 136884.46875	, testing loss - 355712.87500	
2598	 steps: training loss - 101903.67969	, testing loss - 356980.28125	
2599	 steps: training loss - 77801.45312	, testing loss - 358965.25000	
2600	 steps: training loss - 111683.35156	, testing loss - 360987.53125	
2601	 steps: training loss - 125281.82031	, testing loss - 362833.28125	
2602	 steps: training loss - 113021.83594	, testing loss - 364847.71875	
2603	 steps: training loss - 98009.10156	, testing loss - 365152.62500	
2604	 steps: training loss - 127049.07031	, testing loss - 364831.37500	
2605	 steps: training loss - 100329.66406	, testing loss - 364414.46875	
2606	 steps: training loss - 118760.36719	, testing loss - 363962.15625	
2607	 steps: training loss - 100681.79688	, testing loss - 363536.25000	
2608	 steps: training loss - 118473.44531	, testing loss - 363588.87500	
2609	 steps: training loss - 112165.54688	, testing loss - 363898.34375	
2610	 steps: training loss - 137054.67188	, testing loss - 363868.53125	
2611	 steps: training loss - 89960.56250	, testing loss - 362449.87500	
2612	 steps: training loss - 101156.96875	, testing loss - 360530.00000	
2613	 steps: training loss - 115805.51562	, testing loss - 358268.53125	
2614	 steps: training loss - 122607.95312	, testing loss - 355897.37500	
2615	 steps: training loss - 107613.78125	, testing loss - 353899.25000	
2616	 steps: training loss - 120427.06250	, testing loss - 352563.18750	
2617	 steps: training loss - 97606.08594	, testing loss - 352497.00000	
2618	 steps: training loss - 117499.00781	, testing loss - 352573.06250	
2619	 steps: training loss - 128704.71094	, testing loss - 353308.21875	
2620	 steps: training loss - 100095.46875	, testing loss - 354222.34375	
2621	 steps: training loss - 102512.86719	, testing loss - 355628.78125	
2622	 steps: training loss - 113107.18750	, testing loss - 357288.90625	
2623	 steps: training loss - 114138.43750	, testing loss - 359220.09375	
2624	 steps: training loss - 106091.78906	, testing loss - 360799.87500	
2625	 steps: training loss - 134544.53125	, testing loss - 362188.18750	
2626	 steps: training loss - 114445.56250	, testing loss - 363600.56250	
2627	 steps: training loss - 101795.12500	, testing loss - 365164.87500	
2628	 steps: training loss - 112257.37500	, testing loss - 365668.53125	
2629	 steps: training loss - 117475.35938	, testing loss - 365816.81250	
2630	 steps: training loss - 119772.36719	, testing loss - 365352.68750	
2631	 steps: training loss - 102762.82031	, testing loss - 364905.68750	
2632	 steps: training loss - 114391.00000	, testing loss - 364088.81250	
2633	 steps: training loss - 118512.32812	, testing loss - 363764.34375	
2634	 steps: training loss - 104198.76562	, testing loss - 363733.68750	
2635	 steps: training loss - 106677.32031	, testing loss - 363732.28125	
2636	 steps: training loss - 106605.50781	, testing loss - 363632.18750	
2637	 steps: training loss - 124622.69531	, testing loss - 364290.81250	
2638	 steps: training loss - 110401.05469	, testing loss - 365250.43750	
2639	 steps: training loss - 106715.13281	, testing loss - 365054.65625	
2640	 steps: training loss - 118145.35938	, testing loss - 364524.37500	
2641	 steps: training loss - 124380.32031	, testing loss - 364009.50000	
2642	 steps: training loss - 136814.60938	, testing loss - 362530.84375	
2643	 steps: training loss - 106164.27344	, testing loss - 361523.40625	
2644	 steps: training loss - 104135.58594	, testing loss - 360653.59375	
2645	 steps: training loss - 122881.26562	, testing loss - 359066.15625	
2646	 steps: training loss - 128315.50781	, testing loss - 358388.46875	
2647	 steps: training loss - 125405.19531	, testing loss - 357467.68750	
2648	 steps: training loss - 140769.56250	, testing loss - 355815.62500	
2649	 steps: training loss - 95492.93750	, testing loss - 355634.34375	
2650	 steps: training loss - 102689.26562	, testing loss - 355779.37500	
2651	 steps: training loss - 112105.39844	, testing loss - 356010.18750	
2652	 steps: training loss - 109809.42188	, testing loss - 355754.65625	
2653	 steps: training loss - 124842.64062	, testing loss - 355418.03125	
2654	 steps: training loss - 124225.47656	, testing loss - 355183.59375	
2655	 steps: training loss - 94044.82812	, testing loss - 354658.03125	
2656	 steps: training loss - 116300.22656	, testing loss - 354503.96875	
2657	 steps: training loss - 106885.85156	, testing loss - 354457.37500	
2658	 steps: training loss - 120897.25781	, testing loss - 354832.25000	
2659	 steps: training loss - 123582.74219	, testing loss - 355710.40625	
2660	 steps: training loss - 107046.60156	, testing loss - 357312.12500	
2661	 steps: training loss - 128074.62500	, testing loss - 359009.40625	
2662	 steps: training loss - 111458.34375	, testing loss - 360867.53125	
2663	 steps: training loss - 128426.67188	, testing loss - 362069.12500	
2664	 steps: training loss - 132917.07812	, testing loss - 363592.68750	
2665	 steps: training loss - 118724.42188	, testing loss - 364425.71875	
2666	 steps: training loss - 99304.51562	, testing loss - 364729.96875	
2667	 steps: training loss - 123979.06250	, testing loss - 364912.59375	
2668	 steps: training loss - 97491.01562	, testing loss - 364990.46875	
2669	 steps: training loss - 116038.18750	, testing loss - 364761.00000	
2670	 steps: training loss - 109799.56250	, testing loss - 364126.03125	
2671	 steps: training loss - 116465.27344	, testing loss - 364126.37500	
2672	 steps: training loss - 117416.64062	, testing loss - 364182.46875	
2673	 steps: training loss - 106706.31250	, testing loss - 364611.87500	
2674	 steps: training loss - 116550.21094	, testing loss - 366110.34375	
2675	 steps: training loss - 125453.93750	, testing loss - 368362.87500	
2676	 steps: training loss - 109769.61719	, testing loss - 369707.75000	
2677	 steps: training loss - 108760.07812	, testing loss - 369386.18750	
2678	 steps: training loss - 114218.14062	, testing loss - 368640.84375	
2679	 steps: training loss - 99846.31250	, testing loss - 368516.00000	
2680	 steps: training loss - 126920.53125	, testing loss - 368250.59375	
2681	 steps: training loss - 94733.10156	, testing loss - 366616.53125	
2682	 steps: training loss - 109221.51562	, testing loss - 365087.53125	
2683	 steps: training loss - 110517.95312	, testing loss - 365080.00000	
2684	 steps: training loss - 125217.55469	, testing loss - 365166.37500	
2685	 steps: training loss - 102547.29688	, testing loss - 365077.25000	
2686	 steps: training loss - 112286.43750	, testing loss - 363778.37500	
2687	 steps: training loss - 124337.13281	, testing loss - 361962.37500	
2688	 steps: training loss - 95218.05469	, testing loss - 360670.03125	
2689	 steps: training loss - 109443.62500	, testing loss - 359784.59375	
2690	 steps: training loss - 121232.28906	, testing loss - 359227.59375	
2691	 steps: training loss - 132510.15625	, testing loss - 358558.06250	
2692	 steps: training loss - 108429.78125	, testing loss - 357848.84375	
2693	 steps: training loss - 111993.30469	, testing loss - 357619.00000	
2694	 steps: training loss - 120450.14844	, testing loss - 357990.06250	
2695	 steps: training loss - 123145.71875	, testing loss - 357781.62500	
2696	 steps: training loss - 100802.08594	, testing loss - 358158.37500	
2697	 steps: training loss - 82792.11719	, testing loss - 358410.43750	
2698	 steps: training loss - 96957.92969	, testing loss - 358395.56250	
2699	 steps: training loss - 113652.23438	, testing loss - 358533.12500	
2700	 steps: training loss - 96122.07812	, testing loss - 359227.68750	
2701	 steps: training loss - 159173.75000	, testing loss - 359978.06250	
2702	 steps: training loss - 110106.44531	, testing loss - 361270.18750	
2703	 steps: training loss - 106989.23438	, testing loss - 363517.62500	
2704	 steps: training loss - 102017.33594	, testing loss - 365269.09375	
2705	 steps: training loss - 127545.54688	, testing loss - 366323.53125	
2706	 steps: training loss - 127213.16406	, testing loss - 366402.40625	
2707	 steps: training loss - 144780.96875	, testing loss - 365889.96875	
2708	 steps: training loss - 120703.04688	, testing loss - 365511.53125	
2709	 steps: training loss - 127367.26562	, testing loss - 365615.37500	
2710	 steps: training loss - 109126.10938	, testing loss - 366322.40625	
2711	 steps: training loss - 91037.07031	, testing loss - 366620.62500	
2712	 steps: training loss - 121963.21094	, testing loss - 366478.25000	
2713	 steps: training loss - 112216.89844	, testing loss - 367039.68750	
2714	 steps: training loss - 125140.58594	, testing loss - 367470.18750	
2715	 steps: training loss - 102636.35156	, testing loss - 367254.56250	
2716	 steps: training loss - 118945.45312	, testing loss - 366250.21875	
2717	 steps: training loss - 116666.86719	, testing loss - 365452.31250	
2718	 steps: training loss - 137495.12500	, testing loss - 365190.50000	
2719	 steps: training loss - 91641.25781	, testing loss - 363485.75000	
2720	 steps: training loss - 123200.30469	, testing loss - 361789.87500	
2721	 steps: training loss - 108901.42969	, testing loss - 361132.81250	
2722	 steps: training loss - 130224.88281	, testing loss - 362296.06250	
2723	 steps: training loss - 132052.84375	, testing loss - 362945.00000	
2724	 steps: training loss - 118868.05469	, testing loss - 363782.40625	
2725	 steps: training loss - 117758.01562	, testing loss - 364643.25000	
2726	 steps: training loss - 101884.48438	, testing loss - 365441.96875	
2727	 steps: training loss - 116307.81250	, testing loss - 365726.15625	
2728	 steps: training loss - 120434.30469	, testing loss - 366023.09375	
2729	 steps: training loss - 116083.56250	, testing loss - 366430.43750	
2730	 steps: training loss - 85525.85156	, testing loss - 366557.21875	
2731	 steps: training loss - 110078.83594	, testing loss - 366087.37500	
2732	 steps: training loss - 116948.96094	, testing loss - 365736.78125	
2733	 steps: training loss - 115317.25000	, testing loss - 366176.43750	
2734	 steps: training loss - 114648.25781	, testing loss - 367011.00000	
2735	 steps: training loss - 112719.37500	, testing loss - 368773.06250	
2736	 steps: training loss - 108133.15625	, testing loss - 371224.09375	
2737	 steps: training loss - 149469.96875	, testing loss - 374097.31250	
2738	 steps: training loss - 106277.51562	, testing loss - 374241.34375	
2739	 steps: training loss - 133000.62500	, testing loss - 372255.18750	
2740	 steps: training loss - 125098.98438	, testing loss - 370293.75000	
2741	 steps: training loss - 102804.62500	, testing loss - 368031.93750	
2742	 steps: training loss - 126589.83594	, testing loss - 365924.18750	
2743	 steps: training loss - 100313.81250	, testing loss - 364414.18750	
2744	 steps: training loss - 117184.83594	, testing loss - 363379.65625	
2745	 steps: training loss - 115952.65625	, testing loss - 363385.93750	
2746	 steps: training loss - 124769.02344	, testing loss - 363608.75000	
2747	 steps: training loss - 105589.15625	, testing loss - 362843.46875	
2748	 steps: training loss - 101930.83594	, testing loss - 361834.28125	
2749	 steps: training loss - 100026.12500	, testing loss - 361294.53125	
2750	 steps: training loss - 93890.01562	, testing loss - 360754.65625	
2751	 steps: training loss - 127868.34375	, testing loss - 360040.71875	
2752	 steps: training loss - 122041.91406	, testing loss - 360399.59375	
2753	 steps: training loss - 133838.71875	, testing loss - 361030.56250	
2754	 steps: training loss - 98287.60938	, testing loss - 361285.06250	
2755	 steps: training loss - 134636.90625	, testing loss - 361139.21875	
2756	 steps: training loss - 116309.86719	, testing loss - 361141.28125	
2757	 steps: training loss - 119988.53906	, testing loss - 360550.59375	
2758	 steps: training loss - 98428.36719	, testing loss - 359931.87500	
2759	 steps: training loss - 109230.84375	, testing loss - 359806.59375	
2760	 steps: training loss - 106682.89062	, testing loss - 359548.43750	
2761	 steps: training loss - 91275.52344	, testing loss - 359194.06250	
2762	 steps: training loss - 106309.32812	, testing loss - 358594.21875	
2763	 steps: training loss - 132533.26562	, testing loss - 357956.87500	
2764	 steps: training loss - 131548.81250	, testing loss - 358782.78125	
2765	 steps: training loss - 123636.33594	, testing loss - 359925.46875	
2766	 steps: training loss - 105767.55469	, testing loss - 361847.75000	
2767	 steps: training loss - 95853.49219	, testing loss - 364219.96875	
2768	 steps: training loss - 140020.78125	, testing loss - 366109.78125	
2769	 steps: training loss - 125270.70312	, testing loss - 366757.96875	
2770	 steps: training loss - 146205.65625	, testing loss - 368262.09375	
2771	 steps: training loss - 100236.09375	, testing loss - 370181.84375	
2772	 steps: training loss - 126323.46875	, testing loss - 370702.50000	
2773	 steps: training loss - 102404.75000	, testing loss - 369535.81250	
2774	 steps: training loss - 127379.90625	, testing loss - 367671.06250	
2775	 steps: training loss - 166923.01562	, testing loss - 366211.18750	
2776	 steps: training loss - 99313.76562	, testing loss - 364210.68750	
2777	 steps: training loss - 126152.56250	, testing loss - 362171.21875	
2778	 steps: training loss - 91864.77344	, testing loss - 360569.50000	
2779	 steps: training loss - 130112.94531	, testing loss - 359440.03125	
2780	 steps: training loss - 94487.43750	, testing loss - 359270.25000	
2781	 steps: training loss - 108175.93750	, testing loss - 358858.93750	
2782	 steps: training loss - 101381.54688	, testing loss - 358329.96875	
2783	 steps: training loss - 111578.63281	, testing loss - 357825.65625	
2784	 steps: training loss - 141014.57812	, testing loss - 357563.53125	
2785	 steps: training loss - 89957.00000	, testing loss - 357229.00000	
2786	 steps: training loss - 131782.68750	, testing loss - 356626.84375	
2787	 steps: training loss - 105751.56250	, testing loss - 356327.46875	
2788	 steps: training loss - 92660.55469	, testing loss - 355425.96875	
2789	 steps: training loss - 138782.65625	, testing loss - 354307.06250	
2790	 steps: training loss - 112624.37500	, testing loss - 354396.37500	
2791	 steps: training loss - 108822.28125	, testing loss - 354843.40625	
2792	 steps: training loss - 123755.78125	, testing loss - 355225.03125	
2793	 steps: training loss - 106558.90625	, testing loss - 356136.09375	
2794	 steps: training loss - 100438.36719	, testing loss - 356853.06250	
2795	 steps: training loss - 112744.91406	, testing loss - 357523.31250	
2796	 steps: training loss - 126464.59375	, testing loss - 358209.00000	
2797	 steps: training loss - 105259.26562	, testing loss - 358771.62500	
2798	 steps: training loss - 119196.71875	, testing loss - 359788.43750	
2799	 steps: training loss - 112411.39844	, testing loss - 361536.03125	
2800	 steps: training loss - 100455.48438	, testing loss - 362978.56250	
2801	 steps: training loss - 128366.75781	, testing loss - 363474.78125	
2802	 steps: training loss - 140147.78125	, testing loss - 362393.15625	
2803	 steps: training loss - 120792.53125	, testing loss - 360729.75000	
2804	 steps: training loss - 126305.46094	, testing loss - 359614.43750	
2805	 steps: training loss - 120005.05469	, testing loss - 358964.75000	
2806	 steps: training loss - 121592.23438	, testing loss - 358838.93750	
2807	 steps: training loss - 115886.35938	, testing loss - 358361.40625	
2808	 steps: training loss - 116734.34375	, testing loss - 358165.50000	
2809	 steps: training loss - 105024.04688	, testing loss - 358665.56250	
2810	 steps: training loss - 121590.54688	, testing loss - 358937.28125	
2811	 steps: training loss - 110769.78125	, testing loss - 358949.15625	
2812	 steps: training loss - 93296.03906	, testing loss - 357927.46875	
2813	 steps: training loss - 107873.71094	, testing loss - 356667.50000	
2814	 steps: training loss - 107862.64062	, testing loss - 355264.03125	
2815	 steps: training loss - 107245.39844	, testing loss - 353721.62500	
2816	 steps: training loss - 109924.97656	, testing loss - 352096.87500	
2817	 steps: training loss - 129059.66406	, testing loss - 351060.96875	
2818	 steps: training loss - 101030.39844	, testing loss - 351210.75000	
2819	 steps: training loss - 134376.87500	, testing loss - 351701.81250	
2820	 steps: training loss - 133758.67188	, testing loss - 353194.31250	
2821	 steps: training loss - 103210.57812	, testing loss - 355932.03125	
2822	 steps: training loss - 99498.71094	, testing loss - 358557.68750	
2823	 steps: training loss - 99400.50000	, testing loss - 359638.21875	
2824	 steps: training loss - 105178.74219	, testing loss - 360118.68750	
2825	 steps: training loss - 128467.75000	, testing loss - 360344.28125	
2826	 steps: training loss - 118241.03906	, testing loss - 359966.15625	
2827	 steps: training loss - 119416.31250	, testing loss - 359297.87500	
2828	 steps: training loss - 105942.53125	, testing loss - 357591.06250	
2829	 steps: training loss - 111121.37500	, testing loss - 356081.75000	
2830	 steps: training loss - 134112.31250	, testing loss - 355520.25000	
2831	 steps: training loss - 113083.79688	, testing loss - 355191.53125	
2832	 steps: training loss - 128139.68750	, testing loss - 355250.37500	
2833	 steps: training loss - 106879.12500	, testing loss - 355372.31250	
2834	 steps: training loss - 122537.92188	, testing loss - 355060.37500	
2835	 steps: training loss - 93973.85156	, testing loss - 354198.46875	
2836	 steps: training loss - 104816.35938	, testing loss - 353995.34375	
2837	 steps: training loss - 113896.34375	, testing loss - 355422.15625	
2838	 steps: training loss - 128300.09375	, testing loss - 357726.18750	
2839	 steps: training loss - 112328.48438	, testing loss - 360625.09375	
2840	 steps: training loss - 89796.28906	, testing loss - 363756.00000	
2841	 steps: training loss - 94859.18750	, testing loss - 365743.37500	
2842	 steps: training loss - 103687.48438	, testing loss - 366885.12500	
2843	 steps: training loss - 121203.50781	, testing loss - 366964.75000	
2844	 steps: training loss - 92037.14844	, testing loss - 365965.81250	
2845	 steps: training loss - 122066.19531	, testing loss - 364755.75000	
2846	 steps: training loss - 118732.42188	, testing loss - 363547.46875	
2847	 steps: training loss - 93761.92969	, testing loss - 362532.18750	
2848	 steps: training loss - 105705.73438	, testing loss - 361724.34375	
2849	 steps: training loss - 121661.03125	, testing loss - 361851.59375	
2850	 steps: training loss - 123978.89844	, testing loss - 361626.25000	
2851	 steps: training loss - 102496.09375	, testing loss - 361840.81250	
2852	 steps: training loss - 114357.63281	, testing loss - 361706.87500	
2853	 steps: training loss - 100515.53125	, testing loss - 361053.06250	
2854	 steps: training loss - 127902.89844	, testing loss - 360408.12500	
2855	 steps: training loss - 103381.95312	, testing loss - 361461.25000	
2856	 steps: training loss - 106536.67188	, testing loss - 363095.56250	
2857	 steps: training loss - 102772.40625	, testing loss - 364159.18750	
2858	 steps: training loss - 120629.05469	, testing loss - 364287.71875	
2859	 steps: training loss - 135993.87500	, testing loss - 363774.65625	
2860	 steps: training loss - 106268.14844	, testing loss - 364253.40625	
2861	 steps: training loss - 80885.82031	, testing loss - 364369.09375	
2862	 steps: training loss - 122763.75000	, testing loss - 364273.40625	
2863	 steps: training loss - 90561.95312	, testing loss - 364104.65625	
2864	 steps: training loss - 113759.38281	, testing loss - 364328.59375	
2865	 steps: training loss - 119950.14062	, testing loss - 364963.06250	
2866	 steps: training loss - 116403.42188	, testing loss - 365037.96875	
2867	 steps: training loss - 121717.52344	, testing loss - 365489.50000	
2868	 steps: training loss - 115165.99219	, testing loss - 365503.28125	
2869	 steps: training loss - 141707.18750	, testing loss - 365564.15625	
2870	 steps: training loss - 111447.92969	, testing loss - 366449.40625	
2871	 steps: training loss - 107268.63281	, testing loss - 367085.90625	
2872	 steps: training loss - 118432.35938	, testing loss - 366959.37500	
2873	 steps: training loss - 91222.49219	, testing loss - 366670.68750	
2874	 steps: training loss - 129149.14844	, testing loss - 366120.25000	
2875	 steps: training loss - 136177.89062	, testing loss - 366692.84375	
2876	 steps: training loss - 115283.01562	, testing loss - 367986.25000	
2877	 steps: training loss - 114750.75781	, testing loss - 369491.62500	
2878	 steps: training loss - 108316.82031	, testing loss - 370674.31250	
2879	 steps: training loss - 127450.19531	, testing loss - 371271.71875	
2880	 steps: training loss - 96259.17969	, testing loss - 371475.43750	
2881	 steps: training loss - 138316.29688	, testing loss - 371175.96875	
2882	 steps: training loss - 127449.35156	, testing loss - 369941.90625	
2883	 steps: training loss - 109190.03125	, testing loss - 367638.31250	
2884	 steps: training loss - 100632.22656	, testing loss - 365714.37500	
2885	 steps: training loss - 95810.80469	, testing loss - 364188.43750	
2886	 steps: training loss - 108730.28906	, testing loss - 362865.68750	
2887	 steps: training loss - 118220.56250	, testing loss - 360910.53125	
2888	 steps: training loss - 108693.30469	, testing loss - 359325.78125	
2889	 steps: training loss - 107104.21094	, testing loss - 359111.81250	
2890	 steps: training loss - 121353.70312	, testing loss - 358256.56250	
2891	 steps: training loss - 111663.89844	, testing loss - 356893.78125	
2892	 steps: training loss - 132667.71875	, testing loss - 355172.31250	
2893	 steps: training loss - 99920.86719	, testing loss - 354256.68750	
2894	 steps: training loss - 125847.53125	, testing loss - 353726.09375	
2895	 steps: training loss - 141761.23438	, testing loss - 354114.96875	
2896	 steps: training loss - 103909.78906	, testing loss - 354943.43750	
2897	 steps: training loss - 125559.92188	, testing loss - 355365.84375	
2898	 steps: training loss - 105302.83594	, testing loss - 356813.09375	
2899	 steps: training loss - 111254.49219	, testing loss - 358388.40625	
2900	 steps: training loss - 93473.32812	, testing loss - 359948.09375	
2901	 steps: training loss - 123326.16406	, testing loss - 361188.71875	
2902	 steps: training loss - 122938.60938	, testing loss - 361807.65625	
2903	 steps: training loss - 103546.72656	, testing loss - 362108.90625	
2904	 steps: training loss - 114286.46875	, testing loss - 362804.21875	
2905	 steps: training loss - 119067.10938	, testing loss - 363763.90625	
2906	 steps: training loss - 109438.30469	, testing loss - 364492.31250	
2907	 steps: training loss - 124270.19531	, testing loss - 366611.03125	
2908	 steps: training loss - 118657.75781	, testing loss - 368616.31250	
2909	 steps: training loss - 125047.71875	, testing loss - 370469.56250	
2910	 steps: training loss - 111443.58594	, testing loss - 370619.78125	
2911	 steps: training loss - 110103.18750	, testing loss - 370083.56250	
2912	 steps: training loss - 105053.17969	, testing loss - 369046.62500	
2913	 steps: training loss - 147312.98438	, testing loss - 367946.12500	
2914	 steps: training loss - 111647.86719	, testing loss - 365340.40625	
2915	 steps: training loss - 105706.62500	, testing loss - 361644.81250	
2916	 steps: training loss - 122309.43750	, testing loss - 358258.50000	
2917	 steps: training loss - 125058.75000	, testing loss - 355771.87500	
2918	 steps: training loss - 113710.25781	, testing loss - 355199.90625	
2919	 steps: training loss - 115155.25000	, testing loss - 355343.90625	
2920	 steps: training loss - 125219.40625	, testing loss - 355847.00000	
2921	 steps: training loss - 142642.15625	, testing loss - 356061.06250	
2922	 steps: training loss - 119600.85938	, testing loss - 356312.09375	
2923	 steps: training loss - 107960.50000	, testing loss - 356512.00000	
2924	 steps: training loss - 109909.02344	, testing loss - 356473.09375	
2925	 steps: training loss - 116352.01562	, testing loss - 356151.06250	
2926	 steps: training loss - 112738.65625	, testing loss - 356082.65625	
2927	 steps: training loss - 139081.98438	, testing loss - 356808.09375	
2928	 steps: training loss - 101389.33594	, testing loss - 356970.34375	
2929	 steps: training loss - 109104.39062	, testing loss - 357644.06250	
2930	 steps: training loss - 83899.24219	, testing loss - 357863.65625	
2931	 steps: training loss - 130703.81250	, testing loss - 358316.93750	
2932	 steps: training loss - 100786.13281	, testing loss - 358689.06250	
2933	 steps: training loss - 106969.24219	, testing loss - 358975.56250	
2934	 steps: training loss - 96080.04688	, testing loss - 358974.34375	
2935	 steps: training loss - 119752.86719	, testing loss - 358888.00000	
2936	 steps: training loss - 130168.25000	, testing loss - 357795.12500	
2937	 steps: training loss - 98620.93750	, testing loss - 356347.46875	
2938	 steps: training loss - 94075.33594	, testing loss - 354785.50000	
2939	 steps: training loss - 119432.15625	, testing loss - 353413.68750	
2940	 steps: training loss - 139399.48438	, testing loss - 351966.37500	
2941	 steps: training loss - 90406.43750	, testing loss - 351964.75000	
2942	 steps: training loss - 101643.76562	, testing loss - 352815.50000	
2943	 steps: training loss - 115847.46875	, testing loss - 353858.84375	
2944	 steps: training loss - 121417.45312	, testing loss - 355194.84375	
2945	 steps: training loss - 118104.09375	, testing loss - 356418.12500	
2946	 steps: training loss - 115770.53125	, testing loss - 358546.78125	
2947	 steps: training loss - 107162.70312	, testing loss - 360079.06250	
2948	 steps: training loss - 104541.89844	, testing loss - 360378.75000	
2949	 steps: training loss - 101424.31250	, testing loss - 360780.43750	
2950	 steps: training loss - 122673.75781	, testing loss - 361410.93750	
2951	 steps: training loss - 106215.82812	, testing loss - 362290.00000	
2952	 steps: training loss - 120231.57812	, testing loss - 362253.90625	
2953	 steps: training loss - 120320.10938	, testing loss - 361401.90625	
2954	 steps: training loss - 133099.84375	, testing loss - 360510.06250	
2955	 steps: training loss - 107010.09375	, testing loss - 359454.00000	
2956	 steps: training loss - 125762.88281	, testing loss - 358507.09375	
2957	 steps: training loss - 124472.01562	, testing loss - 357528.87500	
2958	 steps: training loss - 116865.89062	, testing loss - 356750.81250	
2959	 steps: training loss - 115635.65625	, testing loss - 356633.62500	
2960	 steps: training loss - 128788.97656	, testing loss - 356800.75000	
2961	 steps: training loss - 110655.75000	, testing loss - 356915.28125	
2962	 steps: training loss - 129331.85156	, testing loss - 357060.78125	
2963	 steps: training loss - 123177.57031	, testing loss - 358118.06250	
2964	 steps: training loss - 122142.21875	, testing loss - 360099.78125	
2965	 steps: training loss - 124883.71875	, testing loss - 361444.09375	
2966	 steps: training loss - 110667.96094	, testing loss - 361663.50000	
2967	 steps: training loss - 113755.44531	, testing loss - 361981.12500	
2968	 steps: training loss - 107285.42188	, testing loss - 361781.12500	
2969	 steps: training loss - 115588.64844	, testing loss - 361141.68750	
2970	 steps: training loss - 120031.17188	, testing loss - 360515.25000	
2971	 steps: training loss - 120343.47656	, testing loss - 359130.31250	
2972	 steps: training loss - 113268.11719	, testing loss - 358233.84375	
2973	 steps: training loss - 106394.35156	, testing loss - 357488.18750	
2974	 steps: training loss - 107930.30469	, testing loss - 356117.87500	
2975	 steps: training loss - 123336.32031	, testing loss - 354939.18750	
2976	 steps: training loss - 80944.27344	, testing loss - 353235.00000	
2977	 steps: training loss - 122113.53125	, testing loss - 351990.53125	
2978	 steps: training loss - 97158.07812	, testing loss - 351080.06250	
2979	 steps: training loss - 100803.18750	, testing loss - 350023.59375	
2980	 steps: training loss - 130677.84375	, testing loss - 349139.53125	
2981	 steps: training loss - 134944.93750	, testing loss - 348535.15625	
2982	 steps: training loss - 122270.71094	, testing loss - 348287.75000	
2983	 steps: training loss - 100281.10938	, testing loss - 348463.81250	
2984	 steps: training loss - 116749.83594	, testing loss - 349146.03125	
2985	 steps: training loss - 112981.31250	, testing loss - 350473.25000	
2986	 steps: training loss - 112329.07031	, testing loss - 352518.71875	
2987	 steps: training loss - 120237.64062	, testing loss - 355415.81250	
2988	 steps: training loss - 121935.32031	, testing loss - 358399.90625	
2989	 steps: training loss - 102605.91406	, testing loss - 361309.00000	
2990	 steps: training loss - 114170.77344	, testing loss - 363411.65625	
2991	 steps: training loss - 104858.25000	, testing loss - 365289.00000	
2992	 steps: training loss - 120605.70312	, testing loss - 367072.28125	
2993	 steps: training loss - 92235.21094	, testing loss - 370472.12500	
2994	 steps: training loss - 135783.40625	, testing loss - 373551.65625	
2995	 steps: training loss - 146119.46875	, testing loss - 376301.40625	
2996	 steps: training loss - 118236.64062	, testing loss - 376385.43750	
2997	 steps: training loss - 136848.59375	, testing loss - 375335.68750	
2998	 steps: training loss - 101478.75781	, testing loss - 373344.46875	
2999	 steps: training loss - 97077.15625	, testing loss - 369948.06250	
3000	 steps: training loss - 112968.30469	, testing loss - 366376.37500	
3001	 steps: training loss - 121334.40625	, testing loss - 363245.59375	
3002	 steps: training loss - 112767.32031	, testing loss - 361266.78125	
3003	 steps: training loss - 90581.18750	, testing loss - 359603.59375	
3004	 steps: training loss - 114651.53906	, testing loss - 357574.09375	
3005	 steps: training loss - 116344.68750	, testing loss - 355738.93750	
3006	 steps: training loss - 142497.25000	, testing loss - 355034.28125	
3007	 steps: training loss - 109764.25000	, testing loss - 354572.06250	
3008	 steps: training loss - 133132.43750	, testing loss - 354888.84375	
3009	 steps: training loss - 104940.38281	, testing loss - 354859.00000	
3010	 steps: training loss - 93280.27344	, testing loss - 354670.56250	
3011	 steps: training loss - 122062.35156	, testing loss - 354138.18750	
3012	 steps: training loss - 121792.71094	, testing loss - 354379.43750	
3013	 steps: training loss - 117533.21094	, testing loss - 355139.21875	
3014	 steps: training loss - 127400.42188	, testing loss - 355786.34375	
3015	 steps: training loss - 94723.42188	, testing loss - 356536.40625	
3016	 steps: training loss - 110469.76562	, testing loss - 357958.75000	
3017	 steps: training loss - 104824.67969	, testing loss - 360021.09375	
3018	 steps: training loss - 100360.23438	, testing loss - 361681.65625	
3019	 steps: training loss - 106101.31250	, testing loss - 362943.31250	
3020	 steps: training loss - 100382.59375	, testing loss - 364479.93750	
3021	 steps: training loss - 117436.85156	, testing loss - 365432.21875	
3022	 steps: training loss - 116561.24219	, testing loss - 365824.43750	
3023	 steps: training loss - 93522.29688	, testing loss - 366127.15625	
3024	 steps: training loss - 111783.82031	, testing loss - 366037.90625	
3025	 steps: training loss - 109087.67188	, testing loss - 366221.81250	
3026	 steps: training loss - 118058.89062	, testing loss - 365534.43750	
3027	 steps: training loss - 105559.22656	, testing loss - 366376.75000	
3028	 steps: training loss - 118971.17969	, testing loss - 366813.96875	
3029	 steps: training loss - 98694.75000	, testing loss - 367053.43750	
3030	 steps: training loss - 133708.81250	, testing loss - 368828.43750	
3031	 steps: training loss - 110586.35156	, testing loss - 371317.43750	
3032	 steps: training loss - 139142.18750	, testing loss - 374646.21875	
3033	 steps: training loss - 118427.93750	, testing loss - 377858.59375	
3034	 steps: training loss - 114091.90625	, testing loss - 379805.37500	
3035	 steps: training loss - 95599.53125	, testing loss - 379988.50000	
3036	 steps: training loss - 121362.15625	, testing loss - 379715.68750	
3037	 steps: training loss - 106852.42969	, testing loss - 377475.34375	
3038	 steps: training loss - 84678.73438	, testing loss - 374658.31250	
3039	 steps: training loss - 102744.79688	, testing loss - 371952.37500	
3040	 steps: training loss - 122682.42969	, testing loss - 369108.81250	
3041	 steps: training loss - 105245.94531	, testing loss - 365865.53125	
3042	 steps: training loss - 123929.19531	, testing loss - 363421.78125	
3043	 steps: training loss - 123546.67969	, testing loss - 361249.75000	
3044	 steps: training loss - 137892.56250	, testing loss - 359057.12500	
3045	 steps: training loss - 112283.72656	, testing loss - 357085.65625	
3046	 steps: training loss - 106073.28125	, testing loss - 355862.12500	
3047	 steps: training loss - 103618.39844	, testing loss - 355456.21875	
3048	 steps: training loss - 89046.70312	, testing loss - 355034.18750	
3049	 steps: training loss - 139957.76562	, testing loss - 354044.03125	
3050	 steps: training loss - 91559.80469	, testing loss - 352996.00000	
3051	 steps: training loss - 126961.07031	, testing loss - 352170.93750	
3052	 steps: training loss - 129032.44531	, testing loss - 351831.68750	
3053	 steps: training loss - 113918.19531	, testing loss - 352129.34375	
3054	 steps: training loss - 132417.12500	, testing loss - 352696.40625	
3055	 steps: training loss - 107947.59375	, testing loss - 352880.90625	
3056	 steps: training loss - 100519.77344	, testing loss - 352843.59375	
3057	 steps: training loss - 93859.07031	, testing loss - 352817.15625	
3058	 steps: training loss - 129098.17188	, testing loss - 353119.75000	
3059	 steps: training loss - 118007.41406	, testing loss - 353696.50000	
3060	 steps: training loss - 82244.55469	, testing loss - 354645.25000	
3061	 steps: training loss - 129400.09375	, testing loss - 355410.59375	
3062	 steps: training loss - 95341.98438	, testing loss - 356048.37500	
3063	 steps: training loss - 117057.25000	, testing loss - 356083.21875	
3064	 steps: training loss - 107166.39062	, testing loss - 355320.15625	
3065	 steps: training loss - 121427.89844	, testing loss - 354544.31250	
3066	 steps: training loss - 147827.68750	, testing loss - 353734.06250	
3067	 steps: training loss - 130178.72656	, testing loss - 352773.31250	
3068	 steps: training loss - 114507.38281	, testing loss - 351926.81250	
3069	 steps: training loss - 121399.83594	, testing loss - 351822.40625	
3070	 steps: training loss - 117304.65625	, testing loss - 351951.93750	
3071	 steps: training loss - 94753.70312	, testing loss - 353083.96875	
3072	 steps: training loss - 129773.57031	, testing loss - 354680.93750	
3073	 steps: training loss - 125844.28125	, testing loss - 356003.15625	
3074	 steps: training loss - 94964.00781	, testing loss - 357121.53125	
3075	 steps: training loss - 117192.75000	, testing loss - 357659.56250	
3076	 steps: training loss - 129159.43750	, testing loss - 358011.65625	
3077	 steps: training loss - 110003.07031	, testing loss - 358670.50000	
3078	 steps: training loss - 90978.96094	, testing loss - 358849.43750	
3079	 steps: training loss - 112397.92188	, testing loss - 358664.62500	
3080	 steps: training loss - 125656.71094	, testing loss - 358648.31250	
3081	 steps: training loss - 117780.73438	, testing loss - 359738.00000	
3082	 steps: training loss - 141053.84375	, testing loss - 360874.56250	
3083	 steps: training loss - 118302.36719	, testing loss - 362437.71875	
3084	 steps: training loss - 107724.58594	, testing loss - 363748.21875	
3085	 steps: training loss - 121361.60156	, testing loss - 365282.78125	
3086	 steps: training loss - 105728.16406	, testing loss - 366719.06250	
3087	 steps: training loss - 122476.88281	, testing loss - 367367.62500	
3088	 steps: training loss - 114388.34375	, testing loss - 367815.84375	
3089	 steps: training loss - 123221.17969	, testing loss - 367627.37500	
3090	 steps: training loss - 102557.51562	, testing loss - 367314.03125	
3091	 steps: training loss - 107136.95312	, testing loss - 366768.18750	
3092	 steps: training loss - 115712.47656	, testing loss - 366551.25000	
3093	 steps: training loss - 112018.28906	, testing loss - 365591.00000	
3094	 steps: training loss - 82841.71875	, testing loss - 364754.68750	
3095	 steps: training loss - 124661.41406	, testing loss - 364197.03125	
3096	 steps: training loss - 125662.13281	, testing loss - 362882.56250	
3097	 steps: training loss - 106337.51562	, testing loss - 361792.78125	
3098	 steps: training loss - 118045.41406	, testing loss - 360464.40625	
3099	 steps: training loss - 143666.46875	, testing loss - 359095.43750	
3100	 steps: training loss - 111079.16406	, testing loss - 358482.90625	
3101	 steps: training loss - 112905.23438	, testing loss - 358078.15625	
3102	 steps: training loss - 114846.28125	, testing loss - 357338.59375	
3103	 steps: training loss - 94094.44531	, testing loss - 356920.56250	
3104	 steps: training loss - 124464.82031	, testing loss - 356398.46875	
3105	 steps: training loss - 112873.56250	, testing loss - 355269.25000	
3106	 steps: training loss - 138544.67188	, testing loss - 353990.15625	
3107	 steps: training loss - 104875.08594	, testing loss - 353591.03125	
3108	 steps: training loss - 109616.84375	, testing loss - 353428.71875	
3109	 steps: training loss - 138859.85938	, testing loss - 354140.00000	
3110	 steps: training loss - 124641.28125	, testing loss - 355822.31250	
3111	 steps: training loss - 124099.81250	, testing loss - 357273.68750	
3112	 steps: training loss - 138253.56250	, testing loss - 358343.21875	
3113	 steps: training loss - 104691.59375	, testing loss - 359046.00000	
3114	 steps: training loss - 141055.07812	, testing loss - 359691.96875	
3115	 steps: training loss - 132013.12500	, testing loss - 359857.90625	
3116	 steps: training loss - 121469.67188	, testing loss - 359366.81250	
3117	 steps: training loss - 128491.95312	, testing loss - 358928.00000	
3118	 steps: training loss - 128877.10156	, testing loss - 358324.90625	
3119	 steps: training loss - 115595.29688	, testing loss - 358712.65625	
3120	 steps: training loss - 99103.59375	, testing loss - 358839.87500	
3121	 steps: training loss - 100389.32031	, testing loss - 358499.21875	
3122	 steps: training loss - 105535.91406	, testing loss - 357998.25000	
3123	 steps: training loss - 122917.53906	, testing loss - 357461.25000	
3124	 steps: training loss - 112416.93750	, testing loss - 357101.50000	
3125	 steps: training loss - 104139.63281	, testing loss - 356390.78125	
3126	 steps: training loss - 134908.20312	, testing loss - 354978.06250	
3127	 steps: training loss - 101395.82031	, testing loss - 353189.12500	
3128	 steps: training loss - 130757.83594	, testing loss - 352005.37500	
3129	 steps: training loss - 120762.88281	, testing loss - 351828.96875	
3130	 steps: training loss - 115050.60938	, testing loss - 352226.75000	
3131	 steps: training loss - 81324.42969	, testing loss - 353149.25000	
3132	 steps: training loss - 135435.09375	, testing loss - 353478.28125	
3133	 steps: training loss - 131188.01562	, testing loss - 353891.62500	
3134	 steps: training loss - 115070.85938	, testing loss - 354326.53125	
3135	 steps: training loss - 89538.17188	, testing loss - 355322.81250	
3136	 steps: training loss - 87763.07031	, testing loss - 356191.96875	
3137	 steps: training loss - 118669.67969	, testing loss - 356062.37500	
3138	 steps: training loss - 109929.15625	, testing loss - 356076.71875	
3139	 steps: training loss - 119026.88281	, testing loss - 356978.18750	
3140	 steps: training loss - 138185.89062	, testing loss - 358312.78125	
3141	 steps: training loss - 126105.54688	, testing loss - 360640.78125	
3142	 steps: training loss - 120011.19531	, testing loss - 362831.21875	
3143	 steps: training loss - 129619.26562	, testing loss - 364920.46875	
3144	 steps: training loss - 107396.76562	, testing loss - 366150.34375	
3145	 steps: training loss - 136572.37500	, testing loss - 368159.25000	
3146	 steps: training loss - 99983.54688	, testing loss - 370604.59375	
3147	 steps: training loss - 97438.45312	, testing loss - 372540.75000	
3148	 steps: training loss - 105988.72656	, testing loss - 373909.31250	
3149	 steps: training loss - 112069.71875	, testing loss - 374294.87500	
3150	 steps: training loss - 133687.23438	, testing loss - 373649.65625	
3151	 steps: training loss - 104173.94531	, testing loss - 371452.00000	
3152	 steps: training loss - 103175.88281	, testing loss - 369841.84375	
3153	 steps: training loss - 112802.00781	, testing loss - 367661.65625	
3154	 steps: training loss - 114050.65625	, testing loss - 365805.40625	
3155	 steps: training loss - 125075.39844	, testing loss - 364838.40625	
3156	 steps: training loss - 125184.40625	, testing loss - 363208.62500	
3157	 steps: training loss - 106436.35156	, testing loss - 362532.00000	
3158	 steps: training loss - 98729.01562	, testing loss - 363148.18750	
3159	 steps: training loss - 94172.96875	, testing loss - 364667.00000	
3160	 steps: training loss - 97047.17969	, testing loss - 365679.93750	
3161	 steps: training loss - 102115.81250	, testing loss - 365702.06250	
3162	 steps: training loss - 106700.25781	, testing loss - 364979.12500	
3163	 steps: training loss - 110543.75781	, testing loss - 365504.37500	
3164	 steps: training loss - 99453.91406	, testing loss - 365863.78125	
3165	 steps: training loss - 99643.47656	, testing loss - 365635.43750	
3166	 steps: training loss - 100394.25781	, testing loss - 365448.00000	
3167	 steps: training loss - 126420.76562	, testing loss - 365651.53125	
3168	 steps: training loss - 123060.76562	, testing loss - 364751.90625	
3169	 steps: training loss - 125365.67969	, testing loss - 362646.03125	
3170	 steps: training loss - 110368.20312	, testing loss - 360843.15625	
3171	 steps: training loss - 100532.39062	, testing loss - 359009.15625	
3172	 steps: training loss - 101969.59375	, testing loss - 357761.62500	
3173	 steps: training loss - 100845.25781	, testing loss - 356086.75000	
3174	 steps: training loss - 114570.98438	, testing loss - 353948.12500	
3175	 steps: training loss - 95702.32031	, testing loss - 352133.15625	
3176	 steps: training loss - 118873.50000	, testing loss - 351213.09375	
3177	 steps: training loss - 106725.66406	, testing loss - 350396.18750	
3178	 steps: training loss - 127653.89844	, testing loss - 349404.59375	
3179	 steps: training loss - 114948.60156	, testing loss - 347793.00000	
3180	 steps: training loss - 105954.74219	, testing loss - 347016.84375	
3181	 steps: training loss - 112647.58594	, testing loss - 347092.03125	
3182	 steps: training loss - 110719.38281	, testing loss - 347994.65625	
3183	 steps: training loss - 125792.42969	, testing loss - 349312.53125	
3184	 steps: training loss - 112980.64062	, testing loss - 350639.50000	
3185	 steps: training loss - 130780.65625	, testing loss - 351823.75000	
3186	 steps: training loss - 99883.85156	, testing loss - 352772.00000	
3187	 steps: training loss - 129737.21094	, testing loss - 353608.21875	
3188	 steps: training loss - 111157.01562	, testing loss - 354990.18750	
3189	 steps: training loss - 110288.05469	, testing loss - 357090.21875	
3190	 steps: training loss - 108425.67969	, testing loss - 359966.62500	
3191	 steps: training loss - 108940.68750	, testing loss - 362777.40625	
3192	 steps: training loss - 124032.20312	, testing loss - 366716.71875	
3193	 steps: training loss - 84406.03906	, testing loss - 370708.87500	
3194	 steps: training loss - 110396.02344	, testing loss - 374093.87500	
3195	 steps: training loss - 103961.69531	, testing loss - 376418.62500	
3196	 steps: training loss - 85933.94531	, testing loss - 378067.40625	
3197	 steps: training loss - 96407.38281	, testing loss - 379408.46875	
3198	 steps: training loss - 118725.01562	, testing loss - 379901.46875	
3199	 steps: training loss - 119374.64062	, testing loss - 379191.12500	
3200	 steps: training loss - 110720.92188	, testing loss - 377948.28125	
3201	 steps: training loss - 134341.01562	, testing loss - 374964.62500	
3202	 steps: training loss - 100579.75000	, testing loss - 370502.37500	
3203	 steps: training loss - 93648.04688	, testing loss - 366437.96875	
3204	 steps: training loss - 119044.13281	, testing loss - 362059.68750	
3205	 steps: training loss - 89408.58594	, testing loss - 358027.90625	
3206	 steps: training loss - 113666.35938	, testing loss - 354732.84375	
3207	 steps: training loss - 74131.98438	, testing loss - 353349.40625	
3208	 steps: training loss - 110462.57812	, testing loss - 352537.87500	
3209	 steps: training loss - 113647.96875	, testing loss - 352008.18750	
3210	 steps: training loss - 135034.98438	, testing loss - 351630.84375	
3211	 steps: training loss - 113963.64062	, testing loss - 351840.68750	
3212	 steps: training loss - 89877.60156	, testing loss - 352223.28125	
3213	 steps: training loss - 123547.67188	, testing loss - 353233.84375	
3214	 steps: training loss - 90418.81250	, testing loss - 353974.37500	
3215	 steps: training loss - 121511.53125	, testing loss - 354346.40625	
3216	 steps: training loss - 108665.45312	, testing loss - 354309.90625	
3217	 steps: training loss - 104236.42188	, testing loss - 354281.56250	
3218	 steps: training loss - 110358.85156	, testing loss - 354894.00000	
3219	 steps: training loss - 103701.26562	, testing loss - 355596.68750	
3220	 steps: training loss - 95564.55469	, testing loss - 356465.78125	
3221	 steps: training loss - 101091.59375	, testing loss - 357211.37500	
3222	 steps: training loss - 104283.54688	, testing loss - 358116.96875	
3223	 steps: training loss - 89268.72656	, testing loss - 359281.03125	
3224	 steps: training loss - 130097.35156	, testing loss - 360461.59375	
3225	 steps: training loss - 115797.39844	, testing loss - 362582.40625	
3226	 steps: training loss - 113218.34375	, testing loss - 364148.46875	
3227	 steps: training loss - 121637.52344	, testing loss - 364142.28125	
3228	 steps: training loss - 111508.75781	, testing loss - 362598.56250	
3229	 steps: training loss - 96163.50781	, testing loss - 360511.71875	
3230	 steps: training loss - 99101.54688	, testing loss - 358796.84375	
3231	 steps: training loss - 118206.50781	, testing loss - 356661.03125	
3232	 steps: training loss - 117347.39062	, testing loss - 355298.43750	
3233	 steps: training loss - 115266.75000	, testing loss - 354943.06250	
3234	 steps: training loss - 115032.98438	, testing loss - 354829.50000	
3235	 steps: training loss - 118748.75000	, testing loss - 355023.31250	
3236	 steps: training loss - 101692.81250	, testing loss - 355356.81250	
3237	 steps: training loss - 120054.39844	, testing loss - 355636.71875	
3238	 steps: training loss - 128238.56250	, testing loss - 356783.00000	
3239	 steps: training loss - 127166.62500	, testing loss - 359070.56250	
3240	 steps: training loss - 107868.85156	, testing loss - 361361.84375	
3241	 steps: training loss - 110933.64844	, testing loss - 363826.62500	
3242	 steps: training loss - 110816.14844	, testing loss - 365558.81250	
3243	 steps: training loss - 115853.07031	, testing loss - 366644.62500	
3244	 steps: training loss - 102559.77344	, testing loss - 367866.46875	
3245	 steps: training loss - 113264.41406	, testing loss - 368584.81250	
3246	 steps: training loss - 123877.58594	, testing loss - 367645.90625	
3247	 steps: training loss - 134474.71875	, testing loss - 366478.84375	
3248	 steps: training loss - 96234.80469	, testing loss - 365231.87500	
3249	 steps: training loss - 117732.10156	, testing loss - 364067.40625	
3250	 steps: training loss - 87081.02344	, testing loss - 362492.09375	
3251	 steps: training loss - 103815.50000	, testing loss - 360982.00000	
3252	 steps: training loss - 116963.22656	, testing loss - 359549.37500	
3253	 steps: training loss - 103930.12500	, testing loss - 358565.46875	
3254	 steps: training loss - 97032.08594	, testing loss - 357820.93750	
3255	 steps: training loss - 77248.58594	, testing loss - 357310.18750	
3256	 steps: training loss - 115079.73438	, testing loss - 357432.93750	
3257	 steps: training loss - 106812.78906	, testing loss - 356572.75000	
3258	 steps: training loss - 127558.25781	, testing loss - 355716.84375	
3259	 steps: training loss - 116201.54688	, testing loss - 355022.46875	
3260	 steps: training loss - 120072.11719	, testing loss - 354332.25000	
3261	 steps: training loss - 109346.23438	, testing loss - 354367.56250	
3262	 steps: training loss - 125923.25781	, testing loss - 355385.50000	
3263	 steps: training loss - 105164.57031	, testing loss - 357807.81250	
3264	 steps: training loss - 123751.15625	, testing loss - 360908.53125	
3265	 steps: training loss - 123770.79688	, testing loss - 362904.68750	
3266	 steps: training loss - 120833.65625	, testing loss - 366316.43750	
3267	 steps: training loss - 146536.04688	, testing loss - 369987.65625	
3268	 steps: training loss - 123146.42969	, testing loss - 371408.34375	
3269	 steps: training loss - 117326.60156	, testing loss - 371118.18750	
3270	 steps: training loss - 105149.46875	, testing loss - 371457.03125	
3271	 steps: training loss - 106429.15625	, testing loss - 372628.87500	
3272	 steps: training loss - 122001.92188	, testing loss - 373391.25000	
3273	 steps: training loss - 115536.46875	, testing loss - 374131.40625	
3274	 steps: training loss - 124639.00000	, testing loss - 374804.50000	
3275	 steps: training loss - 117241.37500	, testing loss - 375600.31250	
3276	 steps: training loss - 125170.96875	, testing loss - 377006.31250	
3277	 steps: training loss - 111483.81250	, testing loss - 377000.37500	
3278	 steps: training loss - 124266.85156	, testing loss - 375468.25000	
3279	 steps: training loss - 115980.23438	, testing loss - 374310.09375	
3280	 steps: training loss - 111359.57031	, testing loss - 371699.31250	
3281	 steps: training loss - 126764.62500	, testing loss - 368726.34375	
3282	 steps: training loss - 104789.67969	, testing loss - 366429.43750	
3283	 steps: training loss - 142821.39062	, testing loss - 364150.84375	
3284	 steps: training loss - 145015.35938	, testing loss - 362325.84375	
3285	 steps: training loss - 119572.32812	, testing loss - 362104.87500	
3286	 steps: training loss - 145825.39062	, testing loss - 362427.34375	
3287	 steps: training loss - 125804.87500	, testing loss - 363009.00000	
3288	 steps: training loss - 102774.42188	, testing loss - 362377.18750	
3289	 steps: training loss - 114378.96094	, testing loss - 361584.21875	
3290	 steps: training loss - 109028.77344	, testing loss - 360582.71875	
3291	 steps: training loss - 118095.07812	, testing loss - 360034.59375	
3292	 steps: training loss - 122539.22656	, testing loss - 359707.28125	
3293	 steps: training loss - 102604.50000	, testing loss - 359638.56250	
3294	 steps: training loss - 118068.35938	, testing loss - 359805.00000	
3295	 steps: training loss - 94031.46094	, testing loss - 360756.40625	
3296	 steps: training loss - 125191.03906	, testing loss - 361668.18750	
3297	 steps: training loss - 116965.31250	, testing loss - 361906.56250	
3298	 steps: training loss - 119954.74219	, testing loss - 362618.53125	
3299	 steps: training loss - 108141.10156	, testing loss - 364033.78125	
3300	 steps: training loss - 122716.09375	, testing loss - 365112.12500	
3301	 steps: training loss - 106888.79688	, testing loss - 367383.06250	
3302	 steps: training loss - 131501.51562	, testing loss - 369720.84375	
3303	 steps: training loss - 128570.76562	, testing loss - 372899.50000	
3304	 steps: training loss - 94966.10156	, testing loss - 374948.53125	
3305	 steps: training loss - 122271.06250	, testing loss - 375617.25000	
3306	 steps: training loss - 98967.35156	, testing loss - 375195.65625	
3307	 steps: training loss - 128094.96094	, testing loss - 374505.46875	
3308	 steps: training loss - 129316.64844	, testing loss - 373114.15625	
3309	 steps: training loss - 120956.74219	, testing loss - 370980.34375	
3310	 steps: training loss - 107459.51562	, testing loss - 368423.78125	
3311	 steps: training loss - 118238.71875	, testing loss - 365956.78125	
3312	 steps: training loss - 108696.62500	, testing loss - 363071.46875	
3313	 steps: training loss - 115527.39062	, testing loss - 360378.40625	
3314	 steps: training loss - 111518.00781	, testing loss - 359312.28125	
3315	 steps: training loss - 111259.23438	, testing loss - 359471.00000	
3316	 steps: training loss - 124174.18750	, testing loss - 359806.90625	
3317	 steps: training loss - 160041.39062	, testing loss - 360169.34375	
3318	 steps: training loss - 145270.45312	, testing loss - 360182.09375	
3319	 steps: training loss - 109992.37500	, testing loss - 360486.12500	
3320	 steps: training loss - 99733.82812	, testing loss - 360026.12500	
3321	 steps: training loss - 118968.60938	, testing loss - 359161.59375	
3322	 steps: training loss - 116132.67188	, testing loss - 359070.03125	
3323	 steps: training loss - 99741.94531	, testing loss - 358841.43750	
3324	 steps: training loss - 110341.10938	, testing loss - 358072.46875	
3325	 steps: training loss - 109199.29688	, testing loss - 356807.93750	
3326	 steps: training loss - 119451.03906	, testing loss - 355597.06250	
3327	 steps: training loss - 108340.15625	, testing loss - 354511.68750	
3328	 steps: training loss - 104901.28125	, testing loss - 353974.46875	
3329	 steps: training loss - 107524.75781	, testing loss - 353382.93750	
3330	 steps: training loss - 88813.14062	, testing loss - 352583.00000	
3331	 steps: training loss - 145240.29688	, testing loss - 351408.65625	
3332	 steps: training loss - 124298.56250	, testing loss - 351358.96875	
3333	 steps: training loss - 121744.57812	, testing loss - 351762.28125	
3334	 steps: training loss - 128482.08594	, testing loss - 352104.53125	
3335	 steps: training loss - 91680.39844	, testing loss - 353258.18750	
3336	 steps: training loss - 115006.03125	, testing loss - 354532.12500	
3337	 steps: training loss - 113627.51562	, testing loss - 356535.03125	
3338	 steps: training loss - 110496.25781	, testing loss - 357938.28125	
3339	 steps: training loss - 101322.71094	, testing loss - 359399.62500	
3340	 steps: training loss - 135553.98438	, testing loss - 361098.84375	
3341	 steps: training loss - 99584.03906	, testing loss - 361880.50000	
3342	 steps: training loss - 129251.20312	, testing loss - 361872.43750	
3343	 steps: training loss - 108934.74219	, testing loss - 361603.34375	
3344	 steps: training loss - 124924.02344	, testing loss - 360681.37500	
3345	 steps: training loss - 123705.87500	, testing loss - 359301.56250	
3346	 steps: training loss - 94589.28125	, testing loss - 357953.53125	
3347	 steps: training loss - 107290.18750	, testing loss - 357137.84375	
3348	 steps: training loss - 108679.26562	, testing loss - 357377.71875	
3349	 steps: training loss - 115728.48438	, testing loss - 358720.84375	
3350	 steps: training loss - 107492.08594	, testing loss - 359868.43750	
3351	 steps: training loss - 123832.04688	, testing loss - 360891.06250	
3352	 steps: training loss - 125511.35156	, testing loss - 361279.34375	
3353	 steps: training loss - 114702.23438	, testing loss - 362070.93750	
3354	 steps: training loss - 95749.49219	, testing loss - 362743.84375	
3355	 steps: training loss - 99836.51562	, testing loss - 363116.34375	
3356	 steps: training loss - 122322.53125	, testing loss - 363038.09375	
3357	 steps: training loss - 105773.41406	, testing loss - 363471.28125	
3358	 steps: training loss - 104968.71875	, testing loss - 364340.34375	
3359	 steps: training loss - 86595.92188	, testing loss - 364813.28125	
3360	 steps: training loss - 128098.02344	, testing loss - 364674.15625	
3361	 steps: training loss - 108811.67188	, testing loss - 364509.81250	
3362	 steps: training loss - 107980.14844	, testing loss - 363290.31250	
3363	 steps: training loss - 108400.50000	, testing loss - 361330.40625	
3364	 steps: training loss - 109956.75000	, testing loss - 358598.71875	
3365	 steps: training loss - 102808.00000	, testing loss - 356917.09375	
3366	 steps: training loss - 111581.21875	, testing loss - 356859.53125	
3367	 steps: training loss - 97714.43750	, testing loss - 358034.68750	
3368	 steps: training loss - 119190.35156	, testing loss - 359015.06250	
3369	 steps: training loss - 126814.90625	, testing loss - 360148.59375	
3370	 steps: training loss - 112431.62500	, testing loss - 360599.68750	
3371	 steps: training loss - 115347.05469	, testing loss - 360228.90625	
3372	 steps: training loss - 127817.83594	, testing loss - 359252.46875	
3373	 steps: training loss - 115127.45312	, testing loss - 358958.43750	
3374	 steps: training loss - 116109.71094	, testing loss - 359277.25000	
3375	 steps: training loss - 119087.30469	, testing loss - 359736.43750	
3376	 steps: training loss - 119379.84375	, testing loss - 359494.59375	
3377	 steps: training loss - 95335.28125	, testing loss - 359012.90625	
3378	 steps: training loss - 122238.43750	, testing loss - 358463.28125	
3379	 steps: training loss - 113597.98438	, testing loss - 358476.15625	
3380	 steps: training loss - 95890.54688	, testing loss - 358508.25000	
3381	 steps: training loss - 127306.35938	, testing loss - 358228.50000	
3382	 steps: training loss - 102253.19531	, testing loss - 358153.43750	
3383	 steps: training loss - 118574.60938	, testing loss - 358078.75000	
3384	 steps: training loss - 98451.67188	, testing loss - 358194.31250	
3385	 steps: training loss - 124355.41406	, testing loss - 357783.15625	
3386	 steps: training loss - 106853.82031	, testing loss - 356680.62500	
3387	 steps: training loss - 110878.87500	, testing loss - 355759.50000	
3388	 steps: training loss - 117060.54688	, testing loss - 354907.12500	
3389	 steps: training loss - 121965.43750	, testing loss - 354329.00000	
3390	 steps: training loss - 133909.45312	, testing loss - 354400.15625	
3391	 steps: training loss - 114415.73438	, testing loss - 354695.87500	
3392	 steps: training loss - 104856.60938	, testing loss - 355610.78125	
3393	 steps: training loss - 110817.64844	, testing loss - 356709.06250	
3394	 steps: training loss - 94754.35156	, testing loss - 357705.40625	
3395	 steps: training loss - 100047.03125	, testing loss - 358099.21875	
3396	 steps: training loss - 106531.35938	, testing loss - 358717.90625	
3397	 steps: training loss - 112608.21094	, testing loss - 359917.78125	
3398	 steps: training loss - 111241.01562	, testing loss - 360504.90625	
3399	 steps: training loss - 103951.87500	, testing loss - 361289.25000	
3400	 steps: training loss - 97383.04688	, testing loss - 361682.37500	
3401	 steps: training loss - 110741.75781	, testing loss - 361428.21875	
3402	 steps: training loss - 102999.68750	, testing loss - 360733.84375	
3403	 steps: training loss - 100469.06250	, testing loss - 360245.65625	
3404	 steps: training loss - 103322.57031	, testing loss - 359983.15625	
3405	 steps: training loss - 128221.14062	, testing loss - 359426.09375	
3406	 steps: training loss - 103493.71875	, testing loss - 359298.31250	
3407	 steps: training loss - 96796.92969	, testing loss - 358950.53125	
3408	 steps: training loss - 112454.18750	, testing loss - 358441.00000	
3409	 steps: training loss - 122846.56250	, testing loss - 358660.37500	
3410	 steps: training loss - 102021.64062	, testing loss - 359027.65625	
3411	 steps: training loss - 92807.78125	, testing loss - 359019.43750	
3412	 steps: training loss - 100639.47656	, testing loss - 358836.03125	
3413	 steps: training loss - 131781.85938	, testing loss - 358873.43750	
3414	 steps: training loss - 110821.16406	, testing loss - 360251.78125	
3415	 steps: training loss - 110566.27344	, testing loss - 361337.18750	
3416	 steps: training loss - 131991.79688	, testing loss - 362214.87500	
3417	 steps: training loss - 143463.92188	, testing loss - 362846.09375	
3418	 steps: training loss - 119509.21875	, testing loss - 362982.34375	
3419	 steps: training loss - 131363.00000	, testing loss - 363247.37500	
3420	 steps: training loss - 117431.90625	, testing loss - 364489.00000	
3421	 steps: training loss - 123222.37500	, testing loss - 365829.34375	
3422	 steps: training loss - 109796.49219	, testing loss - 367204.40625	
3423	 steps: training loss - 92366.39062	, testing loss - 369076.81250	
3424	 steps: training loss - 122236.27344	, testing loss - 370434.31250	
3425	 steps: training loss - 121421.59375	, testing loss - 370695.68750	
3426	 steps: training loss - 123153.39062	, testing loss - 369822.40625	
3427	 steps: training loss - 106531.39062	, testing loss - 367145.43750	
3428	 steps: training loss - 106195.56250	, testing loss - 364641.90625	
3429	 steps: training loss - 119706.28125	, testing loss - 361792.43750	
3430	 steps: training loss - 109978.79688	, testing loss - 359463.40625	
3431	 steps: training loss - 120900.35938	, testing loss - 356960.71875	
3432	 steps: training loss - 129223.64844	, testing loss - 355030.62500	
3433	 steps: training loss - 96937.28906	, testing loss - 354464.34375	
3434	 steps: training loss - 125179.23438	, testing loss - 354108.43750	
3435	 steps: training loss - 96806.89062	, testing loss - 354969.68750	
3436	 steps: training loss - 122532.56250	, testing loss - 355744.78125	
3437	 steps: training loss - 126737.20312	, testing loss - 356067.75000	
3438	 steps: training loss - 116922.84375	, testing loss - 355776.62500	
3439	 steps: training loss - 108919.64844	, testing loss - 356133.00000	
3440	 steps: training loss - 109205.92969	, testing loss - 356464.43750	
3441	 steps: training loss - 119366.25000	, testing loss - 356237.90625	
3442	 steps: training loss - 102869.20312	, testing loss - 355377.68750	
3443	 steps: training loss - 97333.64062	, testing loss - 354138.46875	
3444	 steps: training loss - 123913.82031	, testing loss - 353532.53125	
3445	 steps: training loss - 129846.20312	, testing loss - 353735.28125	
3446	 steps: training loss - 124990.50781	, testing loss - 354169.37500	
3447	 steps: training loss - 126754.64844	, testing loss - 354796.09375	
3448	 steps: training loss - 112195.97656	, testing loss - 355795.87500	
3449	 steps: training loss - 96302.17969	, testing loss - 356073.78125	
3450	 steps: training loss - 108139.34375	, testing loss - 356251.59375	
3451	 steps: training loss - 109576.76562	, testing loss - 356832.81250	
3452	 steps: training loss - 99871.09375	, testing loss - 357757.93750	
3453	 steps: training loss - 105394.39844	, testing loss - 358628.71875	
3454	 steps: training loss - 93929.25781	, testing loss - 358546.03125	
3455	 steps: training loss - 125792.50000	, testing loss - 358227.25000	
3456	 steps: training loss - 115310.39844	, testing loss - 357747.53125	
3457	 steps: training loss - 125470.64062	, testing loss - 356958.62500	
3458	 steps: training loss - 109007.78125	, testing loss - 355877.15625	
3459	 steps: training loss - 98663.17188	, testing loss - 356003.06250	
3460	 steps: training loss - 146665.48438	, testing loss - 355826.50000	
3461	 steps: training loss - 130614.12500	, testing loss - 355892.62500	
3462	 steps: training loss - 98706.29688	, testing loss - 356469.71875	
3463	 steps: training loss - 112383.17188	, testing loss - 358019.43750	
3464	 steps: training loss - 115669.02344	, testing loss - 359083.06250	
3465	 steps: training loss - 124601.20312	, testing loss - 359886.65625	
3466	 steps: training loss - 136846.60938	, testing loss - 359529.65625	
3467	 steps: training loss - 125487.64844	, testing loss - 359120.31250	
3468	 steps: training loss - 122864.96875	, testing loss - 359012.78125	
3469	 steps: training loss - 106014.50000	, testing loss - 359329.93750	
3470	 steps: training loss - 111090.67188	, testing loss - 359908.25000	
3471	 steps: training loss - 112230.39062	, testing loss - 360779.46875	
3472	 steps: training loss - 126278.46875	, testing loss - 360865.09375	
3473	 steps: training loss - 102442.74219	, testing loss - 360953.12500	
3474	 steps: training loss - 122928.04688	, testing loss - 360551.34375	
3475	 steps: training loss - 118158.69531	, testing loss - 360516.71875	
3476	 steps: training loss - 126088.00000	, testing loss - 360470.25000	
3477	 steps: training loss - 104732.17188	, testing loss - 361135.40625	
3478	 steps: training loss - 123226.71875	, testing loss - 362023.18750	
3479	 steps: training loss - 117706.22656	, testing loss - 362774.28125	
3480	 steps: training loss - 105306.14844	, testing loss - 362516.43750	
3481	 steps: training loss - 102393.10938	, testing loss - 362014.46875	
3482	 steps: training loss - 121174.38281	, testing loss - 359890.65625	
3483	 steps: training loss - 135957.64062	, testing loss - 357339.68750	
3484	 steps: training loss - 92016.95312	, testing loss - 355714.81250	
3485	 steps: training loss - 106304.94531	, testing loss - 354390.65625	
3486	 steps: training loss - 107137.41406	, testing loss - 353589.71875	
3487	 steps: training loss - 135979.12500	, testing loss - 353147.21875	
3488	 steps: training loss - 114402.42969	, testing loss - 352567.00000	
3489	 steps: training loss - 118408.55469	, testing loss - 352465.75000	
3490	 steps: training loss - 142870.17188	, testing loss - 352478.53125	
3491	 steps: training loss - 96393.89062	, testing loss - 352384.15625	
3492	 steps: training loss - 99202.65625	, testing loss - 352727.09375	
3493	 steps: training loss - 105566.98438	, testing loss - 353351.28125	
3494	 steps: training loss - 99597.70312	, testing loss - 354367.53125	
3495	 steps: training loss - 103682.60156	, testing loss - 355493.71875	
3496	 steps: training loss - 122529.38281	, testing loss - 356537.50000	
3497	 steps: training loss - 86878.14844	, testing loss - 356557.25000	
3498	 steps: training loss - 111312.50000	, testing loss - 356382.84375	
3499	 steps: training loss - 111186.81250	, testing loss - 356701.71875	
3500	 steps: training loss - 106241.26562	, testing loss - 357035.03125	
3501	 steps: training loss - 116981.30469	, testing loss - 357076.31250	
3502	 steps: training loss - 134465.92188	, testing loss - 358051.90625	
3503	 steps: training loss - 116535.03125	, testing loss - 358693.84375	
3504	 steps: training loss - 92970.57812	, testing loss - 358313.53125	
3505	 steps: training loss - 116804.58594	, testing loss - 357260.15625	
3506	 steps: training loss - 117533.10938	, testing loss - 356165.09375	
3507	 steps: training loss - 130389.02344	, testing loss - 355184.25000	
3508	 steps: training loss - 124179.25000	, testing loss - 354271.12500	
3509	 steps: training loss - 136833.20312	, testing loss - 352776.90625	
3510	 steps: training loss - 106924.42969	, testing loss - 352096.93750	
3511	 steps: training loss - 136705.56250	, testing loss - 351751.96875	
3512	 steps: training loss - 131918.60938	, testing loss - 352222.56250	
3513	 steps: training loss - 103459.52344	, testing loss - 354318.15625	
3514	 steps: training loss - 103355.23438	, testing loss - 356877.84375	
3515	 steps: training loss - 94290.64844	, testing loss - 358902.18750	
3516	 steps: training loss - 123621.20312	, testing loss - 360292.68750	
3517	 steps: training loss - 121825.02344	, testing loss - 361298.65625	
3518	 steps: training loss - 102346.86719	, testing loss - 362063.96875	
3519	 steps: training loss - 130172.06250	, testing loss - 363681.87500	
3520	 steps: training loss - 112275.44531	, testing loss - 365502.84375	
3521	 steps: training loss - 122999.57031	, testing loss - 367423.46875	
3522	 steps: training loss - 133936.09375	, testing loss - 368257.00000	
3523	 steps: training loss - 113858.64844	, testing loss - 368198.93750	
3524	 steps: training loss - 119295.52344	, testing loss - 367870.71875	
3525	 steps: training loss - 134874.84375	, testing loss - 367059.68750	
3526	 steps: training loss - 92571.44531	, testing loss - 365728.21875	
3527	 steps: training loss - 126591.30469	, testing loss - 365710.68750	
3528	 steps: training loss - 114414.43750	, testing loss - 366912.25000	
3529	 steps: training loss - 130049.04688	, testing loss - 367597.62500	
3530	 steps: training loss - 99291.16406	, testing loss - 367059.21875	
3531	 steps: training loss - 124411.89844	, testing loss - 365918.34375	
3532	 steps: training loss - 117612.08594	, testing loss - 365375.53125	
3533	 steps: training loss - 123130.17188	, testing loss - 365075.46875	
3534	 steps: training loss - 101777.08594	, testing loss - 364642.93750	
3535	 steps: training loss - 131786.54688	, testing loss - 363683.56250	
3536	 steps: training loss - 104010.34375	, testing loss - 362632.53125	
3537	 steps: training loss - 106244.56250	, testing loss - 361377.65625	
3538	 steps: training loss - 102998.63281	, testing loss - 360244.34375	
3539	 steps: training loss - 138936.50000	, testing loss - 359405.56250	
3540	 steps: training loss - 111851.64844	, testing loss - 359139.21875	
3541	 steps: training loss - 82897.30469	, testing loss - 358801.31250	
3542	 steps: training loss - 94537.90625	, testing loss - 358571.68750	
3543	 steps: training loss - 99382.24219	, testing loss - 358347.15625	
3544	 steps: training loss - 107978.74219	, testing loss - 357203.71875	
3545	 steps: training loss - 99538.53125	, testing loss - 355824.84375	
3546	 steps: training loss - 106026.57031	, testing loss - 354515.65625	
3547	 steps: training loss - 104100.75000	, testing loss - 353263.12500	
3548	 steps: training loss - 107089.87500	, testing loss - 352476.37500	
3549	 steps: training loss - 104097.51562	, testing loss - 351984.00000	
3550	 steps: training loss - 128582.66406	, testing loss - 352516.93750	
3551	 steps: training loss - 116592.55469	, testing loss - 352908.15625	
3552	 steps: training loss - 119970.27344	, testing loss - 353653.00000	
3553	 steps: training loss - 113467.00000	, testing loss - 354349.96875	
3554	 steps: training loss - 157387.62500	, testing loss - 355250.28125	
3555	 steps: training loss - 141765.34375	, testing loss - 356733.06250	
3556	 steps: training loss - 113788.64062	, testing loss - 358346.00000	
3557	 steps: training loss - 115883.79688	, testing loss - 359963.31250	
3558	 steps: training loss - 93821.42969	, testing loss - 361215.81250	
3559	 steps: training loss - 109235.03906	, testing loss - 362848.56250	
3560	 steps: training loss - 126844.23438	, testing loss - 364701.90625	
3561	 steps: training loss - 143391.25000	, testing loss - 365738.06250	
3562	 steps: training loss - 120784.72656	, testing loss - 366387.59375	
3563	 steps: training loss - 138165.70312	, testing loss - 366697.09375	
3564	 steps: training loss - 132651.60938	, testing loss - 365571.50000	
3565	 steps: training loss - 121329.27344	, testing loss - 363462.78125	
3566	 steps: training loss - 117417.48438	, testing loss - 361524.65625	
3567	 steps: training loss - 119503.45312	, testing loss - 359761.06250	
3568	 steps: training loss - 87349.76562	, testing loss - 358779.25000	
3569	 steps: training loss - 135671.09375	, testing loss - 357771.65625	
3570	 steps: training loss - 98155.10156	, testing loss - 357931.62500	
3571	 steps: training loss - 109710.27344	, testing loss - 357363.40625	
3572	 steps: training loss - 116980.95312	, testing loss - 357382.37500	
3573	 steps: training loss - 108488.79688	, testing loss - 357977.93750	
3574	 steps: training loss - 97682.04688	, testing loss - 359000.15625	
3575	 steps: training loss - 141599.01562	, testing loss - 359865.37500	
3576	 steps: training loss - 134335.95312	, testing loss - 360138.03125	
3577	 steps: training loss - 97370.07031	, testing loss - 360683.09375	
3578	 steps: training loss - 115727.52344	, testing loss - 360807.28125	
3579	 steps: training loss - 110192.47656	, testing loss - 361152.03125	
3580	 steps: training loss - 111102.06250	, testing loss - 361271.93750	
3581	 steps: training loss - 117690.21875	, testing loss - 361164.37500	
3582	 steps: training loss - 103683.37500	, testing loss - 360917.31250	
3583	 steps: training loss - 107497.81250	, testing loss - 360987.96875	
3584	 steps: training loss - 123427.55469	, testing loss - 361740.37500	
3585	 steps: training loss - 107575.25000	, testing loss - 363420.53125	
3586	 steps: training loss - 97385.23438	, testing loss - 364842.78125	
3587	 steps: training loss - 114181.14062	, testing loss - 366024.56250	
3588	 steps: training loss - 101077.86719	, testing loss - 365583.81250	
3589	 steps: training loss - 103718.94531	, testing loss - 363763.21875	
3590	 steps: training loss - 118469.17188	, testing loss - 362048.03125	
3591	 steps: training loss - 132505.54688	, testing loss - 360506.12500	
3592	 steps: training loss - 120548.06250	, testing loss - 358893.34375	
3593	 steps: training loss - 100848.82031	, testing loss - 357613.81250	
3594	 steps: training loss - 92544.38281	, testing loss - 356447.56250	
3595	 steps: training loss - 96345.69531	, testing loss - 355717.93750	
3596	 steps: training loss - 107946.69531	, testing loss - 354628.18750	
3597	 steps: training loss - 109030.81250	, testing loss - 353382.31250	
3598	 steps: training loss - 112696.81250	, testing loss - 352675.28125	
3599	 steps: training loss - 139701.03125	, testing loss - 352704.03125	
3600	 steps: training loss - 110935.57812	, testing loss - 352895.34375	
3601	 steps: training loss - 109954.03906	, testing loss - 353534.40625	
3602	 steps: training loss - 111017.20312	, testing loss - 354394.40625	
3603	 steps: training loss - 103990.58594	, testing loss - 354874.75000	
3604	 steps: training loss - 130384.43750	, testing loss - 354948.21875	
3605	 steps: training loss - 105309.29688	, testing loss - 354626.81250	
3606	 steps: training loss - 107936.67188	, testing loss - 354429.40625	
3607	 steps: training loss - 120108.51562	, testing loss - 353870.09375	
3608	 steps: training loss - 119639.62500	, testing loss - 353289.84375	
3609	 steps: training loss - 115838.74219	, testing loss - 353406.06250	
3610	 steps: training loss - 107403.49219	, testing loss - 353710.50000	
3611	 steps: training loss - 109546.41406	, testing loss - 353502.31250	
3612	 steps: training loss - 115896.57031	, testing loss - 353210.06250	
3613	 steps: training loss - 111175.71094	, testing loss - 353612.56250	
3614	 steps: training loss - 96663.17188	, testing loss - 354478.56250	
3615	 steps: training loss - 110163.70312	, testing loss - 355209.00000	
3616	 steps: training loss - 110334.87500	, testing loss - 355473.65625	
3617	 steps: training loss - 123857.89062	, testing loss - 356746.40625	
3618	 steps: training loss - 119004.51562	, testing loss - 358597.25000	
3619	 steps: training loss - 125938.19531	, testing loss - 360336.28125	
3620	 steps: training loss - 121557.03125	, testing loss - 362254.96875	
3621	 steps: training loss - 107705.70312	, testing loss - 363597.18750	
3622	 steps: training loss - 100989.46875	, testing loss - 364848.18750	
3623	 steps: training loss - 92902.53125	, testing loss - 364323.87500	
3624	 steps: training loss - 121058.50781	, testing loss - 361908.15625	
3625	 steps: training loss - 121621.71094	, testing loss - 359916.12500	
3626	 steps: training loss - 129221.65625	, testing loss - 358760.21875	
3627	 steps: training loss - 105372.78125	, testing loss - 358737.06250	
3628	 steps: training loss - 126197.85938	, testing loss - 358576.28125	
3629	 steps: training loss - 109308.27344	, testing loss - 358377.00000	
3630	 steps: training loss - 103108.41406	, testing loss - 357743.21875	
3631	 steps: training loss - 134384.34375	, testing loss - 357678.28125	
3632	 steps: training loss - 109595.04688	, testing loss - 358183.81250	
3633	 steps: training loss - 119035.35938	, testing loss - 358483.28125	
3634	 steps: training loss - 142924.67188	, testing loss - 358354.46875	
3635	 steps: training loss - 109731.35938	, testing loss - 358070.00000	
3636	 steps: training loss - 88471.11719	, testing loss - 357336.78125	
3637	 steps: training loss - 95455.31250	, testing loss - 356668.37500	
3638	 steps: training loss - 115443.63281	, testing loss - 355986.43750	
3639	 steps: training loss - 104424.68750	, testing loss - 355353.28125	
3640	 steps: training loss - 100094.03125	, testing loss - 354063.59375	
3641	 steps: training loss - 111030.69531	, testing loss - 352747.71875	
3642	 steps: training loss - 119903.02344	, testing loss - 352074.46875	
3643	 steps: training loss - 110760.84375	, testing loss - 351916.43750	
3644	 steps: training loss - 120979.15625	, testing loss - 352419.31250	
3645	 steps: training loss - 107636.29688	, testing loss - 353579.84375	
3646	 steps: training loss - 117048.76562	, testing loss - 354720.21875	
3647	 steps: training loss - 131128.92188	, testing loss - 355998.59375	
3648	 steps: training loss - 109884.05469	, testing loss - 357552.90625	
3649	 steps: training loss - 159894.39062	, testing loss - 359238.00000	
3650	 steps: training loss - 99459.60156	, testing loss - 361388.96875	
3651	 steps: training loss - 95887.94531	, testing loss - 363824.53125	
3652	 steps: training loss - 122772.71094	, testing loss - 366507.46875	
3653	 steps: training loss - 125809.63281	, testing loss - 371492.15625	
3654	 steps: training loss - 127990.53125	, testing loss - 376748.96875	
3655	 steps: training loss - 113234.74219	, testing loss - 382237.37500	
3656	 steps: training loss - 103098.39844	, testing loss - 385064.06250	
3657	 steps: training loss - 110489.96875	, testing loss - 384675.09375	
3658	 steps: training loss - 118009.02344	, testing loss - 382021.59375	
3659	 steps: training loss - 125992.03906	, testing loss - 377455.37500	
3660	 steps: training loss - 134393.14062	, testing loss - 372597.18750	
3661	 steps: training loss - 113698.11719	, testing loss - 368570.90625	
3662	 steps: training loss - 116580.93750	, testing loss - 365121.96875	
3663	 steps: training loss - 114582.79688	, testing loss - 362539.75000	
3664	 steps: training loss - 122415.63281	, testing loss - 360234.75000	
3665	 steps: training loss - 103388.94531	, testing loss - 357995.81250	
3666	 steps: training loss - 111372.48438	, testing loss - 356327.65625	
3667	 steps: training loss - 115640.29688	, testing loss - 355108.75000	
3668	 steps: training loss - 120744.79688	, testing loss - 354136.34375	
3669	 steps: training loss - 84400.23438	, testing loss - 354411.68750	
3670	 steps: training loss - 109365.65625	, testing loss - 354563.03125	
3671	 steps: training loss - 125204.93750	, testing loss - 354993.37500	
3672	 steps: training loss - 113989.25000	, testing loss - 355416.71875	
3673	 steps: training loss - 113262.37500	, testing loss - 355819.09375	
3674	 steps: training loss - 114978.46875	, testing loss - 356478.43750	
3675	 steps: training loss - 108354.47656	, testing loss - 357913.56250	
3676	 steps: training loss - 125164.71094	, testing loss - 359429.25000	
3677	 steps: training loss - 106924.43750	, testing loss - 360422.84375	
3678	 steps: training loss - 110105.36719	, testing loss - 360664.37500	
3679	 steps: training loss - 128304.71875	, testing loss - 361245.46875	
3680	 steps: training loss - 105404.40625	, testing loss - 361328.90625	
3681	 steps: training loss - 94040.81250	, testing loss - 360421.21875	
3682	 steps: training loss - 100581.72656	, testing loss - 358363.78125	
3683	 steps: training loss - 130252.00781	, testing loss - 356216.37500	
3684	 steps: training loss - 121420.09375	, testing loss - 353989.46875	
3685	 steps: training loss - 120849.75000	, testing loss - 353196.31250	
3686	 steps: training loss - 97227.01562	, testing loss - 352116.21875	
3687	 steps: training loss - 122530.48438	, testing loss - 350906.68750	
3688	 steps: training loss - 118391.52344	, testing loss - 350464.75000	
3689	 steps: training loss - 127761.12500	, testing loss - 350548.06250	
3690	 steps: training loss - 104748.41406	, testing loss - 350982.81250	
3691	 steps: training loss - 93750.43750	, testing loss - 351759.06250	
3692	 steps: training loss - 100433.81250	, testing loss - 352504.06250	
3693	 steps: training loss - 101898.67188	, testing loss - 353259.68750	
3694	 steps: training loss - 115520.15625	, testing loss - 354000.37500	
3695	 steps: training loss - 131622.15625	, testing loss - 354244.18750	
3696	 steps: training loss - 128383.17969	, testing loss - 353799.71875	
3697	 steps: training loss - 109318.95312	, testing loss - 354529.00000	
3698	 steps: training loss - 117122.57031	, testing loss - 355244.06250	
3699	 steps: training loss - 118992.21875	, testing loss - 356020.12500	
3700	 steps: training loss - 101442.56250	, testing loss - 356978.18750	
3701	 steps: training loss - 138374.15625	, testing loss - 357574.53125	
3702	 steps: training loss - 97590.29688	, testing loss - 358529.96875	
3703	 steps: training loss - 127072.20312	, testing loss - 359642.71875	
3704	 steps: training loss - 106083.33594	, testing loss - 360208.21875	
3705	 steps: training loss - 115553.64062	, testing loss - 359900.96875	
3706	 steps: training loss - 119112.07031	, testing loss - 359191.18750	
3707	 steps: training loss - 104815.55469	, testing loss - 358601.03125	
3708	 steps: training loss - 115422.26562	, testing loss - 358249.03125	
3709	 steps: training loss - 128329.63281	, testing loss - 358577.12500	
3710	 steps: training loss - 95991.17188	, testing loss - 359066.37500	
3711	 steps: training loss - 124372.23438	, testing loss - 360162.40625	
3712	 steps: training loss - 111004.16406	, testing loss - 362055.96875	
3713	 steps: training loss - 115777.84375	, testing loss - 363856.18750	
3714	 steps: training loss - 107674.63281	, testing loss - 365303.15625	
3715	 steps: training loss - 115546.84375	, testing loss - 365848.00000	
3716	 steps: training loss - 109202.78125	, testing loss - 364954.09375	
3717	 steps: training loss - 114855.17969	, testing loss - 363963.81250	
3718	 steps: training loss - 122266.35938	, testing loss - 362277.00000	
3719	 steps: training loss - 113435.57031	, testing loss - 359459.15625	
3720	 steps: training loss - 106469.72656	, testing loss - 356869.93750	
3721	 steps: training loss - 129116.85156	, testing loss - 355402.12500	
3722	 steps: training loss - 111966.89062	, testing loss - 354464.15625	
3723	 steps: training loss - 92586.55469	, testing loss - 353859.75000	
3724	 steps: training loss - 123544.67188	, testing loss - 354364.43750	
3725	 steps: training loss - 104231.35938	, testing loss - 355148.84375	
3726	 steps: training loss - 126034.44531	, testing loss - 356319.40625	
3727	 steps: training loss - 99181.71094	, testing loss - 357024.09375	
3728	 steps: training loss - 127819.49219	, testing loss - 356773.03125	
3729	 steps: training loss - 106826.67969	, testing loss - 356479.18750	
3730	 steps: training loss - 125789.89062	, testing loss - 356202.90625	
3731	 steps: training loss - 88294.21875	, testing loss - 355648.37500	
3732	 steps: training loss - 120397.29688	, testing loss - 355045.93750	
3733	 steps: training loss - 94158.97656	, testing loss - 355233.53125	
3734	 steps: training loss - 103674.71094	, testing loss - 355843.28125	
3735	 steps: training loss - 105286.16406	, testing loss - 356557.75000	
3736	 steps: training loss - 113627.28906	, testing loss - 357177.40625	
3737	 steps: training loss - 116918.54688	, testing loss - 357309.59375	
3738	 steps: training loss - 91982.84375	, testing loss - 358005.90625	
3739	 steps: training loss - 97781.49219	, testing loss - 358205.68750	
3740	 steps: training loss - 107277.66406	, testing loss - 357431.75000	
3741	 steps: training loss - 126808.92188	, testing loss - 356671.50000	
3742	 steps: training loss - 103274.82812	, testing loss - 355680.93750	
3743	 steps: training loss - 116337.73438	, testing loss - 354451.40625	
3744	 steps: training loss - 109038.51562	, testing loss - 353127.71875	
3745	 steps: training loss - 92181.54688	, testing loss - 352436.84375	
3746	 steps: training loss - 83642.63281	, testing loss - 352687.87500	
3747	 steps: training loss - 117777.36719	, testing loss - 353138.06250	
3748	 steps: training loss - 128624.59375	, testing loss - 353733.56250	
3749	 steps: training loss - 110069.80469	, testing loss - 353664.18750	
3750	 steps: training loss - 111159.17969	, testing loss - 353591.00000	
3751	 steps: training loss - 128857.45312	, testing loss - 352927.40625	
3752	 steps: training loss - 107602.64844	, testing loss - 352856.43750	
3753	 steps: training loss - 118554.87500	, testing loss - 352246.25000	
3754	 steps: training loss - 108615.91406	, testing loss - 352749.34375	
3755	 steps: training loss - 127939.46094	, testing loss - 354127.50000	
3756	 steps: training loss - 83740.97656	, testing loss - 355255.25000	
3757	 steps: training loss - 111586.42969	, testing loss - 355884.03125	
3758	 steps: training loss - 104166.56250	, testing loss - 356491.25000	
3759	 steps: training loss - 121135.70312	, testing loss - 357379.46875	
3760	 steps: training loss - 123582.59375	, testing loss - 358138.06250	
3761	 steps: training loss - 108492.15625	, testing loss - 358410.93750	
3762	 steps: training loss - 115298.27344	, testing loss - 359350.12500	
3763	 steps: training loss - 113932.58594	, testing loss - 360261.31250	
3764	 steps: training loss - 105638.87500	, testing loss - 361132.25000	
3765	 steps: training loss - 121757.46094	, testing loss - 360906.31250	
3766	 steps: training loss - 134452.73438	, testing loss - 359119.09375	
3767	 steps: training loss - 119453.78125	, testing loss - 356167.56250	
3768	 steps: training loss - 114311.89062	, testing loss - 353706.15625	
3769	 steps: training loss - 131785.42188	, testing loss - 351904.84375	
3770	 steps: training loss - 105786.77344	, testing loss - 350780.87500	
3771	 steps: training loss - 99991.19531	, testing loss - 350009.28125	
3772	 steps: training loss - 113739.04688	, testing loss - 349352.56250	
3773	 steps: training loss - 128741.35156	, testing loss - 349239.59375	
3774	 steps: training loss - 107564.99219	, testing loss - 349353.87500	
3775	 steps: training loss - 111188.57812	, testing loss - 349859.25000	
3776	 steps: training loss - 103188.00781	, testing loss - 350994.28125	
3777	 steps: training loss - 105092.58594	, testing loss - 352061.81250	
3778	 steps: training loss - 134795.17188	, testing loss - 352832.84375	
3779	 steps: training loss - 105066.74219	, testing loss - 353045.68750	
3780	 steps: training loss - 85040.77344	, testing loss - 352441.84375	
3781	 steps: training loss - 108875.78125	, testing loss - 351418.59375	
3782	 steps: training loss - 120422.96094	, testing loss - 350733.34375	
3783	 steps: training loss - 107190.25000	, testing loss - 350353.87500	
3784	 steps: training loss - 123115.22656	, testing loss - 350120.37500	
3785	 steps: training loss - 81966.67188	, testing loss - 350194.18750	
3786	 steps: training loss - 96755.95312	, testing loss - 350777.40625	
3787	 steps: training loss - 122010.43750	, testing loss - 351581.37500	
3788	 steps: training loss - 122864.50781	, testing loss - 352499.18750	
3789	 steps: training loss - 96162.94531	, testing loss - 353436.84375	
3790	 steps: training loss - 102074.71875	, testing loss - 354239.56250	
3791	 steps: training loss - 126650.03125	, testing loss - 354845.50000	
3792	 steps: training loss - 119082.86719	, testing loss - 355142.37500	
3793	 steps: training loss - 102869.86719	, testing loss - 355786.96875	
3794	 steps: training loss - 118769.42188	, testing loss - 356968.21875	
3795	 steps: training loss - 143155.26562	, testing loss - 358603.81250	
3796	 steps: training loss - 134423.68750	, testing loss - 361357.90625	
3797	 steps: training loss - 119198.44531	, testing loss - 364062.03125	
3798	 steps: training loss - 106686.21094	, testing loss - 366552.31250	
3799	 steps: training loss - 114807.07031	, testing loss - 367097.31250	
3800	 steps: training loss - 109852.89062	, testing loss - 366429.28125	
3801	 steps: training loss - 105315.64062	, testing loss - 364960.62500	
3802	 steps: training loss - 130783.26562	, testing loss - 363089.68750	
3803	 steps: training loss - 112203.28125	, testing loss - 360118.12500	
3804	 steps: training loss - 109973.28125	, testing loss - 357514.00000	
3805	 steps: training loss - 109998.36719	, testing loss - 355773.00000	
3806	 steps: training loss - 104775.23438	, testing loss - 354678.31250	
3807	 steps: training loss - 110016.61719	, testing loss - 353824.68750	
3808	 steps: training loss - 115524.73438	, testing loss - 353627.00000	
3809	 steps: training loss - 107062.89844	, testing loss - 354757.40625	
3810	 steps: training loss - 115820.30469	, testing loss - 356802.46875	
3811	 steps: training loss - 115250.26562	, testing loss - 358881.40625	
3812	 steps: training loss - 96292.85938	, testing loss - 360123.53125	
3813	 steps: training loss - 107325.24219	, testing loss - 361427.09375	
3814	 steps: training loss - 115331.67969	, testing loss - 362393.78125	
3815	 steps: training loss - 139537.64062	, testing loss - 362293.81250	
3816	 steps: training loss - 136038.00000	, testing loss - 361669.21875	
3817	 steps: training loss - 105242.82812	, testing loss - 361091.53125	
3818	 steps: training loss - 129079.41406	, testing loss - 360489.00000	
3819	 steps: training loss - 97766.60938	, testing loss - 359582.87500	
3820	 steps: training loss - 127336.63281	, testing loss - 358680.81250	
3821	 steps: training loss - 90126.37500	, testing loss - 357882.71875	
3822	 steps: training loss - 148500.96875	, testing loss - 356967.37500	
3823	 steps: training loss - 143948.87500	, testing loss - 356396.06250	
3824	 steps: training loss - 108327.61719	, testing loss - 356465.84375	
3825	 steps: training loss - 101932.49219	, testing loss - 356413.15625	
3826	 steps: training loss - 151456.95312	, testing loss - 356211.34375	
3827	 steps: training loss - 111496.97656	, testing loss - 356430.96875	
3828	 steps: training loss - 112801.78125	, testing loss - 356135.18750	
3829	 steps: training loss - 120411.90625	, testing loss - 355952.56250	
3830	 steps: training loss - 111840.93750	, testing loss - 356589.00000	
3831	 steps: training loss - 108564.39844	, testing loss - 356945.50000	
3832	 steps: training loss - 113816.51562	, testing loss - 356815.34375	
3833	 steps: training loss - 108844.35938	, testing loss - 356846.71875	
3834	 steps: training loss - 127462.64062	, testing loss - 357177.93750	
3835	 steps: training loss - 111458.87500	, testing loss - 358700.31250	
3836	 steps: training loss - 113001.83594	, testing loss - 360216.09375	
3837	 steps: training loss - 108719.85938	, testing loss - 362641.93750	
3838	 steps: training loss - 116030.53906	, testing loss - 364386.71875	
3839	 steps: training loss - 99760.32812	, testing loss - 365347.56250	
3840	 steps: training loss - 87469.78906	, testing loss - 367254.00000	
3841	 steps: training loss - 107092.95312	, testing loss - 369041.62500	
3842	 steps: training loss - 116577.83594	, testing loss - 369926.06250	
3843	 steps: training loss - 99096.28906	, testing loss - 370761.62500	
3844	 steps: training loss - 117348.44531	, testing loss - 372512.28125	
3845	 steps: training loss - 101856.42969	, testing loss - 372365.59375	
3846	 steps: training loss - 129247.87500	, testing loss - 370319.31250	
3847	 steps: training loss - 148247.82812	, testing loss - 369111.81250	
3848	 steps: training loss - 130510.63281	, testing loss - 367791.00000	
3849	 steps: training loss - 104543.02344	, testing loss - 368690.09375	
3850	 steps: training loss - 117298.85938	, testing loss - 369614.56250	
3851	 steps: training loss - 117668.57031	, testing loss - 369709.00000	
3852	 steps: training loss - 102373.41406	, testing loss - 368624.40625	
3853	 steps: training loss - 123263.03125	, testing loss - 366842.00000	
3854	 steps: training loss - 95098.98438	, testing loss - 365922.18750	
3855	 steps: training loss - 122978.67188	, testing loss - 364440.12500	
3856	 steps: training loss - 97806.30469	, testing loss - 363678.09375	
3857	 steps: training loss - 104462.15625	, testing loss - 362499.37500	
3858	 steps: training loss - 99997.03125	, testing loss - 360320.62500	
3859	 steps: training loss - 111803.91406	, testing loss - 357698.68750	
3860	 steps: training loss - 114863.40625	, testing loss - 355556.06250	
3861	 steps: training loss - 118343.53125	, testing loss - 353436.46875	
3862	 steps: training loss - 108496.71875	, testing loss - 351782.62500	
3863	 steps: training loss - 130761.03125	, testing loss - 350394.96875	
3864	 steps: training loss - 104429.25000	, testing loss - 349855.43750	
3865	 steps: training loss - 93718.08594	, testing loss - 349942.75000	
3866	 steps: training loss - 93567.83594	, testing loss - 350029.31250	
3867	 steps: training loss - 109317.12500	, testing loss - 349934.78125	
3868	 steps: training loss - 145425.26562	, testing loss - 350102.46875	
3869	 steps: training loss - 83897.97656	, testing loss - 350704.18750	
3870	 steps: training loss - 118327.13281	, testing loss - 351803.62500	
3871	 steps: training loss - 93571.39844	, testing loss - 353673.75000	
3872	 steps: training loss - 113420.73438	, testing loss - 355632.31250	
3873	 steps: training loss - 107525.75000	, testing loss - 357748.06250	
3874	 steps: training loss - 111643.89062	, testing loss - 360368.56250	
3875	 steps: training loss - 107873.85938	, testing loss - 362882.31250	
3876	 steps: training loss - 125415.15625	, testing loss - 364038.93750	
3877	 steps: training loss - 122791.92188	, testing loss - 363887.90625	
3878	 steps: training loss - 99807.25000	, testing loss - 363226.84375	
3879	 steps: training loss - 128687.29688	, testing loss - 362821.46875	
3880	 steps: training loss - 127350.55469	, testing loss - 362180.18750	
3881	 steps: training loss - 98984.71094	, testing loss - 361775.75000	
3882	 steps: training loss - 95627.50781	, testing loss - 361903.12500	
3883	 steps: training loss - 136105.07812	, testing loss - 361446.84375	
3884	 steps: training loss - 113342.37500	, testing loss - 361335.53125	
3885	 steps: training loss - 120340.69531	, testing loss - 360582.93750	
3886	 steps: training loss - 109937.03906	, testing loss - 358940.84375	
3887	 steps: training loss - 86772.57812	, testing loss - 357087.65625	
3888	 steps: training loss - 127371.07812	, testing loss - 355881.31250	
3889	 steps: training loss - 94191.93750	, testing loss - 355059.62500	
3890	 steps: training loss - 123890.35938	, testing loss - 354339.75000	
3891	 steps: training loss - 119377.87500	, testing loss - 353679.37500	
3892	 steps: training loss - 133168.96875	, testing loss - 353450.21875	
3893	 steps: training loss - 91170.65625	, testing loss - 353527.62500	
3894	 steps: training loss - 101432.67969	, testing loss - 353589.18750	
3895	 steps: training loss - 97040.42188	, testing loss - 353738.40625	
3896	 steps: training loss - 103920.15625	, testing loss - 354932.25000	
3897	 steps: training loss - 115600.82812	, testing loss - 355647.34375	
3898	 steps: training loss - 105921.47656	, testing loss - 356307.28125	
3899	 steps: training loss - 128707.99219	, testing loss - 357809.71875	
3900	 steps: training loss - 105058.60938	, testing loss - 359428.75000	
3901	 steps: training loss - 122444.59375	, testing loss - 361542.09375	
3902	 steps: training loss - 117171.59375	, testing loss - 363584.96875	
3903	 steps: training loss - 151795.68750	, testing loss - 364863.96875	
3904	 steps: training loss - 106870.46875	, testing loss - 366132.68750	
3905	 steps: training loss - 105862.00781	, testing loss - 367063.37500	
3906	 steps: training loss - 97748.96875	, testing loss - 367653.90625	
3907	 steps: training loss - 79109.57812	, testing loss - 368598.84375	
3908	 steps: training loss - 118522.43750	, testing loss - 369772.71875	
3909	 steps: training loss - 102624.71094	, testing loss - 370364.18750	
3910	 steps: training loss - 106870.02344	, testing loss - 369963.37500	
3911	 steps: training loss - 83537.07031	, testing loss - 370101.03125	
3912	 steps: training loss - 94185.68750	, testing loss - 370788.12500	
3913	 steps: training loss - 117191.39844	, testing loss - 372111.25000	
3914	 steps: training loss - 95554.03906	, testing loss - 371802.93750	
3915	 steps: training loss - 105980.93750	, testing loss - 371122.78125	
3916	 steps: training loss - 123775.24219	, testing loss - 372123.12500	
3917	 steps: training loss - 137119.65625	, testing loss - 372628.37500	
3918	 steps: training loss - 125752.39062	, testing loss - 371711.18750	
3919	 steps: training loss - 102904.53125	, testing loss - 370734.68750	
3920	 steps: training loss - 114966.39062	, testing loss - 368952.34375	
3921	 steps: training loss - 102112.61719	, testing loss - 367424.21875	
3922	 steps: training loss - 108049.29688	, testing loss - 366130.59375	
3923	 steps: training loss - 96295.71875	, testing loss - 363689.00000	
3924	 steps: training loss - 133287.70312	, testing loss - 362094.53125	
3925	 steps: training loss - 145251.03125	, testing loss - 361289.68750	
3926	 steps: training loss - 100229.22656	, testing loss - 360664.56250	
3927	 steps: training loss - 107887.60156	, testing loss - 360837.78125	
3928	 steps: training loss - 105840.60938	, testing loss - 360594.65625	
3929	 steps: training loss - 121451.01562	, testing loss - 360054.09375	
3930	 steps: training loss - 124080.19531	, testing loss - 359015.25000	
3931	 steps: training loss - 113389.96094	, testing loss - 357734.84375	
3932	 steps: training loss - 90845.83594	, testing loss - 357749.21875	
3933	 steps: training loss - 134031.92188	, testing loss - 357532.75000	
3934	 steps: training loss - 132397.21875	, testing loss - 357024.78125	
3935	 steps: training loss - 116248.45312	, testing loss - 356368.15625	
3936	 steps: training loss - 126587.05469	, testing loss - 356025.56250	
3937	 steps: training loss - 111279.08594	, testing loss - 355676.68750	
3938	 steps: training loss - 116922.12500	, testing loss - 355474.46875	
3939	 steps: training loss - 104079.32031	, testing loss - 356375.75000	
3940	 steps: training loss - 115648.70312	, testing loss - 356492.65625	
3941	 steps: training loss - 121197.03125	, testing loss - 356151.81250	
3942	 steps: training loss - 148122.32812	, testing loss - 355979.81250	
3943	 steps: training loss - 123315.78906	, testing loss - 355883.43750	
3944	 steps: training loss - 133064.93750	, testing loss - 356275.18750	
3945	 steps: training loss - 98343.45312	, testing loss - 357039.34375	
3946	 steps: training loss - 125437.18750	, testing loss - 358248.28125	
3947	 steps: training loss - 103964.68750	, testing loss - 359987.43750	
3948	 steps: training loss - 99365.40625	, testing loss - 361929.56250	
3949	 steps: training loss - 138905.25000	, testing loss - 364414.50000	
3950	 steps: training loss - 123389.26562	, testing loss - 366431.50000	
3951	 steps: training loss - 122279.59375	, testing loss - 366840.43750	
3952	 steps: training loss - 123648.85938	, testing loss - 365017.34375	
3953	 steps: training loss - 114037.84375	, testing loss - 362340.62500	
3954	 steps: training loss - 117591.93750	, testing loss - 360291.40625	
3955	 steps: training loss - 146415.07812	, testing loss - 358821.21875	
3956	 steps: training loss - 113012.60938	, testing loss - 357131.40625	
3957	 steps: training loss - 109103.74219	, testing loss - 356205.40625	
3958	 steps: training loss - 106020.64844	, testing loss - 356403.28125	
3959	 steps: training loss - 103667.78125	, testing loss - 356014.03125	
3960	 steps: training loss - 102460.74219	, testing loss - 355273.81250	
3961	 steps: training loss - 119143.96875	, testing loss - 355779.34375	
3962	 steps: training loss - 111685.74219	, testing loss - 356773.09375	
3963	 steps: training loss - 121982.55469	, testing loss - 358033.68750	
3964	 steps: training loss - 127818.45312	, testing loss - 359377.37500	
3965	 steps: training loss - 98768.15625	, testing loss - 359365.78125	
3966	 steps: training loss - 112047.84375	, testing loss - 359071.00000	
3967	 steps: training loss - 117717.92969	, testing loss - 359190.25000	
3968	 steps: training loss - 99073.88281	, testing loss - 360446.78125	
3969	 steps: training loss - 123729.35156	, testing loss - 362156.56250	
3970	 steps: training loss - 126410.82812	, testing loss - 363889.43750	
3971	 steps: training loss - 103813.63281	, testing loss - 365753.59375	
3972	 steps: training loss - 94140.38281	, testing loss - 368331.46875	
3973	 steps: training loss - 126664.37500	, testing loss - 370925.78125	
3974	 steps: training loss - 95766.21875	, testing loss - 372383.59375	
3975	 steps: training loss - 126807.55469	, testing loss - 372791.40625	
3976	 steps: training loss - 93185.85938	, testing loss - 372165.25000	
3977	 steps: training loss - 112829.33594	, testing loss - 370733.56250	
3978	 steps: training loss - 132316.79688	, testing loss - 367944.68750	
3979	 steps: training loss - 100820.97656	, testing loss - 365731.50000	
3980	 steps: training loss - 111331.42969	, testing loss - 364934.56250	
3981	 steps: training loss - 96033.16406	, testing loss - 363982.75000	
3982	 steps: training loss - 115991.81250	, testing loss - 362179.25000	
3983	 steps: training loss - 135131.23438	, testing loss - 360074.06250	
3984	 steps: training loss - 116855.53125	, testing loss - 357804.37500	
3985	 steps: training loss - 113407.58594	, testing loss - 356238.34375	
3986	 steps: training loss - 119543.57812	, testing loss - 355462.25000	
3987	 steps: training loss - 110201.00000	, testing loss - 355523.43750	
3988	 steps: training loss - 106762.88281	, testing loss - 355526.50000	
3989	 steps: training loss - 131712.35938	, testing loss - 355909.21875	
3990	 steps: training loss - 119181.84375	, testing loss - 357436.90625	
3991	 steps: training loss - 118972.11719	, testing loss - 359891.53125	
3992	 steps: training loss - 128163.31250	, testing loss - 363464.06250	
3993	 steps: training loss - 95430.01562	, testing loss - 368115.09375	
3994	 steps: training loss - 101967.09375	, testing loss - 372256.90625	
3995	 steps: training loss - 123648.39844	, testing loss - 374933.18750	
3996	 steps: training loss - 118467.00781	, testing loss - 376198.81250	
3997	 steps: training loss - 112645.93750	, testing loss - 375914.18750	
3998	 steps: training loss - 121907.26562	, testing loss - 374908.15625	
3999	 steps: training loss - 123412.72656	, testing loss - 373052.37500	
4000	 steps: training loss - 113971.45312	, testing loss - 370988.43750	
4001	 steps: training loss - 114931.58594	, testing loss - 369360.87500	
4002	 steps: training loss - 135306.54688	, testing loss - 368219.09375	
4003	 steps: training loss - 105996.00781	, testing loss - 367501.50000	
4004	 steps: training loss - 117730.56250	, testing loss - 365961.84375	
4005	 steps: training loss - 99337.64844	, testing loss - 364995.34375	
4006	 steps: training loss - 137027.04688	, testing loss - 365098.21875	
4007	 steps: training loss - 117679.96094	, testing loss - 366125.87500	
4008	 steps: training loss - 114087.96094	, testing loss - 365744.46875	
4009	 steps: training loss - 81151.34375	, testing loss - 364754.31250	
4010	 steps: training loss - 122791.40625	, testing loss - 363783.21875	
4011	 steps: training loss - 94541.08594	, testing loss - 362188.53125	
4012	 steps: training loss - 109750.46875	, testing loss - 360768.96875	
4013	 steps: training loss - 106730.93750	, testing loss - 359446.15625	
4014	 steps: training loss - 128102.81250	, testing loss - 357621.50000	
4015	 steps: training loss - 103021.08594	, testing loss - 356222.56250	
4016	 steps: training loss - 87122.91406	, testing loss - 356046.43750	
4017	 steps: training loss - 120798.51562	, testing loss - 356343.75000	
4018	 steps: training loss - 106292.34375	, testing loss - 356408.21875	
4019	 steps: training loss - 133559.79688	, testing loss - 356601.50000	
4020	 steps: training loss - 118438.07031	, testing loss - 357126.18750	
4021	 steps: training loss - 131086.00000	, testing loss - 357614.71875	
4022	 steps: training loss - 129680.95312	, testing loss - 357358.87500	
4023	 steps: training loss - 120930.50000	, testing loss - 357830.25000	
4024	 steps: training loss - 118684.89844	, testing loss - 358017.40625	
4025	 steps: training loss - 100620.21094	, testing loss - 357299.34375	
4026	 steps: training loss - 139076.82812	, testing loss - 356266.75000	
4027	 steps: training loss - 108851.87500	, testing loss - 355748.96875	
4028	 steps: training loss - 106055.65625	, testing loss - 355773.03125	
4029	 steps: training loss - 120552.05469	, testing loss - 355850.18750	
4030	 steps: training loss - 110434.46875	, testing loss - 355458.34375	
4031	 steps: training loss - 137873.34375	, testing loss - 355083.46875	
4032	 steps: training loss - 106538.85156	, testing loss - 355029.15625	
4033	 steps: training loss - 125916.15625	, testing loss - 355150.53125	
4034	 steps: training loss - 107807.56250	, testing loss - 355892.68750	
4035	 steps: training loss - 107491.40625	, testing loss - 355981.56250	
4036	 steps: training loss - 110745.00000	, testing loss - 356119.84375	
4037	 steps: training loss - 130949.70312	, testing loss - 357138.40625	
4038	 steps: training loss - 139028.95312	, testing loss - 358419.12500	
4039	 steps: training loss - 113122.78125	, testing loss - 358819.03125	
4040	 steps: training loss - 132147.81250	, testing loss - 359557.75000	
4041	 steps: training loss - 122995.81250	, testing loss - 361274.03125	
4042	 steps: training loss - 105632.76562	, testing loss - 363605.78125	
4043	 steps: training loss - 107275.71875	, testing loss - 366584.21875	
4044	 steps: training loss - 128691.67188	, testing loss - 368286.12500	
4045	 steps: training loss - 101628.14062	, testing loss - 368076.87500	
4046	 steps: training loss - 109856.25781	, testing loss - 365815.03125	
4047	 steps: training loss - 103036.64062	, testing loss - 363348.46875	
4048	 steps: training loss - 104849.12500	, testing loss - 360952.68750	
4049	 steps: training loss - 121336.92969	, testing loss - 359185.15625	
4050	 steps: training loss - 112777.66406	, testing loss - 357945.37500	
4051	 steps: training loss - 125448.07812	, testing loss - 357542.68750	
4052	 steps: training loss - 125866.60156	, testing loss - 358395.46875	
4053	 steps: training loss - 106032.05469	, testing loss - 359261.18750	
4054	 steps: training loss - 97613.13281	, testing loss - 360560.65625	
4055	 steps: training loss - 107320.23438	, testing loss - 361450.37500	
4056	 steps: training loss - 125244.44531	, testing loss - 361452.87500	
4057	 steps: training loss - 107853.53125	, testing loss - 361585.84375	
4058	 steps: training loss - 109268.68750	, testing loss - 361845.50000	
4059	 steps: training loss - 123684.71094	, testing loss - 361814.09375	
4060	 steps: training loss - 117708.38281	, testing loss - 360434.90625	
4061	 steps: training loss - 107757.42188	, testing loss - 359103.06250	
4062	 steps: training loss - 109254.78906	, testing loss - 357699.84375	
4063	 steps: training loss - 134379.48438	, testing loss - 356181.90625	
4064	 steps: training loss - 99297.49219	, testing loss - 355838.40625	
4065	 steps: training loss - 88658.92969	, testing loss - 355516.68750	
4066	 steps: training loss - 120553.10156	, testing loss - 355318.37500	
4067	 steps: training loss - 136538.45312	, testing loss - 355752.65625	
4068	 steps: training loss - 116297.46875	, testing loss - 355579.40625	
4069	 steps: training loss - 141141.82812	, testing loss - 355597.00000	
4070	 steps: training loss - 83019.79688	, testing loss - 355869.34375	
4071	 steps: training loss - 109049.85156	, testing loss - 355712.18750	
4072	 steps: training loss - 140812.00000	, testing loss - 355006.84375	
4073	 steps: training loss - 114318.73438	, testing loss - 354730.18750	
4074	 steps: training loss - 110809.21875	, testing loss - 354809.53125	
4075	 steps: training loss - 100093.21875	, testing loss - 354604.50000	
4076	 steps: training loss - 108096.88281	, testing loss - 354998.87500	
4077	 steps: training loss - 116662.30469	, testing loss - 355007.37500	
4078	 steps: training loss - 99657.53125	, testing loss - 354674.34375	
4079	 steps: training loss - 106757.79688	, testing loss - 354611.87500	
4080	 steps: training loss - 113850.67969	, testing loss - 355923.21875	
4081	 steps: training loss - 98631.96875	, testing loss - 356713.21875	
4082	 steps: training loss - 106874.60156	, testing loss - 357289.31250	
4083	 steps: training loss - 107631.03125	, testing loss - 357702.65625	
4084	 steps: training loss - 126888.33594	, testing loss - 357656.65625	
4085	 steps: training loss - 106307.07031	, testing loss - 357576.12500	
4086	 steps: training loss - 119531.71094	, testing loss - 357427.81250	
4087	 steps: training loss - 116225.32031	, testing loss - 357196.12500	
4088	 steps: training loss - 149263.89062	, testing loss - 356503.71875	
4089	 steps: training loss - 135508.93750	, testing loss - 355409.03125	
4090	 steps: training loss - 119791.63281	, testing loss - 354581.84375	
4091	 steps: training loss - 127836.37500	, testing loss - 354229.09375	
4092	 steps: training loss - 113187.96875	, testing loss - 354517.84375	
4093	 steps: training loss - 89921.75781	, testing loss - 355404.78125	
4094	 steps: training loss - 90186.80469	, testing loss - 356801.96875	
4095	 steps: training loss - 125692.96094	, testing loss - 358195.34375	
4096	 steps: training loss - 118205.53125	, testing loss - 360194.03125	
4097	 steps: training loss - 122247.18750	, testing loss - 362006.09375	
4098	 steps: training loss - 140385.93750	, testing loss - 364269.96875	
4099	 steps: training loss - 121825.94531	, testing loss - 367123.50000	
4100	 steps: training loss - 110319.61719	, testing loss - 368604.46875	
4101	 steps: training loss - 109349.35938	, testing loss - 367804.40625	
4102	 steps: training loss - 132963.26562	, testing loss - 365597.15625	
4103	 steps: training loss - 131491.42188	, testing loss - 363557.28125	
4104	 steps: training loss - 114666.69531	, testing loss - 361727.37500	
4105	 steps: training loss - 105386.17969	, testing loss - 360066.71875	
4106	 steps: training loss - 110001.61719	, testing loss - 358900.00000	
4107	 steps: training loss - 94651.25000	, testing loss - 357041.15625	
4108	 steps: training loss - 113658.02344	, testing loss - 355203.25000	
4109	 steps: training loss - 125858.46875	, testing loss - 353314.75000	
4110	 steps: training loss - 111120.63281	, testing loss - 352307.12500	
4111	 steps: training loss - 121370.77344	, testing loss - 352269.81250	
4112	 steps: training loss - 123191.95312	, testing loss - 352463.96875	
4113	 steps: training loss - 104146.76562	, testing loss - 352275.00000	
4114	 steps: training loss - 121794.52344	, testing loss - 352141.03125	
4115	 steps: training loss - 78400.28125	, testing loss - 351971.06250	
4116	 steps: training loss - 115588.23438	, testing loss - 351591.78125	
4117	 steps: training loss - 111064.16406	, testing loss - 351120.81250	
4118	 steps: training loss - 129575.39062	, testing loss - 351642.90625	
4119	 steps: training loss - 116640.18750	, testing loss - 352802.50000	
4120	 steps: training loss - 105095.20312	, testing loss - 353344.65625	
4121	 steps: training loss - 105749.30469	, testing loss - 354022.15625	
4122	 steps: training loss - 97772.45312	, testing loss - 354045.03125	
4123	 steps: training loss - 125115.50781	, testing loss - 353857.84375	
4124	 steps: training loss - 112709.88281	, testing loss - 354432.18750	
4125	 steps: training loss - 111682.95312	, testing loss - 356281.03125	
4126	 steps: training loss - 111152.28125	, testing loss - 358619.25000	
4127	 steps: training loss - 130988.42188	, testing loss - 361698.62500	
4128	 steps: training loss - 125464.75000	, testing loss - 363539.93750	
4129	 steps: training loss - 111759.37500	, testing loss - 363389.37500	
4130	 steps: training loss - 124533.75781	, testing loss - 362211.21875	
4131	 steps: training loss - 115087.39844	, testing loss - 361160.65625	
4132	 steps: training loss - 121023.78125	, testing loss - 360550.50000	
4133	 steps: training loss - 97997.12500	, testing loss - 359487.31250	
4134	 steps: training loss - 93824.60938	, testing loss - 358252.34375	
4135	 steps: training loss - 87982.28906	, testing loss - 356484.00000	
4136	 steps: training loss - 108192.76562	, testing loss - 355151.40625	
4137	 steps: training loss - 88703.15625	, testing loss - 353964.00000	
4138	 steps: training loss - 108622.12500	, testing loss - 353114.21875	
4139	 steps: training loss - 116391.50000	, testing loss - 352982.78125	
4140	 steps: training loss - 120593.46875	, testing loss - 353783.34375	
4141	 steps: training loss - 107393.30469	, testing loss - 355062.81250	
4142	 steps: training loss - 110014.77344	, testing loss - 355163.15625	
4143	 steps: training loss - 131526.60938	, testing loss - 355195.53125	
4144	 steps: training loss - 118274.12500	, testing loss - 354953.12500	
4145	 steps: training loss - 112317.11719	, testing loss - 355142.81250	
4146	 steps: training loss - 125035.00000	, testing loss - 355509.93750	
4147	 steps: training loss - 101763.34375	, testing loss - 356041.34375	
4148	 steps: training loss - 98598.47656	, testing loss - 356839.65625	
4149	 steps: training loss - 113938.67188	, testing loss - 357796.03125	
4150	 steps: training loss - 104850.45312	, testing loss - 358550.37500	
4151	 steps: training loss - 97392.30469	, testing loss - 358906.96875	
4152	 steps: training loss - 95319.00781	, testing loss - 359902.68750	
4153	 steps: training loss - 131258.96875	, testing loss - 360617.40625	
4154	 steps: training loss - 107131.89062	, testing loss - 361203.40625	
4155	 steps: training loss - 118922.13281	, testing loss - 362338.21875	
4156	 steps: training loss - 140365.62500	, testing loss - 363787.43750	
4157	 steps: training loss - 115553.39844	, testing loss - 365376.21875	
4158	 steps: training loss - 96703.42188	, testing loss - 367924.90625	
4159	 steps: training loss - 114766.04688	, testing loss - 371370.28125	
4160	 steps: training loss - 127530.00000	, testing loss - 373268.12500	
4161	 steps: training loss - 101279.64844	, testing loss - 374002.06250	
4162	 steps: training loss - 119758.37500	, testing loss - 373317.87500	
4163	 steps: training loss - 134351.29688	, testing loss - 372516.21875	
4164	 steps: training loss - 105417.06250	, testing loss - 370960.62500	
4165	 steps: training loss - 110511.61719	, testing loss - 369548.03125	
4166	 steps: training loss - 123324.11719	, testing loss - 368669.21875	
4167	 steps: training loss - 108437.42969	, testing loss - 367649.84375	
4168	 steps: training loss - 103839.01562	, testing loss - 367023.25000	
4169	 steps: training loss - 101204.21094	, testing loss - 365593.06250	
4170	 steps: training loss - 92823.63281	, testing loss - 364059.28125	
4171	 steps: training loss - 127081.91406	, testing loss - 363198.21875	
4172	 steps: training loss - 109692.58594	, testing loss - 362466.71875	
4173	 steps: training loss - 111368.75000	, testing loss - 361777.40625	
4174	 steps: training loss - 107494.37500	, testing loss - 360608.56250	
4175	 steps: training loss - 105572.23438	, testing loss - 360239.34375	
4176	 steps: training loss - 129732.92969	, testing loss - 358838.93750	
4177	 steps: training loss - 111303.45312	, testing loss - 357910.18750	
4178	 steps: training loss - 110064.33594	, testing loss - 357140.84375	
4179	 steps: training loss - 129491.15625	, testing loss - 356274.28125	
4180	 steps: training loss - 134005.68750	, testing loss - 355053.40625	
4181	 steps: training loss - 131646.46875	, testing loss - 354333.50000	
4182	 steps: training loss - 122173.63281	, testing loss - 353647.65625	
4183	 steps: training loss - 92879.89062	, testing loss - 352953.90625	
4184	 steps: training loss - 115362.89844	, testing loss - 351862.21875	
4185	 steps: training loss - 112055.72656	, testing loss - 350582.96875	
4186	 steps: training loss - 101594.53906	, testing loss - 350749.25000	
4187	 steps: training loss - 90467.62500	, testing loss - 351599.21875	
4188	 steps: training loss - 135929.40625	, testing loss - 351761.50000	
4189	 steps: training loss - 128049.47656	, testing loss - 351724.00000	
4190	 steps: training loss - 104063.62500	, testing loss - 351645.12500	
4191	 steps: training loss - 133696.79688	, testing loss - 350858.37500	
4192	 steps: training loss - 108380.07812	, testing loss - 350396.06250	
4193	 steps: training loss - 117217.47656	, testing loss - 350437.21875	
4194	 steps: training loss - 113373.03906	, testing loss - 350197.75000	
4195	 steps: training loss - 140107.43750	, testing loss - 350536.00000	
4196	 steps: training loss - 115037.91406	, testing loss - 351342.78125	
4197	 steps: training loss - 125379.75781	, testing loss - 351769.78125	
4198	 steps: training loss - 123247.90625	, testing loss - 351634.90625	
4199	 steps: training loss - 125227.25781	, testing loss - 351265.90625	
4200	 steps: training loss - 133507.43750	, testing loss - 352294.78125	
4201	 steps: training loss - 114712.16406	, testing loss - 353113.09375	
4202	 steps: training loss - 99330.15625	, testing loss - 354541.71875	
4203	 steps: training loss - 107550.01562	, testing loss - 355812.00000	
4204	 steps: training loss - 118846.76562	, testing loss - 356508.71875	
4205	 steps: training loss - 110063.63281	, testing loss - 357296.75000	
4206	 steps: training loss - 104586.59375	, testing loss - 358152.34375	
4207	 steps: training loss - 110883.41406	, testing loss - 358425.53125	
4208	 steps: training loss - 115406.44531	, testing loss - 358547.71875	
4209	 steps: training loss - 112684.26562	, testing loss - 358884.15625	
4210	 steps: training loss - 106773.35156	, testing loss - 359465.71875	
4211	 steps: training loss - 119380.67969	, testing loss - 361566.56250	
4212	 steps: training loss - 115239.65625	, testing loss - 363681.31250	
4213	 steps: training loss - 96955.03906	, testing loss - 365045.21875	
4214	 steps: training loss - 107695.18750	, testing loss - 365028.90625	
4215	 steps: training loss - 113601.64062	, testing loss - 364995.87500	
4216	 steps: training loss - 114099.53906	, testing loss - 364542.96875	
4217	 steps: training loss - 124525.67969	, testing loss - 364061.28125	
4218	 steps: training loss - 99015.21875	, testing loss - 362436.96875	
4219	 steps: training loss - 137260.90625	, testing loss - 360295.21875	
4220	 steps: training loss - 137051.82812	, testing loss - 358344.37500	
4221	 steps: training loss - 132820.76562	, testing loss - 357608.78125	
4222	 steps: training loss - 108236.00781	, testing loss - 356683.15625	
4223	 steps: training loss - 104584.00781	, testing loss - 356178.59375	
4224	 steps: training loss - 104970.24219	, testing loss - 356718.81250	
4225	 steps: training loss - 130690.23438	, testing loss - 357051.93750	
4226	 steps: training loss - 114034.24219	, testing loss - 358668.96875	
4227	 steps: training loss - 116427.89062	, testing loss - 360062.15625	
4228	 steps: training loss - 101824.78906	, testing loss - 361143.68750	
4229	 steps: training loss - 106614.12500	, testing loss - 361126.34375	
4230	 steps: training loss - 119339.33594	, testing loss - 360403.50000	
4231	 steps: training loss - 90209.88281	, testing loss - 359311.37500	
4232	 steps: training loss - 105194.16406	, testing loss - 357872.43750	
4233	 steps: training loss - 113766.20312	, testing loss - 356022.65625	
4234	 steps: training loss - 116941.43750	, testing loss - 355095.87500	
4235	 steps: training loss - 119995.89062	, testing loss - 355671.15625	
4236	 steps: training loss - 115293.23438	, testing loss - 356049.96875	
4237	 steps: training loss - 96539.59375	, testing loss - 356956.31250	
4238	 steps: training loss - 112369.85938	, testing loss - 358074.46875	
4239	 steps: training loss - 128504.28906	, testing loss - 358047.75000	
4240	 steps: training loss - 136044.98438	, testing loss - 357935.59375	
4241	 steps: training loss - 104870.85938	, testing loss - 357576.43750	
4242	 steps: training loss - 97341.12500	, testing loss - 356931.87500	
4243	 steps: training loss - 119814.53125	, testing loss - 355972.18750	
4244	 steps: training loss - 132100.70312	, testing loss - 354133.21875	
4245	 steps: training loss - 101041.88281	, testing loss - 351830.31250	
4246	 steps: training loss - 107397.32812	, testing loss - 349561.59375	
4247	 steps: training loss - 139682.35938	, testing loss - 348207.43750	
4248	 steps: training loss - 117695.32031	, testing loss - 347636.53125	
4249	 steps: training loss - 109473.17969	, testing loss - 347841.46875	
4250	 steps: training loss - 102393.78906	, testing loss - 349391.03125	
4251	 steps: training loss - 110913.92188	, testing loss - 350776.90625	
4252	 steps: training loss - 114753.79688	, testing loss - 352362.78125	
4253	 steps: training loss - 133522.32812	, testing loss - 354189.40625	
4254	 steps: training loss - 114925.87500	, testing loss - 356691.31250	
4255	 steps: training loss - 113442.74219	, testing loss - 359194.71875	
4256	 steps: training loss - 92355.60156	, testing loss - 362306.50000	
4257	 steps: training loss - 97730.14062	, testing loss - 364629.87500	
4258	 steps: training loss - 103321.07812	, testing loss - 365610.81250	
4259	 steps: training loss - 106839.40625	, testing loss - 365691.09375	
4260	 steps: training loss - 124555.51562	, testing loss - 366470.43750	
4261	 steps: training loss - 114193.39062	, testing loss - 366282.81250	
4262	 steps: training loss - 109213.92188	, testing loss - 366735.90625	
4263	 steps: training loss - 114258.42969	, testing loss - 366422.31250	
4264	 steps: training loss - 111245.89844	, testing loss - 365752.46875	
4265	 steps: training loss - 99938.23438	, testing loss - 364758.18750	
4266	 steps: training loss - 112415.91406	, testing loss - 363086.43750	
4267	 steps: training loss - 124251.10156	, testing loss - 361430.43750	
4268	 steps: training loss - 108952.84375	, testing loss - 359886.31250	
4269	 steps: training loss - 94777.23438	, testing loss - 358368.65625	
4270	 steps: training loss - 108251.60156	, testing loss - 357781.12500	
4271	 steps: training loss - 101949.44531	, testing loss - 358541.09375	
4272	 steps: training loss - 100850.25000	, testing loss - 358713.81250	
4273	 steps: training loss - 135998.10938	, testing loss - 358829.21875	
4274	 steps: training loss - 126910.96875	, testing loss - 358512.43750	
4275	 steps: training loss - 98032.63281	, testing loss - 357966.31250	
4276	 steps: training loss - 124679.88281	, testing loss - 357540.90625	
4277	 steps: training loss - 101972.02344	, testing loss - 356847.15625	
4278	 steps: training loss - 92571.53125	, testing loss - 355676.06250	
4279	 steps: training loss - 98401.11719	, testing loss - 354375.84375	
4280	 steps: training loss - 116077.06250	, testing loss - 353596.25000	
4281	 steps: training loss - 115416.19531	, testing loss - 352785.09375	
4282	 steps: training loss - 97176.64062	, testing loss - 352549.68750	
4283	 steps: training loss - 118414.96875	, testing loss - 352206.59375	
4284	 steps: training loss - 119694.97656	, testing loss - 351178.71875	
4285	 steps: training loss - 114723.07812	, testing loss - 349724.71875	
4286	 steps: training loss - 99379.67969	, testing loss - 348843.78125	
4287	 steps: training loss - 114676.82031	, testing loss - 348279.34375	
4288	 steps: training loss - 110207.82031	, testing loss - 348521.43750	
4289	 steps: training loss - 97177.75781	, testing loss - 348687.75000	
4290	 steps: training loss - 90514.82812	, testing loss - 348715.81250	
4291	 steps: training loss - 102254.17188	, testing loss - 349111.90625	
4292	 steps: training loss - 121813.25781	, testing loss - 350080.62500	
4293	 steps: training loss - 106216.29688	, testing loss - 351424.65625	
4294	 steps: training loss - 123378.04688	, testing loss - 352691.06250	
4295	 steps: training loss - 112975.53906	, testing loss - 354247.34375	
4296	 steps: training loss - 128826.01562	, testing loss - 356626.15625	
4297	 steps: training loss - 120745.66406	, testing loss - 358575.31250	
4298	 steps: training loss - 94168.92969	, testing loss - 361045.43750	
4299	 steps: training loss - 118424.24219	, testing loss - 362348.90625	
4300	 steps: training loss - 82282.22656	, testing loss - 362333.28125	
4301	 steps: training loss - 139622.76562	, testing loss - 362288.56250	
4302	 steps: training loss - 121743.50781	, testing loss - 364049.62500	
4303	 steps: training loss - 113605.78906	, testing loss - 365310.65625	
4304	 steps: training loss - 117852.17969	, testing loss - 365662.90625	
4305	 steps: training loss - 106382.56250	, testing loss - 365537.87500	
4306	 steps: training loss - 117945.51562	, testing loss - 364280.00000	
4307	 steps: training loss - 101047.94531	, testing loss - 362832.50000	
4308	 steps: training loss - 115815.92188	, testing loss - 361543.25000	
4309	 steps: training loss - 113656.39844	, testing loss - 359285.56250	
4310	 steps: training loss - 88582.97656	, testing loss - 357657.90625	
4311	 steps: training loss - 102475.39844	, testing loss - 356481.31250	
4312	 steps: training loss - 96430.64062	, testing loss - 354827.12500	
4313	 steps: training loss - 125057.10156	, testing loss - 352974.90625	
4314	 steps: training loss - 95354.36719	, testing loss - 352011.62500	
4315	 steps: training loss - 108751.98438	, testing loss - 351325.96875	
4316	 steps: training loss - 106308.60156	, testing loss - 350800.21875	
4317	 steps: training loss - 117964.50000	, testing loss - 350615.56250	
4318	 steps: training loss - 105796.42188	, testing loss - 350785.68750	
4319	 steps: training loss - 104142.24219	, testing loss - 350798.53125	
4320	 steps: training loss - 117270.22656	, testing loss - 350200.53125	
4321	 steps: training loss - 93313.92969	, testing loss - 350465.81250	
4322	 steps: training loss - 123397.00781	, testing loss - 351059.65625	
4323	 steps: training loss - 112760.38281	, testing loss - 351022.00000	
4324	 steps: training loss - 122835.70312	, testing loss - 351301.81250	
4325	 steps: training loss - 99499.14844	, testing loss - 351762.28125	
4326	 steps: training loss - 112600.48438	, testing loss - 351985.21875	
4327	 steps: training loss - 125236.85938	, testing loss - 352524.84375	
4328	 steps: training loss - 102543.85938	, testing loss - 353046.96875	
4329	 steps: training loss - 106572.50781	, testing loss - 354200.78125	
4330	 steps: training loss - 110936.96875	, testing loss - 355986.78125	
4331	 steps: training loss - 110765.63281	, testing loss - 358535.93750	
4332	 steps: training loss - 134629.20312	, testing loss - 361761.81250	
4333	 steps: training loss - 105125.92969	, testing loss - 365938.53125	
4334	 steps: training loss - 127545.84375	, testing loss - 369052.75000	
4335	 steps: training loss - 122907.63281	, testing loss - 370472.43750	
4336	 steps: training loss - 106385.05469	, testing loss - 370762.31250	
4337	 steps: training loss - 115429.10156	, testing loss - 370140.40625	
4338	 steps: training loss - 87583.15625	, testing loss - 368413.78125	
4339	 steps: training loss - 102314.20312	, testing loss - 365810.03125	
4340	 steps: training loss - 112889.11719	, testing loss - 363195.65625	
4341	 steps: training loss - 92883.04688	, testing loss - 360864.65625	
4342	 steps: training loss - 109589.32812	, testing loss - 358919.90625	
4343	 steps: training loss - 123105.03906	, testing loss - 357470.56250	
4344	 steps: training loss - 112380.21094	, testing loss - 357138.28125	
4345	 steps: training loss - 120596.48438	, testing loss - 356138.62500	
4346	 steps: training loss - 131278.07812	, testing loss - 355243.12500	
4347	 steps: training loss - 104762.57031	, testing loss - 354110.68750	
4348	 steps: training loss - 94584.58594	, testing loss - 353465.50000	
4349	 steps: training loss - 100140.62500	, testing loss - 353374.37500	
4350	 steps: training loss - 118073.25000	, testing loss - 353208.21875	
4351	 steps: training loss - 88441.47656	, testing loss - 352568.90625	
4352	 steps: training loss - 106160.10938	, testing loss - 352177.46875	
4353	 steps: training loss - 102540.69531	, testing loss - 352453.62500	
4354	 steps: training loss - 110851.10938	, testing loss - 353199.81250	
4355	 steps: training loss - 129591.82031	, testing loss - 353495.12500	
4356	 steps: training loss - 127526.33594	, testing loss - 353351.84375	
4357	 steps: training loss - 103513.23438	, testing loss - 352940.03125	
4358	 steps: training loss - 114394.39062	, testing loss - 352477.28125	
4359	 steps: training loss - 101155.59375	, testing loss - 352870.53125	
4360	 steps: training loss - 125475.70312	, testing loss - 353415.62500	
4361	 steps: training loss - 83558.77344	, testing loss - 354011.21875	
4362	 steps: training loss - 79959.77344	, testing loss - 354629.31250	
4363	 steps: training loss - 110906.74219	, testing loss - 355529.71875	
4364	 steps: training loss - 128499.64844	, testing loss - 356906.25000	
4365	 steps: training loss - 95259.94531	, testing loss - 358207.56250	
4366	 steps: training loss - 116453.64062	, testing loss - 359456.18750	
4367	 steps: training loss - 113957.51562	, testing loss - 359973.62500	
4368	 steps: training loss - 118278.33594	, testing loss - 360300.34375	
4369	 steps: training loss - 122395.62500	, testing loss - 360726.37500	
4370	 steps: training loss - 123019.12500	, testing loss - 360459.62500	
4371	 steps: training loss - 133896.23438	, testing loss - 359582.90625	
4372	 steps: training loss - 106883.64844	, testing loss - 359498.00000	
4373	 steps: training loss - 109239.94531	, testing loss - 359498.71875	
4374	 steps: training loss - 120438.67969	, testing loss - 358531.06250	
4375	 steps: training loss - 116862.10938	, testing loss - 357529.31250	
4376	 steps: training loss - 136496.81250	, testing loss - 357061.65625	
4377	 steps: training loss - 95333.56250	, testing loss - 356109.34375	
4378	 steps: training loss - 101324.89062	, testing loss - 355301.81250	
4379	 steps: training loss - 103285.64062	, testing loss - 354802.62500	
4380	 steps: training loss - 148479.96875	, testing loss - 353672.18750	
4381	 steps: training loss - 136351.51562	, testing loss - 353631.09375	
4382	 steps: training loss - 116741.71875	, testing loss - 353984.56250	
4383	 steps: training loss - 131865.40625	, testing loss - 353745.87500	
4384	 steps: training loss - 98917.32812	, testing loss - 352983.18750	
4385	 steps: training loss - 119471.53125	, testing loss - 352147.93750	
4386	 steps: training loss - 93578.75000	, testing loss - 351159.96875	
4387	 steps: training loss - 123799.85156	, testing loss - 350437.28125	
4388	 steps: training loss - 98838.81250	, testing loss - 350155.09375	
4389	 steps: training loss - 127083.14062	, testing loss - 350640.75000	
4390	 steps: training loss - 116400.39062	, testing loss - 351338.87500	
4391	 steps: training loss - 88620.41406	, testing loss - 352666.46875	
4392	 steps: training loss - 120282.45312	, testing loss - 354802.87500	
4393	 steps: training loss - 113556.94531	, testing loss - 357057.78125	
4394	 steps: training loss - 114585.13281	, testing loss - 358601.84375	
4395	 steps: training loss - 137629.98438	, testing loss - 359126.03125	
4396	 steps: training loss - 103622.41406	, testing loss - 359029.75000	
4397	 steps: training loss - 105246.32812	, testing loss - 359431.21875	
4398	 steps: training loss - 121475.43750	, testing loss - 359537.93750	
4399	 steps: training loss - 109740.61719	, testing loss - 359705.21875	
4400	 steps: training loss - 115437.67969	, testing loss - 360665.15625	
4401	 steps: training loss - 92044.81250	, testing loss - 360680.28125	
4402	 steps: training loss - 107543.91406	, testing loss - 360296.28125	
4403	 steps: training loss - 114354.90625	, testing loss - 359622.90625	
4404	 steps: training loss - 119256.93750	, testing loss - 359062.15625	
4405	 steps: training loss - 114477.50000	, testing loss - 358840.87500	
4406	 steps: training loss - 94473.37500	, testing loss - 357758.09375	
4407	 steps: training loss - 83776.15625	, testing loss - 356312.06250	
4408	 steps: training loss - 93958.81250	, testing loss - 354640.09375	
4409	 steps: training loss - 100476.91406	, testing loss - 352425.46875	
4410	 steps: training loss - 110675.82031	, testing loss - 350835.06250	
4411	 steps: training loss - 128172.13281	, testing loss - 350503.18750	
4412	 steps: training loss - 110395.64844	, testing loss - 350548.59375	
4413	 steps: training loss - 109105.89062	, testing loss - 350728.46875	
4414	 steps: training loss - 114208.14062	, testing loss - 350605.15625	
4415	 steps: training loss - 97895.57812	, testing loss - 349906.34375	
4416	 steps: training loss - 103582.74219	, testing loss - 349107.25000	
4417	 steps: training loss - 115989.34375	, testing loss - 348851.09375	
4418	 steps: training loss - 94586.52344	, testing loss - 349083.65625	
4419	 steps: training loss - 118574.98438	, testing loss - 350099.78125	
4420	 steps: training loss - 142817.75000	, testing loss - 351517.56250	
4421	 steps: training loss - 117159.31250	, testing loss - 353048.81250	
4422	 steps: training loss - 149337.03125	, testing loss - 354602.71875	
4423	 steps: training loss - 112714.29688	, testing loss - 355856.87500	
4424	 steps: training loss - 107590.29688	, testing loss - 357526.34375	
4425	 steps: training loss - 109304.02344	, testing loss - 358989.59375	
4426	 steps: training loss - 125983.10938	, testing loss - 360911.84375	
4427	 steps: training loss - 119234.88281	, testing loss - 362676.65625	
4428	 steps: training loss - 112626.46094	, testing loss - 364032.15625	
4429	 steps: training loss - 111865.92969	, testing loss - 366137.96875	
4430	 steps: training loss - 114260.88281	, testing loss - 368241.56250	
4431	 steps: training loss - 91336.32031	, testing loss - 369328.15625	
4432	 steps: training loss - 95255.15625	, testing loss - 369887.25000	
4433	 steps: training loss - 110866.00781	, testing loss - 369800.87500	
4434	 steps: training loss - 130836.00000	, testing loss - 369592.28125	
4435	 steps: training loss - 95503.07031	, testing loss - 367162.65625	
4436	 steps: training loss - 125912.95312	, testing loss - 363847.40625	
4437	 steps: training loss - 118854.52344	, testing loss - 362443.56250	
4438	 steps: training loss - 117950.06250	, testing loss - 361933.03125	
4439	 steps: training loss - 111362.02344	, testing loss - 362513.87500	
4440	 steps: training loss - 125488.90625	, testing loss - 363646.06250	
4441	 steps: training loss - 113104.25781	, testing loss - 364388.87500	
4442	 steps: training loss - 98648.32812	, testing loss - 364451.81250	
4443	 steps: training loss - 128342.51562	, testing loss - 364429.28125	
4444	 steps: training loss - 112595.15625	, testing loss - 363694.09375	
4445	 steps: training loss - 106273.49219	, testing loss - 362997.34375	
4446	 steps: training loss - 103149.17969	, testing loss - 361772.25000	
4447	 steps: training loss - 122061.38281	, testing loss - 360372.12500	
4448	 steps: training loss - 112987.55469	, testing loss - 358370.31250	
4449	 steps: training loss - 110079.48438	, testing loss - 356241.25000	
4450	 steps: training loss - 136415.73438	, testing loss - 354818.37500	
4451	 steps: training loss - 127460.25000	, testing loss - 354549.15625	
4452	 steps: training loss - 129270.05469	, testing loss - 354915.31250	
4453	 steps: training loss - 92654.98438	, testing loss - 355607.90625	
4454	 steps: training loss - 138189.87500	, testing loss - 356333.93750	
4455	 steps: training loss - 101436.42969	, testing loss - 357271.90625	
4456	 steps: training loss - 115349.97656	, testing loss - 357386.87500	
4457	 steps: training loss - 113849.89062	, testing loss - 357484.40625	
4458	 steps: training loss - 115700.66406	, testing loss - 357618.75000	
4459	 steps: training loss - 98510.36719	, testing loss - 357916.65625	
4460	 steps: training loss - 110783.41406	, testing loss - 357518.09375	
4461	 steps: training loss - 120178.78906	, testing loss - 356597.75000	
4462	 steps: training loss - 132364.40625	, testing loss - 355919.68750	
4463	 steps: training loss - 145576.39062	, testing loss - 355454.28125	
4464	 steps: training loss - 108586.89062	, testing loss - 354373.87500	
4465	 steps: training loss - 126593.35938	, testing loss - 353233.93750	
4466	 steps: training loss - 105794.85938	, testing loss - 351643.21875	
4467	 steps: training loss - 117875.20312	, testing loss - 350649.46875	
4468	 steps: training loss - 113066.17969	, testing loss - 349942.46875	
4469	 steps: training loss - 90831.30469	, testing loss - 349592.43750	
4470	 steps: training loss - 119596.97656	, testing loss - 349884.78125	
4471	 steps: training loss - 141244.64062	, testing loss - 350801.34375	
4472	 steps: training loss - 107590.54688	, testing loss - 351685.93750	
4473	 steps: training loss - 112972.35938	, testing loss - 351694.81250	
4474	 steps: training loss - 123675.47656	, testing loss - 350633.71875	
4475	 steps: training loss - 121164.07031	, testing loss - 350246.12500	
4476	 steps: training loss - 120085.58594	, testing loss - 350179.37500	
4477	 steps: training loss - 91324.06250	, testing loss - 350268.78125	
4478	 steps: training loss - 117643.45312	, testing loss - 350111.93750	
4479	 steps: training loss - 122011.84375	, testing loss - 349232.68750	
4480	 steps: training loss - 115128.56250	, testing loss - 348453.03125	
4481	 steps: training loss - 127298.56250	, testing loss - 348429.78125	
4482	 steps: training loss - 104261.97656	, testing loss - 348511.68750	
4483	 steps: training loss - 132909.70312	, testing loss - 349088.28125	
4484	 steps: training loss - 121612.31250	, testing loss - 349614.03125	
4485	 steps: training loss - 123312.09375	, testing loss - 349753.21875	
4486	 steps: training loss - 123295.02344	, testing loss - 350102.62500	
4487	 steps: training loss - 121063.71094	, testing loss - 350900.78125	
4488	 steps: training loss - 114309.36719	, testing loss - 351342.18750	
4489	 steps: training loss - 103648.51562	, testing loss - 351893.81250	
4490	 steps: training loss - 115938.95312	, testing loss - 351990.59375	
4491	 steps: training loss - 119733.23438	, testing loss - 351220.96875	
4492	 steps: training loss - 96817.48438	, testing loss - 350916.78125	
4493	 steps: training loss - 105830.40625	, testing loss - 350871.65625	
4494	 steps: training loss - 110730.68750	, testing loss - 351119.09375	
4495	 steps: training loss - 123479.23438	, testing loss - 351338.65625	
4496	 steps: training loss - 127016.44531	, testing loss - 351063.53125	
4497	 steps: training loss - 100498.79688	, testing loss - 350751.84375	
4498	 steps: training loss - 98216.95312	, testing loss - 351070.03125	
4499	 steps: training loss - 124610.09375	, testing loss - 351181.53125	
4500	 steps: training loss - 108763.73438	, testing loss - 351410.62500	
4501	 steps: training loss - 125440.94531	, testing loss - 350807.59375	
4502	 steps: training loss - 106332.59375	, testing loss - 349902.06250	
4503	 steps: training loss - 122760.99219	, testing loss - 349096.06250	
4504	 steps: training loss - 113526.81250	, testing loss - 348843.75000	
4505	 steps: training loss - 120294.53125	, testing loss - 349239.46875	
4506	 steps: training loss - 95838.60938	, testing loss - 349687.00000	
4507	 steps: training loss - 132360.62500	, testing loss - 349924.00000	
4508	 steps: training loss - 101574.50781	, testing loss - 350125.56250	
4509	 steps: training loss - 129648.79688	, testing loss - 350351.65625	
4510	 steps: training loss - 115831.82812	, testing loss - 351499.00000	
4511	 steps: training loss - 135599.26562	, testing loss - 352963.43750	
4512	 steps: training loss - 110357.14062	, testing loss - 354333.37500	
4513	 steps: training loss - 114626.50781	, testing loss - 354774.12500	
4514	 steps: training loss - 132018.29688	, testing loss - 354754.81250	
4515	 steps: training loss - 113111.43750	, testing loss - 354548.18750	
4516	 steps: training loss - 117075.94531	, testing loss - 355361.43750	
4517	 steps: training loss - 127495.92188	, testing loss - 356471.75000	
4518	 steps: training loss - 99472.96875	, testing loss - 357158.75000	
4519	 steps: training loss - 95675.92969	, testing loss - 357234.84375	
4520	 steps: training loss - 89766.50000	, testing loss - 356868.65625	
4521	 steps: training loss - 100261.66406	, testing loss - 357404.78125	
4522	 steps: training loss - 99297.85938	, testing loss - 358192.96875	
4523	 steps: training loss - 104199.49219	, testing loss - 357781.25000	
4524	 steps: training loss - 93891.03906	, testing loss - 356443.15625	
4525	 steps: training loss - 108686.73438	, testing loss - 354568.62500	
4526	 steps: training loss - 113543.80469	, testing loss - 353184.43750	
4527	 steps: training loss - 128111.60156	, testing loss - 352483.21875	
4528	 steps: training loss - 104099.28125	, testing loss - 352112.50000	
4529	 steps: training loss - 80545.27344	, testing loss - 352166.12500	
4530	 steps: training loss - 101030.68750	, testing loss - 352120.46875	
4531	 steps: training loss - 113028.39844	, testing loss - 352015.21875	
4532	 steps: training loss - 125776.07812	, testing loss - 350813.12500	
4533	 steps: training loss - 139414.26562	, testing loss - 349793.46875	
4534	 steps: training loss - 101985.81250	, testing loss - 348896.43750	
4535	 steps: training loss - 91727.47656	, testing loss - 348141.31250	
4536	 steps: training loss - 129874.35938	, testing loss - 347297.68750	
4537	 steps: training loss - 111143.46875	, testing loss - 346323.06250	
4538	 steps: training loss - 109946.98438	, testing loss - 346312.03125	
4539	 steps: training loss - 134970.53125	, testing loss - 346559.46875	
4540	 steps: training loss - 107380.41406	, testing loss - 347483.90625	
4541	 steps: training loss - 105332.42188	, testing loss - 348333.50000	
4542	 steps: training loss - 98111.22656	, testing loss - 349344.15625	
4543	 steps: training loss - 102334.78906	, testing loss - 350397.68750	
4544	 steps: training loss - 118433.27344	, testing loss - 351340.40625	
4545	 steps: training loss - 122895.70312	, testing loss - 351840.59375	
4546	 steps: training loss - 105625.54688	, testing loss - 352771.40625	
4547	 steps: training loss - 92614.92188	, testing loss - 353414.87500	
4548	 steps: training loss - 92541.75000	, testing loss - 353192.12500	
4549	 steps: training loss - 114424.75000	, testing loss - 352246.18750	
4550	 steps: training loss - 123833.66406	, testing loss - 351720.34375	
4551	 steps: training loss - 137738.65625	, testing loss - 351465.21875	
4552	 steps: training loss - 121944.43750	, testing loss - 351802.59375	
4553	 steps: training loss - 116104.09375	, testing loss - 353999.06250	
4554	 steps: training loss - 113116.39844	, testing loss - 356573.03125	
4555	 steps: training loss - 121791.86719	, testing loss - 357527.96875	
4556	 steps: training loss - 99234.39844	, testing loss - 357956.25000	
4557	 steps: training loss - 96465.69531	, testing loss - 358482.71875	
4558	 steps: training loss - 104265.49219	, testing loss - 359739.53125	
4559	 steps: training loss - 112766.60938	, testing loss - 361213.68750	
4560	 steps: training loss - 103269.25781	, testing loss - 362075.87500	
4561	 steps: training loss - 110977.97656	, testing loss - 362655.18750	
4562	 steps: training loss - 111711.10938	, testing loss - 362196.59375	
4563	 steps: training loss - 97131.60156	, testing loss - 360746.68750	
4564	 steps: training loss - 86233.78906	, testing loss - 359730.09375	
4565	 steps: training loss - 118991.25000	, testing loss - 359005.56250	
4566	 steps: training loss - 103001.96094	, testing loss - 358488.31250	
4567	 steps: training loss - 100702.03125	, testing loss - 358015.25000	
4568	 steps: training loss - 113294.48438	, testing loss - 357604.84375	
4569	 steps: training loss - 111073.52344	, testing loss - 356782.43750	
4570	 steps: training loss - 101837.43750	, testing loss - 356324.12500	
4571	 steps: training loss - 129917.13281	, testing loss - 356256.37500	
4572	 steps: training loss - 122756.90625	, testing loss - 356939.62500	
4573	 steps: training loss - 89649.62500	, testing loss - 358451.87500	
4574	 steps: training loss - 97261.37500	, testing loss - 360988.71875	
4575	 steps: training loss - 107177.20312	, testing loss - 362729.46875	
4576	 steps: training loss - 116623.50781	, testing loss - 363990.34375	
4577	 steps: training loss - 115875.94531	, testing loss - 363968.84375	
4578	 steps: training loss - 133087.65625	, testing loss - 364408.03125	
4579	 steps: training loss - 93013.17188	, testing loss - 363596.62500	
4580	 steps: training loss - 117776.35938	, testing loss - 361674.56250	
4581	 steps: training loss - 113199.64844	, testing loss - 359337.40625	
4582	 steps: training loss - 114051.99219	, testing loss - 356723.81250	
4583	 steps: training loss - 109579.83594	, testing loss - 355231.40625	
4584	 steps: training loss - 116780.94531	, testing loss - 354928.62500	
4585	 steps: training loss - 119189.57031	, testing loss - 354411.43750	
4586	 steps: training loss - 105141.44531	, testing loss - 353618.59375	
4587	 steps: training loss - 112866.85938	, testing loss - 352461.93750	
4588	 steps: training loss - 93364.07812	, testing loss - 351679.37500	
4589	 steps: training loss - 100402.35938	, testing loss - 351366.84375	
4590	 steps: training loss - 85650.64062	, testing loss - 350632.78125	
4591	 steps: training loss - 103330.31250	, testing loss - 349788.65625	
4592	 steps: training loss - 116108.47656	, testing loss - 349163.03125	
4593	 steps: training loss - 106296.95312	, testing loss - 348330.87500	
4594	 steps: training loss - 113034.14062	, testing loss - 347731.06250	
4595	 steps: training loss - 124248.31250	, testing loss - 347266.40625	
4596	 steps: training loss - 121122.78906	, testing loss - 347287.15625	
4597	 steps: training loss - 117704.80469	, testing loss - 348071.15625	
4598	 steps: training loss - 145909.67188	, testing loss - 348682.71875	
4599	 steps: training loss - 121406.21094	, testing loss - 349705.18750	
4600	 steps: training loss - 101740.56250	, testing loss - 351522.03125	
4601	 steps: training loss - 107026.82031	, testing loss - 353234.12500	
4602	 steps: training loss - 105859.87500	, testing loss - 354323.46875	
4603	 steps: training loss - 97023.14844	, testing loss - 355446.81250	
4604	 steps: training loss - 102441.28906	, testing loss - 356456.06250	
4605	 steps: training loss - 115559.68750	, testing loss - 357572.93750	
4606	 steps: training loss - 120317.24219	, testing loss - 359376.34375	
4607	 steps: training loss - 119236.71094	, testing loss - 362050.71875	
4608	 steps: training loss - 118239.87500	, testing loss - 363657.43750	
4609	 steps: training loss - 111596.84375	, testing loss - 364304.09375	
4610	 steps: training loss - 91025.65625	, testing loss - 363942.75000	
4611	 steps: training loss - 135275.37500	, testing loss - 363855.43750	
4612	 steps: training loss - 120326.24219	, testing loss - 363794.03125	
4613	 steps: training loss - 118705.39062	, testing loss - 363912.50000	
4614	 steps: training loss - 123368.67969	, testing loss - 362984.15625	
4615	 steps: training loss - 110853.68750	, testing loss - 360547.56250	
4616	 steps: training loss - 98354.26562	, testing loss - 357876.18750	
4617	 steps: training loss - 110744.51562	, testing loss - 355647.21875	
4618	 steps: training loss - 105262.00000	, testing loss - 353656.59375	
4619	 steps: training loss - 127598.22656	, testing loss - 352728.43750	
4620	 steps: training loss - 127193.96094	, testing loss - 352243.56250	
4621	 steps: training loss - 127863.21875	, testing loss - 353312.84375	
4622	 steps: training loss - 134958.89062	, testing loss - 354260.12500	
4623	 steps: training loss - 123709.99219	, testing loss - 354584.90625	
4624	 steps: training loss - 122931.67188	, testing loss - 354758.40625	
4625	 steps: training loss - 91167.85938	, testing loss - 355366.59375	
4626	 steps: training loss - 107355.54688	, testing loss - 356193.00000	
4627	 steps: training loss - 96702.60156	, testing loss - 356680.65625	
4628	 steps: training loss - 129256.13281	, testing loss - 357067.00000	
4629	 steps: training loss - 105694.78125	, testing loss - 357773.71875	
4630	 steps: training loss - 87389.72656	, testing loss - 358865.15625	
4631	 steps: training loss - 103887.06250	, testing loss - 359391.28125	
4632	 steps: training loss - 104416.15625	, testing loss - 359741.40625	
4633	 steps: training loss - 132539.93750	, testing loss - 359817.21875	
4634	 steps: training loss - 126035.57812	, testing loss - 359331.84375	
4635	 steps: training loss - 110130.45312	, testing loss - 358893.65625	
4636	 steps: training loss - 109369.31250	, testing loss - 358070.65625	
4637	 steps: training loss - 103826.67969	, testing loss - 356851.09375	
4638	 steps: training loss - 114430.99219	, testing loss - 355531.68750	
4639	 steps: training loss - 118855.29688	, testing loss - 354077.56250	
4640	 steps: training loss - 115835.91406	, testing loss - 352675.28125	
4641	 steps: training loss - 83034.68750	, testing loss - 351679.56250	
4642	 steps: training loss - 95636.76562	, testing loss - 351473.84375	
4643	 steps: training loss - 102247.28125	, testing loss - 351535.18750	
4644	 steps: training loss - 126679.05469	, testing loss - 351367.18750	
4645	 steps: training loss - 101216.46094	, testing loss - 351053.06250	
4646	 steps: training loss - 152901.40625	, testing loss - 350947.53125	
4647	 steps: training loss - 120223.57031	, testing loss - 350763.81250	
4648	 steps: training loss - 110255.32031	, testing loss - 350954.62500	
4649	 steps: training loss - 107188.00000	, testing loss - 351796.00000	
4650	 steps: training loss - 106838.02344	, testing loss - 352666.93750	
4651	 steps: training loss - 126387.53906	, testing loss - 353814.96875	
4652	 steps: training loss - 113800.48438	, testing loss - 356705.59375	
4653	 steps: training loss - 99019.94531	, testing loss - 360237.06250	
4654	 steps: training loss - 98259.84375	, testing loss - 363355.81250	
4655	 steps: training loss - 128199.92188	, testing loss - 365069.15625	
4656	 steps: training loss - 122093.36719	, testing loss - 366347.18750	
4657	 steps: training loss - 111857.57812	, testing loss - 367022.90625	
4658	 steps: training loss - 108897.71875	, testing loss - 367498.87500	
4659	 steps: training loss - 133751.71875	, testing loss - 367579.59375	
4660	 steps: training loss - 113246.15625	, testing loss - 365557.50000	
4661	 steps: training loss - 102982.78906	, testing loss - 363051.75000	
4662	 steps: training loss - 108968.38281	, testing loss - 360118.71875	
4663	 steps: training loss - 97597.88281	, testing loss - 358778.12500	
4664	 steps: training loss - 108810.05469	, testing loss - 359122.28125	
4665	 steps: training loss - 100709.75000	, testing loss - 359797.65625	
4666	 steps: training loss - 94960.03906	, testing loss - 360782.78125	
4667	 steps: training loss - 116400.60938	, testing loss - 360860.59375	
4668	 steps: training loss - 121492.01562	, testing loss - 360525.06250	
4669	 steps: training loss - 101467.71875	, testing loss - 359508.03125	
4670	 steps: training loss - 137655.43750	, testing loss - 358439.87500	
4671	 steps: training loss - 111599.66406	, testing loss - 358256.56250	
4672	 steps: training loss - 101448.00000	, testing loss - 359112.37500	
4673	 steps: training loss - 118023.11719	, testing loss - 359890.37500	
4674	 steps: training loss - 124634.86719	, testing loss - 360375.75000	
4675	 steps: training loss - 101155.61719	, testing loss - 359577.46875	
4676	 steps: training loss - 116243.48438	, testing loss - 357606.31250	
4677	 steps: training loss - 132585.85938	, testing loss - 357855.53125	
4678	 steps: training loss - 114590.24219	, testing loss - 358825.87500	
4679	 steps: training loss - 129723.60938	, testing loss - 359430.37500	
4680	 steps: training loss - 138213.37500	, testing loss - 360471.09375	
4681	 steps: training loss - 115459.80469	, testing loss - 360162.78125	
4682	 steps: training loss - 103640.48438	, testing loss - 359736.62500	
4683	 steps: training loss - 112429.42969	, testing loss - 359515.25000	
4684	 steps: training loss - 111848.96875	, testing loss - 359061.15625	
4685	 steps: training loss - 124500.22656	, testing loss - 359073.15625	
4686	 steps: training loss - 141106.53125	, testing loss - 360956.93750	
4687	 steps: training loss - 108699.15625	, testing loss - 364903.71875	
4688	 steps: training loss - 93252.36719	, testing loss - 368866.68750	
4689	 steps: training loss - 86711.43750	, testing loss - 372235.75000	
4690	 steps: training loss - 112781.33594	, testing loss - 373985.50000	
4691	 steps: training loss - 99206.74219	, testing loss - 374598.56250	
4692	 steps: training loss - 95282.75000	, testing loss - 374619.96875	
4693	 steps: training loss - 135807.82812	, testing loss - 373112.06250	
4694	 steps: training loss - 139458.65625	, testing loss - 370957.46875	
4695	 steps: training loss - 113557.57812	, testing loss - 368452.37500	
4696	 steps: training loss - 115878.32031	, testing loss - 365640.90625	
4697	 steps: training loss - 104382.30469	, testing loss - 363946.15625	
4698	 steps: training loss - 111907.74219	, testing loss - 362377.18750	
4699	 steps: training loss - 135265.04688	, testing loss - 360604.03125	
4700	 steps: training loss - 120358.85938	, testing loss - 358086.46875	
4701	 steps: training loss - 103641.57812	, testing loss - 356138.81250	
4702	 steps: training loss - 116954.78125	, testing loss - 354774.68750	
4703	 steps: training loss - 105714.76562	, testing loss - 354153.96875	
4704	 steps: training loss - 102343.88281	, testing loss - 354106.31250	
4705	 steps: training loss - 120316.91406	, testing loss - 353493.18750	
4706	 steps: training loss - 107387.98438	, testing loss - 352364.84375	
4707	 steps: training loss - 120398.31250	, testing loss - 352185.65625	
4708	 steps: training loss - 121278.41406	, testing loss - 353098.34375	
4709	 steps: training loss - 105345.89844	, testing loss - 355180.50000	
4710	 steps: training loss - 113125.42969	, testing loss - 357410.87500	
4711	 steps: training loss - 105227.78125	, testing loss - 359742.68750	
4712	 steps: training loss - 111443.76562	, testing loss - 361170.65625	
4713	 steps: training loss - 91917.60156	, testing loss - 360995.34375	
4714	 steps: training loss - 81970.06250	, testing loss - 360032.09375	
4715	 steps: training loss - 122734.42188	, testing loss - 360134.06250	
4716	 steps: training loss - 86352.76562	, testing loss - 360247.59375	
4717	 steps: training loss - 142426.10938	, testing loss - 360674.90625	
4718	 steps: training loss - 99506.53125	, testing loss - 360645.62500	
4719	 steps: training loss - 114696.41406	, testing loss - 359707.37500	
4720	 steps: training loss - 145136.04688	, testing loss - 359210.68750	
4721	 steps: training loss - 117500.27344	, testing loss - 358589.90625	
4722	 steps: training loss - 138916.29688	, testing loss - 358179.65625	
4723	 steps: training loss - 110615.61719	, testing loss - 357721.71875	
4724	 steps: training loss - 100077.94531	, testing loss - 358245.34375	
4725	 steps: training loss - 123395.43750	, testing loss - 358670.81250	
4726	 steps: training loss - 132605.17188	, testing loss - 358727.87500	
4727	 steps: training loss - 96056.91406	, testing loss - 358515.93750	
4728	 steps: training loss - 137344.54688	, testing loss - 357688.68750	
4729	 steps: training loss - 114518.11719	, testing loss - 356519.68750	
4730	 steps: training loss - 123420.61719	, testing loss - 355446.46875	
4731	 steps: training loss - 114791.55469	, testing loss - 354696.25000	
4732	 steps: training loss - 122613.45312	, testing loss - 353899.71875	
4733	 steps: training loss - 122422.31250	, testing loss - 353909.28125	
4734	 steps: training loss - 109989.20312	, testing loss - 353455.25000	
4735	 steps: training loss - 118398.14062	, testing loss - 352894.25000	
4736	 steps: training loss - 116765.78906	, testing loss - 352420.21875	
4737	 steps: training loss - 86571.24219	, testing loss - 352123.84375	
4738	 steps: training loss - 109708.72656	, testing loss - 351491.31250	
4739	 steps: training loss - 113186.36719	, testing loss - 351749.37500	
4740	 steps: training loss - 112760.07031	, testing loss - 351921.93750	
4741	 steps: training loss - 130274.25000	, testing loss - 352329.25000	
4742	 steps: training loss - 101217.73438	, testing loss - 352520.15625	
4743	 steps: training loss - 116591.32812	, testing loss - 351453.93750	
4744	 steps: training loss - 116297.14062	, testing loss - 350688.31250	
4745	 steps: training loss - 96807.87500	, testing loss - 349701.18750	
4746	 steps: training loss - 134145.67188	, testing loss - 349358.46875	
4747	 steps: training loss - 111445.26562	, testing loss - 349080.28125	
4748	 steps: training loss - 124079.32812	, testing loss - 348737.96875	
4749	 steps: training loss - 89097.43750	, testing loss - 348600.28125	
4750	 steps: training loss - 122368.77344	, testing loss - 348458.03125	
4751	 steps: training loss - 117550.69531	, testing loss - 347802.06250	
4752	 steps: training loss - 108947.36719	, testing loss - 347881.31250	
4753	 steps: training loss - 108723.41406	, testing loss - 348299.15625	
4754	 steps: training loss - 118278.21875	, testing loss - 347829.34375	
4755	 steps: training loss - 114895.10938	, testing loss - 347379.06250	
4756	 steps: training loss - 123659.53125	, testing loss - 347172.81250	
4757	 steps: training loss - 122244.46094	, testing loss - 347622.84375	
4758	 steps: training loss - 112149.29688	, testing loss - 347581.25000	
4759	 steps: training loss - 126285.39062	, testing loss - 347058.43750	
4760	 steps: training loss - 90360.96094	, testing loss - 346687.21875	
4761	 steps: training loss - 107144.40625	, testing loss - 346027.25000	
4762	 steps: training loss - 129348.89844	, testing loss - 345543.90625	
4763	 steps: training loss - 94202.00000	, testing loss - 345305.68750	
4764	 steps: training loss - 135863.23438	, testing loss - 344947.43750	
4765	 steps: training loss - 95493.46094	, testing loss - 344530.87500	
4766	 steps: training loss - 107025.03125	, testing loss - 345139.78125	
4767	 steps: training loss - 153703.20312	, testing loss - 346177.50000	
4768	 steps: training loss - 107970.70312	, testing loss - 347533.34375	
4769	 steps: training loss - 100568.03906	, testing loss - 349781.87500	
4770	 steps: training loss - 99000.34375	, testing loss - 351310.50000	
4771	 steps: training loss - 130249.17969	, testing loss - 352395.75000	
4772	 steps: training loss - 129692.50000	, testing loss - 353357.65625	
4773	 steps: training loss - 102190.35938	, testing loss - 354509.21875	
4774	 steps: training loss - 115965.53125	, testing loss - 356641.03125	
4775	 steps: training loss - 111191.57812	, testing loss - 358451.00000	
4776	 steps: training loss - 125829.34375	, testing loss - 360993.25000	
4777	 steps: training loss - 113594.10156	, testing loss - 364470.84375	
4778	 steps: training loss - 126625.16406	, testing loss - 366614.43750	
4779	 steps: training loss - 110972.88281	, testing loss - 368365.65625	
4780	 steps: training loss - 116980.73438	, testing loss - 369569.46875	
4781	 steps: training loss - 101268.21094	, testing loss - 368267.81250	
4782	 steps: training loss - 82966.54688	, testing loss - 365763.34375	
4783	 steps: training loss - 97858.44531	, testing loss - 363195.28125	
4784	 steps: training loss - 106555.89062	, testing loss - 360288.15625	
4785	 steps: training loss - 111071.38281	, testing loss - 357562.31250	
4786	 steps: training loss - 102856.44531	, testing loss - 355055.46875	
4787	 steps: training loss - 104566.52344	, testing loss - 353159.93750	
4788	 steps: training loss - 121772.60938	, testing loss - 351447.71875	
4789	 steps: training loss - 130417.12500	, testing loss - 349978.28125	
4790	 steps: training loss - 105338.09375	, testing loss - 348268.56250	
4791	 steps: training loss - 135709.60938	, testing loss - 347515.87500	
4792	 steps: training loss - 108873.39844	, testing loss - 347802.37500	
4793	 steps: training loss - 114562.65625	, testing loss - 348315.65625	
4794	 steps: training loss - 112636.67188	, testing loss - 348767.12500	
4795	 steps: training loss - 123300.59375	, testing loss - 349421.21875	
4796	 steps: training loss - 89497.26562	, testing loss - 350290.09375	
4797	 steps: training loss - 109587.92969	, testing loss - 350952.96875	
4798	 steps: training loss - 127195.34375	, testing loss - 351059.75000	
4799	 steps: training loss - 98858.78125	, testing loss - 350532.50000	
4800	 steps: training loss - 109444.71094	, testing loss - 350168.46875	
4801	 steps: training loss - 80783.84375	, testing loss - 349745.15625	
4802	 steps: training loss - 127143.03906	, testing loss - 348913.59375	
4803	 steps: training loss - 130150.25781	, testing loss - 348045.37500	
4804	 steps: training loss - 107915.28125	, testing loss - 346909.31250	
4805	 steps: training loss - 78622.16406	, testing loss - 346043.68750	
4806	 steps: training loss - 97377.18750	, testing loss - 345179.90625	
4807	 steps: training loss - 99331.15625	, testing loss - 344504.75000	
4808	 steps: training loss - 106653.96875	, testing loss - 344146.03125	
4809	 steps: training loss - 122852.29688	, testing loss - 344127.65625	
4810	 steps: training loss - 104576.89062	, testing loss - 344150.78125	
4811	 steps: training loss - 90600.28906	, testing loss - 344312.59375	
4812	 steps: training loss - 100830.92188	, testing loss - 345050.50000	
4813	 steps: training loss - 101144.48438	, testing loss - 346420.93750	
4814	 steps: training loss - 104535.03125	, testing loss - 347641.78125	
4815	 steps: training loss - 101220.67969	, testing loss - 348318.34375	
4816	 steps: training loss - 132954.73438	, testing loss - 348893.09375	
4817	 steps: training loss - 99781.48438	, testing loss - 349828.78125	
4818	 steps: training loss - 112603.49219	, testing loss - 350631.56250	
4819	 steps: training loss - 104762.00000	, testing loss - 352095.90625	
4820	 steps: training loss - 119237.17969	, testing loss - 353816.46875	
4821	 steps: training loss - 103178.49219	, testing loss - 355105.25000	
4822	 steps: training loss - 102990.43750	, testing loss - 356039.18750	
4823	 steps: training loss - 100830.39062	, testing loss - 358060.71875	
4824	 steps: training loss - 102059.37500	, testing loss - 359868.81250	
4825	 steps: training loss - 82415.26562	, testing loss - 360506.90625	
4826	 steps: training loss - 96627.25781	, testing loss - 360876.18750	
4827	 steps: training loss - 125806.10156	, testing loss - 361459.53125	
4828	 steps: training loss - 114699.94531	, testing loss - 362235.25000	
4829	 steps: training loss - 104564.92969	, testing loss - 362612.65625	
4830	 steps: training loss - 98316.85156	, testing loss - 361830.46875	
4831	 steps: training loss - 99791.12500	, testing loss - 361479.28125	
4832	 steps: training loss - 115464.82031	, testing loss - 362475.06250	
4833	 steps: training loss - 91222.32812	, testing loss - 365295.90625	
4834	 steps: training loss - 130269.50000	, testing loss - 369509.59375	
4835	 steps: training loss - 110797.53906	, testing loss - 372956.37500	
4836	 steps: training loss - 99618.71875	, testing loss - 374557.09375	
4837	 steps: training loss - 119968.11719	, testing loss - 375598.31250	
4838	 steps: training loss - 120993.78125	, testing loss - 376971.43750	
4839	 steps: training loss - 158732.37500	, testing loss - 378817.62500	
4840	 steps: training loss - 132714.46875	, testing loss - 378097.81250	
4841	 steps: training loss - 100190.03125	, testing loss - 374841.31250	
4842	 steps: training loss - 92098.13281	, testing loss - 371298.53125	
4843	 steps: training loss - 106722.31250	, testing loss - 366934.90625	
4844	 steps: training loss - 108831.13281	, testing loss - 363051.34375	
4845	 steps: training loss - 130246.26562	, testing loss - 360834.81250	
4846	 steps: training loss - 92582.35156	, testing loss - 358633.28125	
4847	 steps: training loss - 100018.51562	, testing loss - 357086.12500	
4848	 steps: training loss - 96971.81250	, testing loss - 355782.43750	
4849	 steps: training loss - 131622.00000	, testing loss - 354554.43750	
4850	 steps: training loss - 121608.39844	, testing loss - 353058.25000	
4851	 steps: training loss - 79542.94531	, testing loss - 353444.93750	
4852	 steps: training loss - 103190.32812	, testing loss - 353846.06250	
4853	 steps: training loss - 102036.01562	, testing loss - 354032.31250	
4854	 steps: training loss - 97622.34375	, testing loss - 353548.75000	
4855	 steps: training loss - 132771.07812	, testing loss - 354020.37500	
4856	 steps: training loss - 122565.08594	, testing loss - 354257.03125	
4857	 steps: training loss - 119742.55469	, testing loss - 355250.31250	
4858	 steps: training loss - 95386.19531	, testing loss - 356235.34375	
4859	 steps: training loss - 97797.68750	, testing loss - 356825.87500	
4860	 steps: training loss - 105131.47656	, testing loss - 357535.75000	
4861	 steps: training loss - 117656.94531	, testing loss - 358271.03125	
4862	 steps: training loss - 117112.84375	, testing loss - 357953.56250	
4863	 steps: training loss - 140880.70312	, testing loss - 357965.06250	
4864	 steps: training loss - 94865.30469	, testing loss - 356938.84375	
4865	 steps: training loss - 104840.06250	, testing loss - 355890.40625	
4866	 steps: training loss - 93657.98438	, testing loss - 354963.21875	
4867	 steps: training loss - 95612.08594	, testing loss - 354572.46875	
4868	 steps: training loss - 108614.64844	, testing loss - 354202.90625	
4869	 steps: training loss - 123460.35938	, testing loss - 353997.46875	
4870	 steps: training loss - 92466.21875	, testing loss - 353839.53125	
4871	 steps: training loss - 110953.36719	, testing loss - 354258.34375	
4872	 steps: training loss - 97850.88281	, testing loss - 354062.50000	
4873	 steps: training loss - 94189.79688	, testing loss - 353476.37500	
4874	 steps: training loss - 90326.89062	, testing loss - 353108.50000	
4875	 steps: training loss - 123491.04688	, testing loss - 352910.96875	
4876	 steps: training loss - 115958.35156	, testing loss - 353174.78125	
4877	 steps: training loss - 110062.98438	, testing loss - 354032.62500	
4878	 steps: training loss - 147395.00000	, testing loss - 355289.75000	
4879	 steps: training loss - 99364.21094	, testing loss - 355701.71875	
4880	 steps: training loss - 100629.75000	, testing loss - 355732.84375	
4881	 steps: training loss - 127221.07031	, testing loss - 356218.28125	
4882	 steps: training loss - 127019.84375	, testing loss - 355890.25000	
4883	 steps: training loss - 133159.87500	, testing loss - 355270.53125	
4884	 steps: training loss - 118973.08594	, testing loss - 354754.87500	
4885	 steps: training loss - 96584.55469	, testing loss - 354576.53125	
4886	 steps: training loss - 132326.17188	, testing loss - 354192.37500	
4887	 steps: training loss - 110594.89844	, testing loss - 353500.12500	
4888	 steps: training loss - 133058.23438	, testing loss - 352479.81250	
4889	 steps: training loss - 116958.05469	, testing loss - 351656.37500	
4890	 steps: training loss - 134709.35938	, testing loss - 351103.68750	
4891	 steps: training loss - 108682.82812	, testing loss - 351076.81250	
4892	 steps: training loss - 107482.07031	, testing loss - 350574.96875	
4893	 steps: training loss - 103325.24219	, testing loss - 350101.31250	
4894	 steps: training loss - 108720.59375	, testing loss - 349737.00000	
4895	 steps: training loss - 118883.64062	, testing loss - 348737.00000	
4896	 steps: training loss - 119901.50000	, testing loss - 348321.31250	
4897	 steps: training loss - 100951.83594	, testing loss - 348093.53125	
4898	 steps: training loss - 103362.03906	, testing loss - 348197.87500	
4899	 steps: training loss - 114996.95312	, testing loss - 348191.15625	
4900	 steps: training loss - 88243.76562	, testing loss - 348114.93750	
4901	 steps: training loss - 92349.55469	, testing loss - 347751.93750	
4902	 steps: training loss - 127856.99219	, testing loss - 347734.90625	
4903	 steps: training loss - 107741.96094	, testing loss - 348261.06250	
4904	 steps: training loss - 116666.63281	, testing loss - 348656.87500	
4905	 steps: training loss - 115947.55469	, testing loss - 349675.37500	
4906	 steps: training loss - 91182.30469	, testing loss - 350705.15625	
4907	 steps: training loss - 109262.10938	, testing loss - 351400.65625	
4908	 steps: training loss - 122284.52344	, testing loss - 351932.21875	
4909	 steps: training loss - 112608.75781	, testing loss - 351620.25000	
4910	 steps: training loss - 142671.90625	, testing loss - 351740.12500	
4911	 steps: training loss - 115843.14844	, testing loss - 352070.15625	
4912	 steps: training loss - 120975.25781	, testing loss - 353573.96875	
4913	 steps: training loss - 119984.51562	, testing loss - 354981.43750	
4914	 steps: training loss - 108280.08594	, testing loss - 356667.09375	
4915	 steps: training loss - 133912.92188	, testing loss - 357956.78125	
4916	 steps: training loss - 122881.03125	, testing loss - 358592.06250	
4917	 steps: training loss - 122376.83594	, testing loss - 358662.84375	
4918	 steps: training loss - 95581.60938	, testing loss - 357820.31250	
4919	 steps: training loss - 122906.74219	, testing loss - 356910.53125	
4920	 steps: training loss - 98595.71875	, testing loss - 355506.15625	
4921	 steps: training loss - 96751.71875	, testing loss - 354642.75000	
4922	 steps: training loss - 117589.10156	, testing loss - 353406.56250	
4923	 steps: training loss - 87555.91406	, testing loss - 353635.87500	
4924	 steps: training loss - 106422.23438	, testing loss - 353501.81250	
4925	 steps: training loss - 115512.79688	, testing loss - 352834.15625	
4926	 steps: training loss - 100585.95312	, testing loss - 352340.28125	
4927	 steps: training loss - 110545.21875	, testing loss - 352371.46875	
4928	 steps: training loss - 99913.60938	, testing loss - 353133.65625	
4929	 steps: training loss - 119574.13281	, testing loss - 354342.59375	
4930	 steps: training loss - 86985.76562	, testing loss - 356901.18750	
4931	 steps: training loss - 110161.74219	, testing loss - 359943.78125	
4932	 steps: training loss - 101241.01562	, testing loss - 362678.56250	
4933	 steps: training loss - 134080.29688	, testing loss - 364674.09375	
4934	 steps: training loss - 111040.97656	, testing loss - 365547.81250	
4935	 steps: training loss - 122619.76562	, testing loss - 365247.18750	
4936	 steps: training loss - 115054.03906	, testing loss - 363622.25000	
4937	 steps: training loss - 113546.88281	, testing loss - 362235.40625	
4938	 steps: training loss - 130262.31250	, testing loss - 361537.12500	
4939	 steps: training loss - 103741.57812	, testing loss - 360648.71875	
4940	 steps: training loss - 138546.68750	, testing loss - 359474.62500	
4941	 steps: training loss - 117661.77344	, testing loss - 357576.90625	
4942	 steps: training loss - 96102.39844	, testing loss - 355640.65625	
4943	 steps: training loss - 103200.07031	, testing loss - 353628.84375	
4944	 steps: training loss - 124062.54688	, testing loss - 351907.46875	
4945	 steps: training loss - 109919.17188	, testing loss - 350283.56250	
4946	 steps: training loss - 113080.35156	, testing loss - 349561.43750	
4947	 steps: training loss - 132069.51562	, testing loss - 348772.56250	
4948	 steps: training loss - 101021.15625	, testing loss - 348631.68750	
4949	 steps: training loss - 120928.73438	, testing loss - 349376.09375	
4950	 steps: training loss - 119334.85938	, testing loss - 351027.40625	
4951	 steps: training loss - 134503.28125	, testing loss - 353519.90625	
4952	 steps: training loss - 94959.23438	, testing loss - 356609.71875	
4953	 steps: training loss - 99613.75000	, testing loss - 360185.18750	
4954	 steps: training loss - 117941.83594	, testing loss - 364085.93750	
4955	 steps: training loss - 126206.57812	, testing loss - 367578.28125	
4956	 steps: training loss - 85708.71094	, testing loss - 368879.78125	
4957	 steps: training loss - 105519.24219	, testing loss - 369544.34375	
4958	 steps: training loss - 139883.32812	, testing loss - 369489.03125	
4959	 steps: training loss - 110314.03125	, testing loss - 368828.28125	
4960	 steps: training loss - 125101.38281	, testing loss - 368201.12500	
4961	 steps: training loss - 91725.06250	, testing loss - 366839.06250	
4962	 steps: training loss - 85502.17969	, testing loss - 365613.18750	
4963	 steps: training loss - 115276.31250	, testing loss - 364142.03125	
4964	 steps: training loss - 90328.48438	, testing loss - 361647.62500	
4965	 steps: training loss - 112194.78125	, testing loss - 360123.50000	
4966	 steps: training loss - 122640.38281	, testing loss - 358757.21875	
4967	 steps: training loss - 110632.71875	, testing loss - 356994.25000	
4968	 steps: training loss - 76255.33594	, testing loss - 355208.06250	
4969	 steps: training loss - 126940.92188	, testing loss - 353461.18750	
4970	 steps: training loss - 144176.50000	, testing loss - 351398.00000	
4971	 steps: training loss - 102657.05469	, testing loss - 350540.40625	
4972	 steps: training loss - 121536.57812	, testing loss - 350485.06250	
4973	 steps: training loss - 110875.44531	, testing loss - 351126.37500	
4974	 steps: training loss - 118434.83594	, testing loss - 352729.68750	
4975	 steps: training loss - 122201.51562	, testing loss - 353608.59375	
4976	 steps: training loss - 111847.78906	, testing loss - 354284.21875	
4977	 steps: training loss - 117826.03125	, testing loss - 355232.28125	
4978	 steps: training loss - 112253.00000	, testing loss - 356143.43750	
4979	 steps: training loss - 102405.32812	, testing loss - 356267.87500	
4980	 steps: training loss - 86710.14844	, testing loss - 355479.34375	
4981	 steps: training loss - 105309.53906	, testing loss - 354498.93750	
4982	 steps: training loss - 118383.29688	, testing loss - 354450.00000	
4983	 steps: training loss - 128146.25781	, testing loss - 355068.15625	
4984	 steps: training loss - 112767.11719	, testing loss - 356260.56250	
4985	 steps: training loss - 93001.31250	, testing loss - 358352.65625	
4986	 steps: training loss - 80949.13281	, testing loss - 360067.40625	
4987	 steps: training loss - 95854.25000	, testing loss - 360983.71875	
4988	 steps: training loss - 119624.76562	, testing loss - 360798.50000	
4989	 steps: training loss - 118053.09375	, testing loss - 360555.56250	
4990	 steps: training loss - 115045.33594	, testing loss - 359445.50000	
4991	 steps: training loss - 124780.32031	, testing loss - 357151.65625	
4992	 steps: training loss - 111367.21094	, testing loss - 354649.96875	
4993	 steps: training loss - 114912.00781	, testing loss - 352939.37500	
4994	 steps: training loss - 117820.14062	, testing loss - 352298.56250	
4995	 steps: training loss - 128814.22656	, testing loss - 351756.06250	
4996	 steps: training loss - 100577.35156	, testing loss - 351378.12500	
4997	 steps: training loss - 123660.88281	, testing loss - 351807.50000	
4998	 steps: training loss - 133223.62500	, testing loss - 353013.40625	
4999	 steps: training loss - 114690.74219	, testing loss - 355046.53125	
5000	 steps: training loss - 112223.67188	, testing loss - 356958.37500	
5001	 steps: training loss - 116541.05469	, testing loss - 358915.62500	
5002	 steps: training loss - 103101.56250	, testing loss - 360865.31250	
5003	 steps: training loss - 101888.92969	, testing loss - 363325.90625	
5004	 steps: training loss - 93969.30469	, testing loss - 365672.71875	
5005	 steps: training loss - 102234.34375	, testing loss - 367664.28125	
5006	 steps: training loss - 85676.07031	, testing loss - 368960.18750	
5007	 steps: training loss - 114953.85938	, testing loss - 368457.40625	
5008	 steps: training loss - 105537.95312	, testing loss - 366143.71875	
5009	 steps: training loss - 146368.67188	, testing loss - 365012.12500	
5010	 steps: training loss - 123922.84375	, testing loss - 363945.84375	
5011	 steps: training loss - 113725.74219	, testing loss - 362912.62500	
5012	 steps: training loss - 118391.03125	, testing loss - 361113.96875	
5013	 steps: training loss - 114976.66406	, testing loss - 359223.87500	
5014	 steps: training loss - 103910.34375	, testing loss - 357597.78125	
5015	 steps: training loss - 141303.96875	, testing loss - 356024.31250	
5016	 steps: training loss - 121134.94531	, testing loss - 354717.06250	
5017	 steps: training loss - 97543.00781	, testing loss - 352815.37500	
5018	 steps: training loss - 112531.82031	, testing loss - 350941.87500	
5019	 steps: training loss - 113901.91406	, testing loss - 349520.00000	
5020	 steps: training loss - 118668.69531	, testing loss - 348975.90625	
5021	 steps: training loss - 139178.92188	, testing loss - 348751.25000	
5022	 steps: training loss - 107159.69531	, testing loss - 348856.40625	
5023	 steps: training loss - 115546.42188	, testing loss - 349406.03125	
5024	 steps: training loss - 105741.48438	, testing loss - 349959.43750	
5025	 steps: training loss - 124636.36719	, testing loss - 350182.93750	
5026	 steps: training loss - 128264.51562	, testing loss - 350500.53125	
5027	 steps: training loss - 111889.07812	, testing loss - 351673.56250	
5028	 steps: training loss - 99418.78125	, testing loss - 352970.56250	
5029	 steps: training loss - 120237.27344	, testing loss - 353971.25000	
5030	 steps: training loss - 106494.25000	, testing loss - 355023.25000	
5031	 steps: training loss - 114177.84375	, testing loss - 356303.37500	
5032	 steps: training loss - 115103.09375	, testing loss - 356220.00000	
5033	 steps: training loss - 86877.49219	, testing loss - 355484.34375	
5034	 steps: training loss - 115370.21094	, testing loss - 354429.81250	
5035	 steps: training loss - 119216.53125	, testing loss - 353661.75000	
5036	 steps: training loss - 117793.64062	, testing loss - 353702.31250	
5037	 steps: training loss - 116806.98438	, testing loss - 354217.06250	
5038	 steps: training loss - 108468.37500	, testing loss - 354623.09375	
5039	 steps: training loss - 104745.96094	, testing loss - 355049.62500	
5040	 steps: training loss - 115249.00000	, testing loss - 354619.87500	
5041	 steps: training loss - 123099.62500	, testing loss - 353837.34375	
5042	 steps: training loss - 105961.32031	, testing loss - 352766.25000	
5043	 steps: training loss - 99288.75000	, testing loss - 351720.56250	
5044	 steps: training loss - 144666.06250	, testing loss - 351333.09375	
5045	 steps: training loss - 124270.98438	, testing loss - 350844.12500	
5046	 steps: training loss - 121427.14062	, testing loss - 350904.12500	
5047	 steps: training loss - 94850.28906	, testing loss - 351100.46875	
5048	 steps: training loss - 110924.46875	, testing loss - 351601.96875	
5049	 steps: training loss - 117847.72656	, testing loss - 352316.81250	
5050	 steps: training loss - 140170.76562	, testing loss - 353151.59375	
5051	 steps: training loss - 113949.96875	, testing loss - 354315.31250	
5052	 steps: training loss - 132925.51562	, testing loss - 355335.50000	
5053	 steps: training loss - 99472.78125	, testing loss - 356327.12500	
5054	 steps: training loss - 114103.05469	, testing loss - 356537.96875	
5055	 steps: training loss - 115604.72656	, testing loss - 356951.21875	
5056	 steps: training loss - 95302.39844	, testing loss - 357334.25000	
5057	 steps: training loss - 102081.33594	, testing loss - 357217.06250	
5058	 steps: training loss - 94071.68750	, testing loss - 357723.18750	
5059	 steps: training loss - 121686.92969	, testing loss - 358202.71875	
5060	 steps: training loss - 102444.66406	, testing loss - 357985.59375	
5061	 steps: training loss - 126181.13281	, testing loss - 358661.65625	
5062	 steps: training loss - 130377.53906	, testing loss - 359596.53125	
5063	 steps: training loss - 115518.93750	, testing loss - 360418.78125	
5064	 steps: training loss - 95305.82812	, testing loss - 360842.43750	
5065	 steps: training loss - 119809.44531	, testing loss - 361487.25000	
5066	 steps: training loss - 113880.85938	, testing loss - 361484.25000	
5067	 steps: training loss - 135137.60938	, testing loss - 360979.43750	
5068	 steps: training loss - 115064.56250	, testing loss - 360598.75000	
5069	 steps: training loss - 104844.96094	, testing loss - 359812.15625	
5070	 steps: training loss - 93387.58594	, testing loss - 359094.34375	
5071	 steps: training loss - 99548.34375	, testing loss - 357702.00000	
5072	 steps: training loss - 104407.96094	, testing loss - 356219.28125	
5073	 steps: training loss - 88467.20312	, testing loss - 354946.96875	
5074	 steps: training loss - 84742.27344	, testing loss - 353331.03125	
5075	 steps: training loss - 104490.64062	, testing loss - 352024.59375	
5076	 steps: training loss - 125026.81250	, testing loss - 351519.53125	
5077	 steps: training loss - 103710.00781	, testing loss - 351053.28125	
5078	 steps: training loss - 127103.53125	, testing loss - 350229.46875	
5079	 steps: training loss - 108992.88281	, testing loss - 349978.81250	
5080	 steps: training loss - 130079.07031	, testing loss - 349747.65625	
5081	 steps: training loss - 112867.21094	, testing loss - 349788.68750	
5082	 steps: training loss - 91112.74219	, testing loss - 349595.78125	
5083	 steps: training loss - 85481.45312	, testing loss - 349220.71875	
5084	 steps: training loss - 111900.23438	, testing loss - 349157.37500	
5085	 steps: training loss - 131451.34375	, testing loss - 349190.03125	
5086	 steps: training loss - 92467.35938	, testing loss - 349799.50000	
5087	 steps: training loss - 107494.53906	, testing loss - 351146.09375	
5088	 steps: training loss - 120236.05469	, testing loss - 352482.12500	
5089	 steps: training loss - 104371.56250	, testing loss - 354055.90625	
5090	 steps: training loss - 108452.17188	, testing loss - 355077.25000	
5091	 steps: training loss - 103355.92969	, testing loss - 356728.37500	
5092	 steps: training loss - 105571.04688	, testing loss - 357664.21875	
5093	 steps: training loss - 95227.32812	, testing loss - 359530.15625	
5094	 steps: training loss - 124994.37500	, testing loss - 360536.65625	
5095	 steps: training loss - 99794.34375	, testing loss - 360577.59375	
5096	 steps: training loss - 109597.57812	, testing loss - 360862.62500	
5097	 steps: training loss - 110853.53125	, testing loss - 361144.03125	
5098	 steps: training loss - 133707.53125	, testing loss - 361698.53125	
5099	 steps: training loss - 107395.17188	, testing loss - 362001.65625	
5100	 steps: training loss - 110779.89062	, testing loss - 361499.93750	
5101	 steps: training loss - 143393.32812	, testing loss - 360200.03125	
5102	 steps: training loss - 104073.96875	, testing loss - 357720.03125	
5103	 steps: training loss - 126258.64062	, testing loss - 354766.28125	
5104	 steps: training loss - 106432.57031	, testing loss - 352319.34375	
5105	 steps: training loss - 102984.16406	, testing loss - 351064.15625	
5106	 steps: training loss - 102894.07812	, testing loss - 350635.84375	
5107	 steps: training loss - 100348.40625	, testing loss - 350378.78125	
5108	 steps: training loss - 106990.74219	, testing loss - 350531.18750	
5109	 steps: training loss - 125769.60156	, testing loss - 351618.65625	
5110	 steps: training loss - 133391.75000	, testing loss - 353205.93750	
5111	 steps: training loss - 124764.16406	, testing loss - 354496.56250	
5112	 steps: training loss - 117976.82812	, testing loss - 355808.28125	
5113	 steps: training loss - 122594.94531	, testing loss - 356380.25000	
5114	 steps: training loss - 122013.07031	, testing loss - 356731.00000	
5115	 steps: training loss - 140209.82812	, testing loss - 356922.03125	
5116	 steps: training loss - 102364.76562	, testing loss - 357691.43750	
5117	 steps: training loss - 115819.03906	, testing loss - 358530.09375	
5118	 steps: training loss - 94513.06250	, testing loss - 359302.21875	
5119	 steps: training loss - 119508.07812	, testing loss - 360162.12500	
5120	 steps: training loss - 128023.00000	, testing loss - 359080.21875	
5121	 steps: training loss - 103591.25781	, testing loss - 357592.18750	
5122	 steps: training loss - 106539.37500	, testing loss - 356624.31250	
5123	 steps: training loss - 116259.10156	, testing loss - 356203.37500	
5124	 steps: training loss - 119158.23438	, testing loss - 356459.00000	
5125	 steps: training loss - 95786.25000	, testing loss - 357673.15625	
5126	 steps: training loss - 96186.41406	, testing loss - 359302.87500	
5127	 steps: training loss - 110686.03906	, testing loss - 360526.71875	
5128	 steps: training loss - 108751.03125	, testing loss - 361679.53125	
5129	 steps: training loss - 112627.30469	, testing loss - 362969.31250	
5130	 steps: training loss - 105092.28906	, testing loss - 364258.34375	
5131	 steps: training loss - 118205.28125	, testing loss - 365362.65625	
5132	 steps: training loss - 126499.93750	, testing loss - 367464.03125	
5133	 steps: training loss - 90697.87500	, testing loss - 368497.12500	
5134	 steps: training loss - 106850.33594	, testing loss - 368370.03125	
5135	 steps: training loss - 107864.02344	, testing loss - 368545.34375	
5136	 steps: training loss - 125505.22656	, testing loss - 367846.31250	
5137	 steps: training loss - 109079.72656	, testing loss - 368641.18750	
5138	 steps: training loss - 106984.65625	, testing loss - 370294.25000	
5139	 steps: training loss - 98404.94531	, testing loss - 372475.25000	
5140	 steps: training loss - 132672.64062	, testing loss - 374882.15625	
5141	 steps: training loss - 127842.74219	, testing loss - 376206.18750	
5142	 steps: training loss - 109396.61719	, testing loss - 376922.78125	
5143	 steps: training loss - 118608.38281	, testing loss - 377785.21875	
5144	 steps: training loss - 113452.60156	, testing loss - 379217.96875	
5145	 steps: training loss - 123568.59375	, testing loss - 378697.28125	
5146	 steps: training loss - 90486.18750	, testing loss - 377571.18750	
5147	 steps: training loss - 94319.32812	, testing loss - 375143.81250	
5148	 steps: training loss - 97747.20312	, testing loss - 372519.96875	
5149	 steps: training loss - 119411.84375	, testing loss - 369311.28125	
5150	 steps: training loss - 105774.91406	, testing loss - 365958.96875	
5151	 steps: training loss - 113876.72656	, testing loss - 363763.59375	
5152	 steps: training loss - 111399.73438	, testing loss - 362789.34375	
5153	 steps: training loss - 135144.85938	, testing loss - 361937.68750	
5154	 steps: training loss - 115166.44531	, testing loss - 360872.03125	
5155	 steps: training loss - 90038.23438	, testing loss - 359741.93750	
5156	 steps: training loss - 115016.98438	, testing loss - 359015.03125	
5157	 steps: training loss - 92078.70312	, testing loss - 358699.53125	
5158	 steps: training loss - 103261.89062	, testing loss - 358131.75000	
5159	 steps: training loss - 119773.00000	, testing loss - 358373.37500	
5160	 steps: training loss - 85945.83594	, testing loss - 358435.06250	
5161	 steps: training loss - 124853.36719	, testing loss - 357576.75000	
5162	 steps: training loss - 97506.38281	, testing loss - 355634.25000	
5163	 steps: training loss - 117614.13281	, testing loss - 353996.09375	
5164	 steps: training loss - 125812.40625	, testing loss - 352549.81250	
5165	 steps: training loss - 105636.67188	, testing loss - 351489.25000	
5166	 steps: training loss - 109484.37500	, testing loss - 351007.06250	
5167	 steps: training loss - 117191.27344	, testing loss - 351279.78125	
5168	 steps: training loss - 98739.07812	, testing loss - 351343.21875	
5169	 steps: training loss - 137668.48438	, testing loss - 351838.40625	
5170	 steps: training loss - 141248.06250	, testing loss - 352920.81250	
5171	 steps: training loss - 92491.59375	, testing loss - 354006.62500	
5172	 steps: training loss - 107359.02344	, testing loss - 354717.87500	
5173	 steps: training loss - 105699.49219	, testing loss - 355112.81250	
5174	 steps: training loss - 98235.71875	, testing loss - 354534.00000	
5175	 steps: training loss - 112822.68750	, testing loss - 353483.15625	
5176	 steps: training loss - 119263.42188	, testing loss - 352294.84375	
5177	 steps: training loss - 102454.92188	, testing loss - 350841.37500	
5178	 steps: training loss - 118339.89062	, testing loss - 349127.31250	
5179	 steps: training loss - 108435.08594	, testing loss - 348117.43750	
5180	 steps: training loss - 95928.89062	, testing loss - 347740.96875	
5181	 steps: training loss - 98695.37500	, testing loss - 347075.03125	
5182	 steps: training loss - 134429.57812	, testing loss - 346313.34375	
5183	 steps: training loss - 110366.41406	, testing loss - 346072.03125	
5184	 steps: training loss - 118226.75781	, testing loss - 346214.12500	
5185	 steps: training loss - 110783.25781	, testing loss - 346191.15625	
5186	 steps: training loss - 123187.66406	, testing loss - 346492.53125	
5187	 steps: training loss - 108239.65625	, testing loss - 348050.81250	
5188	 steps: training loss - 139279.03125	, testing loss - 349950.96875	
5189	 steps: training loss - 127598.77344	, testing loss - 352701.25000	
5190	 steps: training loss - 115375.21875	, testing loss - 356207.75000	
5191	 steps: training loss - 109421.53125	, testing loss - 359155.81250	
5192	 steps: training loss - 119006.78906	, testing loss - 360868.34375	
5193	 steps: training loss - 117284.64844	, testing loss - 363587.03125	
5194	 steps: training loss - 129904.76562	, testing loss - 367340.43750	
5195	 steps: training loss - 114635.84375	, testing loss - 370083.31250	
5196	 steps: training loss - 109252.26562	, testing loss - 371324.15625	
5197	 steps: training loss - 120550.19531	, testing loss - 369677.62500	
5198	 steps: training loss - 113793.32812	, testing loss - 366685.34375	
5199	 steps: training loss - 133988.06250	, testing loss - 363658.53125	
5200	 steps: training loss - 94211.15625	, testing loss - 361321.65625	
5201	 steps: training loss - 102533.52344	, testing loss - 359574.56250	
5202	 steps: training loss - 135020.79688	, testing loss - 358429.90625	
5203	 steps: training loss - 123896.06250	, testing loss - 356841.50000	
5204	 steps: training loss - 109745.91406	, testing loss - 355491.53125	
5205	 steps: training loss - 88819.21875	, testing loss - 354383.87500	
5206	 steps: training loss - 117268.71875	, testing loss - 352980.93750	
5207	 steps: training loss - 140836.82812	, testing loss - 352303.31250	
5208	 steps: training loss - 128284.03125	, testing loss - 351903.87500	
5209	 steps: training loss - 97903.29688	, testing loss - 351186.93750	
5210	 steps: training loss - 90747.23438	, testing loss - 350778.71875	
5211	 steps: training loss - 127288.90625	, testing loss - 350757.50000	
5212	 steps: training loss - 115027.60938	, testing loss - 351572.31250	
5213	 steps: training loss - 120461.64844	, testing loss - 352141.75000	
5214	 steps: training loss - 107789.10938	, testing loss - 352812.37500	
5215	 steps: training loss - 134213.07812	, testing loss - 353370.31250	
5216	 steps: training loss - 106566.94531	, testing loss - 354851.46875	
5217	 steps: training loss - 130297.35156	, testing loss - 356519.93750	
5218	 steps: training loss - 110598.67188	, testing loss - 356327.68750	
5219	 steps: training loss - 98393.54688	, testing loss - 356826.56250	
5220	 steps: training loss - 97353.63281	, testing loss - 357312.50000	
5221	 steps: training loss - 119070.66406	, testing loss - 357471.00000	
5222	 steps: training loss - 92526.33594	, testing loss - 356967.84375	
5223	 steps: training loss - 93626.11719	, testing loss - 356836.25000	
5224	 steps: training loss - 109765.46875	, testing loss - 357046.87500	
5225	 steps: training loss - 106821.63281	, testing loss - 357926.06250	
5226	 steps: training loss - 131515.89062	, testing loss - 359936.34375	
5227	 steps: training loss - 99229.50781	, testing loss - 363213.18750	
5228	 steps: training loss - 106800.89062	, testing loss - 365740.90625	
5229	 steps: training loss - 130848.69531	, testing loss - 367283.34375	
5230	 steps: training loss - 112116.54688	, testing loss - 368975.12500	
5231	 steps: training loss - 100791.68750	, testing loss - 370366.93750	
5232	 steps: training loss - 106649.03125	, testing loss - 371423.31250	
5233	 steps: training loss - 108112.59375	, testing loss - 373700.25000	
5234	 steps: training loss - 112435.89062	, testing loss - 375407.09375	
5235	 steps: training loss - 120937.22656	, testing loss - 375777.50000	
5236	 steps: training loss - 124226.67969	, testing loss - 374771.87500	
5237	 steps: training loss - 99128.39844	, testing loss - 373913.59375	
5238	 steps: training loss - 111950.60938	, testing loss - 372858.46875	
5239	 steps: training loss - 136335.31250	, testing loss - 371089.87500	
5240	 steps: training loss - 143497.37500	, testing loss - 369421.50000	
5241	 steps: training loss - 123812.18750	, testing loss - 367116.75000	
5242	 steps: training loss - 135728.73438	, testing loss - 364953.43750	
5243	 steps: training loss - 114477.14062	, testing loss - 361259.81250	
5244	 steps: training loss - 108127.64062	, testing loss - 356819.84375	
5245	 steps: training loss - 114988.04688	, testing loss - 352865.71875	
5246	 steps: training loss - 116797.88281	, testing loss - 351105.25000	
5247	 steps: training loss - 121512.39062	, testing loss - 350829.18750	
5248	 steps: training loss - 113032.59375	, testing loss - 351104.56250	
5249	 steps: training loss - 110064.55469	, testing loss - 351187.59375	
5250	 steps: training loss - 108224.06250	, testing loss - 350899.34375	
5251	 steps: training loss - 97970.90625	, testing loss - 351056.37500	
5252	 steps: training loss - 105522.25000	, testing loss - 351705.21875	
5253	 steps: training loss - 133453.07812	, testing loss - 352802.28125	
5254	 steps: training loss - 106771.35156	, testing loss - 354150.93750	
5255	 steps: training loss - 124433.85156	, testing loss - 354641.12500	
5256	 steps: training loss - 131740.87500	, testing loss - 354910.81250	
5257	 steps: training loss - 111854.45312	, testing loss - 354155.12500	
5258	 steps: training loss - 89694.49219	, testing loss - 353537.40625	
5259	 steps: training loss - 118144.67188	, testing loss - 352861.28125	
5260	 steps: training loss - 108849.16406	, testing loss - 352167.46875	
5261	 steps: training loss - 86797.77344	, testing loss - 350940.09375	
5262	 steps: training loss - 111566.40625	, testing loss - 349811.50000	
5263	 steps: training loss - 106762.03906	, testing loss - 349080.21875	
5264	 steps: training loss - 114226.00000	, testing loss - 348843.65625	
5265	 steps: training loss - 107603.33594	, testing loss - 349127.40625	
5266	 steps: training loss - 67039.19531	, testing loss - 349542.25000	
5267	 steps: training loss - 128815.64844	, testing loss - 349476.50000	
5268	 steps: training loss - 115950.57031	, testing loss - 349847.78125	
5269	 steps: training loss - 115317.43750	, testing loss - 350863.37500	
5270	 steps: training loss - 102546.19531	, testing loss - 352263.37500	
5271	 steps: training loss - 111429.22656	, testing loss - 354023.25000	
5272	 steps: training loss - 117183.89844	, testing loss - 355527.03125	
5273	 steps: training loss - 127826.96875	, testing loss - 356747.46875	
5274	 steps: training loss - 108660.00000	, testing loss - 356563.50000	
5275	 steps: training loss - 92378.29688	, testing loss - 356510.78125	
5276	 steps: training loss - 130523.68750	, testing loss - 356749.75000	
5277	 steps: training loss - 106937.94531	, testing loss - 356804.90625	
5278	 steps: training loss - 131479.48438	, testing loss - 356267.06250	
5279	 steps: training loss - 104620.75000	, testing loss - 356670.40625	
5280	 steps: training loss - 114578.45312	, testing loss - 357074.59375	
5281	 steps: training loss - 96717.99219	, testing loss - 357051.65625	
5282	 steps: training loss - 111064.03125	, testing loss - 356760.09375	
5283	 steps: training loss - 115005.18750	, testing loss - 355320.71875	
5284	 steps: training loss - 123611.10156	, testing loss - 354003.75000	
5285	 steps: training loss - 117376.51562	, testing loss - 352963.90625	
5286	 steps: training loss - 105692.00000	, testing loss - 352071.43750	
5287	 steps: training loss - 106953.39844	, testing loss - 351725.18750	
5288	 steps: training loss - 116447.92969	, testing loss - 351487.93750	
5289	 steps: training loss - 100649.74219	, testing loss - 352355.43750	
5290	 steps: training loss - 109477.96094	, testing loss - 353094.03125	
5291	 steps: training loss - 130768.69531	, testing loss - 353791.34375	
5292	 steps: training loss - 131138.68750	, testing loss - 355943.87500	
5293	 steps: training loss - 121762.59375	, testing loss - 358260.15625	
5294	 steps: training loss - 107461.16406	, testing loss - 359274.21875	
5295	 steps: training loss - 131123.40625	, testing loss - 359429.46875	
5296	 steps: training loss - 111288.90625	, testing loss - 359062.65625	
5297	 steps: training loss - 112529.03906	, testing loss - 357892.31250	
5298	 steps: training loss - 124518.44531	, testing loss - 356234.06250	
5299	 steps: training loss - 141112.81250	, testing loss - 355166.46875	
5300	 steps: training loss - 119804.60156	, testing loss - 354810.90625	
5301	 steps: training loss - 119171.90625	, testing loss - 355137.25000	
5302	 steps: training loss - 124703.35938	, testing loss - 354856.12500	
5303	 steps: training loss - 104530.05469	, testing loss - 354571.90625	
5304	 steps: training loss - 151244.43750	, testing loss - 355774.25000	
5305	 steps: training loss - 96196.28906	, testing loss - 357196.78125	
5306	 steps: training loss - 102536.26562	, testing loss - 357606.62500	
5307	 steps: training loss - 102626.76562	, testing loss - 357947.68750	
5308	 steps: training loss - 103057.93750	, testing loss - 358716.34375	
5309	 steps: training loss - 105900.76562	, testing loss - 358741.03125	
5310	 steps: training loss - 124863.08594	, testing loss - 358650.56250	
5311	 steps: training loss - 91275.48438	, testing loss - 358187.00000	
5312	 steps: training loss - 122039.38281	, testing loss - 357305.15625	
5313	 steps: training loss - 110231.96875	, testing loss - 356351.18750	
5314	 steps: training loss - 101598.36719	, testing loss - 355307.09375	
5315	 steps: training loss - 118199.20312	, testing loss - 354004.65625	
5316	 steps: training loss - 100319.32812	, testing loss - 352855.09375	
5317	 steps: training loss - 122458.35156	, testing loss - 351979.43750	
5318	 steps: training loss - 106673.28125	, testing loss - 351659.12500	
5319	 steps: training loss - 107293.75000	, testing loss - 352199.15625	
5320	 steps: training loss - 115752.93750	, testing loss - 352923.34375	
5321	 steps: training loss - 126365.52344	, testing loss - 353553.65625	
5322	 steps: training loss - 106793.06250	, testing loss - 354515.81250	
5323	 steps: training loss - 92563.59375	, testing loss - 355340.93750	
5324	 steps: training loss - 134718.03125	, testing loss - 356462.78125	
5325	 steps: training loss - 91311.79688	, testing loss - 357569.87500	
5326	 steps: training loss - 123108.36719	, testing loss - 358526.68750	
5327	 steps: training loss - 116325.37500	, testing loss - 360906.12500	
5328	 steps: training loss - 99603.64844	, testing loss - 363054.50000	
5329	 steps: training loss - 98187.04688	, testing loss - 363903.81250	
5330	 steps: training loss - 117804.85938	, testing loss - 363281.37500	
5331	 steps: training loss - 116419.36719	, testing loss - 361580.87500	
5332	 steps: training loss - 117771.45312	, testing loss - 359572.59375	
5333	 steps: training loss - 120918.41406	, testing loss - 356987.18750	
5334	 steps: training loss - 99905.68750	, testing loss - 355400.53125	
5335	 steps: training loss - 92933.16406	, testing loss - 355005.40625	
5336	 steps: training loss - 114684.87500	, testing loss - 354814.87500	
5337	 steps: training loss - 99893.48438	, testing loss - 355099.28125	
5338	 steps: training loss - 102707.62500	, testing loss - 355304.09375	
5339	 steps: training loss - 103302.28125	, testing loss - 355803.18750	
5340	 steps: training loss - 113603.96094	, testing loss - 356072.46875	
5341	 steps: training loss - 100056.03125	, testing loss - 356087.03125	
5342	 steps: training loss - 120080.82812	, testing loss - 355058.65625	
5343	 steps: training loss - 101638.67969	, testing loss - 353378.15625	
5344	 steps: training loss - 110591.15625	, testing loss - 352607.93750	
5345	 steps: training loss - 94867.85938	, testing loss - 352518.37500	
5346	 steps: training loss - 131806.23438	, testing loss - 352673.93750	
5347	 steps: training loss - 110166.11719	, testing loss - 352720.65625	
5348	 steps: training loss - 119785.35156	, testing loss - 352916.40625	
5349	 steps: training loss - 109197.21875	, testing loss - 353873.84375	
5350	 steps: training loss - 110067.60156	, testing loss - 355052.53125	
5351	 steps: training loss - 114562.77344	, testing loss - 357200.75000	
5352	 steps: training loss - 117224.01562	, testing loss - 359036.84375	
5353	 steps: training loss - 98005.83594	, testing loss - 360365.59375	
5354	 steps: training loss - 127490.55469	, testing loss - 361836.50000	
5355	 steps: training loss - 105822.99219	, testing loss - 363067.34375	
5356	 steps: training loss - 124951.85156	, testing loss - 364013.84375	
5357	 steps: training loss - 134036.90625	, testing loss - 365499.46875	
5358	 steps: training loss - 91412.99219	, testing loss - 366424.18750	
5359	 steps: training loss - 98113.55469	, testing loss - 366263.59375	
5360	 steps: training loss - 116728.50000	, testing loss - 365524.43750	
5361	 steps: training loss - 98622.75000	, testing loss - 364670.90625	
5362	 steps: training loss - 103973.18750	, testing loss - 364004.84375	
5363	 steps: training loss - 102068.58594	, testing loss - 363035.75000	
5364	 steps: training loss - 119435.42969	, testing loss - 361222.96875	
5365	 steps: training loss - 135805.43750	, testing loss - 359104.43750	
5366	 steps: training loss - 116918.17188	, testing loss - 358319.90625	
5367	 steps: training loss - 113776.57031	, testing loss - 357224.25000	
5368	 steps: training loss - 113800.40625	, testing loss - 356482.21875	
5369	 steps: training loss - 112896.69531	, testing loss - 357649.53125	
5370	 steps: training loss - 127310.65625	, testing loss - 358504.12500	
5371	 steps: training loss - 89214.28125	, testing loss - 359053.34375	
5372	 steps: training loss - 135550.54688	, testing loss - 359051.34375	
5373	 steps: training loss - 121863.65625	, testing loss - 358192.12500	
5374	 steps: training loss - 106646.21875	, testing loss - 356408.06250	
5375	 steps: training loss - 103492.34375	, testing loss - 355236.21875	
5376	 steps: training loss - 128073.48438	, testing loss - 355671.59375	
5377	 steps: training loss - 107413.28125	, testing loss - 356132.46875	
5378	 steps: training loss - 88952.92969	, testing loss - 356190.40625	
5379	 steps: training loss - 108602.74219	, testing loss - 356145.40625	
5380	 steps: training loss - 91522.76562	, testing loss - 356063.68750	
5381	 steps: training loss - 113788.27344	, testing loss - 355499.71875	
5382	 steps: training loss - 114276.70312	, testing loss - 353923.65625	
5383	 steps: training loss - 122250.28125	, testing loss - 352843.15625	
5384	 steps: training loss - 85360.43750	, testing loss - 351813.50000	
5385	 steps: training loss - 103913.82812	, testing loss - 350412.53125	
5386	 steps: training loss - 95406.58594	, testing loss - 349321.53125	
5387	 steps: training loss - 113560.66406	, testing loss - 348659.28125	
5388	 steps: training loss - 129880.91406	, testing loss - 347863.90625	
5389	 steps: training loss - 114950.64062	, testing loss - 347685.53125	
5390	 steps: training loss - 99895.39062	, testing loss - 347534.93750	
5391	 steps: training loss - 92145.89062	, testing loss - 346873.25000	
5392	 steps: training loss - 99318.11719	, testing loss - 346517.87500	
5393	 steps: training loss - 121808.92188	, testing loss - 346497.65625	
5394	 steps: training loss - 129591.28906	, testing loss - 346680.68750	
5395	 steps: training loss - 112559.51562	, testing loss - 346703.18750	
5396	 steps: training loss - 119999.42188	, testing loss - 346950.75000	
5397	 steps: training loss - 94193.17188	, testing loss - 347635.96875	
5398	 steps: training loss - 102037.23438	, testing loss - 349316.46875	
5399	 steps: training loss - 116588.40625	, testing loss - 350858.59375	
5400	 steps: training loss - 96170.75781	, testing loss - 351954.18750	
5401	 steps: training loss - 127011.32812	, testing loss - 352990.28125	
5402	 steps: training loss - 99443.78906	, testing loss - 353466.84375	
5403	 steps: training loss - 110793.74219	, testing loss - 354010.21875	
5404	 steps: training loss - 105928.05469	, testing loss - 353828.96875	
5405	 steps: training loss - 109855.82031	, testing loss - 352746.50000	
5406	 steps: training loss - 108562.89844	, testing loss - 352066.03125	
5407	 steps: training loss - 123319.99219	, testing loss - 352081.53125	
5408	 steps: training loss - 80532.21094	, testing loss - 351603.71875	
5409	 steps: training loss - 92201.96094	, testing loss - 351217.68750	
5410	 steps: training loss - 130214.17188	, testing loss - 351020.81250	
5411	 steps: training loss - 93866.29688	, testing loss - 351108.50000	
5412	 steps: training loss - 111490.57812	, testing loss - 350787.12500	
5413	 steps: training loss - 110481.13281	, testing loss - 349792.50000	
5414	 steps: training loss - 109309.49219	, testing loss - 348919.81250	
5415	 steps: training loss - 115418.00781	, testing loss - 347881.59375	
5416	 steps: training loss - 101872.52344	, testing loss - 347192.75000	
5417	 steps: training loss - 104275.26562	, testing loss - 346823.12500	
5418	 steps: training loss - 135313.46875	, testing loss - 346595.59375	
5419	 steps: training loss - 128202.75781	, testing loss - 346616.65625	
5420	 steps: training loss - 130506.35938	, testing loss - 347570.71875	
5421	 steps: training loss - 125077.34375	, testing loss - 349375.03125	
5422	 steps: training loss - 93342.18750	, testing loss - 350946.87500	
5423	 steps: training loss - 106853.95312	, testing loss - 351695.68750	
5424	 steps: training loss - 104908.39844	, testing loss - 351966.71875	
5425	 steps: training loss - 107787.46094	, testing loss - 352339.34375	
5426	 steps: training loss - 108877.65625	, testing loss - 353322.03125	
5427	 steps: training loss - 112779.19531	, testing loss - 354478.71875	
5428	 steps: training loss - 99395.82812	, testing loss - 355390.28125	
5429	 steps: training loss - 108562.63281	, testing loss - 355564.37500	
5430	 steps: training loss - 115460.56250	, testing loss - 355790.78125	
5431	 steps: training loss - 112060.32812	, testing loss - 356571.00000	
5432	 steps: training loss - 127535.99219	, testing loss - 358151.03125	
5433	 steps: training loss - 113938.96875	, testing loss - 360436.12500	
5434	 steps: training loss - 106447.22656	, testing loss - 364114.62500	
5435	 steps: training loss - 98525.30469	, testing loss - 367749.12500	
5436	 steps: training loss - 107911.15625	, testing loss - 370224.43750	
5437	 steps: training loss - 110117.92188	, testing loss - 371922.68750	
5438	 steps: training loss - 76763.57812	, testing loss - 372214.18750	
5439	 steps: training loss - 101484.12500	, testing loss - 372081.78125	
5440	 steps: training loss - 132896.00000	, testing loss - 371755.68750	
5441	 steps: training loss - 100613.65625	, testing loss - 371188.50000	
5442	 steps: training loss - 100083.56250	, testing loss - 368943.78125	
5443	 steps: training loss - 112553.93750	, testing loss - 365547.65625	
5444	 steps: training loss - 108764.03125	, testing loss - 361629.87500	
5445	 steps: training loss - 106685.28906	, testing loss - 358878.65625	
5446	 steps: training loss - 117622.60938	, testing loss - 356879.68750	
5447	 steps: training loss - 120541.53125	, testing loss - 356056.06250	
5448	 steps: training loss - 127857.24219	, testing loss - 355491.62500	
5449	 steps: training loss - 137777.79688	, testing loss - 355536.00000	
5450	 steps: training loss - 105466.64062	, testing loss - 356681.43750	
5451	 steps: training loss - 132551.65625	, testing loss - 358498.00000	
5452	 steps: training loss - 100673.45312	, testing loss - 360233.65625	
5453	 steps: training loss - 115161.03125	, testing loss - 361818.93750	
5454	 steps: training loss - 114216.24219	, testing loss - 362851.81250	
5455	 steps: training loss - 121924.68750	, testing loss - 363798.15625	
5456	 steps: training loss - 120088.93750	, testing loss - 364181.87500	
5457	 steps: training loss - 136492.06250	, testing loss - 363950.06250	
5458	 steps: training loss - 110670.49219	, testing loss - 362832.65625	
5459	 steps: training loss - 94125.28125	, testing loss - 360936.56250	
5460	 steps: training loss - 112177.17969	, testing loss - 358846.59375	
5461	 steps: training loss - 113130.27344	, testing loss - 357351.53125	
5462	 steps: training loss - 99175.27344	, testing loss - 357232.21875	
5463	 steps: training loss - 117178.27344	, testing loss - 357940.06250	
5464	 steps: training loss - 113690.99219	, testing loss - 359624.50000	
5465	 steps: training loss - 107157.08594	, testing loss - 361502.59375	
5466	 steps: training loss - 127912.11719	, testing loss - 362234.18750	
5467	 steps: training loss - 109038.17188	, testing loss - 361582.40625	
5468	 steps: training loss - 135137.12500	, testing loss - 361142.78125	
5469	 steps: training loss - 115831.63281	, testing loss - 360838.25000	
5470	 steps: training loss - 101037.59375	, testing loss - 360154.18750	
5471	 steps: training loss - 105361.07031	, testing loss - 359687.06250	
5472	 steps: training loss - 128709.49219	, testing loss - 358646.09375	
5473	 steps: training loss - 98729.43750	, testing loss - 357484.28125	
5474	 steps: training loss - 141020.43750	, testing loss - 356878.56250	
5475	 steps: training loss - 102474.84375	, testing loss - 356672.15625	
5476	 steps: training loss - 115832.31250	, testing loss - 356436.62500	
5477	 steps: training loss - 110704.87500	, testing loss - 355895.50000	
5478	 steps: training loss - 98209.07812	, testing loss - 355746.46875	
5479	 steps: training loss - 106669.99219	, testing loss - 355289.78125	
5480	 steps: training loss - 86021.67969	, testing loss - 354319.53125	
5481	 steps: training loss - 94968.46094	, testing loss - 353066.59375	
5482	 steps: training loss - 102485.88281	, testing loss - 352792.37500	
5483	 steps: training loss - 100737.51562	, testing loss - 353614.96875	
5484	 steps: training loss - 111025.43750	, testing loss - 354767.43750	
5485	 steps: training loss - 110690.28906	, testing loss - 355955.28125	
5486	 steps: training loss - 124150.49219	, testing loss - 357422.06250	
5487	 steps: training loss - 122594.00781	, testing loss - 358557.46875	
5488	 steps: training loss - 114960.86719	, testing loss - 359100.84375	
5489	 steps: training loss - 100178.72656	, testing loss - 358888.43750	
5490	 steps: training loss - 109016.97656	, testing loss - 357752.12500	
5491	 steps: training loss - 115981.47656	, testing loss - 355903.12500	
5492	 steps: training loss - 110751.96875	, testing loss - 353680.90625	
5493	 steps: training loss - 131478.71875	, testing loss - 351615.25000	
5494	 steps: training loss - 117069.63281	, testing loss - 350146.12500	
5495	 steps: training loss - 103466.84375	, testing loss - 349564.46875	
5496	 steps: training loss - 112045.85156	, testing loss - 349303.21875	
5497	 steps: training loss - 120277.32812	, testing loss - 349317.46875	
5498	 steps: training loss - 132216.12500	, testing loss - 349677.37500	
5499	 steps: training loss - 102976.98438	, testing loss - 350722.53125	
5500	 steps: training loss - 123854.77344	, testing loss - 352724.37500	
5501	 steps: training loss - 102392.40625	, testing loss - 354868.75000	
5502	 steps: training loss - 114390.09375	, testing loss - 357175.12500	
5503	 steps: training loss - 114006.49219	, testing loss - 359471.90625	
5504	 steps: training loss - 109538.90625	, testing loss - 362326.06250	
5505	 steps: training loss - 105616.75000	, testing loss - 364915.90625	
5506	 steps: training loss - 99103.82812	, testing loss - 367293.00000	
5507	 steps: training loss - 138336.73438	, testing loss - 368708.96875	
5508	 steps: training loss - 128521.89844	, testing loss - 370052.00000	
5509	 steps: training loss - 106560.32812	, testing loss - 372142.68750	
5510	 steps: training loss - 89636.29688	, testing loss - 372309.15625	
5511	 steps: training loss - 125138.73438	, testing loss - 370841.75000	
5512	 steps: training loss - 99324.02344	, testing loss - 368065.81250	
5513	 steps: training loss - 99661.82031	, testing loss - 365317.21875	
5514	 steps: training loss - 105407.95312	, testing loss - 363906.53125	
5515	 steps: training loss - 106814.40625	, testing loss - 362641.84375	
5516	 steps: training loss - 117518.06250	, testing loss - 360713.25000	
5517	 steps: training loss - 111457.14062	, testing loss - 358845.34375	
5518	 steps: training loss - 145237.87500	, testing loss - 357587.31250	
5519	 steps: training loss - 100815.13281	, testing loss - 357073.06250	
5520	 steps: training loss - 119370.35156	, testing loss - 356019.00000	
5521	 steps: training loss - 133272.39062	, testing loss - 355672.25000	
5522	 steps: training loss - 104131.58594	, testing loss - 356484.81250	
5523	 steps: training loss - 100213.60938	, testing loss - 357638.28125	
5524	 steps: training loss - 130387.25000	, testing loss - 358754.62500	
5525	 steps: training loss - 92587.89844	, testing loss - 360315.15625	
5526	 steps: training loss - 113794.28906	, testing loss - 361622.37500	
5527	 steps: training loss - 112266.84375	, testing loss - 362871.65625	
5528	 steps: training loss - 148920.73438	, testing loss - 363685.59375	
5529	 steps: training loss - 98794.82031	, testing loss - 363984.81250	
5530	 steps: training loss - 105625.39062	, testing loss - 364088.43750	
5531	 steps: training loss - 129835.58594	, testing loss - 363549.96875	
5532	 steps: training loss - 92754.05469	, testing loss - 363818.00000	
5533	 steps: training loss - 101728.21094	, testing loss - 364945.31250	
5534	 steps: training loss - 101890.62500	, testing loss - 366393.87500	
5535	 steps: training loss - 130917.36719	, testing loss - 366837.50000	
5536	 steps: training loss - 92639.79688	, testing loss - 366229.34375	
5537	 steps: training loss - 118232.06250	, testing loss - 364982.00000	
5538	 steps: training loss - 91536.85938	, testing loss - 363099.34375	
5539	 steps: training loss - 124916.38281	, testing loss - 361487.34375	
5540	 steps: training loss - 104898.19531	, testing loss - 360473.21875	
5541	 steps: training loss - 117243.84375	, testing loss - 359155.40625	
5542	 steps: training loss - 123433.45312	, testing loss - 357642.09375	
5543	 steps: training loss - 122015.82031	, testing loss - 355494.00000	
5544	 steps: training loss - 107174.87500	, testing loss - 353530.09375	
5545	 steps: training loss - 108830.24219	, testing loss - 352526.78125	
5546	 steps: training loss - 110275.85938	, testing loss - 352039.71875	
5547	 steps: training loss - 120523.12500	, testing loss - 352172.71875	
5548	 steps: training loss - 103151.26562	, testing loss - 352409.18750	
5549	 steps: training loss - 85902.14844	, testing loss - 352852.18750	
5550	 steps: training loss - 134273.92188	, testing loss - 353133.53125	
5551	 steps: training loss - 112042.17188	, testing loss - 353711.12500	
5552	 steps: training loss - 108989.39844	, testing loss - 355261.21875	
5553	 steps: training loss - 112450.82812	, testing loss - 355800.93750	
5554	 steps: training loss - 113542.41406	, testing loss - 356064.50000	
5555	 steps: training loss - 103872.32812	, testing loss - 356358.25000	
5556	 steps: training loss - 121160.62500	, testing loss - 357116.90625	
5557	 steps: training loss - 108851.27344	, testing loss - 357329.50000	
5558	 steps: training loss - 103665.25000	, testing loss - 356999.50000	
5559	 steps: training loss - 135533.67188	, testing loss - 355919.96875	
5560	 steps: training loss - 108858.71094	, testing loss - 355100.81250	
5561	 steps: training loss - 93729.12500	, testing loss - 354992.65625	
5562	 steps: training loss - 91712.59375	, testing loss - 354716.93750	
5563	 steps: training loss - 121113.21094	, testing loss - 355082.46875	
5564	 steps: training loss - 94929.65625	, testing loss - 354706.25000	
5565	 steps: training loss - 136618.87500	, testing loss - 354191.43750	
5566	 steps: training loss - 93168.71094	, testing loss - 353391.50000	
5567	 steps: training loss - 89784.05469	, testing loss - 353744.75000	
5568	 steps: training loss - 144857.93750	, testing loss - 354739.03125	
5569	 steps: training loss - 105714.36719	, testing loss - 356902.62500	
5570	 steps: training loss - 114983.96094	, testing loss - 358675.84375	
5571	 steps: training loss - 115410.21094	, testing loss - 360348.81250	
5572	 steps: training loss - 117926.07812	, testing loss - 360786.81250	
5573	 steps: training loss - 122678.26562	, testing loss - 360314.12500	
5574	 steps: training loss - 88447.63281	, testing loss - 358699.87500	
5575	 steps: training loss - 107408.76562	, testing loss - 357007.68750	
5576	 steps: training loss - 120491.79688	, testing loss - 354895.37500	
5577	 steps: training loss - 112055.14844	, testing loss - 353229.12500	
5578	 steps: training loss - 89808.22656	, testing loss - 351567.06250	
5579	 steps: training loss - 125088.94531	, testing loss - 350076.68750	
5580	 steps: training loss - 97685.51562	, testing loss - 348309.25000	
5581	 steps: training loss - 112806.34375	, testing loss - 347326.93750	
5582	 steps: training loss - 115157.64062	, testing loss - 347374.40625	
5583	 steps: training loss - 123568.05469	, testing loss - 347247.46875	
5584	 steps: training loss - 104165.71094	, testing loss - 347435.06250	
5585	 steps: training loss - 87806.32812	, testing loss - 347869.96875	
5586	 steps: training loss - 116007.95312	, testing loss - 348441.09375	
5587	 steps: training loss - 93796.50000	, testing loss - 349204.34375	
5588	 steps: training loss - 100939.70312	, testing loss - 350379.46875	
5589	 steps: training loss - 99179.10156	, testing loss - 351710.87500	
5590	 steps: training loss - 131103.45312	, testing loss - 352375.75000	
5591	 steps: training loss - 107777.51562	, testing loss - 352600.28125	
5592	 steps: training loss - 117440.93750	, testing loss - 352286.90625	
5593	 steps: training loss - 115274.47656	, testing loss - 351875.96875	
5594	 steps: training loss - 107838.41406	, testing loss - 351384.87500	
5595	 steps: training loss - 88365.21094	, testing loss - 350966.75000	
5596	 steps: training loss - 123660.00000	, testing loss - 350481.93750	
5597	 steps: training loss - 118242.29688	, testing loss - 350950.59375	
5598	 steps: training loss - 101257.20312	, testing loss - 351747.46875	
5599	 steps: training loss - 133692.18750	, testing loss - 352150.84375	
5600	 steps: training loss - 115285.75781	, testing loss - 353971.56250	
5601	 steps: training loss - 105887.56250	, testing loss - 356069.21875	
5602	 steps: training loss - 110209.79688	, testing loss - 357615.43750	
5603	 steps: training loss - 104998.67188	, testing loss - 359930.84375	
5604	 steps: training loss - 125383.72656	, testing loss - 362028.25000	
5605	 steps: training loss - 98863.12500	, testing loss - 364342.06250	
5606	 steps: training loss - 110985.45312	, testing loss - 365071.78125	
5607	 steps: training loss - 118957.96875	, testing loss - 365109.87500	
5608	 steps: training loss - 99174.31250	, testing loss - 365320.37500	
5609	 steps: training loss - 104011.53125	, testing loss - 365210.43750	
5610	 steps: training loss - 97960.70312	, testing loss - 365054.12500	
5611	 steps: training loss - 106307.61719	, testing loss - 364520.75000	
5612	 steps: training loss - 93836.34375	, testing loss - 363494.03125	
5613	 steps: training loss - 91925.71875	, testing loss - 362563.03125	
5614	 steps: training loss - 92732.28125	, testing loss - 360902.12500	
5615	 steps: training loss - 106181.02344	, testing loss - 360183.34375	
5616	 steps: training loss - 112957.57031	, testing loss - 358868.56250	
5617	 steps: training loss - 113263.30469	, testing loss - 357667.31250	
5618	 steps: training loss - 120049.95312	, testing loss - 356340.75000	
5619	 steps: training loss - 93489.27344	, testing loss - 354585.68750	
5620	 steps: training loss - 96640.78125	, testing loss - 352728.31250	
5621	 steps: training loss - 82087.67969	, testing loss - 350732.62500	
5622	 steps: training loss - 105978.23438	, testing loss - 349672.50000	
5623	 steps: training loss - 99287.73438	, testing loss - 349097.09375	
5624	 steps: training loss - 105845.07031	, testing loss - 348592.03125	
5625	 steps: training loss - 126315.07031	, testing loss - 348699.28125	
5626	 steps: training loss - 89125.38281	, testing loss - 349006.81250	
5627	 steps: training loss - 103459.25000	, testing loss - 349454.21875	
5628	 steps: training loss - 132585.09375	, testing loss - 350097.78125	
5629	 steps: training loss - 120758.89062	, testing loss - 349990.78125	
5630	 steps: training loss - 110578.87500	, testing loss - 350098.68750	
5631	 steps: training loss - 120780.74219	, testing loss - 350655.65625	
5632	 steps: training loss - 100318.92188	, testing loss - 351012.40625	
5633	 steps: training loss - 102828.46094	, testing loss - 351593.28125	
5634	 steps: training loss - 129379.87500	, testing loss - 352143.65625	
5635	 steps: training loss - 99040.92188	, testing loss - 351881.09375	
5636	 steps: training loss - 81206.63281	, testing loss - 351595.75000	
5637	 steps: training loss - 76559.73438	, testing loss - 351595.37500	
5638	 steps: training loss - 128160.78906	, testing loss - 351770.50000	
5639	 steps: training loss - 118309.50000	, testing loss - 351696.21875	
5640	 steps: training loss - 113379.51562	, testing loss - 351472.90625	
5641	 steps: training loss - 103072.30469	, testing loss - 350638.46875	
5642	 steps: training loss - 122552.25000	, testing loss - 349121.53125	
5643	 steps: training loss - 106868.07812	, testing loss - 347463.18750	
5644	 steps: training loss - 100380.71875	, testing loss - 346352.50000	
5645	 steps: training loss - 132163.45312	, testing loss - 346202.84375	
5646	 steps: training loss - 110035.86719	, testing loss - 346461.50000	
5647	 steps: training loss - 125930.39844	, testing loss - 347660.90625	
5648	 steps: training loss - 99927.78125	, testing loss - 350211.18750	
5649	 steps: training loss - 117182.25000	, testing loss - 352991.21875	
5650	 steps: training loss - 111574.89062	, testing loss - 354802.93750	
5651	 steps: training loss - 121521.64844	, testing loss - 356226.75000	
5652	 steps: training loss - 127748.20312	, testing loss - 358790.06250	
5653	 steps: training loss - 106954.70312	, testing loss - 360980.12500	
5654	 steps: training loss - 112426.45312	, testing loss - 362751.12500	
5655	 steps: training loss - 114195.28125	, testing loss - 364814.18750	
5656	 steps: training loss - 112565.57031	, testing loss - 366480.68750	
5657	 steps: training loss - 119792.25781	, testing loss - 367615.93750	
5658	 steps: training loss - 106934.73438	, testing loss - 368159.31250	
5659	 steps: training loss - 133947.45312	, testing loss - 367316.59375	
5660	 steps: training loss - 102484.15625	, testing loss - 365525.62500	
5661	 steps: training loss - 164025.78125	, testing loss - 364040.87500	
5662	 steps: training loss - 109433.82812	, testing loss - 361313.90625	
5663	 steps: training loss - 106192.93750	, testing loss - 358424.12500	
5664	 steps: training loss - 147114.09375	, testing loss - 355143.43750	
5665	 steps: training loss - 128005.95312	, testing loss - 352092.18750	
5666	 steps: training loss - 93820.45312	, testing loss - 350229.84375	
5667	 steps: training loss - 88701.82812	, testing loss - 348144.81250	
5668	 steps: training loss - 103115.58594	, testing loss - 346668.68750	
5669	 steps: training loss - 135895.54688	, testing loss - 345490.56250	
5670	 steps: training loss - 123251.90625	, testing loss - 345517.87500	
5671	 steps: training loss - 114339.24219	, testing loss - 346164.56250	
5672	 steps: training loss - 114267.39844	, testing loss - 347247.43750	
5673	 steps: training loss - 100275.35938	, testing loss - 348743.93750	
5674	 steps: training loss - 108648.97656	, testing loss - 350752.75000	
5675	 steps: training loss - 121254.46875	, testing loss - 352716.93750	
5676	 steps: training loss - 117161.38281	, testing loss - 354132.65625	
5677	 steps: training loss - 105279.03906	, testing loss - 354817.34375	
5678	 steps: training loss - 125990.58594	, testing loss - 354454.00000	
5679	 steps: training loss - 96794.71094	, testing loss - 353818.31250	
5680	 steps: training loss - 120907.70312	, testing loss - 353385.68750	
5681	 steps: training loss - 117784.39844	, testing loss - 352882.21875	
5682	 steps: training loss - 118299.32812	, testing loss - 353297.37500	
5683	 steps: training loss - 107584.08594	, testing loss - 353301.65625	
5684	 steps: training loss - 108456.97656	, testing loss - 353432.65625	
5685	 steps: training loss - 134611.48438	, testing loss - 354373.43750	
5686	 steps: training loss - 106692.10938	, testing loss - 355718.18750	
5687	 steps: training loss - 117652.69531	, testing loss - 356467.50000	
5688	 steps: training loss - 99802.93750	, testing loss - 356445.43750	
5689	 steps: training loss - 110231.73438	, testing loss - 355720.56250	
5690	 steps: training loss - 123929.46094	, testing loss - 355129.84375	
5691	 steps: training loss - 105937.65625	, testing loss - 355127.84375	
5692	 steps: training loss - 112219.61719	, testing loss - 354647.28125	
5693	 steps: training loss - 110842.60938	, testing loss - 353806.43750	
5694	 steps: training loss - 117675.39062	, testing loss - 352577.78125	
5695	 steps: training loss - 102842.39844	, testing loss - 352041.50000	
5696	 steps: training loss - 140549.39062	, testing loss - 352625.15625	
5697	 steps: training loss - 113955.83594	, testing loss - 354437.40625	
5698	 steps: training loss - 121084.65625	, testing loss - 356375.15625	
5699	 steps: training loss - 129102.85156	, testing loss - 357040.84375	
5700	 steps: training loss - 95857.75000	, testing loss - 357351.53125	
5701	 steps: training loss - 106413.07031	, testing loss - 357640.93750	
5702	 steps: training loss - 100872.71094	, testing loss - 357481.62500	
5703	 steps: training loss - 109945.03906	, testing loss - 356336.03125	
5704	 steps: training loss - 109812.33594	, testing loss - 355344.00000	
5705	 steps: training loss - 118969.91406	, testing loss - 354278.25000	
5706	 steps: training loss - 110754.12500	, testing loss - 353344.96875	
5707	 steps: training loss - 118160.84375	, testing loss - 352739.21875	
5708	 steps: training loss - 92042.84375	, testing loss - 353149.87500	
5709	 steps: training loss - 115271.65625	, testing loss - 353283.81250	
5710	 steps: training loss - 96501.17969	, testing loss - 352890.21875	
5711	 steps: training loss - 114853.64062	, testing loss - 352016.12500	
5712	 steps: training loss - 101378.12500	, testing loss - 351066.43750	
5713	 steps: training loss - 94612.64844	, testing loss - 350216.37500	
5714	 steps: training loss - 110930.07031	, testing loss - 349286.18750	
5715	 steps: training loss - 96118.95312	, testing loss - 348110.15625	
5716	 steps: training loss - 109665.39062	, testing loss - 346717.28125	
5717	 steps: training loss - 127036.37500	, testing loss - 345697.78125	
5718	 steps: training loss - 98808.42188	, testing loss - 345112.53125	
5719	 steps: training loss - 118056.19531	, testing loss - 345214.09375	
5720	 steps: training loss - 110494.87500	, testing loss - 346128.37500	
5721	 steps: training loss - 111304.46875	, testing loss - 346912.90625	
5722	 steps: training loss - 117297.55469	, testing loss - 347846.28125	
5723	 steps: training loss - 102237.50000	, testing loss - 348773.09375	
5724	 steps: training loss - 123801.44531	, testing loss - 349771.59375	
5725	 steps: training loss - 115744.87500	, testing loss - 350445.93750	
5726	 steps: training loss - 104923.14062	, testing loss - 350683.34375	
5727	 steps: training loss - 127428.89062	, testing loss - 350536.84375	
5728	 steps: training loss - 116729.14844	, testing loss - 350922.15625	
5729	 steps: training loss - 120798.67188	, testing loss - 351490.34375	
5730	 steps: training loss - 126791.32812	, testing loss - 351723.37500	
5731	 steps: training loss - 97397.32812	, testing loss - 352838.50000	
5732	 steps: training loss - 121974.36719	, testing loss - 353837.28125	
5733	 steps: training loss - 122710.21875	, testing loss - 354568.37500	
5734	 steps: training loss - 112419.84375	, testing loss - 354198.06250	
5735	 steps: training loss - 115287.13281	, testing loss - 352847.25000	
5736	 steps: training loss - 125290.92969	, testing loss - 351384.90625	
5737	 steps: training loss - 111108.14062	, testing loss - 350023.50000	
5738	 steps: training loss - 131413.57812	, testing loss - 348861.50000	
5739	 steps: training loss - 98092.28125	, testing loss - 348172.56250	
5740	 steps: training loss - 77844.32812	, testing loss - 347567.43750	
5741	 steps: training loss - 106192.10938	, testing loss - 346818.84375	
5742	 steps: training loss - 131838.31250	, testing loss - 346305.25000	
5743	 steps: training loss - 123688.31250	, testing loss - 346106.71875	
5744	 steps: training loss - 110150.28906	, testing loss - 345879.78125	
5745	 steps: training loss - 120440.29688	, testing loss - 345462.28125	
5746	 steps: training loss - 110965.92188	, testing loss - 346050.75000	
5747	 steps: training loss - 109583.57031	, testing loss - 346536.06250	
5748	 steps: training loss - 98752.66406	, testing loss - 346879.09375	
5749	 steps: training loss - 114136.26562	, testing loss - 347668.21875	
5750	 steps: training loss - 102731.21875	, testing loss - 349021.25000	
5751	 steps: training loss - 92827.39062	, testing loss - 350125.28125	
5752	 steps: training loss - 91174.10156	, testing loss - 351969.06250	
5753	 steps: training loss - 112156.67969	, testing loss - 353489.96875	
5754	 steps: training loss - 91785.55469	, testing loss - 355510.28125	
5755	 steps: training loss - 119607.19531	, testing loss - 357681.43750	
5756	 steps: training loss - 110224.58594	, testing loss - 359551.68750	
5757	 steps: training loss - 98753.01562	, testing loss - 360437.34375	
5758	 steps: training loss - 109737.43750	, testing loss - 361362.75000	
5759	 steps: training loss - 103661.10156	, testing loss - 361634.96875	
5760	 steps: training loss - 114191.84375	, testing loss - 361585.03125	
5761	 steps: training loss - 118123.89844	, testing loss - 360569.59375	
5762	 steps: training loss - 113750.98438	, testing loss - 358023.03125	
5763	 steps: training loss - 145039.42188	, testing loss - 355690.21875	
5764	 steps: training loss - 108283.78906	, testing loss - 353508.12500	
5765	 steps: training loss - 102554.64844	, testing loss - 351994.00000	
5766	 steps: training loss - 122995.82812	, testing loss - 351415.71875	
5767	 steps: training loss - 107338.81250	, testing loss - 350990.62500	
5768	 steps: training loss - 80000.20312	, testing loss - 350805.18750	
5769	 steps: training loss - 116505.38281	, testing loss - 350618.71875	
5770	 steps: training loss - 99404.14844	, testing loss - 350161.37500	
5771	 steps: training loss - 106302.11719	, testing loss - 349905.71875	
5772	 steps: training loss - 83500.06250	, testing loss - 349174.93750	
5773	 steps: training loss - 120569.91406	, testing loss - 348565.81250	
5774	 steps: training loss - 100549.68750	, testing loss - 348725.43750	
5775	 steps: training loss - 104785.25000	, testing loss - 348495.56250	
5776	 steps: training loss - 109648.06250	, testing loss - 348376.00000	
5777	 steps: training loss - 115447.21875	, testing loss - 348313.12500	
5778	 steps: training loss - 100899.91406	, testing loss - 348966.59375	
5779	 steps: training loss - 125546.72656	, testing loss - 349643.50000	
5780	 steps: training loss - 110217.80469	, testing loss - 350219.09375	
5781	 steps: training loss - 98463.20312	, testing loss - 351402.31250	
5782	 steps: training loss - 114807.90625	, testing loss - 352415.90625	
5783	 steps: training loss - 114760.66406	, testing loss - 353638.84375	
5784	 steps: training loss - 103813.38281	, testing loss - 354397.00000	
5785	 steps: training loss - 115454.89062	, testing loss - 354655.21875	
5786	 steps: training loss - 106303.02344	, testing loss - 354846.37500	
5787	 steps: training loss - 110190.45312	, testing loss - 354918.18750	
5788	 steps: training loss - 112715.59375	, testing loss - 354459.53125	
5789	 steps: training loss - 107689.27344	, testing loss - 354429.12500	
5790	 steps: training loss - 144914.12500	, testing loss - 354389.59375	
5791	 steps: training loss - 101075.00000	, testing loss - 354268.09375	
5792	 steps: training loss - 85573.95312	, testing loss - 355244.56250	
5793	 steps: training loss - 119269.99219	, testing loss - 355905.31250	
5794	 steps: training loss - 115662.82031	, testing loss - 355328.00000	
5795	 steps: training loss - 127309.71875	, testing loss - 354329.87500	
5796	 steps: training loss - 111391.15625	, testing loss - 353534.59375	
5797	 steps: training loss - 127355.25781	, testing loss - 352374.56250	
5798	 steps: training loss - 115454.80469	, testing loss - 352854.40625	
5799	 steps: training loss - 97248.71875	, testing loss - 353630.31250	
5800	 steps: training loss - 110287.21094	, testing loss - 355054.28125	
5801	 steps: training loss - 128742.03906	, testing loss - 356429.96875	
5802	 steps: training loss - 93063.53906	, testing loss - 357519.03125	
5803	 steps: training loss - 104808.89062	, testing loss - 358430.12500	
5804	 steps: training loss - 103463.25781	, testing loss - 358520.21875	
5805	 steps: training loss - 90355.63281	, testing loss - 358491.34375	
5806	 steps: training loss - 92033.33594	, testing loss - 359321.34375	
5807	 steps: training loss - 80902.03125	, testing loss - 359813.93750	
5808	 steps: training loss - 128627.31250	, testing loss - 359869.34375	
5809	 steps: training loss - 114255.83594	, testing loss - 359553.18750	
5810	 steps: training loss - 126477.46875	, testing loss - 360114.71875	
5811	 steps: training loss - 103573.92188	, testing loss - 361621.71875	
5812	 steps: training loss - 120672.28906	, testing loss - 364007.50000	
5813	 steps: training loss - 139603.98438	, testing loss - 365677.78125	
5814	 steps: training loss - 119161.03125	, testing loss - 365375.96875	
5815	 steps: training loss - 115307.15625	, testing loss - 363320.31250	
5816	 steps: training loss - 101644.97656	, testing loss - 361843.59375	
5817	 steps: training loss - 105414.40625	, testing loss - 360127.59375	
5818	 steps: training loss - 104262.91406	, testing loss - 359529.78125	
5819	 steps: training loss - 106732.89844	, testing loss - 358808.03125	
5820	 steps: training loss - 105274.49219	, testing loss - 358117.93750	
5821	 steps: training loss - 111810.19531	, testing loss - 357481.09375	
5822	 steps: training loss - 110383.21875	, testing loss - 358667.59375	
5823	 steps: training loss - 111082.30469	, testing loss - 359444.28125	
5824	 steps: training loss - 120689.03125	, testing loss - 359526.18750	
5825	 steps: training loss - 109787.19531	, testing loss - 359212.59375	
5826	 steps: training loss - 75067.54688	, testing loss - 357397.87500	
5827	 steps: training loss - 88357.67969	, testing loss - 355439.71875	
5828	 steps: training loss - 124946.31250	, testing loss - 353679.93750	
5829	 steps: training loss - 120064.75000	, testing loss - 352691.50000	
5830	 steps: training loss - 128745.29688	, testing loss - 352603.81250	
5831	 steps: training loss - 119831.51562	, testing loss - 352646.81250	
5832	 steps: training loss - 111144.10156	, testing loss - 351744.78125	
5833	 steps: training loss - 93281.83594	, testing loss - 351238.40625	
5834	 steps: training loss - 103985.68750	, testing loss - 350886.84375	
5835	 steps: training loss - 102826.14844	, testing loss - 350545.87500	
5836	 steps: training loss - 118723.39062	, testing loss - 351003.93750	
5837	 steps: training loss - 92828.82031	, testing loss - 351756.28125	
5838	 steps: training loss - 91771.57812	, testing loss - 352796.37500	
5839	 steps: training loss - 94033.71875	, testing loss - 354003.50000	
5840	 steps: training loss - 114397.70312	, testing loss - 355817.56250	
5841	 steps: training loss - 140026.92188	, testing loss - 357002.25000	
5842	 steps: training loss - 121498.15625	, testing loss - 357407.21875	
5843	 steps: training loss - 126380.66406	, testing loss - 356915.65625	
5844	 steps: training loss - 126144.12500	, testing loss - 356055.68750	
5845	 steps: training loss - 127133.63281	, testing loss - 354644.65625	
5846	 steps: training loss - 121448.52344	, testing loss - 353353.81250	
5847	 steps: training loss - 104930.34375	, testing loss - 353365.81250	
5848	 steps: training loss - 148017.62500	, testing loss - 353484.46875	
5849	 steps: training loss - 109000.35938	, testing loss - 354109.68750	
5850	 steps: training loss - 114128.50781	, testing loss - 354774.09375	
5851	 steps: training loss - 91940.92969	, testing loss - 355909.28125	
5852	 steps: training loss - 98756.00781	, testing loss - 358315.31250	
5853	 steps: training loss - 82188.41406	, testing loss - 359815.71875	
5854	 steps: training loss - 118905.67969	, testing loss - 360575.75000	
5855	 steps: training loss - 127888.93750	, testing loss - 361953.00000	
5856	 steps: training loss - 108836.64844	, testing loss - 361895.50000	
5857	 steps: training loss - 116674.33594	, testing loss - 360629.34375	
5858	 steps: training loss - 99109.53125	, testing loss - 357865.78125	
5859	 steps: training loss - 102871.85938	, testing loss - 355161.06250	
5860	 steps: training loss - 85857.21875	, testing loss - 352342.56250	
5861	 steps: training loss - 99430.89062	, testing loss - 350968.90625	
5862	 steps: training loss - 138333.54688	, testing loss - 349863.81250	
5863	 steps: training loss - 122325.64062	, testing loss - 349311.62500	
5864	 steps: training loss - 87016.17188	, testing loss - 348915.75000	
5865	 steps: training loss - 119575.89844	, testing loss - 348563.43750	
5866	 steps: training loss - 127355.71094	, testing loss - 348425.34375	
5867	 steps: training loss - 119250.42188	, testing loss - 348229.59375	
5868	 steps: training loss - 104208.07031	, testing loss - 347924.65625	
5869	 steps: training loss - 101161.28906	, testing loss - 348077.84375	
5870	 steps: training loss - 113021.57031	, testing loss - 348332.68750	
5871	 steps: training loss - 120252.83594	, testing loss - 349146.31250	
5872	 steps: training loss - 86513.28906	, testing loss - 349657.31250	
5873	 steps: training loss - 104764.57812	, testing loss - 350061.68750	
5874	 steps: training loss - 112880.75781	, testing loss - 350140.03125	
5875	 steps: training loss - 104293.11719	, testing loss - 350048.81250	
5876	 steps: training loss - 83284.22656	, testing loss - 350240.87500	
5877	 steps: training loss - 136753.65625	, testing loss - 350636.37500	
5878	 steps: training loss - 127541.42969	, testing loss - 350798.90625	
5879	 steps: training loss - 99805.84375	, testing loss - 351185.43750	
5880	 steps: training loss - 92504.57031	, testing loss - 352345.87500	
5881	 steps: training loss - 139927.09375	, testing loss - 354439.90625	
5882	 steps: training loss - 107667.24219	, testing loss - 356508.75000	
5883	 steps: training loss - 143363.45312	, testing loss - 359685.81250	
5884	 steps: training loss - 119955.08594	, testing loss - 362197.37500	
5885	 steps: training loss - 123867.09375	, testing loss - 363744.71875	
5886	 steps: training loss - 133236.51562	, testing loss - 364523.90625	
5887	 steps: training loss - 87437.96094	, testing loss - 365494.81250	
5888	 steps: training loss - 94198.26562	, testing loss - 367580.96875	
5889	 steps: training loss - 114627.45312	, testing loss - 370446.31250	
5890	 steps: training loss - 106707.46094	, testing loss - 371130.87500	
5891	 steps: training loss - 121471.60938	, testing loss - 370382.09375	
5892	 steps: training loss - 108354.14062	, testing loss - 369379.31250	
5893	 steps: training loss - 122971.08594	, testing loss - 368128.68750	
5894	 steps: training loss - 103720.12500	, testing loss - 366420.90625	
5895	 steps: training loss - 116877.02344	, testing loss - 364885.53125	
5896	 steps: training loss - 116064.47656	, testing loss - 363123.18750	
5897	 steps: training loss - 93426.98438	, testing loss - 361141.21875	
5898	 steps: training loss - 117982.89062	, testing loss - 359987.53125	
5899	 steps: training loss - 105819.99219	, testing loss - 358375.84375	
5900	 steps: training loss - 84797.11719	, testing loss - 356571.18750	
5901	 steps: training loss - 97011.20312	, testing loss - 354794.87500	
5902	 steps: training loss - 126362.86719	, testing loss - 352961.84375	
5903	 steps: training loss - 119124.14844	, testing loss - 350620.31250	
5904	 steps: training loss - 124276.80469	, testing loss - 348826.28125	
5905	 steps: training loss - 123984.42969	, testing loss - 347716.46875	
5906	 steps: training loss - 106622.14844	, testing loss - 347220.65625	
5907	 steps: training loss - 116737.86719	, testing loss - 346784.68750	
5908	 steps: training loss - 97835.60156	, testing loss - 345803.93750	
5909	 steps: training loss - 98595.44531	, testing loss - 344458.78125	
5910	 steps: training loss - 106935.01562	, testing loss - 343614.46875	
5911	 steps: training loss - 118303.79688	, testing loss - 343188.50000	
5912	 steps: training loss - 135204.20312	, testing loss - 343332.53125	
5913	 steps: training loss - 129214.85156	, testing loss - 343830.25000	
5914	 steps: training loss - 108625.14844	, testing loss - 344892.31250	
5915	 steps: training loss - 131792.26562	, testing loss - 346751.03125	
5916	 steps: training loss - 111508.39062	, testing loss - 349348.40625	
5917	 steps: training loss - 115413.50000	, testing loss - 352113.65625	
5918	 steps: training loss - 97125.22656	, testing loss - 355104.00000	
5919	 steps: training loss - 118848.23438	, testing loss - 358620.62500	
5920	 steps: training loss - 87067.90625	, testing loss - 361753.12500	
5921	 steps: training loss - 89290.55469	, testing loss - 363627.40625	
5922	 steps: training loss - 102321.69531	, testing loss - 364741.59375	
5923	 steps: training loss - 119291.46875	, testing loss - 364697.96875	
5924	 steps: training loss - 85110.56250	, testing loss - 364875.37500	
5925	 steps: training loss - 112613.19531	, testing loss - 363624.75000	
5926	 steps: training loss - 113893.45312	, testing loss - 361916.50000	
5927	 steps: training loss - 124763.25000	, testing loss - 359709.15625	
5928	 steps: training loss - 102056.48438	, testing loss - 357761.87500	
5929	 steps: training loss - 93992.50000	, testing loss - 356338.62500	
5930	 steps: training loss - 101182.62500	, testing loss - 354800.81250	
5931	 steps: training loss - 106850.63281	, testing loss - 353273.81250	
5932	 steps: training loss - 108701.50781	, testing loss - 351804.65625	
5933	 steps: training loss - 103137.48438	, testing loss - 351626.90625	
5934	 steps: training loss - 104882.56250	, testing loss - 352240.78125	
5935	 steps: training loss - 123162.11719	, testing loss - 352395.87500	
5936	 steps: training loss - 121406.67188	, testing loss - 352740.62500	
5937	 steps: training loss - 115581.89062	, testing loss - 353583.71875	
5938	 steps: training loss - 82326.23438	, testing loss - 353754.21875	
5939	 steps: training loss - 107639.96094	, testing loss - 353085.93750	
5940	 steps: training loss - 128444.67188	, testing loss - 352783.15625	
5941	 steps: training loss - 111886.95312	, testing loss - 352754.59375	
5942	 steps: training loss - 107606.74219	, testing loss - 352621.18750	
5943	 steps: training loss - 77661.00781	, testing loss - 352218.84375	
5944	 steps: training loss - 127643.88281	, testing loss - 351952.81250	
5945	 steps: training loss - 111309.36719	, testing loss - 352332.71875	
5946	 steps: training loss - 100490.46875	, testing loss - 352661.06250	
5947	 steps: training loss - 121114.50781	, testing loss - 353140.68750	
5948	 steps: training loss - 109495.42969	, testing loss - 354182.62500	
5949	 steps: training loss - 97467.60938	, testing loss - 355393.96875	
5950	 steps: training loss - 114276.83594	, testing loss - 356540.12500	
5951	 steps: training loss - 125766.71094	, testing loss - 358238.06250	
5952	 steps: training loss - 134846.37500	, testing loss - 359740.78125	
5953	 steps: training loss - 101572.46094	, testing loss - 359094.31250	
5954	 steps: training loss - 108393.21094	, testing loss - 357665.18750	
5955	 steps: training loss - 118844.31250	, testing loss - 355758.00000	
5956	 steps: training loss - 116381.56250	, testing loss - 354125.87500	
5957	 steps: training loss - 124181.65625	, testing loss - 352576.56250	
5958	 steps: training loss - 86846.98438	, testing loss - 351068.56250	
5959	 steps: training loss - 107873.56250	, testing loss - 349882.56250	
5960	 steps: training loss - 96436.15625	, testing loss - 349848.81250	
5961	 steps: training loss - 91228.13281	, testing loss - 350277.53125	
5962	 steps: training loss - 114305.62500	, testing loss - 350768.34375	
5963	 steps: training loss - 122238.78906	, testing loss - 351136.34375	
5964	 steps: training loss - 137829.51562	, testing loss - 351740.78125	
5965	 steps: training loss - 103695.37500	, testing loss - 352195.84375	
5966	 steps: training loss - 86140.72656	, testing loss - 352909.25000	
5967	 steps: training loss - 99149.60938	, testing loss - 353994.31250	
5968	 steps: training loss - 117806.71094	, testing loss - 354790.62500	
5969	 steps: training loss - 101955.78125	, testing loss - 355834.90625	
5970	 steps: training loss - 118339.81250	, testing loss - 355690.81250	
5971	 steps: training loss - 112830.21875	, testing loss - 354579.75000	
5972	 steps: training loss - 106273.04688	, testing loss - 353143.84375	
5973	 steps: training loss - 103396.30469	, testing loss - 351624.31250	
5974	 steps: training loss - 109549.11719	, testing loss - 349938.53125	
5975	 steps: training loss - 145448.42188	, testing loss - 349573.59375	
5976	 steps: training loss - 134950.14062	, testing loss - 349824.34375	
5977	 steps: training loss - 118459.98438	, testing loss - 349856.50000	
5978	 steps: training loss - 99474.75781	, testing loss - 349365.71875	
5979	 steps: training loss - 100303.58594	, testing loss - 348627.71875	
5980	 steps: training loss - 103381.23438	, testing loss - 348537.71875	
5981	 steps: training loss - 100375.35156	, testing loss - 349202.62500	
5982	 steps: training loss - 119424.64062	, testing loss - 349628.90625	
5983	 steps: training loss - 125913.61719	, testing loss - 349661.59375	
5984	 steps: training loss - 108750.51562	, testing loss - 349204.21875	
5985	 steps: training loss - 118637.43750	, testing loss - 348439.28125	
5986	 steps: training loss - 98661.28125	, testing loss - 347818.31250	
5987	 steps: training loss - 112999.70312	, testing loss - 347647.59375	
5988	 steps: training loss - 120094.29688	, testing loss - 347047.15625	
5989	 steps: training loss - 120698.50781	, testing loss - 347186.03125	
5990	 steps: training loss - 128948.96094	, testing loss - 348062.12500	
5991	 steps: training loss - 90827.73438	, testing loss - 348678.12500	
5992	 steps: training loss - 96970.97656	, testing loss - 349238.81250	
5993	 steps: training loss - 104371.97656	, testing loss - 350848.53125	
5994	 steps: training loss - 84445.14062	, testing loss - 351514.03125	
5995	 steps: training loss - 94266.12500	, testing loss - 351715.90625	
5996	 steps: training loss - 102738.17188	, testing loss - 351731.21875	
5997	 steps: training loss - 111561.65625	, testing loss - 351698.46875	
5998	 steps: training loss - 114206.81250	, testing loss - 351553.71875	
5999	 steps: training loss - 95163.26562	, testing loss - 351879.84375	
6000	 steps: training loss - 114644.45312	, testing loss - 352670.37500	
6001	 steps: training loss - 96179.22656	, testing loss - 353405.09375	
6002	 steps: training loss - 124851.80469	, testing loss - 353812.68750	
6003	 steps: training loss - 133250.25000	, testing loss - 353776.96875	
6004	 steps: training loss - 118670.79688	, testing loss - 353101.28125	
6005	 steps: training loss - 103562.33594	, testing loss - 352669.59375	
6006	 steps: training loss - 135955.67188	, testing loss - 352693.68750	
6007	 steps: training loss - 99517.80469	, testing loss - 352489.09375	
6008	 steps: training loss - 84424.21094	, testing loss - 352720.09375	
6009	 steps: training loss - 102006.08594	, testing loss - 352850.18750	
6010	 steps: training loss - 108379.23438	, testing loss - 352331.03125	
6011	 steps: training loss - 125079.13281	, testing loss - 352128.43750	
6012	 steps: training loss - 128756.09375	, testing loss - 351484.09375	
6013	 steps: training loss - 116933.78906	, testing loss - 351751.06250	
6014	 steps: training loss - 100026.75781	, testing loss - 352225.84375	
6015	 steps: training loss - 108406.14062	, testing loss - 352486.00000	
6016	 steps: training loss - 91873.33594	, testing loss - 352999.00000	
6017	 steps: training loss - 109074.11719	, testing loss - 353571.68750	
6018	 steps: training loss - 118993.92188	, testing loss - 353019.75000	
6019	 steps: training loss - 115740.80469	, testing loss - 352456.78125	
6020	 steps: training loss - 124774.15625	, testing loss - 352472.93750	
6021	 steps: training loss - 114995.10938	, testing loss - 352288.53125	
6022	 steps: training loss - 110553.35938	, testing loss - 351811.21875	
6023	 steps: training loss - 110549.09375	, testing loss - 350963.65625	
6024	 steps: training loss - 103934.77344	, testing loss - 350099.09375	
6025	 steps: training loss - 108729.21094	, testing loss - 349127.43750	
6026	 steps: training loss - 135748.87500	, testing loss - 348456.34375	
6027	 steps: training loss - 102377.92969	, testing loss - 348759.31250	
6028	 steps: training loss - 117842.10938	, testing loss - 349253.25000	
6029	 steps: training loss - 111168.16406	, testing loss - 349982.43750	
6030	 steps: training loss - 157590.28125	, testing loss - 351072.15625	
6031	 steps: training loss - 106424.23438	, testing loss - 352673.84375	
6032	 steps: training loss - 90672.41406	, testing loss - 355360.37500	
6033	 steps: training loss - 118605.66406	, testing loss - 357606.12500	
6034	 steps: training loss - 103495.04688	, testing loss - 358697.28125	
6035	 steps: training loss - 120731.83594	, testing loss - 359510.87500	
6036	 steps: training loss - 107509.65625	, testing loss - 359481.53125	
6037	 steps: training loss - 131400.75000	, testing loss - 358879.56250	
6038	 steps: training loss - 100934.48438	, testing loss - 358310.34375	
6039	 steps: training loss - 101290.76562	, testing loss - 357597.53125	
6040	 steps: training loss - 125763.37500	, testing loss - 356921.15625	
6041	 steps: training loss - 126208.23438	, testing loss - 356161.09375	
6042	 steps: training loss - 132837.23438	, testing loss - 356052.12500	
6043	 steps: training loss - 108128.71094	, testing loss - 356473.46875	
6044	 steps: training loss - 107721.49219	, testing loss - 357615.31250	
6045	 steps: training loss - 131826.03125	, testing loss - 358016.75000	
6046	 steps: training loss - 104950.82031	, testing loss - 357628.25000	
6047	 steps: training loss - 103650.75000	, testing loss - 357755.28125	
6048	 steps: training loss - 105350.33594	, testing loss - 357734.03125	
6049	 steps: training loss - 118952.92188	, testing loss - 357429.40625	
6050	 steps: training loss - 112491.89844	, testing loss - 358202.87500	
6051	 steps: training loss - 122215.28125	, testing loss - 358083.87500	
6052	 steps: training loss - 120476.51562	, testing loss - 357684.59375	
6053	 steps: training loss - 130591.55469	, testing loss - 357395.93750	
6054	 steps: training loss - 104130.25000	, testing loss - 357057.68750	
6055	 steps: training loss - 109032.64844	, testing loss - 356267.65625	
6056	 steps: training loss - 115498.60156	, testing loss - 355616.78125	
6057	 steps: training loss - 88337.19531	, testing loss - 355920.31250	
6058	 steps: training loss - 108110.46094	, testing loss - 356446.21875	
6059	 steps: training loss - 103816.82812	, testing loss - 357183.34375	
6060	 steps: training loss - 89491.91406	, testing loss - 358969.12500	
6061	 steps: training loss - 125474.86719	, testing loss - 361556.18750	
6062	 steps: training loss - 109378.17188	, testing loss - 364286.53125	
6063	 steps: training loss - 109135.84375	, testing loss - 367696.15625	
6064	 steps: training loss - 120925.78906	, testing loss - 369042.21875	
6065	 steps: training loss - 110315.87500	, testing loss - 368550.75000	
6066	 steps: training loss - 119142.00000	, testing loss - 368761.34375	
6067	 steps: training loss - 118749.25781	, testing loss - 369052.96875	
6068	 steps: training loss - 90062.35156	, testing loss - 368422.25000	
6069	 steps: training loss - 103434.32812	, testing loss - 367350.21875	
6070	 steps: training loss - 112974.50000	, testing loss - 366518.15625	
6071	 steps: training loss - 118770.55469	, testing loss - 366950.81250	
6072	 steps: training loss - 100345.42188	, testing loss - 367387.68750	
6073	 steps: training loss - 119472.17969	, testing loss - 367663.71875	
6074	 steps: training loss - 126698.60156	, testing loss - 367292.78125	
6075	 steps: training loss - 115298.19531	, testing loss - 365664.06250	
6076	 steps: training loss - 95362.72656	, testing loss - 363231.96875	
6077	 steps: training loss - 98115.14844	, testing loss - 361147.31250	
6078	 steps: training loss - 112000.61719	, testing loss - 359467.71875	
6079	 steps: training loss - 102706.69531	, testing loss - 357988.65625	
6080	 steps: training loss - 134050.60938	, testing loss - 356124.40625	
6081	 steps: training loss - 117679.35156	, testing loss - 354991.90625	
6082	 steps: training loss - 102031.06250	, testing loss - 355272.75000	
6083	 steps: training loss - 140821.25000	, testing loss - 357445.31250	
6084	 steps: training loss - 110819.97656	, testing loss - 358979.81250	
6085	 steps: training loss - 101240.21094	, testing loss - 359431.40625	
6086	 steps: training loss - 125519.71875	, testing loss - 360021.56250	
6087	 steps: training loss - 127589.25000	, testing loss - 359358.09375	
6088	 steps: training loss - 115023.00000	, testing loss - 358765.84375	
6089	 steps: training loss - 98293.96094	, testing loss - 357786.18750	
6090	 steps: training loss - 122439.45312	, testing loss - 357033.09375	
6091	 steps: training loss - 102160.52344	, testing loss - 357158.53125	
6092	 steps: training loss - 117838.22656	, testing loss - 357167.53125	
6093	 steps: training loss - 117857.70312	, testing loss - 357180.12500	
6094	 steps: training loss - 119452.00781	, testing loss - 357472.62500	
6095	 steps: training loss - 111116.95312	, testing loss - 358033.12500	
6096	 steps: training loss - 119442.22656	, testing loss - 357635.06250	
6097	 steps: training loss - 92233.71875	, testing loss - 356060.62500	
6098	 steps: training loss - 105887.85938	, testing loss - 355115.84375	
6099	 steps: training loss - 116431.40625	, testing loss - 355472.93750	
6100	 steps: training loss - 116980.39062	, testing loss - 355755.46875	
6101	 steps: training loss - 101097.49219	, testing loss - 355659.71875	
6102	 steps: training loss - 118984.90625	, testing loss - 355421.31250	
6103	 steps: training loss - 105505.64062	, testing loss - 354550.68750	
6104	 steps: training loss - 99886.01562	, testing loss - 353668.00000	
6105	 steps: training loss - 108969.08594	, testing loss - 353695.81250	
6106	 steps: training loss - 134363.12500	, testing loss - 354148.40625	
6107	 steps: training loss - 109864.10156	, testing loss - 354475.56250	
6108	 steps: training loss - 93792.17188	, testing loss - 354524.50000	
6109	 steps: training loss - 82901.17188	, testing loss - 353882.93750	
6110	 steps: training loss - 119565.50000	, testing loss - 354225.56250	
6111	 steps: training loss - 91780.29688	, testing loss - 354739.50000	
6112	 steps: training loss - 122337.82812	, testing loss - 354763.68750	
6113	 steps: training loss - 120006.07031	, testing loss - 354988.09375	
6114	 steps: training loss - 107591.45312	, testing loss - 354286.65625	
6115	 steps: training loss - 86047.61719	, testing loss - 353571.90625	
6116	 steps: training loss - 101868.43750	, testing loss - 353358.15625	
6117	 steps: training loss - 135032.10938	, testing loss - 353329.65625	
6118	 steps: training loss - 123353.78906	, testing loss - 352924.34375	
6119	 steps: training loss - 112933.82031	, testing loss - 352432.46875	
6120	 steps: training loss - 109076.14844	, testing loss - 351365.65625	
6121	 steps: training loss - 114742.64844	, testing loss - 350682.75000	
6122	 steps: training loss - 102729.98438	, testing loss - 350249.46875	
6123	 steps: training loss - 131227.43750	, testing loss - 350363.90625	
6124	 steps: training loss - 128776.67188	, testing loss - 350361.68750	
6125	 steps: training loss - 107572.09375	, testing loss - 349249.56250	
6126	 steps: training loss - 115620.94531	, testing loss - 347583.75000	
6127	 steps: training loss - 114794.66406	, testing loss - 347290.84375	
6128	 steps: training loss - 146955.87500	, testing loss - 347635.56250	
6129	 steps: training loss - 102646.92188	, testing loss - 348962.78125	
6130	 steps: training loss - 125136.73438	, testing loss - 350162.00000	
6131	 steps: training loss - 139022.29688	, testing loss - 350932.46875	
6132	 steps: training loss - 92713.07812	, testing loss - 350340.62500	
6133	 steps: training loss - 124719.81250	, testing loss - 349395.34375	
6134	 steps: training loss - 114362.09375	, testing loss - 350060.12500	
6135	 steps: training loss - 105602.74219	, testing loss - 350585.78125	
6136	 steps: training loss - 94865.13281	, testing loss - 351669.25000	
6137	 steps: training loss - 99667.11719	, testing loss - 353157.96875	
6138	 steps: training loss - 114753.92969	, testing loss - 353708.46875	
6139	 steps: training loss - 121957.31250	, testing loss - 354001.81250	
6140	 steps: training loss - 105538.72656	, testing loss - 353410.09375	
6141	 steps: training loss - 117959.37500	, testing loss - 351823.59375	
6142	 steps: training loss - 115301.85156	, testing loss - 350407.18750	
6143	 steps: training loss - 106645.62500	, testing loss - 348698.43750	
6144	 steps: training loss - 99840.25000	, testing loss - 347730.65625	
6145	 steps: training loss - 121837.68750	, testing loss - 347316.03125	
6146	 steps: training loss - 118862.49219	, testing loss - 347801.75000	
6147	 steps: training loss - 105567.78125	, testing loss - 349291.59375	
6148	 steps: training loss - 104871.17188	, testing loss - 350770.78125	
6149	 steps: training loss - 120386.92188	, testing loss - 351659.03125	
6150	 steps: training loss - 105258.70312	, testing loss - 351078.40625	
6151	 steps: training loss - 143791.64062	, testing loss - 350450.09375	
6152	 steps: training loss - 107076.28125	, testing loss - 350333.71875	
6153	 steps: training loss - 159068.21875	, testing loss - 350704.90625	
6154	 steps: training loss - 103170.85938	, testing loss - 351994.90625	
6155	 steps: training loss - 80562.14062	, testing loss - 353236.90625	
6156	 steps: training loss - 101950.84375	, testing loss - 354182.06250	
6157	 steps: training loss - 109038.88281	, testing loss - 355337.12500	
6158	 steps: training loss - 112426.50781	, testing loss - 356009.84375	
6159	 steps: training loss - 82194.28906	, testing loss - 355744.53125	
6160	 steps: training loss - 115965.99219	, testing loss - 355232.81250	
6161	 steps: training loss - 115715.03906	, testing loss - 355446.50000	
6162	 steps: training loss - 124197.54688	, testing loss - 355880.78125	
6163	 steps: training loss - 130995.31250	, testing loss - 355531.18750	
6164	 steps: training loss - 85807.28125	, testing loss - 353209.09375	
6165	 steps: training loss - 116164.96875	, testing loss - 350919.75000	
6166	 steps: training loss - 104347.43750	, testing loss - 348927.31250	
6167	 steps: training loss - 102950.10938	, testing loss - 347293.68750	
6168	 steps: training loss - 105093.87500	, testing loss - 346257.68750	
6169	 steps: training loss - 104650.34375	, testing loss - 345332.90625	
6170	 steps: training loss - 132323.57812	, testing loss - 344118.93750	
6171	 steps: training loss - 117438.23438	, testing loss - 343271.18750	
6172	 steps: training loss - 88689.50000	, testing loss - 342929.28125	
6173	 steps: training loss - 104674.09375	, testing loss - 342947.34375	
6174	 steps: training loss - 109697.11719	, testing loss - 343104.53125	
6175	 steps: training loss - 112553.59375	, testing loss - 344040.03125	
6176	 steps: training loss - 116985.47656	, testing loss - 344764.31250	
6177	 steps: training loss - 75360.32812	, testing loss - 345503.21875	
6178	 steps: training loss - 115885.70312	, testing loss - 345763.00000	
6179	 steps: training loss - 125554.26562	, testing loss - 347085.81250	
6180	 steps: training loss - 107337.65625	, testing loss - 347968.25000	
6181	 steps: training loss - 86363.40625	, testing loss - 348294.75000	
6182	 steps: training loss - 88787.05469	, testing loss - 348417.03125	
6183	 steps: training loss - 107613.88281	, testing loss - 349202.81250	
6184	 steps: training loss - 115283.55469	, testing loss - 350656.31250	
6185	 steps: training loss - 104229.65625	, testing loss - 352208.12500	
6186	 steps: training loss - 117364.35156	, testing loss - 353026.59375	
6187	 steps: training loss - 121538.05469	, testing loss - 353662.62500	
6188	 steps: training loss - 111857.36719	, testing loss - 354499.93750	
6189	 steps: training loss - 101310.14062	, testing loss - 354867.84375	
6190	 steps: training loss - 123235.01562	, testing loss - 355389.56250	
6191	 steps: training loss - 100148.75781	, testing loss - 356342.59375	
6192	 steps: training loss - 101132.75000	, testing loss - 356699.50000	
6193	 steps: training loss - 110285.82812	, testing loss - 355986.09375	
6194	 steps: training loss - 108276.39844	, testing loss - 354717.31250	
6195	 steps: training loss - 110563.48438	, testing loss - 353502.15625	
6196	 steps: training loss - 119613.03125	, testing loss - 352816.56250	
6197	 steps: training loss - 88074.87500	, testing loss - 352284.46875	
6198	 steps: training loss - 95419.87500	, testing loss - 351547.46875	
6199	 steps: training loss - 116689.64844	, testing loss - 350380.25000	
6200	 steps: training loss - 114940.73438	, testing loss - 349407.18750	
6201	 steps: training loss - 102453.96875	, testing loss - 348336.87500	
6202	 steps: training loss - 124890.98438	, testing loss - 347619.37500	
6203	 steps: training loss - 126409.87500	, testing loss - 346395.03125	
6204	 steps: training loss - 93769.10156	, testing loss - 345735.09375	
6205	 steps: training loss - 98335.49219	, testing loss - 345519.53125	
6206	 steps: training loss - 96844.06250	, testing loss - 345561.37500	
6207	 steps: training loss - 119596.19531	, testing loss - 345849.96875	
6208	 steps: training loss - 112333.85156	, testing loss - 346635.31250	
6209	 steps: training loss - 107391.62500	, testing loss - 349057.03125	
6210	 steps: training loss - 104206.69531	, testing loss - 352187.90625	
6211	 steps: training loss - 103392.03906	, testing loss - 355787.75000	
6212	 steps: training loss - 134303.62500	, testing loss - 360383.40625	
6213	 steps: training loss - 87974.61719	, testing loss - 364918.53125	
6214	 steps: training loss - 116527.10938	, testing loss - 368237.21875	
6215	 steps: training loss - 111193.76562	, testing loss - 369852.53125	
6216	 steps: training loss - 121650.46094	, testing loss - 369164.28125	
6217	 steps: training loss - 131739.23438	, testing loss - 367344.62500	
6218	 steps: training loss - 117817.67969	, testing loss - 364188.68750	
6219	 steps: training loss - 105938.65625	, testing loss - 361205.96875	
6220	 steps: training loss - 120675.50000	, testing loss - 358394.90625	
6221	 steps: training loss - 106789.44531	, testing loss - 355403.56250	
6222	 steps: training loss - 125705.06250	, testing loss - 352972.18750	
6223	 steps: training loss - 110222.68750	, testing loss - 352233.43750	
6224	 steps: training loss - 106706.30469	, testing loss - 353505.68750	
6225	 steps: training loss - 98203.08594	, testing loss - 354497.40625	
6226	 steps: training loss - 102229.11719	, testing loss - 354727.62500	
6227	 steps: training loss - 97871.00781	, testing loss - 354363.37500	
6228	 steps: training loss - 104341.82812	, testing loss - 354111.28125	
6229	 steps: training loss - 119244.89062	, testing loss - 353521.78125	
6230	 steps: training loss - 112286.50781	, testing loss - 352516.93750	
6231	 steps: training loss - 110357.00781	, testing loss - 351658.50000	
6232	 steps: training loss - 84991.62500	, testing loss - 350590.00000	
6233	 steps: training loss - 103523.03906	, testing loss - 349563.96875	
6234	 steps: training loss - 107426.55469	, testing loss - 349484.59375	
6235	 steps: training loss - 112017.78125	, testing loss - 348867.75000	
6236	 steps: training loss - 126945.96875	, testing loss - 348802.43750	
6237	 steps: training loss - 94467.96875	, testing loss - 349583.93750	
6238	 steps: training loss - 101876.41406	, testing loss - 350970.62500	
6239	 steps: training loss - 108515.64844	, testing loss - 352127.90625	
6240	 steps: training loss - 107183.67969	, testing loss - 352935.09375	
6241	 steps: training loss - 111872.50781	, testing loss - 353867.12500	
6242	 steps: training loss - 128756.10156	, testing loss - 355650.46875	
6243	 steps: training loss - 92805.39062	, testing loss - 357395.62500	
6244	 steps: training loss - 108972.00000	, testing loss - 358241.68750	
6245	 steps: training loss - 137858.01562	, testing loss - 358232.03125	
6246	 steps: training loss - 112621.04688	, testing loss - 357228.40625	
6247	 steps: training loss - 104747.14062	, testing loss - 355067.40625	
6248	 steps: training loss - 113987.56250	, testing loss - 352502.28125	
6249	 steps: training loss - 103067.75781	, testing loss - 350616.40625	
6250	 steps: training loss - 112329.50000	, testing loss - 349530.90625	
6251	 steps: training loss - 108079.28125	, testing loss - 349526.71875	
6252	 steps: training loss - 109768.67188	, testing loss - 349769.78125	
6253	 steps: training loss - 133891.40625	, testing loss - 349040.09375	
6254	 steps: training loss - 99342.96875	, testing loss - 348566.46875	
6255	 steps: training loss - 118755.46875	, testing loss - 347253.96875	
6256	 steps: training loss - 114903.67969	, testing loss - 345308.31250	
6257	 steps: training loss - 116855.42188	, testing loss - 343928.31250	
6258	 steps: training loss - 136981.98438	, testing loss - 342994.40625	
6259	 steps: training loss - 87600.99219	, testing loss - 342813.84375	
6260	 steps: training loss - 109209.46875	, testing loss - 343034.75000	
6261	 steps: training loss - 96171.42969	, testing loss - 343541.53125	
6262	 steps: training loss - 130074.78906	, testing loss - 343818.87500	
6263	 steps: training loss - 108477.27344	, testing loss - 344349.28125	
6264	 steps: training loss - 122908.59375	, testing loss - 345839.62500	
6265	 steps: training loss - 104726.67969	, testing loss - 347649.34375	
6266	 steps: training loss - 88464.10938	, testing loss - 349945.81250	
6267	 steps: training loss - 124947.66406	, testing loss - 351877.25000	
6268	 steps: training loss - 103524.00781	, testing loss - 353985.96875	
6269	 steps: training loss - 97459.10156	, testing loss - 356407.68750	
6270	 steps: training loss - 111708.89844	, testing loss - 357737.00000	
6271	 steps: training loss - 122270.63281	, testing loss - 360854.65625	
6272	 steps: training loss - 126784.92188	, testing loss - 364622.96875	
6273	 steps: training loss - 125449.84375	, testing loss - 365521.78125	
6274	 steps: training loss - 145913.53125	, testing loss - 364625.00000	
6275	 steps: training loss - 109012.21875	, testing loss - 362011.03125	
6276	 steps: training loss - 87007.31250	, testing loss - 358326.21875	
6277	 steps: training loss - 96050.87500	, testing loss - 354464.18750	
6278	 steps: training loss - 122734.00000	, testing loss - 351824.34375	
6279	 steps: training loss - 94733.78125	, testing loss - 350032.40625	
6280	 steps: training loss - 117262.22656	, testing loss - 348833.34375	
6281	 steps: training loss - 106931.58594	, testing loss - 347159.50000	
6282	 steps: training loss - 120426.44531	, testing loss - 345589.71875	
6283	 steps: training loss - 98321.32812	, testing loss - 345099.84375	
6284	 steps: training loss - 106658.07031	, testing loss - 345401.75000	
6285	 steps: training loss - 121599.67188	, testing loss - 345746.40625	
6286	 steps: training loss - 111175.79688	, testing loss - 345761.96875	
6287	 steps: training loss - 102778.10156	, testing loss - 345668.31250	
6288	 steps: training loss - 100688.07031	, testing loss - 345759.65625	
6289	 steps: training loss - 88805.11719	, testing loss - 346195.18750	
6290	 steps: training loss - 142361.76562	, testing loss - 347063.68750	
6291	 steps: training loss - 109627.96094	, testing loss - 348952.81250	
6292	 steps: training loss - 109618.83594	, testing loss - 351542.81250	
6293	 steps: training loss - 143136.15625	, testing loss - 353192.68750	
6294	 steps: training loss - 96497.76562	, testing loss - 354319.00000	
6295	 steps: training loss - 103939.07031	, testing loss - 355342.96875	
6296	 steps: training loss - 128030.12500	, testing loss - 355891.62500	
6297	 steps: training loss - 110789.92969	, testing loss - 356131.53125	
6298	 steps: training loss - 99973.96875	, testing loss - 357225.81250	
6299	 steps: training loss - 113199.27344	, testing loss - 358390.37500	
6300	 steps: training loss - 112318.78125	, testing loss - 360564.50000	
6301	 steps: training loss - 109023.01562	, testing loss - 362649.46875	
6302	 steps: training loss - 120994.85156	, testing loss - 363109.93750	
6303	 steps: training loss - 103431.73438	, testing loss - 363042.28125	
6304	 steps: training loss - 98491.42188	, testing loss - 363643.96875	
6305	 steps: training loss - 118794.10156	, testing loss - 363628.93750	
6306	 steps: training loss - 102066.96094	, testing loss - 363322.06250	
6307	 steps: training loss - 104742.60938	, testing loss - 363618.00000	
6308	 steps: training loss - 102727.92188	, testing loss - 363816.96875	
6309	 steps: training loss - 91091.75781	, testing loss - 364711.31250	
6310	 steps: training loss - 111922.35938	, testing loss - 365053.50000	
6311	 steps: training loss - 102098.91406	, testing loss - 364407.53125	
6312	 steps: training loss - 113313.13281	, testing loss - 363347.00000	
6313	 steps: training loss - 119430.71094	, testing loss - 360713.09375	
6314	 steps: training loss - 107681.04688	, testing loss - 357367.87500	
6315	 steps: training loss - 128424.42188	, testing loss - 354752.21875	
6316	 steps: training loss - 123079.03125	, testing loss - 353334.06250	
6317	 steps: training loss - 114794.77344	, testing loss - 352930.09375	
6318	 steps: training loss - 105328.86719	, testing loss - 352255.56250	
6319	 steps: training loss - 128012.14062	, testing loss - 352066.75000	
6320	 steps: training loss - 130351.10938	, testing loss - 353178.71875	
6321	 steps: training loss - 101256.69531	, testing loss - 354427.90625	
6322	 steps: training loss - 142032.35938	, testing loss - 354941.84375	
6323	 steps: training loss - 113903.14844	, testing loss - 355266.90625	
6324	 steps: training loss - 119057.51562	, testing loss - 356100.87500	
6325	 steps: training loss - 103855.02344	, testing loss - 358319.84375	
6326	 steps: training loss - 102787.10938	, testing loss - 361704.43750	
6327	 steps: training loss - 107987.28906	, testing loss - 365630.84375	
6328	 steps: training loss - 127141.20312	, testing loss - 368450.37500	
6329	 steps: training loss - 131321.62500	, testing loss - 369358.75000	
6330	 steps: training loss - 125027.10938	, testing loss - 369285.12500	
6331	 steps: training loss - 117382.80469	, testing loss - 367717.81250	
6332	 steps: training loss - 107649.17969	, testing loss - 365683.62500	
6333	 steps: training loss - 101934.52344	, testing loss - 363637.46875	
6334	 steps: training loss - 117726.10156	, testing loss - 362398.21875	
6335	 steps: training loss - 116408.41406	, testing loss - 361054.46875	
6336	 steps: training loss - 107261.36719	, testing loss - 359200.78125	
6337	 steps: training loss - 106550.03125	, testing loss - 357930.90625	
6338	 steps: training loss - 105295.81250	, testing loss - 357853.43750	
6339	 steps: training loss - 121767.57031	, testing loss - 357563.59375	
6340	 steps: training loss - 114439.06250	, testing loss - 357177.12500	
6341	 steps: training loss - 112895.00781	, testing loss - 358037.40625	
6342	 steps: training loss - 125155.81250	, testing loss - 360491.37500	
6343	 steps: training loss - 115621.43750	, testing loss - 362372.78125	
6344	 steps: training loss - 115754.05469	, testing loss - 363443.15625	
6345	 steps: training loss - 130675.58594	, testing loss - 364383.62500	
6346	 steps: training loss - 118159.84375	, testing loss - 363595.81250	
6347	 steps: training loss - 103652.73438	, testing loss - 362992.68750	
6348	 steps: training loss - 99896.70312	, testing loss - 362822.96875	
6349	 steps: training loss - 103596.95312	, testing loss - 363015.96875	
6350	 steps: training loss - 104841.39062	, testing loss - 363770.68750	
6351	 steps: training loss - 106349.64062	, testing loss - 365214.25000	
6352	 steps: training loss - 102124.10156	, testing loss - 366479.40625	
6353	 steps: training loss - 127038.41406	, testing loss - 366973.18750	
6354	 steps: training loss - 104123.78125	, testing loss - 365849.43750	
6355	 steps: training loss - 101598.73438	, testing loss - 365127.00000	
6356	 steps: training loss - 110990.23438	, testing loss - 365643.06250	
6357	 steps: training loss - 111175.16406	, testing loss - 365820.03125	
6358	 steps: training loss - 96933.40625	, testing loss - 366098.93750	
6359	 steps: training loss - 117567.27344	, testing loss - 366988.84375	
6360	 steps: training loss - 135085.12500	, testing loss - 366243.87500	
6361	 steps: training loss - 120843.25781	, testing loss - 366461.68750	
6362	 steps: training loss - 104384.98438	, testing loss - 365221.28125	
6363	 steps: training loss - 114535.95312	, testing loss - 362974.71875	
6364	 steps: training loss - 109459.50781	, testing loss - 361430.93750	
6365	 steps: training loss - 105153.60156	, testing loss - 359674.34375	
6366	 steps: training loss - 100499.50781	, testing loss - 357879.53125	
6367	 steps: training loss - 128280.26562	, testing loss - 356442.25000	
6368	 steps: training loss - 90701.98438	, testing loss - 355193.71875	
6369	 steps: training loss - 128307.65625	, testing loss - 353496.18750	
6370	 steps: training loss - 97795.17969	, testing loss - 351860.00000	
6371	 steps: training loss - 130459.53125	, testing loss - 350940.71875	
6372	 steps: training loss - 122575.82812	, testing loss - 349565.18750	
6373	 steps: training loss - 83310.83594	, testing loss - 348355.37500	
6374	 steps: training loss - 104470.16406	, testing loss - 347392.37500	
6375	 steps: training loss - 120976.10938	, testing loss - 347255.59375	
6376	 steps: training loss - 106338.57031	, testing loss - 347870.28125	
6377	 steps: training loss - 105310.35156	, testing loss - 348149.28125	
6378	 steps: training loss - 125177.78906	, testing loss - 349422.12500	
6379	 steps: training loss - 104205.47656	, testing loss - 351551.31250	
6380	 steps: training loss - 106094.08594	, testing loss - 353154.90625	
6381	 steps: training loss - 105176.74219	, testing loss - 352873.15625	
6382	 steps: training loss - 89883.14844	, testing loss - 351823.90625	
6383	 steps: training loss - 108166.01562	, testing loss - 351546.00000	
6384	 steps: training loss - 102938.47656	, testing loss - 351506.28125	
6385	 steps: training loss - 101600.19531	, testing loss - 351017.03125	
6386	 steps: training loss - 110118.62500	, testing loss - 350891.96875	
6387	 steps: training loss - 131466.87500	, testing loss - 350660.40625	
6388	 steps: training loss - 117366.42969	, testing loss - 350790.37500	
6389	 steps: training loss - 101344.72656	, testing loss - 351347.00000	
6390	 steps: training loss - 126126.63281	, testing loss - 351754.90625	
6391	 steps: training loss - 105504.87500	, testing loss - 352947.34375	
6392	 steps: training loss - 100283.77344	, testing loss - 353721.87500	
6393	 steps: training loss - 127338.57812	, testing loss - 353847.68750	
6394	 steps: training loss - 101788.95312	, testing loss - 353173.87500	
6395	 steps: training loss - 120176.22656	, testing loss - 353009.50000	
6396	 steps: training loss - 137236.28125	, testing loss - 352664.62500	
6397	 steps: training loss - 97116.27344	, testing loss - 350942.31250	
6398	 steps: training loss - 102019.38281	, testing loss - 348589.40625	
6399	 steps: training loss - 102514.55469	, testing loss - 346227.62500	
6400	 steps: training loss - 109995.27344	, testing loss - 344288.12500	
6401	 steps: training loss - 95011.75000	, testing loss - 342644.75000	
6402	 steps: training loss - 114605.71094	, testing loss - 341523.96875	
6403	 steps: training loss - 93409.27344	, testing loss - 341023.68750	
6404	 steps: training loss - 94139.12500	, testing loss - 341192.09375	
6405	 steps: training loss - 100430.32812	, testing loss - 341712.31250	
6406	 steps: training loss - 106230.21094	, testing loss - 343089.50000	
6407	 steps: training loss - 121203.38281	, testing loss - 344781.71875	
6408	 steps: training loss - 97431.11719	, testing loss - 346483.87500	
6409	 steps: training loss - 127765.53906	, testing loss - 347963.25000	
6410	 steps: training loss - 127831.00781	, testing loss - 348320.46875	
6411	 steps: training loss - 90026.33594	, testing loss - 348261.56250	
6412	 steps: training loss - 106880.75000	, testing loss - 349736.12500	
6413	 steps: training loss - 106796.55469	, testing loss - 351763.18750	
6414	 steps: training loss - 126614.71875	, testing loss - 353945.81250	
6415	 steps: training loss - 106425.67969	, testing loss - 355565.50000	
6416	 steps: training loss - 93213.71875	, testing loss - 356157.03125	
6417	 steps: training loss - 115790.47656	, testing loss - 357359.53125	
6418	 steps: training loss - 74030.87500	, testing loss - 359913.96875	
6419	 steps: training loss - 126508.36719	, testing loss - 362549.34375	
6420	 steps: training loss - 121249.69531	, testing loss - 363864.53125	
6421	 steps: training loss - 110393.25781	, testing loss - 364113.96875	
6422	 steps: training loss - 109736.12500	, testing loss - 363225.25000	
6423	 steps: training loss - 100139.25000	, testing loss - 361997.84375	
6424	 steps: training loss - 111607.57031	, testing loss - 360546.09375	
6425	 steps: training loss - 99900.35938	, testing loss - 359021.53125	
6426	 steps: training loss - 121557.93750	, testing loss - 357493.75000	
6427	 steps: training loss - 105244.03906	, testing loss - 356008.46875	
6428	 steps: training loss - 145925.64062	, testing loss - 355037.43750	
6429	 steps: training loss - 128122.35156	, testing loss - 354640.59375	
6430	 steps: training loss - 91920.74219	, testing loss - 353988.87500	
6431	 steps: training loss - 117001.24219	, testing loss - 353366.25000	
6432	 steps: training loss - 101872.34375	, testing loss - 352675.25000	
6433	 steps: training loss - 111353.75781	, testing loss - 351949.56250	
6434	 steps: training loss - 135521.50000	, testing loss - 351968.43750	
6435	 steps: training loss - 102101.96875	, testing loss - 351813.56250	
6436	 steps: training loss - 95938.81250	, testing loss - 351403.21875	
6437	 steps: training loss - 120646.85938	, testing loss - 351369.87500	
6438	 steps: training loss - 99150.52344	, testing loss - 351788.87500	
6439	 steps: training loss - 96271.24219	, testing loss - 352577.90625	
6440	 steps: training loss - 108188.03906	, testing loss - 353948.56250	
6441	 steps: training loss - 105610.28125	, testing loss - 354634.40625	
6442	 steps: training loss - 99781.78906	, testing loss - 355018.78125	
6443	 steps: training loss - 122898.42188	, testing loss - 355546.06250	
6444	 steps: training loss - 113578.06250	, testing loss - 356292.81250	
6445	 steps: training loss - 114850.14062	, testing loss - 356839.93750	
6446	 steps: training loss - 112946.42188	, testing loss - 356976.65625	
6447	 steps: training loss - 110375.37500	, testing loss - 356406.50000	
6448	 steps: training loss - 107698.42969	, testing loss - 355939.78125	
6449	 steps: training loss - 135723.48438	, testing loss - 356067.84375	
6450	 steps: training loss - 87061.90625	, testing loss - 357022.40625	
6451	 steps: training loss - 112911.30469	, testing loss - 357495.21875	
6452	 steps: training loss - 127526.10156	, testing loss - 358515.62500	
6453	 steps: training loss - 123632.61719	, testing loss - 359253.37500	
6454	 steps: training loss - 108099.06250	, testing loss - 359474.43750	
6455	 steps: training loss - 101538.25000	, testing loss - 359611.71875	
6456	 steps: training loss - 98179.07812	, testing loss - 359088.81250	
6457	 steps: training loss - 120433.14062	, testing loss - 358225.03125	
6458	 steps: training loss - 102379.42188	, testing loss - 356861.46875	
6459	 steps: training loss - 97824.41406	, testing loss - 355822.31250	
6460	 steps: training loss - 91989.57031	, testing loss - 355576.15625	
6461	 steps: training loss - 100243.37500	, testing loss - 354825.03125	
6462	 steps: training loss - 109006.83594	, testing loss - 353947.56250	
6463	 steps: training loss - 133288.50000	, testing loss - 352756.09375	
6464	 steps: training loss - 95118.10938	, testing loss - 352176.12500	
6465	 steps: training loss - 97596.92188	, testing loss - 351996.75000	
6466	 steps: training loss - 101701.39844	, testing loss - 351932.62500	
6467	 steps: training loss - 119711.74219	, testing loss - 351925.59375	
6468	 steps: training loss - 101403.96094	, testing loss - 351911.90625	
6469	 steps: training loss - 111535.12500	, testing loss - 351471.65625	
6470	 steps: training loss - 133242.43750	, testing loss - 350593.87500	
6471	 steps: training loss - 116800.88281	, testing loss - 349976.09375	
6472	 steps: training loss - 107292.53906	, testing loss - 348541.53125	
6473	 steps: training loss - 90263.75000	, testing loss - 347093.87500	
6474	 steps: training loss - 133709.70312	, testing loss - 346008.28125	
6475	 steps: training loss - 93213.12500	, testing loss - 344923.40625	
6476	 steps: training loss - 114886.44531	, testing loss - 344647.12500	
6477	 steps: training loss - 95284.78125	, testing loss - 344307.37500	
6478	 steps: training loss - 80863.43750	, testing loss - 343906.25000	
6479	 steps: training loss - 130214.31250	, testing loss - 343405.28125	
6480	 steps: training loss - 115117.89062	, testing loss - 343246.59375	
6481	 steps: training loss - 109172.97656	, testing loss - 343234.00000	
6482	 steps: training loss - 102312.03906	, testing loss - 344134.81250	
6483	 steps: training loss - 126597.72656	, testing loss - 345333.96875	
6484	 steps: training loss - 112558.18750	, testing loss - 346288.46875	
6485	 steps: training loss - 110732.83594	, testing loss - 347319.37500	
6486	 steps: training loss - 132417.81250	, testing loss - 348233.28125	
6487	 steps: training loss - 109343.14062	, testing loss - 349622.31250	
6488	 steps: training loss - 146242.09375	, testing loss - 350549.96875	
6489	 steps: training loss - 136841.79688	, testing loss - 351818.78125	
6490	 steps: training loss - 103153.49219	, testing loss - 353184.53125	
6491	 steps: training loss - 101984.37500	, testing loss - 355720.71875	
6492	 steps: training loss - 121226.13281	, testing loss - 359352.53125	
6493	 steps: training loss - 92763.28906	, testing loss - 361621.46875	
6494	 steps: training loss - 106070.21875	, testing loss - 361985.62500	
6495	 steps: training loss - 114055.53125	, testing loss - 360434.00000	
6496	 steps: training loss - 98153.92969	, testing loss - 358246.84375	
6497	 steps: training loss - 101898.36719	, testing loss - 355118.71875	
6498	 steps: training loss - 90932.34375	, testing loss - 353067.62500	
6499	 steps: training loss - 124669.64062	, testing loss - 351441.06250	
6500	 steps: training loss - 106052.32812	, testing loss - 349617.46875	
6501	 steps: training loss - 125288.79688	, testing loss - 347326.34375	
6502	 steps: training loss - 99666.67188	, testing loss - 345543.93750	
6503	 steps: training loss - 114743.67188	, testing loss - 344543.93750	
6504	 steps: training loss - 88906.07812	, testing loss - 344175.90625	
6505	 steps: training loss - 108807.20312	, testing loss - 344064.62500	
6506	 steps: training loss - 104414.87500	, testing loss - 343904.78125	
6507	 steps: training loss - 127140.14062	, testing loss - 343539.59375	
6508	 steps: training loss - 111551.49219	, testing loss - 343061.90625	
6509	 steps: training loss - 104350.32031	, testing loss - 342944.50000	
6510	 steps: training loss - 127815.75781	, testing loss - 343149.93750	
6511	 steps: training loss - 78164.10938	, testing loss - 343726.81250	
6512	 steps: training loss - 98361.37500	, testing loss - 344553.31250	
6513	 steps: training loss - 131470.56250	, testing loss - 345986.15625	
6514	 steps: training loss - 121344.47656	, testing loss - 347440.75000	
6515	 steps: training loss - 136283.48438	, testing loss - 349624.25000	
6516	 steps: training loss - 115411.82812	, testing loss - 352547.37500	
6517	 steps: training loss - 132781.70312	, testing loss - 356204.93750	
6518	 steps: training loss - 137200.95312	, testing loss - 360433.06250	
6519	 steps: training loss - 112727.57031	, testing loss - 364381.65625	
6520	 steps: training loss - 96533.08594	, testing loss - 366270.18750	
6521	 steps: training loss - 92396.80469	, testing loss - 367579.31250	
6522	 steps: training loss - 99439.10156	, testing loss - 367888.71875	
6523	 steps: training loss - 117312.74219	, testing loss - 366876.90625	
6524	 steps: training loss - 123617.63281	, testing loss - 366353.34375	
6525	 steps: training loss - 121449.46094	, testing loss - 364130.37500	
6526	 steps: training loss - 118460.21094	, testing loss - 360946.50000	
6527	 steps: training loss - 107339.70312	, testing loss - 357526.68750	
6528	 steps: training loss - 130241.90625	, testing loss - 354485.81250	
6529	 steps: training loss - 93911.06250	, testing loss - 351450.06250	
6530	 steps: training loss - 127856.50000	, testing loss - 348480.93750	
6531	 steps: training loss - 118184.67188	, testing loss - 346190.68750	
6532	 steps: training loss - 123732.45312	, testing loss - 344632.68750	
6533	 steps: training loss - 107146.27344	, testing loss - 344325.15625	
6534	 steps: training loss - 112906.85938	, testing loss - 344044.84375	
6535	 steps: training loss - 97585.46875	, testing loss - 344016.46875	
6536	 steps: training loss - 110090.38281	, testing loss - 344327.40625	
6537	 steps: training loss - 125335.06250	, testing loss - 344500.59375	
6538	 steps: training loss - 101367.38281	, testing loss - 344540.87500	
6539	 steps: training loss - 101789.29688	, testing loss - 344276.12500	
6540	 steps: training loss - 124916.75781	, testing loss - 344101.21875	
6541	 steps: training loss - 88864.35156	, testing loss - 344383.46875	
6542	 steps: training loss - 100573.96094	, testing loss - 344704.71875	
6543	 steps: training loss - 107926.42969	, testing loss - 344955.37500	
6544	 steps: training loss - 88386.24219	, testing loss - 345088.43750	
6545	 steps: training loss - 130140.70312	, testing loss - 344737.87500	
6546	 steps: training loss - 127493.33594	, testing loss - 344345.96875	
6547	 steps: training loss - 132635.28125	, testing loss - 344589.37500	
6548	 steps: training loss - 129960.72656	, testing loss - 345401.40625	
6549	 steps: training loss - 121362.66406	, testing loss - 346962.56250	
6550	 steps: training loss - 86130.35156	, testing loss - 348841.31250	
6551	 steps: training loss - 111747.30469	, testing loss - 350364.31250	
6552	 steps: training loss - 134811.87500	, testing loss - 352212.03125	
6553	 steps: training loss - 106170.51562	, testing loss - 353884.81250	
6554	 steps: training loss - 116639.13281	, testing loss - 355517.56250	
6555	 steps: training loss - 111911.37500	, testing loss - 356623.00000	
6556	 steps: training loss - 109229.32031	, testing loss - 358126.81250	
6557	 steps: training loss - 109923.75000	, testing loss - 360680.68750	
6558	 steps: training loss - 107523.50000	, testing loss - 363133.46875	
6559	 steps: training loss - 121310.10156	, testing loss - 364042.03125	
6560	 steps: training loss - 94298.76562	, testing loss - 364257.53125	
6561	 steps: training loss - 117516.82812	, testing loss - 363937.15625	
6562	 steps: training loss - 142597.89062	, testing loss - 362489.87500	
6563	 steps: training loss - 130354.99219	, testing loss - 361827.25000	
6564	 steps: training loss - 108468.15625	, testing loss - 360703.84375	
6565	 steps: training loss - 124190.93750	, testing loss - 360561.78125	
6566	 steps: training loss - 118750.03906	, testing loss - 360730.93750	
6567	 steps: training loss - 93649.21875	, testing loss - 361549.53125	
6568	 steps: training loss - 118977.45312	, testing loss - 362287.87500	
6569	 steps: training loss - 133840.18750	, testing loss - 362971.21875	
6570	 steps: training loss - 123092.80469	, testing loss - 362989.75000	
6571	 steps: training loss - 115002.55469	, testing loss - 362774.75000	
6572	 steps: training loss - 122734.05469	, testing loss - 361181.87500	
6573	 steps: training loss - 98587.57812	, testing loss - 359008.21875	
6574	 steps: training loss - 120757.25000	, testing loss - 357528.21875	
6575	 steps: training loss - 108381.14844	, testing loss - 357154.18750	
6576	 steps: training loss - 101004.50781	, testing loss - 356386.43750	
6577	 steps: training loss - 87359.20312	, testing loss - 355531.12500	
6578	 steps: training loss - 114727.77344	, testing loss - 354353.37500	
6579	 steps: training loss - 116851.85938	, testing loss - 353604.03125	
6580	 steps: training loss - 86228.64844	, testing loss - 352555.18750	
6581	 steps: training loss - 97459.87500	, testing loss - 351055.37500	
6582	 steps: training loss - 127763.85156	, testing loss - 349807.18750	
6583	 steps: training loss - 93807.61719	, testing loss - 349525.18750	
6584	 steps: training loss - 123680.16406	, testing loss - 349466.18750	
6585	 steps: training loss - 118111.74219	, testing loss - 350286.31250	
6586	 steps: training loss - 94824.00781	, testing loss - 352363.81250	
6587	 steps: training loss - 106552.37500	, testing loss - 354080.90625	
6588	 steps: training loss - 89432.80469	, testing loss - 355351.18750	
6589	 steps: training loss - 96172.53125	, testing loss - 355501.59375	
6590	 steps: training loss - 113908.61719	, testing loss - 355065.50000	
6591	 steps: training loss - 92615.39844	, testing loss - 354761.90625	
6592	 steps: training loss - 116991.11719	, testing loss - 355028.15625	
6593	 steps: training loss - 95245.25000	, testing loss - 355647.81250	
6594	 steps: training loss - 119247.92188	, testing loss - 356180.46875	
6595	 steps: training loss - 84387.01562	, testing loss - 356191.21875	
6596	 steps: training loss - 116994.57812	, testing loss - 356022.03125	
6597	 steps: training loss - 109138.86719	, testing loss - 355146.46875	
6598	 steps: training loss - 116985.27344	, testing loss - 353772.81250	
6599	 steps: training loss - 94126.73438	, testing loss - 353168.65625	
6600	 steps: training loss - 96546.35938	, testing loss - 353226.12500	
6601	 steps: training loss - 97968.90625	, testing loss - 353058.15625	
6602	 steps: training loss - 117979.67188	, testing loss - 353275.06250	
6603	 steps: training loss - 120228.21094	, testing loss - 353738.78125	
6604	 steps: training loss - 110551.71094	, testing loss - 353596.56250	
6605	 steps: training loss - 116014.12500	, testing loss - 353116.34375	
6606	 steps: training loss - 106891.00781	, testing loss - 352326.37500	
6607	 steps: training loss - 100392.52344	, testing loss - 351449.59375	
6608	 steps: training loss - 126004.92188	, testing loss - 350828.78125	
6609	 steps: training loss - 101359.76562	, testing loss - 350410.65625	
6610	 steps: training loss - 105552.64844	, testing loss - 350051.46875	
6611	 steps: training loss - 113685.85156	, testing loss - 349714.90625	
6612	 steps: training loss - 125011.45312	, testing loss - 349446.31250	
6613	 steps: training loss - 123811.68750	, testing loss - 349079.28125	
6614	 steps: training loss - 115472.60938	, testing loss - 349718.40625	
6615	 steps: training loss - 126166.10156	, testing loss - 350286.00000	
6616	 steps: training loss - 91482.98438	, testing loss - 350177.53125	
6617	 steps: training loss - 101875.71875	, testing loss - 349970.43750	
6618	 steps: training loss - 127114.87500	, testing loss - 350003.21875	
6619	 steps: training loss - 96175.09375	, testing loss - 349883.21875	
6620	 steps: training loss - 102029.59375	, testing loss - 349943.00000	
6621	 steps: training loss - 116113.82031	, testing loss - 350142.50000	
6622	 steps: training loss - 86846.58594	, testing loss - 350331.96875	
6623	 steps: training loss - 103656.77344	, testing loss - 351406.43750	
6624	 steps: training loss - 110076.39062	, testing loss - 353324.65625	
6625	 steps: training loss - 112608.96875	, testing loss - 354561.65625	
6626	 steps: training loss - 101118.92188	, testing loss - 355465.06250	
6627	 steps: training loss - 109142.06250	, testing loss - 355727.68750	
6628	 steps: training loss - 117869.67969	, testing loss - 355656.31250	
6629	 steps: training loss - 113037.05469	, testing loss - 356194.40625	
6630	 steps: training loss - 117033.85156	, testing loss - 355915.21875	
6631	 steps: training loss - 103436.97656	, testing loss - 354899.21875	
6632	 steps: training loss - 112568.23438	, testing loss - 353991.12500	
6633	 steps: training loss - 105539.66406	, testing loss - 352299.71875	
6634	 steps: training loss - 140938.46875	, testing loss - 351185.75000	
6635	 steps: training loss - 108757.41406	, testing loss - 350530.93750	
6636	 steps: training loss - 116940.32031	, testing loss - 350106.25000	
6637	 steps: training loss - 112611.46094	, testing loss - 350620.12500	
6638	 steps: training loss - 122798.89062	, testing loss - 351025.71875	
6639	 steps: training loss - 104005.47656	, testing loss - 352172.46875	
6640	 steps: training loss - 86617.57031	, testing loss - 353346.21875	
6641	 steps: training loss - 109799.73438	, testing loss - 354214.46875	
6642	 steps: training loss - 114507.10156	, testing loss - 354697.68750	
6643	 steps: training loss - 119704.71875	, testing loss - 354337.46875	
6644	 steps: training loss - 114469.97656	, testing loss - 352576.12500	
6645	 steps: training loss - 85394.39062	, testing loss - 350902.53125	
6646	 steps: training loss - 118675.96094	, testing loss - 349757.96875	
6647	 steps: training loss - 125031.95312	, testing loss - 348806.12500	
6648	 steps: training loss - 88669.51562	, testing loss - 347491.15625	
6649	 steps: training loss - 109150.17969	, testing loss - 346154.09375	
6650	 steps: training loss - 92701.33594	, testing loss - 344567.59375	
6651	 steps: training loss - 85918.26562	, testing loss - 344098.12500	
6652	 steps: training loss - 127601.57031	, testing loss - 344509.53125	
6653	 steps: training loss - 105902.57031	, testing loss - 345518.81250	
6654	 steps: training loss - 105483.31250	, testing loss - 346746.21875	
6655	 steps: training loss - 114438.28125	, testing loss - 348101.53125	
6656	 steps: training loss - 100653.10156	, testing loss - 350119.34375	
6657	 steps: training loss - 116427.06250	, testing loss - 351474.71875	
6658	 steps: training loss - 98716.41406	, testing loss - 352081.40625	
6659	 steps: training loss - 122957.85938	, testing loss - 352276.03125	
6660	 steps: training loss - 102828.50000	, testing loss - 352563.03125	
6661	 steps: training loss - 111110.74219	, testing loss - 352969.28125	
6662	 steps: training loss - 95119.96875	, testing loss - 352967.53125	
6663	 steps: training loss - 113987.33594	, testing loss - 353154.84375	
6664	 steps: training loss - 112873.50000	, testing loss - 354392.03125	
6665	 steps: training loss - 107347.54688	, testing loss - 355035.00000	
6666	 steps: training loss - 133256.12500	, testing loss - 355229.75000	
6667	 steps: training loss - 108486.33594	, testing loss - 355746.59375	
6668	 steps: training loss - 110425.65625	, testing loss - 356896.46875	
6669	 steps: training loss - 108569.14844	, testing loss - 357754.18750	
6670	 steps: training loss - 120347.67969	, testing loss - 358629.21875	
6671	 steps: training loss - 116848.97656	, testing loss - 359745.34375	
6672	 steps: training loss - 120843.63281	, testing loss - 360814.84375	
6673	 steps: training loss - 95572.01562	, testing loss - 360294.53125	
6674	 steps: training loss - 114380.42188	, testing loss - 358731.93750	
6675	 steps: training loss - 106642.20312	, testing loss - 357749.34375	
6676	 steps: training loss - 111417.54688	, testing loss - 357549.68750	
6677	 steps: training loss - 112067.42188	, testing loss - 357682.81250	
6678	 steps: training loss - 85304.13281	, testing loss - 357181.00000	
6679	 steps: training loss - 132297.15625	, testing loss - 356937.09375	
6680	 steps: training loss - 103142.07812	, testing loss - 357579.09375	
6681	 steps: training loss - 99362.25000	, testing loss - 357831.28125	
6682	 steps: training loss - 111099.10938	, testing loss - 357487.31250	
6683	 steps: training loss - 104544.71875	, testing loss - 357200.62500	
6684	 steps: training loss - 96002.34375	, testing loss - 356380.43750	
6685	 steps: training loss - 105428.11719	, testing loss - 355527.62500	
6686	 steps: training loss - 94155.87500	, testing loss - 353804.25000	
6687	 steps: training loss - 106510.90625	, testing loss - 351814.43750	
6688	 steps: training loss - 94831.85938	, testing loss - 350230.84375	
6689	 steps: training loss - 99139.09375	, testing loss - 349284.12500	
6690	 steps: training loss - 125457.52344	, testing loss - 348835.28125	
6691	 steps: training loss - 83640.75000	, testing loss - 348655.15625	
6692	 steps: training loss - 103313.51562	, testing loss - 349030.78125	
6693	 steps: training loss - 126509.24219	, testing loss - 349531.87500	
6694	 steps: training loss - 79646.50781	, testing loss - 349709.03125	
6695	 steps: training loss - 107544.37500	, testing loss - 349392.53125	
6696	 steps: training loss - 144209.07812	, testing loss - 348493.93750	
6697	 steps: training loss - 122270.83594	, testing loss - 347674.68750	
6698	 steps: training loss - 92554.52344	, testing loss - 346394.18750	
6699	 steps: training loss - 109210.71094	, testing loss - 345406.62500	
6700	 steps: training loss - 95016.79688	, testing loss - 345056.18750	
6701	 steps: training loss - 120057.26562	, testing loss - 345329.50000	
6702	 steps: training loss - 128150.39844	, testing loss - 346054.18750	
6703	 steps: training loss - 113260.10156	, testing loss - 346625.62500	
6704	 steps: training loss - 114603.19531	, testing loss - 348563.87500	
6705	 steps: training loss - 94793.84375	, testing loss - 350553.62500	
6706	 steps: training loss - 105278.94531	, testing loss - 352082.40625	
6707	 steps: training loss - 122256.67188	, testing loss - 353227.40625	
6708	 steps: training loss - 108614.17188	, testing loss - 353586.93750	
6709	 steps: training loss - 80050.77344	, testing loss - 354275.25000	
6710	 steps: training loss - 123157.70312	, testing loss - 355608.12500	
6711	 steps: training loss - 108173.41406	, testing loss - 355380.53125	
6712	 steps: training loss - 113187.12500	, testing loss - 354264.00000	
6713	 steps: training loss - 120886.70312	, testing loss - 354195.25000	
6714	 steps: training loss - 100253.06250	, testing loss - 353779.90625	
6715	 steps: training loss - 112924.84375	, testing loss - 352623.15625	
6716	 steps: training loss - 121267.38281	, testing loss - 351589.15625	
6717	 steps: training loss - 133006.15625	, testing loss - 351070.28125	
6718	 steps: training loss - 107971.83594	, testing loss - 351325.37500	
6719	 steps: training loss - 101714.50781	, testing loss - 351580.43750	
6720	 steps: training loss - 103810.00000	, testing loss - 352286.09375	
6721	 steps: training loss - 108894.05469	, testing loss - 352340.09375	
6722	 steps: training loss - 101181.06250	, testing loss - 352467.46875	
6723	 steps: training loss - 114211.52344	, testing loss - 352115.59375	
6724	 steps: training loss - 92879.94531	, testing loss - 351570.09375	
6725	 steps: training loss - 99573.86719	, testing loss - 351408.06250	
6726	 steps: training loss - 95603.43750	, testing loss - 351508.56250	
6727	 steps: training loss - 123154.07031	, testing loss - 351109.84375	
6728	 steps: training loss - 129435.57031	, testing loss - 349886.12500	
6729	 steps: training loss - 124846.99219	, testing loss - 347731.59375	
6730	 steps: training loss - 101194.64844	, testing loss - 345976.50000	
6731	 steps: training loss - 114141.22656	, testing loss - 345109.65625	
6732	 steps: training loss - 116398.71094	, testing loss - 344858.03125	
6733	 steps: training loss - 120000.21875	, testing loss - 344317.50000	
6734	 steps: training loss - 95897.27344	, testing loss - 343837.62500	
6735	 steps: training loss - 100294.31250	, testing loss - 342936.56250	
6736	 steps: training loss - 104063.42188	, testing loss - 342520.25000	
6737	 steps: training loss - 100760.21094	, testing loss - 342312.15625	
6738	 steps: training loss - 115053.60938	, testing loss - 342071.12500	
6739	 steps: training loss - 106219.26562	, testing loss - 342298.09375	
6740	 steps: training loss - 109909.79688	, testing loss - 342890.87500	
6741	 steps: training loss - 106270.75781	, testing loss - 343565.06250	
6742	 steps: training loss - 104169.50000	, testing loss - 344195.96875	
6743	 steps: training loss - 114868.64062	, testing loss - 344475.65625	
6744	 steps: training loss - 107236.03125	, testing loss - 344605.46875	
6745	 steps: training loss - 103309.70312	, testing loss - 344415.75000	
6746	 steps: training loss - 82780.32031	, testing loss - 343934.12500	
6747	 steps: training loss - 100461.45312	, testing loss - 343576.50000	
6748	 steps: training loss - 91665.71875	, testing loss - 343347.18750	
6749	 steps: training loss - 107919.76562	, testing loss - 343140.81250	
6750	 steps: training loss - 101098.58594	, testing loss - 342729.06250	
6751	 steps: training loss - 106917.75781	, testing loss - 342093.40625	
6752	 steps: training loss - 88329.14062	, testing loss - 341571.68750	
6753	 steps: training loss - 115299.50000	, testing loss - 341151.78125	
6754	 steps: training loss - 109580.19531	, testing loss - 341348.71875	
6755	 steps: training loss - 130479.21875	, testing loss - 342025.31250	
6756	 steps: training loss - 132652.46875	, testing loss - 342515.12500	
6757	 steps: training loss - 130346.46875	, testing loss - 343968.12500	
6758	 steps: training loss - 117144.17188	, testing loss - 345685.12500	
6759	 steps: training loss - 137124.26562	, testing loss - 347692.40625	
6760	 steps: training loss - 90762.03125	, testing loss - 349100.06250	
6761	 steps: training loss - 120456.25000	, testing loss - 350751.62500	
6762	 steps: training loss - 101018.22656	, testing loss - 352240.09375	
6763	 steps: training loss - 97480.52344	, testing loss - 353744.43750	
6764	 steps: training loss - 94776.90625	, testing loss - 355022.28125	
6765	 steps: training loss - 113920.42188	, testing loss - 354866.09375	
6766	 steps: training loss - 116971.36719	, testing loss - 354057.71875	
6767	 steps: training loss - 116452.57031	, testing loss - 353894.34375	
6768	 steps: training loss - 103647.71094	, testing loss - 353484.56250	
6769	 steps: training loss - 110183.71094	, testing loss - 353277.81250	
6770	 steps: training loss - 117740.86719	, testing loss - 353247.53125	
6771	 steps: training loss - 104713.78906	, testing loss - 352159.15625	
6772	 steps: training loss - 115291.46875	, testing loss - 351985.21875	
6773	 steps: training loss - 120924.81250	, testing loss - 352214.03125	
6774	 steps: training loss - 114493.51562	, testing loss - 353801.87500	
6775	 steps: training loss - 105488.21094	, testing loss - 355636.75000	
6776	 steps: training loss - 106726.09375	, testing loss - 356836.06250	
6777	 steps: training loss - 114599.00000	, testing loss - 356831.43750	
6778	 steps: training loss - 127318.20312	, testing loss - 356270.09375	
6779	 steps: training loss - 93185.06250	, testing loss - 354124.53125	
6780	 steps: training loss - 107450.15625	, testing loss - 352527.71875	
6781	 steps: training loss - 125192.92969	, testing loss - 350906.84375	
6782	 steps: training loss - 114954.21094	, testing loss - 348853.09375	
6783	 steps: training loss - 110585.91406	, testing loss - 346724.96875	
6784	 steps: training loss - 103764.58594	, testing loss - 344882.09375	
6785	 steps: training loss - 134373.46875	, testing loss - 344071.96875	
6786	 steps: training loss - 98245.76562	, testing loss - 343839.09375	
6787	 steps: training loss - 103950.60938	, testing loss - 343456.78125	
6788	 steps: training loss - 102620.07812	, testing loss - 343366.06250	
6789	 steps: training loss - 109740.62500	, testing loss - 342943.09375	
6790	 steps: training loss - 103456.55469	, testing loss - 342264.68750	
6791	 steps: training loss - 109252.63281	, testing loss - 342006.09375	
6792	 steps: training loss - 82385.32812	, testing loss - 342529.00000	
6793	 steps: training loss - 110421.69531	, testing loss - 343187.53125	
6794	 steps: training loss - 105355.73438	, testing loss - 343582.50000	
6795	 steps: training loss - 115688.92188	, testing loss - 343448.31250	
6796	 steps: training loss - 125657.37500	, testing loss - 343450.78125	
6797	 steps: training loss - 121159.34375	, testing loss - 344525.25000	
6798	 steps: training loss - 113271.73438	, testing loss - 346284.43750	
6799	 steps: training loss - 121942.25781	, testing loss - 348080.71875	
6800	 steps: training loss - 120521.54688	, testing loss - 348877.71875	
6801	 steps: training loss - 114871.82031	, testing loss - 349053.62500	
6802	 steps: training loss - 113476.25000	, testing loss - 348921.84375	
6803	 steps: training loss - 109751.42188	, testing loss - 348410.78125	
6804	 steps: training loss - 112768.36719	, testing loss - 348233.50000	
6805	 steps: training loss - 100823.05469	, testing loss - 348079.81250	
6806	 steps: training loss - 85625.14062	, testing loss - 348238.12500	
6807	 steps: training loss - 92915.53906	, testing loss - 348243.09375	
6808	 steps: training loss - 123166.47656	, testing loss - 347948.00000	
6809	 steps: training loss - 78615.35938	, testing loss - 347795.12500	
6810	 steps: training loss - 109875.33594	, testing loss - 347558.62500	
6811	 steps: training loss - 113406.39062	, testing loss - 346872.53125	
6812	 steps: training loss - 113566.50000	, testing loss - 346332.34375	
6813	 steps: training loss - 118821.18750	, testing loss - 345968.25000	
6814	 steps: training loss - 120259.86719	, testing loss - 345779.56250	
6815	 steps: training loss - 109763.73438	, testing loss - 345402.43750	
6816	 steps: training loss - 94889.99219	, testing loss - 344936.84375	
6817	 steps: training loss - 115923.21094	, testing loss - 344734.65625	
6818	 steps: training loss - 101645.05469	, testing loss - 344161.18750	
6819	 steps: training loss - 114676.40625	, testing loss - 343199.28125	
6820	 steps: training loss - 95822.07812	, testing loss - 342414.25000	
6821	 steps: training loss - 127871.59375	, testing loss - 342048.50000	
6822	 steps: training loss - 136482.37500	, testing loss - 341904.12500	
6823	 steps: training loss - 125064.09375	, testing loss - 341638.53125	
6824	 steps: training loss - 108695.76562	, testing loss - 341592.00000	
6825	 steps: training loss - 114124.42188	, testing loss - 342416.09375	
6826	 steps: training loss - 104650.89844	, testing loss - 343505.46875	
6827	 steps: training loss - 102086.12500	, testing loss - 344476.28125	
6828	 steps: training loss - 127119.15625	, testing loss - 345914.37500	
6829	 steps: training loss - 126826.21875	, testing loss - 347813.59375	
6830	 steps: training loss - 112695.56250	, testing loss - 349167.65625	
6831	 steps: training loss - 94091.70312	, testing loss - 350343.40625	
6832	 steps: training loss - 112127.39844	, testing loss - 351587.09375	
6833	 steps: training loss - 105475.50000	, testing loss - 352376.12500	
6834	 steps: training loss - 127078.62500	, testing loss - 352224.50000	
6835	 steps: training loss - 87134.68750	, testing loss - 352002.50000	
6836	 steps: training loss - 109296.06250	, testing loss - 351574.18750	
6837	 steps: training loss - 131961.87500	, testing loss - 351580.06250	
6838	 steps: training loss - 92494.62500	, testing loss - 351829.21875	
6839	 steps: training loss - 112837.10938	, testing loss - 352289.43750	
6840	 steps: training loss - 128520.51562	, testing loss - 352713.12500	
6841	 steps: training loss - 133215.53125	, testing loss - 353515.84375	
6842	 steps: training loss - 93113.37500	, testing loss - 354146.00000	
6843	 steps: training loss - 122690.71094	, testing loss - 354548.06250	
6844	 steps: training loss - 111041.63281	, testing loss - 354629.00000	
6845	 steps: training loss - 119640.57031	, testing loss - 354013.78125	
6846	 steps: training loss - 117160.22656	, testing loss - 354158.06250	
6847	 steps: training loss - 109528.85156	, testing loss - 353838.28125	
6848	 steps: training loss - 132020.37500	, testing loss - 352885.40625	
6849	 steps: training loss - 104428.67969	, testing loss - 352121.81250	
6850	 steps: training loss - 126040.47656	, testing loss - 350963.65625	
6851	 steps: training loss - 96272.86719	, testing loss - 350037.31250	
6852	 steps: training loss - 120397.10156	, testing loss - 348637.81250	
6853	 steps: training loss - 132964.78125	, testing loss - 347816.00000	
6854	 steps: training loss - 100463.85156	, testing loss - 346998.62500	
6855	 steps: training loss - 145291.96875	, testing loss - 346495.96875	
6856	 steps: training loss - 116403.78125	, testing loss - 346443.21875	
6857	 steps: training loss - 104874.85938	, testing loss - 347171.25000	
6858	 steps: training loss - 97662.24219	, testing loss - 348595.15625	
6859	 steps: training loss - 110724.06250	, testing loss - 349921.21875	
6860	 steps: training loss - 96677.89844	, testing loss - 350914.81250	
6861	 steps: training loss - 109280.48438	, testing loss - 351529.78125	
6862	 steps: training loss - 123281.84375	, testing loss - 351916.93750	
6863	 steps: training loss - 115186.26562	, testing loss - 351442.46875	
6864	 steps: training loss - 120528.22656	, testing loss - 350228.40625	
6865	 steps: training loss - 143621.93750	, testing loss - 349704.46875	
6866	 steps: training loss - 98015.53125	, testing loss - 349685.40625	
6867	 steps: training loss - 107334.92188	, testing loss - 349711.31250	
6868	 steps: training loss - 91001.17969	, testing loss - 349174.40625	
6869	 steps: training loss - 91971.54688	, testing loss - 347959.37500	
6870	 steps: training loss - 107813.69531	, testing loss - 346064.84375	
6871	 steps: training loss - 105198.80469	, testing loss - 344322.15625	
6872	 steps: training loss - 110607.84375	, testing loss - 342813.84375	
6873	 steps: training loss - 137786.21875	, testing loss - 341680.31250	
6874	 steps: training loss - 118163.31250	, testing loss - 341260.40625	
6875	 steps: training loss - 88098.85156	, testing loss - 341335.25000	
6876	 steps: training loss - 93077.78125	, testing loss - 341540.25000	
6877	 steps: training loss - 107627.81250	, testing loss - 341821.62500	
6878	 steps: training loss - 121128.46875	, testing loss - 341870.03125	
6879	 steps: training loss - 118837.57812	, testing loss - 341894.43750	
6880	 steps: training loss - 98833.68750	, testing loss - 341751.68750	
6881	 steps: training loss - 82451.10156	, testing loss - 341404.37500	
6882	 steps: training loss - 113781.57812	, testing loss - 341420.28125	
6883	 steps: training loss - 102501.39062	, testing loss - 341822.28125	
6884	 steps: training loss - 103822.61719	, testing loss - 342190.93750	
6885	 steps: training loss - 111095.05469	, testing loss - 342826.75000	
6886	 steps: training loss - 121362.65625	, testing loss - 343878.96875	
6887	 steps: training loss - 88283.45312	, testing loss - 344269.78125	
6888	 steps: training loss - 96275.80469	, testing loss - 344232.18750	
6889	 steps: training loss - 92076.64844	, testing loss - 344237.34375	
6890	 steps: training loss - 116541.63281	, testing loss - 344438.68750	
6891	 steps: training loss - 98622.41406	, testing loss - 344928.25000	
6892	 steps: training loss - 119783.93750	, testing loss - 345430.31250	
6893	 steps: training loss - 104634.21875	, testing loss - 345820.68750	
6894	 steps: training loss - 144716.71875	, testing loss - 346567.37500	
6895	 steps: training loss - 97965.41406	, testing loss - 348330.71875	
6896	 steps: training loss - 124294.82812	, testing loss - 349829.50000	
6897	 steps: training loss - 106248.50781	, testing loss - 349896.87500	
6898	 steps: training loss - 78480.25000	, testing loss - 349598.96875	
6899	 steps: training loss - 116947.38281	, testing loss - 349645.06250	
6900	 steps: training loss - 99690.84375	, testing loss - 349003.87500	
6901	 steps: training loss - 113030.00781	, testing loss - 348218.53125	
6902	 steps: training loss - 102193.84375	, testing loss - 346955.18750	
6903	 steps: training loss - 98619.89844	, testing loss - 346034.12500	
6904	 steps: training loss - 101929.27344	, testing loss - 346289.25000	
6905	 steps: training loss - 101286.60938	, testing loss - 346808.84375	
6906	 steps: training loss - 74720.34375	, testing loss - 346849.81250	
6907	 steps: training loss - 106751.92188	, testing loss - 346856.50000	
6908	 steps: training loss - 108333.07812	, testing loss - 346182.31250	
6909	 steps: training loss - 93677.29688	, testing loss - 344834.34375	
6910	 steps: training loss - 152781.67188	, testing loss - 343444.12500	
6911	 steps: training loss - 115368.31250	, testing loss - 342609.68750	
6912	 steps: training loss - 102805.78906	, testing loss - 341949.68750	
6913	 steps: training loss - 114632.68750	, testing loss - 341724.18750	
6914	 steps: training loss - 110528.92969	, testing loss - 342100.34375	
6915	 steps: training loss - 105921.29688	, testing loss - 343158.96875	
6916	 steps: training loss - 134381.31250	, testing loss - 343797.34375	
6917	 steps: training loss - 108575.03125	, testing loss - 344652.03125	
6918	 steps: training loss - 108635.07031	, testing loss - 345634.59375	
6919	 steps: training loss - 112380.47656	, testing loss - 347774.87500	
6920	 steps: training loss - 90411.50781	, testing loss - 349797.84375	
6921	 steps: training loss - 112082.25000	, testing loss - 351302.56250	
6922	 steps: training loss - 99360.23438	, testing loss - 353056.68750	
6923	 steps: training loss - 100990.27344	, testing loss - 354620.56250	
6924	 steps: training loss - 112735.44531	, testing loss - 354784.12500	
6925	 steps: training loss - 120412.57031	, testing loss - 355300.84375	
6926	 steps: training loss - 94885.96094	, testing loss - 356147.68750	
6927	 steps: training loss - 118285.67188	, testing loss - 356430.25000	
6928	 steps: training loss - 110941.22656	, testing loss - 356932.71875	
6929	 steps: training loss - 111753.18750	, testing loss - 357145.93750	
6930	 steps: training loss - 120933.44531	, testing loss - 356548.40625	
6931	 steps: training loss - 136378.75000	, testing loss - 355093.90625	
6932	 steps: training loss - 105682.60156	, testing loss - 354447.59375	
6933	 steps: training loss - 112114.47656	, testing loss - 354917.37500	
6934	 steps: training loss - 103326.67969	, testing loss - 355746.84375	
6935	 steps: training loss - 103003.91406	, testing loss - 355564.37500	
6936	 steps: training loss - 117407.70312	, testing loss - 355940.37500	
6937	 steps: training loss - 116737.35156	, testing loss - 356842.43750	
6938	 steps: training loss - 131238.07812	, testing loss - 358221.18750	
6939	 steps: training loss - 102316.68750	, testing loss - 359030.40625	
6940	 steps: training loss - 98378.35938	, testing loss - 359094.81250	
6941	 steps: training loss - 98853.56250	, testing loss - 358636.43750	
6942	 steps: training loss - 124711.11719	, testing loss - 357337.53125	
6943	 steps: training loss - 110714.94531	, testing loss - 357176.15625	
6944	 steps: training loss - 130458.99219	, testing loss - 357047.46875	
6945	 steps: training loss - 108686.35156	, testing loss - 355853.50000	
6946	 steps: training loss - 104620.04688	, testing loss - 355138.03125	
6947	 steps: training loss - 112837.85938	, testing loss - 355154.18750	
6948	 steps: training loss - 99813.71875	, testing loss - 354881.53125	
6949	 steps: training loss - 111040.31250	, testing loss - 355118.93750	
6950	 steps: training loss - 93637.60938	, testing loss - 355166.71875	
6951	 steps: training loss - 111583.94531	, testing loss - 356030.40625	
6952	 steps: training loss - 118386.03906	, testing loss - 356730.46875	
6953	 steps: training loss - 99438.63281	, testing loss - 358100.34375	
6954	 steps: training loss - 112243.89844	, testing loss - 360724.37500	
6955	 steps: training loss - 109590.55469	, testing loss - 362914.37500	
6956	 steps: training loss - 111035.18750	, testing loss - 363182.78125	
6957	 steps: training loss - 126723.10938	, testing loss - 362856.56250	
6958	 steps: training loss - 99019.89062	, testing loss - 361728.40625	
6959	 steps: training loss - 103287.60156	, testing loss - 362031.21875	
6960	 steps: training loss - 105764.05469	, testing loss - 362885.59375	
6961	 steps: training loss - 99801.14062	, testing loss - 363168.62500	
6962	 steps: training loss - 105251.81250	, testing loss - 364476.43750	
6963	 steps: training loss - 92044.05469	, testing loss - 365254.03125	
6964	 steps: training loss - 103589.56250	, testing loss - 365114.93750	
6965	 steps: training loss - 125687.88281	, testing loss - 363662.96875	
6966	 steps: training loss - 113111.31250	, testing loss - 361487.65625	
6967	 steps: training loss - 119792.69531	, testing loss - 360141.65625	
6968	 steps: training loss - 102035.06250	, testing loss - 359555.37500	
6969	 steps: training loss - 104301.25000	, testing loss - 358291.34375	
6970	 steps: training loss - 107550.92188	, testing loss - 356893.65625	
6971	 steps: training loss - 96980.92969	, testing loss - 356367.50000	
6972	 steps: training loss - 90738.87500	, testing loss - 356921.93750	
6973	 steps: training loss - 101695.42188	, testing loss - 356741.37500	
6974	 steps: training loss - 117652.75000	, testing loss - 356786.59375	
6975	 steps: training loss - 97446.89062	, testing loss - 356591.18750	
6976	 steps: training loss - 115177.74219	, testing loss - 356151.00000	
6977	 steps: training loss - 126633.75000	, testing loss - 355743.56250	
6978	 steps: training loss - 97408.63281	, testing loss - 355014.34375	
6979	 steps: training loss - 105960.96875	, testing loss - 355355.00000	
6980	 steps: training loss - 111614.96094	, testing loss - 355808.78125	
6981	 steps: training loss - 105029.60156	, testing loss - 355599.75000	
6982	 steps: training loss - 102067.25000	, testing loss - 355005.31250	
6983	 steps: training loss - 96940.96094	, testing loss - 353569.06250	
6984	 steps: training loss - 112786.74219	, testing loss - 351829.87500	
6985	 steps: training loss - 116180.79688	, testing loss - 350412.34375	
6986	 steps: training loss - 111640.39844	, testing loss - 349966.15625	
6987	 steps: training loss - 95932.23438	, testing loss - 349498.00000	
6988	 steps: training loss - 106067.17969	, testing loss - 348741.96875	
6989	 steps: training loss - 96295.06250	, testing loss - 347844.09375	
6990	 steps: training loss - 107552.52344	, testing loss - 347375.68750	
6991	 steps: training loss - 113800.32031	, testing loss - 347115.00000	
6992	 steps: training loss - 127679.10938	, testing loss - 346713.93750	
6993	 steps: training loss - 119410.74219	, testing loss - 346682.28125	
6994	 steps: training loss - 121753.64844	, testing loss - 346645.37500	
6995	 steps: training loss - 78511.31250	, testing loss - 347019.75000	
6996	 steps: training loss - 121899.35156	, testing loss - 347507.03125	
6997	 steps: training loss - 118488.46875	, testing loss - 347931.40625	
6998	 steps: training loss - 134786.59375	, testing loss - 347918.31250	
6999	 steps: training loss - 124401.37500	, testing loss - 348616.15625	
7000	 steps: training loss - 114631.87500	, testing loss - 350042.65625	
7001	 steps: training loss - 115695.04688	, testing loss - 351662.06250	
7002	 steps: training loss - 115194.89062	, testing loss - 353993.50000	
7003	 steps: training loss - 102708.85938	, testing loss - 356340.40625	
7004	 steps: training loss - 115082.60938	, testing loss - 357713.87500	
7005	 steps: training loss - 121426.97656	, testing loss - 358144.46875	
7006	 steps: training loss - 125945.59375	, testing loss - 359654.40625	
7007	 steps: training loss - 104700.60156	, testing loss - 360992.12500	
7008	 steps: training loss - 111480.27344	, testing loss - 362620.25000	
7009	 steps: training loss - 121427.89062	, testing loss - 362990.28125	
7010	 steps: training loss - 110825.32812	, testing loss - 363447.50000	
7011	 steps: training loss - 105515.77344	, testing loss - 363705.75000	
7012	 steps: training loss - 111342.01562	, testing loss - 364103.62500	
7013	 steps: training loss - 117610.25000	, testing loss - 365197.78125	
7014	 steps: training loss - 126830.10156	, testing loss - 365031.43750	
7015	 steps: training loss - 122192.57812	, testing loss - 363216.65625	
7016	 steps: training loss - 123981.36719	, testing loss - 360772.59375	
7017	 steps: training loss - 111090.72656	, testing loss - 358900.46875	
7018	 steps: training loss - 111279.85156	, testing loss - 357410.53125	
7019	 steps: training loss - 98396.09375	, testing loss - 356371.84375	
7020	 steps: training loss - 109016.28125	, testing loss - 355828.37500	
7021	 steps: training loss - 101320.65625	, testing loss - 354813.40625	
7022	 steps: training loss - 98831.32031	, testing loss - 353687.12500	
7023	 steps: training loss - 107712.96094	, testing loss - 352909.28125	
7024	 steps: training loss - 98550.83594	, testing loss - 351899.37500	
7025	 steps: training loss - 120107.83594	, testing loss - 351154.93750	
7026	 steps: training loss - 79521.28906	, testing loss - 350240.87500	
7027	 steps: training loss - 105992.07812	, testing loss - 349164.03125	
7028	 steps: training loss - 113891.86719	, testing loss - 348320.34375	
7029	 steps: training loss - 99411.20312	, testing loss - 347603.56250	
7030	 steps: training loss - 94296.16406	, testing loss - 346791.46875	
7031	 steps: training loss - 103331.64062	, testing loss - 345651.34375	
7032	 steps: training loss - 105696.42969	, testing loss - 344759.78125	
7033	 steps: training loss - 121935.36719	, testing loss - 343813.59375	
7034	 steps: training loss - 117836.71094	, testing loss - 343590.43750	
7035	 steps: training loss - 109399.64844	, testing loss - 343913.78125	
7036	 steps: training loss - 125400.75781	, testing loss - 344728.40625	
7037	 steps: training loss - 103404.96875	, testing loss - 345803.31250	
7038	 steps: training loss - 119241.39062	, testing loss - 347358.78125	
7039	 steps: training loss - 112224.93750	, testing loss - 349099.78125	
7040	 steps: training loss - 104799.17969	, testing loss - 351067.65625	
7041	 steps: training loss - 130411.22656	, testing loss - 352616.46875	
7042	 steps: training loss - 102751.59375	, testing loss - 354954.96875	
7043	 steps: training loss - 120300.90625	, testing loss - 356445.03125	
7044	 steps: training loss - 98962.03125	, testing loss - 357889.12500	
7045	 steps: training loss - 98046.17188	, testing loss - 359153.81250	
7046	 steps: training loss - 99225.71875	, testing loss - 360195.84375	
7047	 steps: training loss - 101527.68750	, testing loss - 359635.43750	
7048	 steps: training loss - 109782.62500	, testing loss - 358586.40625	
7049	 steps: training loss - 96752.88281	, testing loss - 356895.34375	
7050	 steps: training loss - 95906.35156	, testing loss - 355715.93750	
7051	 steps: training loss - 104408.29688	, testing loss - 354766.71875	
7052	 steps: training loss - 108645.44531	, testing loss - 354025.90625	
7053	 steps: training loss - 135024.84375	, testing loss - 354385.90625	
7054	 steps: training loss - 122879.42188	, testing loss - 355554.06250	
7055	 steps: training loss - 121477.89844	, testing loss - 358224.06250	
7056	 steps: training loss - 102359.00781	, testing loss - 361669.71875	
7057	 steps: training loss - 118911.10938	, testing loss - 365416.12500	
7058	 steps: training loss - 101791.10938	, testing loss - 369379.06250	
7059	 steps: training loss - 97820.72656	, testing loss - 372255.34375	
7060	 steps: training loss - 108703.57812	, testing loss - 375223.78125	
7061	 steps: training loss - 130068.99219	, testing loss - 376466.03125	
7062	 steps: training loss - 117197.78125	, testing loss - 377211.78125	
7063	 steps: training loss - 121677.71875	, testing loss - 376319.03125	
7064	 steps: training loss - 101930.70312	, testing loss - 375334.06250	
7065	 steps: training loss - 110852.23438	, testing loss - 374591.50000	
7066	 steps: training loss - 113753.10156	, testing loss - 372653.90625	
7067	 steps: training loss - 120168.71094	, testing loss - 370999.50000	
7068	 steps: training loss - 132903.29688	, testing loss - 369145.25000	
7069	 steps: training loss - 91858.58594	, testing loss - 366911.96875	
7070	 steps: training loss - 96734.26562	, testing loss - 364345.18750	
7071	 steps: training loss - 122653.97656	, testing loss - 360893.96875	
7072	 steps: training loss - 110691.32812	, testing loss - 357635.37500	
7073	 steps: training loss - 109365.00781	, testing loss - 353647.46875	
7074	 steps: training loss - 108737.62500	, testing loss - 350426.84375	
7075	 steps: training loss - 105825.46094	, testing loss - 348913.78125	
7076	 steps: training loss - 99677.76562	, testing loss - 347198.03125	
7077	 steps: training loss - 98465.05469	, testing loss - 345701.43750	
7078	 steps: training loss - 98003.75000	, testing loss - 344879.46875	
7079	 steps: training loss - 110666.43750	, testing loss - 344614.00000	
7080	 steps: training loss - 135874.32812	, testing loss - 345387.40625	
7081	 steps: training loss - 112854.40625	, testing loss - 346685.59375	
7082	 steps: training loss - 110936.26562	, testing loss - 347599.21875	
7083	 steps: training loss - 113363.55469	, testing loss - 348706.65625	
7084	 steps: training loss - 120810.85156	, testing loss - 349155.21875	
7085	 steps: training loss - 107594.46094	, testing loss - 349308.12500	
7086	 steps: training loss - 97123.33594	, testing loss - 348967.96875	
7087	 steps: training loss - 113920.35156	, testing loss - 349074.50000	
7088	 steps: training loss - 123730.34375	, testing loss - 349525.96875	
7089	 steps: training loss - 111064.88281	, testing loss - 349441.31250	
7090	 steps: training loss - 106565.14844	, testing loss - 349160.78125	
7091	 steps: training loss - 122806.88281	, testing loss - 349131.09375	
7092	 steps: training loss - 105299.92969	, testing loss - 349404.84375	
7093	 steps: training loss - 84065.50781	, testing loss - 349348.15625	
7094	 steps: training loss - 121982.42188	, testing loss - 348569.56250	
7095	 steps: training loss - 115565.89844	, testing loss - 348174.62500	
7096	 steps: training loss - 132838.87500	, testing loss - 347860.68750	
7097	 steps: training loss - 100707.30469	, testing loss - 348263.00000	
7098	 steps: training loss - 92714.20312	, testing loss - 349057.71875	
7099	 steps: training loss - 129112.26562	, testing loss - 350957.93750	
7100	 steps: training loss - 112533.49219	, testing loss - 352310.12500	
7101	 steps: training loss - 94621.20312	, testing loss - 353007.59375	
7102	 steps: training loss - 114900.14062	, testing loss - 353360.09375	
7103	 steps: training loss - 116026.89062	, testing loss - 352522.15625	
7104	 steps: training loss - 124274.13281	, testing loss - 351530.84375	
7105	 steps: training loss - 106034.65625	, testing loss - 350507.96875	
7106	 steps: training loss - 102696.04688	, testing loss - 350081.46875	
7107	 steps: training loss - 110476.03906	, testing loss - 350671.71875	
7108	 steps: training loss - 107876.08594	, testing loss - 351440.90625	
7109	 steps: training loss - 106548.70312	, testing loss - 352398.90625	
7110	 steps: training loss - 114283.35156	, testing loss - 352698.37500	
7111	 steps: training loss - 110826.14062	, testing loss - 352933.37500	
7112	 steps: training loss - 108419.28125	, testing loss - 353175.28125	
7113	 steps: training loss - 129725.48438	, testing loss - 352944.93750	
7114	 steps: training loss - 113226.76562	, testing loss - 352617.50000	
7115	 steps: training loss - 124631.47656	, testing loss - 352410.78125	
7116	 steps: training loss - 121112.06250	, testing loss - 352673.00000	
7117	 steps: training loss - 100937.46875	, testing loss - 353571.12500	
7118	 steps: training loss - 108943.86719	, testing loss - 354887.00000	
7119	 steps: training loss - 114618.18750	, testing loss - 357483.21875	
7120	 steps: training loss - 97803.62500	, testing loss - 359196.00000	
7121	 steps: training loss - 118341.14062	, testing loss - 359153.18750	
7122	 steps: training loss - 124286.00781	, testing loss - 358277.43750	
7123	 steps: training loss - 125060.38281	, testing loss - 356942.28125	
7124	 steps: training loss - 106318.60156	, testing loss - 356172.93750	
7125	 steps: training loss - 118671.50781	, testing loss - 356003.87500	
7126	 steps: training loss - 121905.53906	, testing loss - 356345.71875	
7127	 steps: training loss - 114461.77344	, testing loss - 357099.43750	
7128	 steps: training loss - 103863.27344	, testing loss - 357154.62500	
7129	 steps: training loss - 115264.51562	, testing loss - 357123.18750	
7130	 steps: training loss - 100391.71094	, testing loss - 357613.00000	
7131	 steps: training loss - 104759.55469	, testing loss - 356977.87500	
7132	 steps: training loss - 103685.26562	, testing loss - 356506.12500	
7133	 steps: training loss - 106226.71094	, testing loss - 356661.81250	
7134	 steps: training loss - 99659.23438	, testing loss - 357246.37500	
7135	 steps: training loss - 122633.00781	, testing loss - 357264.78125	
7136	 steps: training loss - 122872.06250	, testing loss - 356655.09375	
7137	 steps: training loss - 122996.27344	, testing loss - 355379.12500	
7138	 steps: training loss - 113375.07812	, testing loss - 353960.15625	
7139	 steps: training loss - 115452.14062	, testing loss - 351936.09375	
7140	 steps: training loss - 117917.08594	, testing loss - 349566.81250	
7141	 steps: training loss - 109709.36719	, testing loss - 347361.18750	
7142	 steps: training loss - 124588.48438	, testing loss - 345041.87500	
7143	 steps: training loss - 133748.67188	, testing loss - 343435.81250	
7144	 steps: training loss - 111251.27344	, testing loss - 342360.25000	
7145	 steps: training loss - 111800.96875	, testing loss - 341721.06250	
7146	 steps: training loss - 113818.60938	, testing loss - 341461.93750	
7147	 steps: training loss - 127202.55469	, testing loss - 341308.40625	
7148	 steps: training loss - 101065.04688	, testing loss - 342119.53125	
7149	 steps: training loss - 110788.78125	, testing loss - 343043.43750	
7150	 steps: training loss - 92246.91406	, testing loss - 343748.78125	
7151	 steps: training loss - 114181.90625	, testing loss - 344143.40625	
7152	 steps: training loss - 98618.26562	, testing loss - 345208.78125	
7153	 steps: training loss - 75630.25000	, testing loss - 346200.71875	
7154	 steps: training loss - 117627.12500	, testing loss - 346269.18750	
7155	 steps: training loss - 112193.90625	, testing loss - 346091.15625	
7156	 steps: training loss - 116796.75781	, testing loss - 346351.50000	
7157	 steps: training loss - 82033.06250	, testing loss - 346981.28125	
7158	 steps: training loss - 105724.87500	, testing loss - 347016.90625	
7159	 steps: training loss - 93563.25000	, testing loss - 347684.93750	
7160	 steps: training loss - 123224.20312	, testing loss - 348410.25000	
7161	 steps: training loss - 146303.73438	, testing loss - 348909.15625	
7162	 steps: training loss - 100116.92188	, testing loss - 348864.34375	
7163	 steps: training loss - 104801.73438	, testing loss - 348045.53125	
7164	 steps: training loss - 89857.85156	, testing loss - 347986.59375	
7165	 steps: training loss - 118535.24219	, testing loss - 348210.90625	
7166	 steps: training loss - 123531.71094	, testing loss - 348507.53125	
7167	 steps: training loss - 122261.85938	, testing loss - 348095.50000	
7168	 steps: training loss - 104540.07812	, testing loss - 347976.50000	
7169	 steps: training loss - 104967.39844	, testing loss - 348255.25000	
7170	 steps: training loss - 113623.96875	, testing loss - 348691.40625	
7171	 steps: training loss - 127095.31250	, testing loss - 348419.34375	
7172	 steps: training loss - 109509.57812	, testing loss - 348474.50000	
7173	 steps: training loss - 108592.86719	, testing loss - 348709.68750	
7174	 steps: training loss - 112545.13281	, testing loss - 348876.87500	
7175	 steps: training loss - 131131.14062	, testing loss - 348763.68750	
7176	 steps: training loss - 127575.02344	, testing loss - 348855.46875	
7177	 steps: training loss - 127036.81250	, testing loss - 348808.50000	
7178	 steps: training loss - 105886.35938	, testing loss - 349307.34375	
7179	 steps: training loss - 108309.02344	, testing loss - 351302.40625	
7180	 steps: training loss - 130884.13281	, testing loss - 353753.12500	
7181	 steps: training loss - 106254.41406	, testing loss - 355117.68750	
7182	 steps: training loss - 105003.81250	, testing loss - 355057.00000	
7183	 steps: training loss - 126326.51562	, testing loss - 354125.65625	
7184	 steps: training loss - 118171.13281	, testing loss - 352996.34375	
7185	 steps: training loss - 118239.10156	, testing loss - 352134.40625	
7186	 steps: training loss - 91155.17969	, testing loss - 351304.68750	
7187	 steps: training loss - 121608.14844	, testing loss - 350721.56250	
7188	 steps: training loss - 104826.94531	, testing loss - 351480.03125	
7189	 steps: training loss - 112300.77344	, testing loss - 351905.43750	
7190	 steps: training loss - 121967.35938	, testing loss - 352148.09375	
7191	 steps: training loss - 87110.42969	, testing loss - 352594.09375	
7192	 steps: training loss - 146676.14062	, testing loss - 353777.75000	
7193	 steps: training loss - 105305.87500	, testing loss - 355076.53125	
7194	 steps: training loss - 117214.04688	, testing loss - 356147.03125	
7195	 steps: training loss - 118042.60938	, testing loss - 356627.12500	
7196	 steps: training loss - 100692.71094	, testing loss - 356129.25000	
7197	 steps: training loss - 130189.31250	, testing loss - 354895.06250	
7198	 steps: training loss - 136220.21875	, testing loss - 353376.50000	
7199	 steps: training loss - 104714.51562	, testing loss - 351706.68750	
7200	 steps: training loss - 109954.10156	, testing loss - 350464.62500	
7201	 steps: training loss - 106024.61719	, testing loss - 349852.68750	
7202	 steps: training loss - 121043.35938	, testing loss - 349319.68750	
7203	 steps: training loss - 105756.71875	, testing loss - 348479.09375	
7204	 steps: training loss - 108967.39844	, testing loss - 347404.34375	
7205	 steps: training loss - 94996.63281	, testing loss - 347785.71875	
7206	 steps: training loss - 101379.25000	, testing loss - 348738.96875	
7207	 steps: training loss - 85876.77344	, testing loss - 349222.09375	
7208	 steps: training loss - 118800.99219	, testing loss - 349745.53125	
7209	 steps: training loss - 120692.27344	, testing loss - 350913.31250	
7210	 steps: training loss - 108179.42188	, testing loss - 353521.25000	
7211	 steps: training loss - 106066.60156	, testing loss - 356001.56250	
7212	 steps: training loss - 120322.36719	, testing loss - 358031.62500	
7213	 steps: training loss - 121746.28125	, testing loss - 358747.62500	
7214	 steps: training loss - 92566.09375	, testing loss - 358019.25000	
7215	 steps: training loss - 104146.35156	, testing loss - 357496.00000	
7216	 steps: training loss - 113028.81250	, testing loss - 355753.68750	
7217	 steps: training loss - 139651.78125	, testing loss - 354235.50000	
7218	 steps: training loss - 125814.89062	, testing loss - 352331.40625	
7219	 steps: training loss - 99091.45312	, testing loss - 350534.75000	
7220	 steps: training loss - 101754.28125	, testing loss - 348635.59375	
7221	 steps: training loss - 99892.06250	, testing loss - 346421.78125	
7222	 steps: training loss - 126340.22656	, testing loss - 344143.53125	
7223	 steps: training loss - 105968.09375	, testing loss - 342238.03125	
7224	 steps: training loss - 115161.98438	, testing loss - 340841.87500	
7225	 steps: training loss - 97686.65625	, testing loss - 340204.06250	
7226	 steps: training loss - 105352.06250	, testing loss - 340541.28125	
7227	 steps: training loss - 136242.45312	, testing loss - 341346.43750	
7228	 steps: training loss - 102005.66406	, testing loss - 341715.46875	
7229	 steps: training loss - 119385.46094	, testing loss - 341814.09375	
7230	 steps: training loss - 119908.55469	, testing loss - 342300.12500	
7231	 steps: training loss - 105273.08594	, testing loss - 342239.37500	
7232	 steps: training loss - 99569.50781	, testing loss - 342332.40625	
7233	 steps: training loss - 114778.03906	, testing loss - 342639.31250	
7234	 steps: training loss - 108733.48438	, testing loss - 342263.93750	
7235	 steps: training loss - 109756.00781	, testing loss - 341908.28125	
7236	 steps: training loss - 104894.53906	, testing loss - 341456.25000	
7237	 steps: training loss - 110372.46094	, testing loss - 341020.09375	
7238	 steps: training loss - 120202.81250	, testing loss - 340970.31250	
7239	 steps: training loss - 93420.82031	, testing loss - 341488.43750	
7240	 steps: training loss - 128522.32812	, testing loss - 342716.12500	
7241	 steps: training loss - 130488.46094	, testing loss - 343235.18750	
7242	 steps: training loss - 105073.18750	, testing loss - 343088.93750	
7243	 steps: training loss - 102539.36719	, testing loss - 342624.46875	
7244	 steps: training loss - 103299.76562	, testing loss - 342813.62500	
7245	 steps: training loss - 100032.18750	, testing loss - 343162.62500	
7246	 steps: training loss - 105896.36719	, testing loss - 343827.53125	
7247	 steps: training loss - 118764.25000	, testing loss - 344113.81250	
7248	 steps: training loss - 123656.56250	, testing loss - 345057.90625	
7249	 steps: training loss - 127835.71094	, testing loss - 345833.31250	
7250	 steps: training loss - 114794.39062	, testing loss - 346014.06250	
7251	 steps: training loss - 95049.57031	, testing loss - 346555.65625	
7252	 steps: training loss - 90098.86719	, testing loss - 346554.50000	
7253	 steps: training loss - 116698.47656	, testing loss - 345943.50000	
7254	 steps: training loss - 127586.11719	, testing loss - 344943.09375	
7255	 steps: training loss - 97354.92188	, testing loss - 344557.87500	
7256	 steps: training loss - 116729.83594	, testing loss - 345008.75000	
7257	 steps: training loss - 99525.00000	, testing loss - 345428.25000	
7258	 steps: training loss - 131759.87500	, testing loss - 345633.87500	
7259	 steps: training loss - 120416.17969	, testing loss - 346349.75000	
7260	 steps: training loss - 103396.85938	, testing loss - 346463.03125	
7261	 steps: training loss - 108779.33594	, testing loss - 347001.12500	
7262	 steps: training loss - 131136.00000	, testing loss - 348045.65625	
7263	 steps: training loss - 117823.42188	, testing loss - 347787.87500	
7264	 steps: training loss - 123714.15625	, testing loss - 347825.53125	
7265	 steps: training loss - 117716.61719	, testing loss - 347561.46875	
7266	 steps: training loss - 123915.68750	, testing loss - 347199.21875	
7267	 steps: training loss - 76887.00781	, testing loss - 346864.09375	
7268	 steps: training loss - 104937.90625	, testing loss - 346246.59375	
7269	 steps: training loss - 116165.54688	, testing loss - 345823.84375	
7270	 steps: training loss - 129256.17969	, testing loss - 345524.68750	
7271	 steps: training loss - 115358.46875	, testing loss - 346431.50000	
7272	 steps: training loss - 107184.49219	, testing loss - 348084.84375	
7273	 steps: training loss - 106919.19531	, testing loss - 350015.43750	
7274	 steps: training loss - 96425.17188	, testing loss - 352074.31250	
7275	 steps: training loss - 103145.21094	, testing loss - 354092.43750	
7276	 steps: training loss - 144506.84375	, testing loss - 355329.81250	
7277	 steps: training loss - 102035.60938	, testing loss - 355719.18750	
7278	 steps: training loss - 99136.65625	, testing loss - 355885.81250	
7279	 steps: training loss - 134345.73438	, testing loss - 355734.43750	
7280	 steps: training loss - 91817.08594	, testing loss - 354606.31250	
7281	 steps: training loss - 113367.07812	, testing loss - 353316.62500	
7282	 steps: training loss - 111690.51562	, testing loss - 351713.84375	
7283	 steps: training loss - 128619.89844	, testing loss - 349807.46875	
7284	 steps: training loss - 112154.86719	, testing loss - 348488.87500	
7285	 steps: training loss - 108376.30469	, testing loss - 347453.84375	
7286	 steps: training loss - 86378.25781	, testing loss - 346687.59375	
7287	 steps: training loss - 111868.75781	, testing loss - 346110.37500	
7288	 steps: training loss - 105455.62500	, testing loss - 345646.84375	
7289	 steps: training loss - 112247.82812	, testing loss - 345521.84375	
7290	 steps: training loss - 98818.44531	, testing loss - 345809.31250	
7291	 steps: training loss - 138861.90625	, testing loss - 346248.18750	
7292	 steps: training loss - 110183.86719	, testing loss - 347872.78125	
7293	 steps: training loss - 104738.91406	, testing loss - 350531.53125	
7294	 steps: training loss - 106342.74219	, testing loss - 353756.53125	
7295	 steps: training loss - 126247.10938	, testing loss - 357496.93750	
7296	 steps: training loss - 107249.64062	, testing loss - 361341.93750	
7297	 steps: training loss - 119993.42188	, testing loss - 365944.56250	
7298	 steps: training loss - 112240.42188	, testing loss - 367608.87500	
7299	 steps: training loss - 101131.42969	, testing loss - 367924.00000	
7300	 steps: training loss - 128815.61719	, testing loss - 366132.15625	
7301	 steps: training loss - 112609.27344	, testing loss - 364526.18750	
7302	 steps: training loss - 105888.68750	, testing loss - 362320.65625	
7303	 steps: training loss - 129380.98438	, testing loss - 359747.65625	
7304	 steps: training loss - 124358.79688	, testing loss - 358789.84375	
7305	 steps: training loss - 124180.84375	, testing loss - 357729.00000	
7306	 steps: training loss - 104909.87500	, testing loss - 356968.09375	
7307	 steps: training loss - 122171.71094	, testing loss - 356923.78125	
7308	 steps: training loss - 87877.00000	, testing loss - 355829.34375	
7309	 steps: training loss - 117968.92188	, testing loss - 353960.28125	
7310	 steps: training loss - 102588.80469	, testing loss - 351985.71875	
7311	 steps: training loss - 124424.82812	, testing loss - 350839.75000	
7312	 steps: training loss - 100689.55469	, testing loss - 350682.03125	
7313	 steps: training loss - 102040.52344	, testing loss - 350371.00000	
7314	 steps: training loss - 120821.97656	, testing loss - 349582.53125	
7315	 steps: training loss - 105394.12500	, testing loss - 348449.90625	
7316	 steps: training loss - 102823.70312	, testing loss - 347842.50000	
7317	 steps: training loss - 108421.00781	, testing loss - 348569.18750	
7318	 steps: training loss - 134435.79688	, testing loss - 348984.59375	
7319	 steps: training loss - 116692.85938	, testing loss - 348709.81250	
7320	 steps: training loss - 123349.93750	, testing loss - 348674.53125	
7321	 steps: training loss - 110558.89062	, testing loss - 347557.68750	
7322	 steps: training loss - 103507.57031	, testing loss - 347590.46875	
7323	 steps: training loss - 109944.74219	, testing loss - 347078.65625	
7324	 steps: training loss - 88908.25000	, testing loss - 346922.28125	
7325	 steps: training loss - 90212.85938	, testing loss - 346525.68750	
7326	 steps: training loss - 103121.41406	, testing loss - 346040.09375	
7327	 steps: training loss - 114455.71094	, testing loss - 345826.25000	
7328	 steps: training loss - 110446.86719	, testing loss - 346910.31250	
7329	 steps: training loss - 90084.17969	, testing loss - 348651.37500	
7330	 steps: training loss - 120298.60156	, testing loss - 350365.71875	
7331	 steps: training loss - 101417.80469	, testing loss - 351399.03125	
7332	 steps: training loss - 129514.34375	, testing loss - 352482.96875	
7333	 steps: training loss - 110945.89062	, testing loss - 353009.50000	
7334	 steps: training loss - 120861.17969	, testing loss - 352372.34375	
7335	 steps: training loss - 117081.78906	, testing loss - 351110.00000	
7336	 steps: training loss - 115485.96875	, testing loss - 349273.15625	
7337	 steps: training loss - 100873.20312	, testing loss - 346794.46875	
7338	 steps: training loss - 101269.27344	, testing loss - 344680.43750	
7339	 steps: training loss - 90434.01562	, testing loss - 343104.90625	
7340	 steps: training loss - 108280.68750	, testing loss - 342025.28125	
7341	 steps: training loss - 106920.54688	, testing loss - 341746.03125	
7342	 steps: training loss - 97474.23438	, testing loss - 341592.50000	
7343	 steps: training loss - 126977.24219	, testing loss - 341411.65625	
7344	 steps: training loss - 111332.08594	, testing loss - 341601.21875	
7345	 steps: training loss - 117644.12500	, testing loss - 342327.90625	
7346	 steps: training loss - 120792.88281	, testing loss - 343162.12500	
7347	 steps: training loss - 105256.83594	, testing loss - 343790.59375	
7348	 steps: training loss - 109856.41406	, testing loss - 344643.00000	
7349	 steps: training loss - 122279.60156	, testing loss - 345875.34375	
7350	 steps: training loss - 102904.87500	, testing loss - 347227.34375	
7351	 steps: training loss - 90075.85938	, testing loss - 348614.62500	
7352	 steps: training loss - 118042.90625	, testing loss - 349794.40625	
7353	 steps: training loss - 130393.12500	, testing loss - 351625.09375	
7354	 steps: training loss - 118089.70312	, testing loss - 353894.62500	
7355	 steps: training loss - 116690.02344	, testing loss - 355446.03125	
7356	 steps: training loss - 112422.82812	, testing loss - 356062.56250	
7357	 steps: training loss - 130116.72656	, testing loss - 355440.71875	
7358	 steps: training loss - 91711.09375	, testing loss - 354820.53125	
7359	 steps: training loss - 122120.05469	, testing loss - 353648.78125	
7360	 steps: training loss - 102277.95312	, testing loss - 352982.56250	
7361	 steps: training loss - 109527.97656	, testing loss - 353446.06250	
7362	 steps: training loss - 117313.69531	, testing loss - 353319.50000	
7363	 steps: training loss - 91053.64844	, testing loss - 352727.00000	
7364	 steps: training loss - 114762.53906	, testing loss - 351469.87500	
7365	 steps: training loss - 119054.71094	, testing loss - 350776.68750	
7366	 steps: training loss - 101735.71094	, testing loss - 350273.87500	
7367	 steps: training loss - 97773.39062	, testing loss - 350345.46875	
7368	 steps: training loss - 103571.23438	, testing loss - 350072.21875	
7369	 steps: training loss - 111605.46875	, testing loss - 350125.18750	
7370	 steps: training loss - 103035.17188	, testing loss - 349749.50000	
7371	 steps: training loss - 122696.46875	, testing loss - 349620.62500	
7372	 steps: training loss - 110009.19531	, testing loss - 350025.62500	
7373	 steps: training loss - 123054.80469	, testing loss - 351053.50000	
7374	 steps: training loss - 109566.89062	, testing loss - 352542.62500	
7375	 steps: training loss - 104846.37500	, testing loss - 354183.03125	
7376	 steps: training loss - 109973.91406	, testing loss - 355470.43750	
7377	 steps: training loss - 96643.28906	, testing loss - 357615.59375	
7378	 steps: training loss - 117396.18750	, testing loss - 360275.28125	
7379	 steps: training loss - 118977.03906	, testing loss - 362753.09375	
7380	 steps: training loss - 106525.68750	, testing loss - 363703.31250	
7381	 steps: training loss - 122092.14062	, testing loss - 364104.34375	
7382	 steps: training loss - 114473.07031	, testing loss - 363858.96875	
7383	 steps: training loss - 124849.10938	, testing loss - 363999.87500	
7384	 steps: training loss - 94311.27344	, testing loss - 362947.09375	
7385	 steps: training loss - 110987.07031	, testing loss - 362792.53125	
7386	 steps: training loss - 100904.50781	, testing loss - 362714.31250	
7387	 steps: training loss - 115570.21875	, testing loss - 362014.25000	
7388	 steps: training loss - 103715.86719	, testing loss - 360416.28125	
7389	 steps: training loss - 124377.00000	, testing loss - 358315.71875	
7390	 steps: training loss - 123904.56250	, testing loss - 356466.53125	
7391	 steps: training loss - 129467.46094	, testing loss - 355334.68750	
7392	 steps: training loss - 129974.38281	, testing loss - 354960.28125	
7393	 steps: training loss - 111580.65625	, testing loss - 353578.03125	
7394	 steps: training loss - 98427.81250	, testing loss - 352264.53125	
7395	 steps: training loss - 107556.76562	, testing loss - 351050.03125	
7396	 steps: training loss - 114575.81250	, testing loss - 350130.65625	
7397	 steps: training loss - 117439.46875	, testing loss - 349362.21875	
7398	 steps: training loss - 104007.89844	, testing loss - 349052.46875	
7399	 steps: training loss - 109815.62500	, testing loss - 349794.87500	
7400	 steps: training loss - 97321.87500	, testing loss - 351270.56250	
7401	 steps: training loss - 113059.77344	, testing loss - 351945.18750	
7402	 steps: training loss - 97742.75781	, testing loss - 352893.25000	
7403	 steps: training loss - 100903.61719	, testing loss - 353964.71875	
7404	 steps: training loss - 90123.34375	, testing loss - 355469.50000	
7405	 steps: training loss - 90194.67969	, testing loss - 356695.46875	
7406	 steps: training loss - 103979.01562	, testing loss - 357995.50000	
7407	 steps: training loss - 127852.90625	, testing loss - 359776.00000	
7408	 steps: training loss - 84805.23438	, testing loss - 360508.75000	
7409	 steps: training loss - 145475.28125	, testing loss - 360507.56250	
7410	 steps: training loss - 100964.03125	, testing loss - 359855.68750	
7411	 steps: training loss - 117069.67969	, testing loss - 358216.03125	
7412	 steps: training loss - 111454.21094	, testing loss - 355495.96875	
7413	 steps: training loss - 107877.12500	, testing loss - 352675.87500	
7414	 steps: training loss - 107885.68750	, testing loss - 350576.34375	
7415	 steps: training loss - 101192.66406	, testing loss - 349576.25000	
7416	 steps: training loss - 119473.14844	, testing loss - 348533.81250	
7417	 steps: training loss - 99910.43750	, testing loss - 347937.62500	
7418	 steps: training loss - 104476.30469	, testing loss - 348659.28125	
7419	 steps: training loss - 100832.78125	, testing loss - 348961.90625	
7420	 steps: training loss - 116466.42188	, testing loss - 349259.93750	
7421	 steps: training loss - 113256.46094	, testing loss - 350330.65625	
7422	 steps: training loss - 114290.96875	, testing loss - 351347.28125	
7423	 steps: training loss - 129770.89062	, testing loss - 352770.15625	
7424	 steps: training loss - 109538.92969	, testing loss - 353594.25000	
7425	 steps: training loss - 94975.40625	, testing loss - 354428.43750	
7426	 steps: training loss - 125559.63281	, testing loss - 354483.28125	
7427	 steps: training loss - 109238.60938	, testing loss - 353789.40625	
7428	 steps: training loss - 95151.67969	, testing loss - 354009.62500	
7429	 steps: training loss - 104376.35156	, testing loss - 354786.46875	
7430	 steps: training loss - 107516.02344	, testing loss - 355079.40625	
7431	 steps: training loss - 134285.96875	, testing loss - 355140.96875	
7432	 steps: training loss - 96188.31250	, testing loss - 354186.21875	
7433	 steps: training loss - 90515.93750	, testing loss - 353438.78125	
7434	 steps: training loss - 125809.97656	, testing loss - 352143.43750	
7435	 steps: training loss - 85899.50781	, testing loss - 350097.09375	
7436	 steps: training loss - 91813.79688	, testing loss - 348338.21875	
7437	 steps: training loss - 98859.80469	, testing loss - 347061.06250	
7438	 steps: training loss - 105051.48438	, testing loss - 345996.09375	
7439	 steps: training loss - 111696.88281	, testing loss - 345791.81250	
7440	 steps: training loss - 81291.50781	, testing loss - 346360.18750	
7441	 steps: training loss - 106641.64844	, testing loss - 346879.53125	
7442	 steps: training loss - 108242.35938	, testing loss - 347109.96875	
7443	 steps: training loss - 112993.46875	, testing loss - 347015.09375	
7444	 steps: training loss - 113184.91406	, testing loss - 346675.87500	
7445	 steps: training loss - 92029.89062	, testing loss - 346178.31250	
7446	 steps: training loss - 99582.91406	, testing loss - 345959.53125	
7447	 steps: training loss - 98674.14844	, testing loss - 346017.68750	
7448	 steps: training loss - 90027.10938	, testing loss - 346659.78125	
7449	 steps: training loss - 110587.42188	, testing loss - 347395.62500	
7450	 steps: training loss - 101561.95312	, testing loss - 347629.56250	
7451	 steps: training loss - 91418.09375	, testing loss - 348194.93750	
7452	 steps: training loss - 129703.83594	, testing loss - 349248.43750	
7453	 steps: training loss - 124662.82812	, testing loss - 351091.96875	
7454	 steps: training loss - 115577.27344	, testing loss - 352556.28125	
7455	 steps: training loss - 103483.23438	, testing loss - 353257.46875	
7456	 steps: training loss - 108246.50000	, testing loss - 353356.93750	
7457	 steps: training loss - 138018.35938	, testing loss - 353305.84375	
7458	 steps: training loss - 117082.20312	, testing loss - 352936.21875	
7459	 steps: training loss - 105182.50781	, testing loss - 353588.21875	
7460	 steps: training loss - 136871.06250	, testing loss - 354087.25000	
7461	 steps: training loss - 111416.07812	, testing loss - 353892.93750	
7462	 steps: training loss - 87247.68750	, testing loss - 352902.96875	
7463	 steps: training loss - 99551.33594	, testing loss - 352265.96875	
7464	 steps: training loss - 96278.46875	, testing loss - 352464.62500	
7465	 steps: training loss - 95035.96875	, testing loss - 352290.09375	
7466	 steps: training loss - 111439.93750	, testing loss - 351592.68750	
7467	 steps: training loss - 93356.35938	, testing loss - 350092.03125	
7468	 steps: training loss - 87045.29688	, testing loss - 348876.62500	
7469	 steps: training loss - 91758.66406	, testing loss - 348071.37500	
7470	 steps: training loss - 147753.45312	, testing loss - 347128.53125	
7471	 steps: training loss - 87334.00000	, testing loss - 346902.21875	
7472	 steps: training loss - 80726.79688	, testing loss - 347064.34375	
7473	 steps: training loss - 142111.54688	, testing loss - 347578.65625	
7474	 steps: training loss - 121206.51562	, testing loss - 348088.84375	
7475	 steps: training loss - 110884.16406	, testing loss - 348626.81250	
7476	 steps: training loss - 115942.10156	, testing loss - 349366.50000	
7477	 steps: training loss - 101333.71875	, testing loss - 350457.28125	
7478	 steps: training loss - 107078.39844	, testing loss - 351534.31250	
7479	 steps: training loss - 87675.12500	, testing loss - 353496.06250	
7480	 steps: training loss - 92159.08594	, testing loss - 355991.53125	
7481	 steps: training loss - 110473.72656	, testing loss - 358685.43750	
7482	 steps: training loss - 113328.94531	, testing loss - 361573.18750	
7483	 steps: training loss - 123211.59375	, testing loss - 366463.28125	
7484	 steps: training loss - 96015.89062	, testing loss - 371700.65625	
7485	 steps: training loss - 115591.00781	, testing loss - 376852.21875	
7486	 steps: training loss - 112225.03906	, testing loss - 378807.50000	
7487	 steps: training loss - 117310.29688	, testing loss - 378631.59375	
7488	 steps: training loss - 114720.35938	, testing loss - 378299.00000	
7489	 steps: training loss - 121580.78906	, testing loss - 377630.81250	
7490	 steps: training loss - 92292.13281	, testing loss - 376535.93750	
7491	 steps: training loss - 116444.81250	, testing loss - 375496.84375	
7492	 steps: training loss - 125353.23438	, testing loss - 373314.84375	
7493	 steps: training loss - 118802.98438	, testing loss - 369011.96875	
7494	 steps: training loss - 110451.07031	, testing loss - 364112.68750	
7495	 steps: training loss - 108160.19531	, testing loss - 359882.75000	
7496	 steps: training loss - 91273.35938	, testing loss - 356831.28125	
7497	 steps: training loss - 122624.05469	, testing loss - 354515.46875	
7498	 steps: training loss - 107393.92969	, testing loss - 352654.15625	
7499	 steps: training loss - 118255.39844	, testing loss - 350693.56250	
7500	 steps: training loss - 120908.90625	, testing loss - 349647.31250	
7501	 steps: training loss - 110925.89062	, testing loss - 348931.00000	
7502	 steps: training loss - 106898.45312	, testing loss - 347781.78125	
7503	 steps: training loss - 108341.41406	, testing loss - 346966.18750	
7504	 steps: training loss - 114816.58594	, testing loss - 346785.09375	
7505	 steps: training loss - 126389.07812	, testing loss - 347117.50000	
7506	 steps: training loss - 111187.88281	, testing loss - 348177.90625	
7507	 steps: training loss - 112232.52344	, testing loss - 348932.71875	
7508	 steps: training loss - 104500.75781	, testing loss - 349950.65625	
7509	 steps: training loss - 107468.85156	, testing loss - 352124.81250	
7510	 steps: training loss - 114226.56250	, testing loss - 354829.96875	
7511	 steps: training loss - 111073.93750	, testing loss - 357776.06250	
7512	 steps: training loss - 111815.12500	, testing loss - 360974.40625	
7513	 steps: training loss - 106948.85156	, testing loss - 363155.78125	
7514	 steps: training loss - 89337.07031	, testing loss - 363492.65625	
7515	 steps: training loss - 114755.61719	, testing loss - 364516.43750	
7516	 steps: training loss - 119933.49219	, testing loss - 364851.62500	
7517	 steps: training loss - 130216.21094	, testing loss - 364211.15625	
7518	 steps: training loss - 130957.96094	, testing loss - 363587.59375	
7519	 steps: training loss - 105603.84375	, testing loss - 362952.34375	
7520	 steps: training loss - 117008.03125	, testing loss - 361660.68750	
7521	 steps: training loss - 117101.07031	, testing loss - 360621.65625	
7522	 steps: training loss - 106603.60156	, testing loss - 358540.21875	
7523	 steps: training loss - 132235.28125	, testing loss - 355763.31250	
7524	 steps: training loss - 97516.25000	, testing loss - 353616.75000	
7525	 steps: training loss - 121009.75000	, testing loss - 351995.50000	
7526	 steps: training loss - 102186.19531	, testing loss - 350783.75000	
7527	 steps: training loss - 110255.50000	, testing loss - 350048.56250	
7528	 steps: training loss - 115686.53906	, testing loss - 350419.90625	
7529	 steps: training loss - 105632.38281	, testing loss - 351365.18750	
7530	 steps: training loss - 109288.25781	, testing loss - 353117.62500	
7531	 steps: training loss - 105609.92188	, testing loss - 355163.46875	
7532	 steps: training loss - 76506.37500	, testing loss - 357331.90625	
7533	 steps: training loss - 80393.52344	, testing loss - 359312.25000	
7534	 steps: training loss - 89034.07031	, testing loss - 361069.90625	
7535	 steps: training loss - 133425.09375	, testing loss - 361956.50000	
7536	 steps: training loss - 96182.31250	, testing loss - 362486.34375	
7537	 steps: training loss - 100911.42188	, testing loss - 363455.12500	
7538	 steps: training loss - 120565.78125	, testing loss - 364603.15625	
7539	 steps: training loss - 112668.35156	, testing loss - 365498.06250	
7540	 steps: training loss - 112212.98438	, testing loss - 365188.93750	
7541	 steps: training loss - 118614.92969	, testing loss - 364463.84375	
7542	 steps: training loss - 102306.85156	, testing loss - 363047.59375	
7543	 steps: training loss - 119279.61719	, testing loss - 360290.09375	
7544	 steps: training loss - 125261.78906	, testing loss - 357823.71875	
7545	 steps: training loss - 109860.15625	, testing loss - 356127.78125	
7546	 steps: training loss - 115533.80469	, testing loss - 355399.78125	
7547	 steps: training loss - 116263.02344	, testing loss - 354474.09375	
7548	 steps: training loss - 100444.97656	, testing loss - 354694.90625	
7549	 steps: training loss - 91471.76562	, testing loss - 354968.84375	
7550	 steps: training loss - 103022.42969	, testing loss - 356133.71875	
7551	 steps: training loss - 118305.50781	, testing loss - 357333.46875	
7552	 steps: training loss - 131983.46875	, testing loss - 358767.43750	
7553	 steps: training loss - 101715.47656	, testing loss - 358788.09375	
7554	 steps: training loss - 103861.50781	, testing loss - 358632.81250	
7555	 steps: training loss - 84056.89062	, testing loss - 358720.40625	
7556	 steps: training loss - 110821.72656	, testing loss - 359423.96875	
7557	 steps: training loss - 105535.55469	, testing loss - 360412.81250	
7558	 steps: training loss - 122503.75781	, testing loss - 361626.56250	
7559	 steps: training loss - 104863.71875	, testing loss - 362272.00000	
7560	 steps: training loss - 114711.53125	, testing loss - 362016.28125	
7561	 steps: training loss - 125820.97656	, testing loss - 360760.62500	
7562	 steps: training loss - 118491.98438	, testing loss - 360271.96875	
7563	 steps: training loss - 100365.06250	, testing loss - 359671.28125	
7564	 steps: training loss - 125285.02344	, testing loss - 359562.75000	
7565	 steps: training loss - 105572.67969	, testing loss - 360166.18750	
7566	 steps: training loss - 88872.98438	, testing loss - 361308.75000	
7567	 steps: training loss - 114576.92188	, testing loss - 361575.37500	
7568	 steps: training loss - 109387.10156	, testing loss - 361199.40625	
7569	 steps: training loss - 105399.96875	, testing loss - 360713.59375	
7570	 steps: training loss - 117844.38281	, testing loss - 359161.34375	
7571	 steps: training loss - 115880.15625	, testing loss - 357446.50000	
7572	 steps: training loss - 94481.80469	, testing loss - 356107.65625	
7573	 steps: training loss - 102041.41406	, testing loss - 354412.21875	
7574	 steps: training loss - 90505.35156	, testing loss - 352622.12500	
7575	 steps: training loss - 114808.24219	, testing loss - 351518.37500	
7576	 steps: training loss - 101903.02344	, testing loss - 350656.93750	
7577	 steps: training loss - 115178.78125	, testing loss - 349844.56250	
7578	 steps: training loss - 95464.96875	, testing loss - 348490.90625	
7579	 steps: training loss - 102378.79688	, testing loss - 346996.34375	
7580	 steps: training loss - 108690.24219	, testing loss - 345352.21875	
7581	 steps: training loss - 138433.96875	, testing loss - 343679.96875	
7582	 steps: training loss - 101181.18750	, testing loss - 343025.65625	
7583	 steps: training loss - 103302.92188	, testing loss - 342922.25000	
7584	 steps: training loss - 120842.64844	, testing loss - 344185.53125	
7585	 steps: training loss - 118606.37500	, testing loss - 345675.93750	
7586	 steps: training loss - 122716.88281	, testing loss - 346977.06250	
7587	 steps: training loss - 92637.43750	, testing loss - 349283.03125	
7588	 steps: training loss - 112743.70312	, testing loss - 351107.21875	
7589	 steps: training loss - 130391.81250	, testing loss - 353057.87500	
7590	 steps: training loss - 111235.62500	, testing loss - 354299.40625	
7591	 steps: training loss - 117378.28906	, testing loss - 355328.37500	
7592	 steps: training loss - 115561.38281	, testing loss - 357191.03125	
7593	 steps: training loss - 112609.06250	, testing loss - 359692.96875	
7594	 steps: training loss - 114395.53906	, testing loss - 361239.06250	
7595	 steps: training loss - 114721.04688	, testing loss - 361534.00000	
7596	 steps: training loss - 89730.65625	, testing loss - 361796.65625	
7597	 steps: training loss - 93495.27344	, testing loss - 361616.71875	
7598	 steps: training loss - 124081.24219	, testing loss - 360090.21875	
7599	 steps: training loss - 107594.66406	, testing loss - 358979.25000	
7600	 steps: training loss - 117785.71094	, testing loss - 357432.87500	
7601	 steps: training loss - 97890.82812	, testing loss - 355211.37500	
7602	 steps: training loss - 112118.46094	, testing loss - 352241.09375	
7603	 steps: training loss - 111276.46094	, testing loss - 350988.43750	
7604	 steps: training loss - 130759.64844	, testing loss - 351205.81250	
7605	 steps: training loss - 104472.56250	, testing loss - 352091.81250	
7606	 steps: training loss - 98345.78125	, testing loss - 353069.12500	
7607	 steps: training loss - 126405.48438	, testing loss - 353387.25000	
7608	 steps: training loss - 99189.73438	, testing loss - 352912.15625	
7609	 steps: training loss - 144293.96875	, testing loss - 352802.84375	
7610	 steps: training loss - 113859.77344	, testing loss - 352897.15625	
7611	 steps: training loss - 114022.54688	, testing loss - 353173.34375	
7612	 steps: training loss - 105922.76562	, testing loss - 352375.90625	
7613	 steps: training loss - 101291.32812	, testing loss - 351913.12500	
7614	 steps: training loss - 106661.83594	, testing loss - 350666.12500	
7615	 steps: training loss - 100325.23438	, testing loss - 349982.90625	
7616	 steps: training loss - 101147.50781	, testing loss - 349299.37500	
7617	 steps: training loss - 130784.75000	, testing loss - 347856.00000	
7618	 steps: training loss - 111579.57031	, testing loss - 346700.71875	
7619	 steps: training loss - 108591.85938	, testing loss - 346684.43750	
7620	 steps: training loss - 115431.14062	, testing loss - 347108.09375	
7621	 steps: training loss - 127598.88281	, testing loss - 346904.28125	
7622	 steps: training loss - 115883.53125	, testing loss - 346642.12500	
7623	 steps: training loss - 121585.59375	, testing loss - 346777.53125	
7624	 steps: training loss - 132006.85938	, testing loss - 347825.40625	
7625	 steps: training loss - 113146.32812	, testing loss - 348904.34375	
7626	 steps: training loss - 109556.32031	, testing loss - 351103.93750	
7627	 steps: training loss - 125579.50781	, testing loss - 353875.62500	
7628	 steps: training loss - 112640.32812	, testing loss - 355482.84375	
7629	 steps: training loss - 92227.95312	, testing loss - 356078.65625	
7630	 steps: training loss - 121638.12500	, testing loss - 356673.93750	
7631	 steps: training loss - 108071.42969	, testing loss - 356426.96875	
7632	 steps: training loss - 112837.85938	, testing loss - 355813.68750	
7633	 steps: training loss - 128659.78125	, testing loss - 355222.90625	
7634	 steps: training loss - 115307.49219	, testing loss - 353965.43750	
7635	 steps: training loss - 100271.64844	, testing loss - 351854.81250	
7636	 steps: training loss - 114517.31250	, testing loss - 350714.62500	
7637	 steps: training loss - 105603.28125	, testing loss - 349850.12500	
7638	 steps: training loss - 107346.91406	, testing loss - 348773.59375	
7639	 steps: training loss - 106488.33594	, testing loss - 347824.75000	
7640	 steps: training loss - 110945.57812	, testing loss - 347380.00000	
7641	 steps: training loss - 113473.82031	, testing loss - 346730.50000	
7642	 steps: training loss - 107840.37500	, testing loss - 346340.93750	
7643	 steps: training loss - 107213.08594	, testing loss - 346265.43750	
7644	 steps: training loss - 111615.23438	, testing loss - 346783.96875	
7645	 steps: training loss - 109315.80469	, testing loss - 347692.75000	
7646	 steps: training loss - 100116.60156	, testing loss - 348656.37500	
7647	 steps: training loss - 99561.71875	, testing loss - 349985.68750	
7648	 steps: training loss - 99342.61719	, testing loss - 351109.31250	
7649	 steps: training loss - 139061.68750	, testing loss - 352152.40625	
7650	 steps: training loss - 134775.78125	, testing loss - 352677.21875	
7651	 steps: training loss - 124281.20312	, testing loss - 354634.40625	
7652	 steps: training loss - 103540.07812	, testing loss - 357908.06250	
7653	 steps: training loss - 123771.35156	, testing loss - 361344.71875	
7654	 steps: training loss - 89480.82031	, testing loss - 363912.00000	
7655	 steps: training loss - 87972.90625	, testing loss - 365025.59375	
7656	 steps: training loss - 124845.12500	, testing loss - 365229.09375	
7657	 steps: training loss - 104286.55469	, testing loss - 365016.18750	
7658	 steps: training loss - 92962.76562	, testing loss - 365238.65625	
7659	 steps: training loss - 129479.77344	, testing loss - 364234.06250	
7660	 steps: training loss - 96906.46094	, testing loss - 363339.12500	
7661	 steps: training loss - 131010.35156	, testing loss - 361090.93750	
7662	 steps: training loss - 126014.92188	, testing loss - 358908.68750	
7663	 steps: training loss - 116973.92188	, testing loss - 356566.56250	
7664	 steps: training loss - 114142.18750	, testing loss - 354297.84375	
7665	 steps: training loss - 93633.67969	, testing loss - 352327.25000	
7666	 steps: training loss - 109444.14844	, testing loss - 351639.09375	
7667	 steps: training loss - 110326.46094	, testing loss - 350874.71875	
7668	 steps: training loss - 105866.32812	, testing loss - 350479.84375	
7669	 steps: training loss - 104743.87500	, testing loss - 350461.09375	
7670	 steps: training loss - 85382.60156	, testing loss - 350872.50000	
7671	 steps: training loss - 94016.41406	, testing loss - 352113.43750	
7672	 steps: training loss - 110834.28906	, testing loss - 353327.12500	
7673	 steps: training loss - 105081.29688	, testing loss - 354302.78125	
7674	 steps: training loss - 77321.85938	, testing loss - 354508.25000	
7675	 steps: training loss - 108827.95312	, testing loss - 354227.59375	
7676	 steps: training loss - 98801.38281	, testing loss - 353951.18750	
7677	 steps: training loss - 114862.06250	, testing loss - 353356.56250	
7678	 steps: training loss - 105247.02344	, testing loss - 352068.96875	
7679	 steps: training loss - 124589.43750	, testing loss - 350108.65625	
7680	 steps: training loss - 135981.12500	, testing loss - 349624.15625	
7681	 steps: training loss - 106542.75000	, testing loss - 349133.50000	
7682	 steps: training loss - 119131.57812	, testing loss - 348024.75000	
7683	 steps: training loss - 109600.38281	, testing loss - 347303.68750	
7684	 steps: training loss - 118511.52344	, testing loss - 346885.43750	
7685	 steps: training loss - 99471.13281	, testing loss - 347247.62500	
7686	 steps: training loss - 109874.46875	, testing loss - 348013.15625	
7687	 steps: training loss - 115865.47656	, testing loss - 348260.96875	
7688	 steps: training loss - 109379.97656	, testing loss - 348892.00000	
7689	 steps: training loss - 99747.66406	, testing loss - 349244.06250	
7690	 steps: training loss - 96847.72656	, testing loss - 349034.75000	
7691	 steps: training loss - 89417.50781	, testing loss - 349270.78125	
7692	 steps: training loss - 109994.59375	, testing loss - 350838.37500	
7693	 steps: training loss - 92384.78125	, testing loss - 352731.37500	
7694	 steps: training loss - 112260.57031	, testing loss - 353437.93750	
7695	 steps: training loss - 123559.38281	, testing loss - 352933.43750	
7696	 steps: training loss - 98660.85156	, testing loss - 351677.09375	
7697	 steps: training loss - 134405.04688	, testing loss - 350308.21875	
7698	 steps: training loss - 90130.81250	, testing loss - 348550.62500	
7699	 steps: training loss - 119355.25781	, testing loss - 347439.28125	
7700	 steps: training loss - 121640.00000	, testing loss - 346988.25000	
7701	 steps: training loss - 141817.20312	, testing loss - 346594.12500	
7702	 steps: training loss - 93134.78125	, testing loss - 346352.12500	
7703	 steps: training loss - 120884.50000	, testing loss - 346518.81250	
7704	 steps: training loss - 97060.59375	, testing loss - 347777.43750	
7705	 steps: training loss - 109917.71875	, testing loss - 349246.12500	
7706	 steps: training loss - 105630.26562	, testing loss - 350708.18750	
7707	 steps: training loss - 123378.68750	, testing loss - 352126.75000	
7708	 steps: training loss - 124974.47656	, testing loss - 352896.50000	
7709	 steps: training loss - 132593.68750	, testing loss - 352286.50000	
7710	 steps: training loss - 104058.71094	, testing loss - 351587.34375	
7711	 steps: training loss - 120602.71094	, testing loss - 350390.21875	
7712	 steps: training loss - 120284.01562	, testing loss - 349319.28125	
7713	 steps: training loss - 92229.63281	, testing loss - 348133.06250	
7714	 steps: training loss - 114225.95312	, testing loss - 347463.06250	
7715	 steps: training loss - 138510.50000	, testing loss - 347275.31250	
7716	 steps: training loss - 111850.84375	, testing loss - 346861.43750	
7717	 steps: training loss - 101037.45312	, testing loss - 347472.65625	
7718	 steps: training loss - 93153.89062	, testing loss - 348070.71875	
7719	 steps: training loss - 99419.75781	, testing loss - 348687.90625	
7720	 steps: training loss - 106069.92188	, testing loss - 348793.31250	
7721	 steps: training loss - 94068.00781	, testing loss - 349070.71875	
7722	 steps: training loss - 117724.82812	, testing loss - 349012.34375	
7723	 steps: training loss - 122624.32031	, testing loss - 348948.56250	
7724	 steps: training loss - 106585.09375	, testing loss - 349008.31250	
7725	 steps: training loss - 99397.92969	, testing loss - 348578.03125	
7726	 steps: training loss - 101454.95312	, testing loss - 348439.37500	
7727	 steps: training loss - 120029.82812	, testing loss - 348911.40625	
7728	 steps: training loss - 134330.35938	, testing loss - 348749.09375	
7729	 steps: training loss - 109978.98438	, testing loss - 348103.21875	
7730	 steps: training loss - 98826.03906	, testing loss - 347164.59375	
7731	 steps: training loss - 107970.68750	, testing loss - 346640.21875	
7732	 steps: training loss - 114354.46875	, testing loss - 346520.43750	
7733	 steps: training loss - 113241.00781	, testing loss - 346404.81250	
7734	 steps: training loss - 106052.52344	, testing loss - 347011.62500	
7735	 steps: training loss - 115222.12500	, testing loss - 347165.37500	
7736	 steps: training loss - 114117.85156	, testing loss - 347912.68750	
7737	 steps: training loss - 95657.13281	, testing loss - 348986.65625	
7738	 steps: training loss - 109240.74219	, testing loss - 349744.71875	
7739	 steps: training loss - 90141.92969	, testing loss - 350538.71875	
7740	 steps: training loss - 95358.88281	, testing loss - 350921.15625	
7741	 steps: training loss - 109553.44531	, testing loss - 351203.21875	
7742	 steps: training loss - 134115.17188	, testing loss - 351821.34375	
7743	 steps: training loss - 103928.36719	, testing loss - 351990.68750	
7744	 steps: training loss - 103981.87500	, testing loss - 352462.93750	
7745	 steps: training loss - 127190.96875	, testing loss - 353414.34375	
7746	 steps: training loss - 86384.25781	, testing loss - 353842.43750	
7747	 steps: training loss - 103131.05469	, testing loss - 353702.62500	
7748	 steps: training loss - 91399.00000	, testing loss - 352767.71875	
7749	 steps: training loss - 102861.79688	, testing loss - 351449.15625	
7750	 steps: training loss - 113274.59375	, testing loss - 349487.59375	
7751	 steps: training loss - 117148.83594	, testing loss - 348061.71875	
7752	 steps: training loss - 148678.18750	, testing loss - 346809.21875	
7753	 steps: training loss - 110301.21875	, testing loss - 346428.81250	
7754	 steps: training loss - 117180.30469	, testing loss - 347030.06250	
7755	 steps: training loss - 112359.75781	, testing loss - 347413.03125	
7756	 steps: training loss - 110231.20312	, testing loss - 348090.53125	
7757	 steps: training loss - 116813.32812	, testing loss - 348835.62500	
7758	 steps: training loss - 89718.22656	, testing loss - 349177.78125	
7759	 steps: training loss - 99918.16406	, testing loss - 349145.00000	
7760	 steps: training loss - 122300.32812	, testing loss - 349374.50000	
7761	 steps: training loss - 96171.42188	, testing loss - 349341.56250	
7762	 steps: training loss - 127390.82031	, testing loss - 349504.28125	
7763	 steps: training loss - 80734.31250	, testing loss - 349644.03125	
7764	 steps: training loss - 110462.00781	, testing loss - 349580.62500	
7765	 steps: training loss - 123816.54688	, testing loss - 349006.90625	
7766	 steps: training loss - 116259.35938	, testing loss - 347968.06250	
7767	 steps: training loss - 99007.10156	, testing loss - 348253.06250	
7768	 steps: training loss - 135846.78125	, testing loss - 348194.68750	
7769	 steps: training loss - 121156.78125	, testing loss - 348997.78125	
7770	 steps: training loss - 108352.42188	, testing loss - 349878.62500	
7771	 steps: training loss - 115154.14062	, testing loss - 350223.15625	
7772	 steps: training loss - 85137.58594	, testing loss - 351388.53125	
7773	 steps: training loss - 92953.56250	, testing loss - 353150.28125	
7774	 steps: training loss - 101739.16406	, testing loss - 354555.68750	
7775	 steps: training loss - 129489.23438	, testing loss - 354881.03125	
7776	 steps: training loss - 101643.49219	, testing loss - 353978.43750	
7777	 steps: training loss - 118108.10938	, testing loss - 352910.06250	
7778	 steps: training loss - 116590.81250	, testing loss - 351946.65625	
7779	 steps: training loss - 86841.84375	, testing loss - 350791.34375	
7780	 steps: training loss - 94018.86719	, testing loss - 349523.81250	
7781	 steps: training loss - 90909.42969	, testing loss - 348736.78125	
7782	 steps: training loss - 90422.16406	, testing loss - 348058.81250	
7783	 steps: training loss - 84170.03125	, testing loss - 347073.21875	
7784	 steps: training loss - 99934.12500	, testing loss - 346458.34375	
7785	 steps: training loss - 113866.60938	, testing loss - 345974.75000	
7786	 steps: training loss - 99297.25781	, testing loss - 346399.40625	
7787	 steps: training loss - 140804.59375	, testing loss - 346926.31250	
7788	 steps: training loss - 121424.54688	, testing loss - 347904.56250	
7789	 steps: training loss - 103371.09375	, testing loss - 348375.06250	
7790	 steps: training loss - 100894.10156	, testing loss - 347531.93750	
7791	 steps: training loss - 101144.45312	, testing loss - 346873.62500	
7792	 steps: training loss - 114245.27344	, testing loss - 346505.87500	
7793	 steps: training loss - 97386.25781	, testing loss - 346863.87500	
7794	 steps: training loss - 105926.96875	, testing loss - 347690.31250	
7795	 steps: training loss - 86770.13281	, testing loss - 348514.68750	
7796	 steps: training loss - 106088.07031	, testing loss - 349380.81250	
7797	 steps: training loss - 113234.39844	, testing loss - 350200.96875	
7798	 steps: training loss - 118125.78125	, testing loss - 350092.46875	
7799	 steps: training loss - 108871.74219	, testing loss - 349424.37500	
7800	 steps: training loss - 112474.89844	, testing loss - 349182.81250	
7801	 steps: training loss - 94909.65625	, testing loss - 349633.43750	
7802	 steps: training loss - 107308.32031	, testing loss - 349947.09375	
7803	 steps: training loss - 118977.99219	, testing loss - 349584.18750	
7804	 steps: training loss - 102269.27344	, testing loss - 349609.59375	
7805	 steps: training loss - 121684.45312	, testing loss - 350103.21875	
7806	 steps: training loss - 107999.06250	, testing loss - 350920.31250	
7807	 steps: training loss - 104842.11719	, testing loss - 352325.93750	
7808	 steps: training loss - 98309.11719	, testing loss - 354271.40625	
7809	 steps: training loss - 116890.02344	, testing loss - 356640.28125	
7810	 steps: training loss - 117285.45312	, testing loss - 357855.56250	
7811	 steps: training loss - 107756.08594	, testing loss - 358271.34375	
7812	 steps: training loss - 109692.10156	, testing loss - 357973.09375	
7813	 steps: training loss - 94516.64844	, testing loss - 357878.09375	
7814	 steps: training loss - 105820.84375	, testing loss - 358212.09375	
7815	 steps: training loss - 141508.07812	, testing loss - 357388.90625	
7816	 steps: training loss - 105679.23438	, testing loss - 356761.28125	
7817	 steps: training loss - 129683.37500	, testing loss - 356779.65625	
7818	 steps: training loss - 105611.15625	, testing loss - 355577.34375	
7819	 steps: training loss - 109646.04688	, testing loss - 353295.40625	
7820	 steps: training loss - 108829.95312	, testing loss - 350517.81250	
7821	 steps: training loss - 114706.75000	, testing loss - 348302.03125	
7822	 steps: training loss - 114076.42188	, testing loss - 346926.03125	
7823	 steps: training loss - 123686.07812	, testing loss - 346342.78125	
7824	 steps: training loss - 113386.94531	, testing loss - 346735.90625	
7825	 steps: training loss - 98699.83594	, testing loss - 347457.21875	
7826	 steps: training loss - 101337.49219	, testing loss - 348439.53125	
7827	 steps: training loss - 121077.26562	, testing loss - 349069.90625	
7828	 steps: training loss - 115289.57812	, testing loss - 349932.84375	
7829	 steps: training loss - 100929.00000	, testing loss - 351844.90625	
7830	 steps: training loss - 126030.25781	, testing loss - 353557.68750	
7831	 steps: training loss - 81824.37500	, testing loss - 354329.34375	
7832	 steps: training loss - 107124.69531	, testing loss - 354382.59375	
7833	 steps: training loss - 104325.76562	, testing loss - 354459.46875	
7834	 steps: training loss - 126034.03125	, testing loss - 354254.96875	
7835	 steps: training loss - 108296.63281	, testing loss - 355528.93750	
7836	 steps: training loss - 89800.91406	, testing loss - 357122.18750	
7837	 steps: training loss - 100323.63281	, testing loss - 358169.31250	
7838	 steps: training loss - 130035.21875	, testing loss - 358543.65625	
7839	 steps: training loss - 85441.21094	, testing loss - 358015.75000	
7840	 steps: training loss - 123090.12500	, testing loss - 357467.68750	
7841	 steps: training loss - 124439.10156	, testing loss - 357435.12500	
7842	 steps: training loss - 97985.91406	, testing loss - 356570.96875	
7843	 steps: training loss - 106609.36719	, testing loss - 354833.21875	
7844	 steps: training loss - 103684.33594	, testing loss - 353085.71875	
7845	 steps: training loss - 111735.72656	, testing loss - 350980.15625	
7846	 steps: training loss - 112748.39062	, testing loss - 349249.34375	
7847	 steps: training loss - 98405.50781	, testing loss - 348089.25000	
7848	 steps: training loss - 133763.29688	, testing loss - 347451.34375	
7849	 steps: training loss - 103717.07031	, testing loss - 347282.84375	
7850	 steps: training loss - 111952.15625	, testing loss - 347422.06250	
7851	 steps: training loss - 136113.17188	, testing loss - 347711.18750	
7852	 steps: training loss - 112449.98438	, testing loss - 348424.75000	
7853	 steps: training loss - 111287.03125	, testing loss - 349645.18750	
7854	 steps: training loss - 119844.95312	, testing loss - 349686.53125	
7855	 steps: training loss - 88512.42188	, testing loss - 348979.96875	
7856	 steps: training loss - 88460.85938	, testing loss - 347776.34375	
7857	 steps: training loss - 114016.39844	, testing loss - 347094.93750	
7858	 steps: training loss - 111807.23438	, testing loss - 347124.31250	
7859	 steps: training loss - 106703.46875	, testing loss - 348325.34375	
7860	 steps: training loss - 87448.47656	, testing loss - 349732.34375	
7861	 steps: training loss - 98786.47656	, testing loss - 350462.28125	
7862	 steps: training loss - 113601.71094	, testing loss - 350919.59375	
7863	 steps: training loss - 130364.96875	, testing loss - 351658.81250	
7864	 steps: training loss - 104976.42188	, testing loss - 352864.43750	
7865	 steps: training loss - 114902.39844	, testing loss - 353588.78125	
7866	 steps: training loss - 87641.13281	, testing loss - 353546.06250	
7867	 steps: training loss - 102220.02344	, testing loss - 353246.84375	
7868	 steps: training loss - 93080.65625	, testing loss - 352264.56250	
7869	 steps: training loss - 134877.64062	, testing loss - 351435.68750	
7870	 steps: training loss - 112221.62500	, testing loss - 350090.15625	
7871	 steps: training loss - 117308.65625	, testing loss - 349072.68750	
7872	 steps: training loss - 109176.59375	, testing loss - 348522.09375	
7873	 steps: training loss - 100442.03125	, testing loss - 348072.68750	
7874	 steps: training loss - 100075.07812	, testing loss - 347781.43750	
7875	 steps: training loss - 98266.67969	, testing loss - 348117.12500	
7876	 steps: training loss - 113888.36719	, testing loss - 348655.93750	
7877	 steps: training loss - 104372.65625	, testing loss - 349670.84375	
7878	 steps: training loss - 126316.23438	, testing loss - 350292.78125	
7879	 steps: training loss - 107981.67188	, testing loss - 350447.28125	
7880	 steps: training loss - 83658.26562	, testing loss - 350637.62500	
7881	 steps: training loss - 121446.32812	, testing loss - 350465.40625	
7882	 steps: training loss - 130302.71094	, testing loss - 349420.96875	
7883	 steps: training loss - 114372.32812	, testing loss - 348740.15625	
7884	 steps: training loss - 88415.05469	, testing loss - 347615.87500	
7885	 steps: training loss - 76892.75781	, testing loss - 346754.96875	
7886	 steps: training loss - 111266.75781	, testing loss - 346322.37500	
7887	 steps: training loss - 102874.60938	, testing loss - 345600.09375	
7888	 steps: training loss - 119323.71094	, testing loss - 345394.62500	
7889	 steps: training loss - 105181.01562	, testing loss - 344564.68750	
7890	 steps: training loss - 126118.89062	, testing loss - 343815.21875	
7891	 steps: training loss - 98807.75781	, testing loss - 343402.40625	
7892	 steps: training loss - 122676.80469	, testing loss - 343429.59375	
7893	 steps: training loss - 99541.68750	, testing loss - 344443.15625	
7894	 steps: training loss - 117181.27344	, testing loss - 345171.93750	
7895	 steps: training loss - 99097.69531	, testing loss - 346051.37500	
7896	 steps: training loss - 109928.17188	, testing loss - 347055.81250	
7897	 steps: training loss - 96774.69531	, testing loss - 348530.96875	
7898	 steps: training loss - 95518.57031	, testing loss - 350465.81250	
7899	 steps: training loss - 115805.16406	, testing loss - 352794.37500	
7900	 steps: training loss - 114860.66406	, testing loss - 355773.62500	
7901	 steps: training loss - 121857.18750	, testing loss - 360347.12500	
7902	 steps: training loss - 90925.57031	, testing loss - 364780.84375	
7903	 steps: training loss - 106946.42188	, testing loss - 368280.78125	
7904	 steps: training loss - 93244.91406	, testing loss - 369268.75000	
7905	 steps: training loss - 109830.46875	, testing loss - 368713.96875	
7906	 steps: training loss - 118150.78906	, testing loss - 368225.81250	
7907	 steps: training loss - 138834.70312	, testing loss - 367429.46875	
7908	 steps: training loss - 128815.55469	, testing loss - 367689.78125	
7909	 steps: training loss - 138318.67188	, testing loss - 367050.40625	
7910	 steps: training loss - 116558.39844	, testing loss - 364598.00000	
7911	 steps: training loss - 133800.23438	, testing loss - 361193.75000	
7912	 steps: training loss - 92533.42188	, testing loss - 357188.06250	
7913	 steps: training loss - 126061.92188	, testing loss - 353264.28125	
7914	 steps: training loss - 94913.25781	, testing loss - 350560.15625	
7915	 steps: training loss - 111741.26562	, testing loss - 348559.15625	
7916	 steps: training loss - 107093.83594	, testing loss - 347238.75000	
7917	 steps: training loss - 109314.01562	, testing loss - 345515.18750	
7918	 steps: training loss - 105759.18750	, testing loss - 343688.90625	
7919	 steps: training loss - 132673.79688	, testing loss - 342765.12500	
7920	 steps: training loss - 110622.34375	, testing loss - 342963.06250	
7921	 steps: training loss - 116092.70312	, testing loss - 343622.65625	
7922	 steps: training loss - 92908.57031	, testing loss - 343971.31250	
7923	 steps: training loss - 103982.44531	, testing loss - 344311.68750	
7924	 steps: training loss - 106845.07031	, testing loss - 344896.90625	
7925	 steps: training loss - 103821.85938	, testing loss - 344941.00000	
7926	 steps: training loss - 117814.85156	, testing loss - 344898.25000	
7927	 steps: training loss - 98991.71094	, testing loss - 345301.28125	
7928	 steps: training loss - 86726.60156	, testing loss - 345629.25000	
7929	 steps: training loss - 99066.70312	, testing loss - 345939.71875	
7930	 steps: training loss - 82093.86719	, testing loss - 346586.78125	
7931	 steps: training loss - 107228.65625	, testing loss - 347112.75000	
7932	 steps: training loss - 96763.18750	, testing loss - 347421.65625	
7933	 steps: training loss - 114186.55469	, testing loss - 347248.56250	
7934	 steps: training loss - 81125.90625	, testing loss - 347748.28125	
7935	 steps: training loss - 95717.03906	, testing loss - 348403.00000	
7936	 steps: training loss - 101549.38281	, testing loss - 349060.68750	
7937	 steps: training loss - 81059.68750	, testing loss - 350217.46875	
7938	 steps: training loss - 130019.67188	, testing loss - 351320.15625	
7939	 steps: training loss - 137793.68750	, testing loss - 351672.31250	
7940	 steps: training loss - 99303.35156	, testing loss - 352970.96875	
7941	 steps: training loss - 84850.91406	, testing loss - 354017.31250	
7942	 steps: training loss - 114253.31250	, testing loss - 354580.68750	
7943	 steps: training loss - 87847.80469	, testing loss - 355514.37500	
7944	 steps: training loss - 117275.35938	, testing loss - 357854.15625	
7945	 steps: training loss - 93607.61719	, testing loss - 361000.12500	
7946	 steps: training loss - 110538.32812	, testing loss - 363403.18750	
7947	 steps: training loss - 119339.38281	, testing loss - 364962.43750	
7948	 steps: training loss - 118924.84375	, testing loss - 364552.25000	
7949	 steps: training loss - 128410.22656	, testing loss - 364357.06250	
7950	 steps: training loss - 140219.25000	, testing loss - 362836.00000	
7951	 steps: training loss - 126260.77344	, testing loss - 358621.37500	
7952	 steps: training loss - 86048.65625	, testing loss - 355032.53125	
7953	 steps: training loss - 94873.42188	, testing loss - 351881.59375	
7954	 steps: training loss - 97532.07031	, testing loss - 349525.46875	
7955	 steps: training loss - 102797.69531	, testing loss - 348108.12500	
7956	 steps: training loss - 120227.72656	, testing loss - 347364.06250	
7957	 steps: training loss - 128717.17969	, testing loss - 347060.68750	
7958	 steps: training loss - 102335.67969	, testing loss - 348047.78125	
7959	 steps: training loss - 94571.51562	, testing loss - 349532.62500	
7960	 steps: training loss - 88944.92969	, testing loss - 351277.93750	
7961	 steps: training loss - 120452.64062	, testing loss - 352124.34375	
7962	 steps: training loss - 123370.36719	, testing loss - 350827.56250	
7963	 steps: training loss - 121611.15625	, testing loss - 349572.96875	
7964	 steps: training loss - 123270.15625	, testing loss - 347832.15625	
7965	 steps: training loss - 120424.08594	, testing loss - 346282.03125	
7966	 steps: training loss - 129811.46094	, testing loss - 344663.28125	
7967	 steps: training loss - 121824.12500	, testing loss - 343367.68750	
7968	 steps: training loss - 103995.02344	, testing loss - 342374.34375	
7969	 steps: training loss - 93709.96875	, testing loss - 342122.43750	
7970	 steps: training loss - 87812.39844	, testing loss - 342571.96875	
7971	 steps: training loss - 104443.17188	, testing loss - 343878.50000	
7972	 steps: training loss - 103716.03125	, testing loss - 345300.71875	
7973	 steps: training loss - 110146.29688	, testing loss - 346921.43750	
7974	 steps: training loss - 113805.14844	, testing loss - 348928.65625	
7975	 steps: training loss - 97286.77344	, testing loss - 350549.53125	
7976	 steps: training loss - 114364.90625	, testing loss - 351633.21875	
7977	 steps: training loss - 111511.03125	, testing loss - 352278.53125	
7978	 steps: training loss - 126043.97656	, testing loss - 352520.37500	
7979	 steps: training loss - 92175.77344	, testing loss - 352302.65625	
7980	 steps: training loss - 112043.42969	, testing loss - 352190.09375	
7981	 steps: training loss - 102154.27344	, testing loss - 352123.71875	
7982	 steps: training loss - 103510.43750	, testing loss - 353002.75000	
7983	 steps: training loss - 90595.31250	, testing loss - 355348.90625	
7984	 steps: training loss - 106668.16406	, testing loss - 357716.50000	
7985	 steps: training loss - 128138.51562	, testing loss - 359383.65625	
7986	 steps: training loss - 108498.71094	, testing loss - 360428.09375	
7987	 steps: training loss - 124185.36719	, testing loss - 362303.93750	
7988	 steps: training loss - 109029.71094	, testing loss - 363761.46875	
7989	 steps: training loss - 111832.17188	, testing loss - 364147.28125	
7990	 steps: training loss - 113361.02344	, testing loss - 364857.96875	
7991	 steps: training loss - 118224.27344	, testing loss - 366890.37500	
7992	 steps: training loss - 121055.19531	, testing loss - 368504.12500	
7993	 steps: training loss - 128173.42188	, testing loss - 368646.90625	
7994	 steps: training loss - 95206.78906	, testing loss - 366103.59375	
7995	 steps: training loss - 113316.47656	, testing loss - 362896.40625	
7996	 steps: training loss - 118068.54688	, testing loss - 359168.34375	
7997	 steps: training loss - 88711.54688	, testing loss - 355819.03125	
7998	 steps: training loss - 127617.28906	, testing loss - 353376.81250	
7999	 steps: training loss - 120309.57031	, testing loss - 350144.43750	
8000	 steps: training loss - 95206.90625	, testing loss - 346893.25000	
8001	 steps: training loss - 119900.24219	, testing loss - 344457.18750	
8002	 steps: training loss - 85199.91406	, testing loss - 342710.25000	
8003	 steps: training loss - 100514.03125	, testing loss - 341352.40625	
8004	 steps: training loss - 108985.07812	, testing loss - 340005.59375	
8005	 steps: training loss - 94253.54688	, testing loss - 338730.53125	
8006	 steps: training loss - 111131.16406	, testing loss - 338055.06250	
8007	 steps: training loss - 113974.57031	, testing loss - 338308.15625	
8008	 steps: training loss - 129273.44531	, testing loss - 339106.37500	
8009	 steps: training loss - 131684.53125	, testing loss - 340081.46875	
8010	 steps: training loss - 112964.23438	, testing loss - 341054.96875	
8011	 steps: training loss - 104602.81250	, testing loss - 343031.59375	
8012	 steps: training loss - 104879.50000	, testing loss - 345417.06250	
8013	 steps: training loss - 113771.70312	, testing loss - 347580.65625	
8014	 steps: training loss - 120025.67188	, testing loss - 348769.78125	
8015	 steps: training loss - 127760.75000	, testing loss - 349835.50000	
8016	 steps: training loss - 100308.79688	, testing loss - 352194.78125	
8017	 steps: training loss - 99361.01562	, testing loss - 353757.00000	
8018	 steps: training loss - 134637.85938	, testing loss - 354662.46875	
8019	 steps: training loss - 119692.60938	, testing loss - 355375.53125	
8020	 steps: training loss - 139640.82812	, testing loss - 355280.75000	
8021	 steps: training loss - 109948.60156	, testing loss - 355786.96875	
8022	 steps: training loss - 116686.36719	, testing loss - 355316.53125	
8023	 steps: training loss - 99559.25000	, testing loss - 355034.90625	
8024	 steps: training loss - 114180.51562	, testing loss - 354413.34375	
8025	 steps: training loss - 106180.30469	, testing loss - 352895.31250	
8026	 steps: training loss - 121149.82812	, testing loss - 350937.81250	
8027	 steps: training loss - 100457.99219	, testing loss - 349026.28125	
8028	 steps: training loss - 121516.86719	, testing loss - 347757.03125	
8029	 steps: training loss - 124775.74219	, testing loss - 347096.75000	
8030	 steps: training loss - 125649.48438	, testing loss - 347025.09375	
8031	 steps: training loss - 117093.04688	, testing loss - 347645.71875	
8032	 steps: training loss - 120337.53906	, testing loss - 347700.00000	
8033	 steps: training loss - 101952.90625	, testing loss - 347213.90625	
8034	 steps: training loss - 114435.88281	, testing loss - 347734.56250	
8035	 steps: training loss - 95179.58594	, testing loss - 348921.43750	
8036	 steps: training loss - 125929.22656	, testing loss - 350013.93750	
8037	 steps: training loss - 129651.85156	, testing loss - 351248.56250	
8038	 steps: training loss - 102545.85938	, testing loss - 352163.84375	
8039	 steps: training loss - 97804.30469	, testing loss - 352568.71875	
8040	 steps: training loss - 113540.09375	, testing loss - 352748.75000	
8041	 steps: training loss - 113523.41406	, testing loss - 352835.96875	
8042	 steps: training loss - 127310.99219	, testing loss - 352291.46875	
8043	 steps: training loss - 108639.36719	, testing loss - 352667.31250	
8044	 steps: training loss - 129227.32812	, testing loss - 353413.34375	
8045	 steps: training loss - 95242.44531	, testing loss - 353745.84375	
8046	 steps: training loss - 101091.37500	, testing loss - 354023.15625	
8047	 steps: training loss - 99037.51562	, testing loss - 352936.87500	
8048	 steps: training loss - 128782.38281	, testing loss - 351361.06250	
8049	 steps: training loss - 125166.73438	, testing loss - 350001.34375	
8050	 steps: training loss - 112116.57812	, testing loss - 350354.71875	
8051	 steps: training loss - 120445.12500	, testing loss - 350502.09375	
8052	 steps: training loss - 113977.75781	, testing loss - 350653.56250	
8053	 steps: training loss - 136495.29688	, testing loss - 350470.37500	
8054	 steps: training loss - 120830.82812	, testing loss - 349635.25000	
8055	 steps: training loss - 119035.23438	, testing loss - 348569.03125	
8056	 steps: training loss - 108583.42188	, testing loss - 348438.12500	
8057	 steps: training loss - 107239.35156	, testing loss - 348665.53125	
8058	 steps: training loss - 130198.75781	, testing loss - 348727.31250	
8059	 steps: training loss - 147093.39062	, testing loss - 349385.03125	
8060	 steps: training loss - 126582.59375	, testing loss - 349667.78125	
8061	 steps: training loss - 105653.94531	, testing loss - 350171.71875	
8062	 steps: training loss - 113814.60938	, testing loss - 350757.84375	
8063	 steps: training loss - 121118.44531	, testing loss - 351134.25000	
8064	 steps: training loss - 103275.91406	, testing loss - 352427.59375	
8065	 steps: training loss - 125283.15625	, testing loss - 354444.43750	
8066	 steps: training loss - 107105.83594	, testing loss - 356392.43750	
8067	 steps: training loss - 129048.26562	, testing loss - 358476.71875	
8068	 steps: training loss - 108375.73438	, testing loss - 359737.34375	
8069	 steps: training loss - 114122.44531	, testing loss - 359779.59375	
8070	 steps: training loss - 115221.71875	, testing loss - 359339.81250	
8071	 steps: training loss - 97217.85938	, testing loss - 358303.81250	
8072	 steps: training loss - 103106.43750	, testing loss - 356740.12500	
8073	 steps: training loss - 95940.60156	, testing loss - 356439.18750	
8074	 steps: training loss - 108738.85156	, testing loss - 355460.68750	
8075	 steps: training loss - 106267.75000	, testing loss - 353754.21875	
8076	 steps: training loss - 84993.03906	, testing loss - 351637.00000	
8077	 steps: training loss - 100226.70312	, testing loss - 349675.90625	
8078	 steps: training loss - 104469.60156	, testing loss - 347847.65625	
8079	 steps: training loss - 110663.53125	, testing loss - 346144.59375	
8080	 steps: training loss - 113789.11719	, testing loss - 344932.62500	
8081	 steps: training loss - 123555.41406	, testing loss - 343688.53125	
8082	 steps: training loss - 123054.04688	, testing loss - 343274.34375	
8083	 steps: training loss - 97558.07031	, testing loss - 343343.59375	
8084	 steps: training loss - 101444.18750	, testing loss - 343664.65625	
8085	 steps: training loss - 125561.87500	, testing loss - 344400.68750	
8086	 steps: training loss - 103275.42969	, testing loss - 345863.68750	
8087	 steps: training loss - 138978.23438	, testing loss - 348116.71875	
8088	 steps: training loss - 108447.87500	, testing loss - 350764.56250	
8089	 steps: training loss - 103344.25000	, testing loss - 353136.93750	
8090	 steps: training loss - 127948.28906	, testing loss - 354562.00000	
8091	 steps: training loss - 114049.08594	, testing loss - 354882.81250	
8092	 steps: training loss - 124981.57812	, testing loss - 355008.28125	
8093	 steps: training loss - 121053.61719	, testing loss - 354761.03125	
8094	 steps: training loss - 109947.51562	, testing loss - 354629.06250	
8095	 steps: training loss - 115126.76562	, testing loss - 354125.68750	
8096	 steps: training loss - 88492.85156	, testing loss - 352828.68750	
8097	 steps: training loss - 113344.85938	, testing loss - 351488.53125	
8098	 steps: training loss - 96430.79688	, testing loss - 349379.68750	
8099	 steps: training loss - 94057.95312	, testing loss - 347417.65625	
8100	 steps: training loss - 131083.89062	, testing loss - 345952.56250	
8101	 steps: training loss - 123644.80469	, testing loss - 345380.65625	
8102	 steps: training loss - 127771.31250	, testing loss - 344980.71875	
8103	 steps: training loss - 116892.92188	, testing loss - 344707.78125	
8104	 steps: training loss - 103230.69531	, testing loss - 345240.37500	
8105	 steps: training loss - 104922.36719	, testing loss - 346042.18750	
8106	 steps: training loss - 127717.04688	, testing loss - 346491.75000	
8107	 steps: training loss - 114359.34375	, testing loss - 346483.93750	
8108	 steps: training loss - 89393.07812	, testing loss - 346254.78125	
8109	 steps: training loss - 120174.70312	, testing loss - 346290.53125	
8110	 steps: training loss - 103836.48438	, testing loss - 346251.65625	
8111	 steps: training loss - 103648.38281	, testing loss - 346012.84375	
8112	 steps: training loss - 114095.74219	, testing loss - 345868.25000	
8113	 steps: training loss - 129876.93750	, testing loss - 346496.34375	
8114	 steps: training loss - 90718.20312	, testing loss - 347136.03125	
8115	 steps: training loss - 113440.28125	, testing loss - 348262.43750	
8116	 steps: training loss - 115815.68750	, testing loss - 349419.68750	
8117	 steps: training loss - 104551.64062	, testing loss - 350823.34375	
8118	 steps: training loss - 129503.60156	, testing loss - 352135.90625	
8119	 steps: training loss - 109736.64844	, testing loss - 352966.56250	
8120	 steps: training loss - 101949.37500	, testing loss - 352692.75000	
8121	 steps: training loss - 124463.65625	, testing loss - 351021.53125	
8122	 steps: training loss - 76259.25781	, testing loss - 349874.93750	
8123	 steps: training loss - 123672.17969	, testing loss - 348493.71875	
8124	 steps: training loss - 92033.11719	, testing loss - 346802.78125	
8125	 steps: training loss - 86093.13281	, testing loss - 345159.28125	
8126	 steps: training loss - 102160.51562	, testing loss - 344117.75000	
8127	 steps: training loss - 119980.87500	, testing loss - 343215.40625	
8128	 steps: training loss - 117631.07031	, testing loss - 342741.31250	
8129	 steps: training loss - 129524.86719	, testing loss - 342476.28125	
8130	 steps: training loss - 120383.64844	, testing loss - 342276.90625	
8131	 steps: training loss - 118095.69531	, testing loss - 342184.09375	
8132	 steps: training loss - 104709.74219	, testing loss - 342208.87500	
8133	 steps: training loss - 111730.90625	, testing loss - 342564.81250	
8134	 steps: training loss - 93469.46094	, testing loss - 343273.12500	
8135	 steps: training loss - 132327.65625	, testing loss - 344131.28125	
8136	 steps: training loss - 102966.89062	, testing loss - 344147.25000	
8137	 steps: training loss - 106880.95312	, testing loss - 343558.81250	
8138	 steps: training loss - 111360.02344	, testing loss - 343753.37500	
8139	 steps: training loss - 102435.87500	, testing loss - 344290.68750	
8140	 steps: training loss - 120078.56250	, testing loss - 345853.56250	
8141	 steps: training loss - 104484.16406	, testing loss - 347298.56250	
8142	 steps: training loss - 95082.01562	, testing loss - 348788.18750	
8143	 steps: training loss - 112755.67969	, testing loss - 349915.56250	
8144	 steps: training loss - 118588.69531	, testing loss - 350687.65625	
8145	 steps: training loss - 99455.59375	, testing loss - 352409.84375	
8146	 steps: training loss - 95004.74219	, testing loss - 353237.75000	
8147	 steps: training loss - 117825.45312	, testing loss - 352876.09375	
8148	 steps: training loss - 121136.20312	, testing loss - 352595.09375	
8149	 steps: training loss - 78790.94531	, testing loss - 351203.28125	
8150	 steps: training loss - 105233.17969	, testing loss - 350079.87500	
8151	 steps: training loss - 84715.18750	, testing loss - 350092.93750	
8152	 steps: training loss - 105524.09375	, testing loss - 350253.75000	
8153	 steps: training loss - 117853.68750	, testing loss - 350022.43750	
8154	 steps: training loss - 124572.60938	, testing loss - 350025.00000	
8155	 steps: training loss - 105255.76562	, testing loss - 349038.34375	
8156	 steps: training loss - 98798.89844	, testing loss - 347935.78125	
8157	 steps: training loss - 110020.47656	, testing loss - 346127.56250	
8158	 steps: training loss - 127108.15625	, testing loss - 344839.65625	
8159	 steps: training loss - 111035.42969	, testing loss - 344220.93750	
8160	 steps: training loss - 106978.89062	, testing loss - 344605.81250	
8161	 steps: training loss - 97162.61719	, testing loss - 345074.15625	
8162	 steps: training loss - 85496.11719	, testing loss - 345338.75000	
8163	 steps: training loss - 107501.03125	, testing loss - 345545.40625	
8164	 steps: training loss - 129048.09375	, testing loss - 346057.53125	
8165	 steps: training loss - 110995.57812	, testing loss - 346733.25000	
8166	 steps: training loss - 115291.46094	, testing loss - 347059.81250	
8167	 steps: training loss - 111466.13281	, testing loss - 347811.06250	
8168	 steps: training loss - 106696.03906	, testing loss - 348581.75000	
8169	 steps: training loss - 101576.12500	, testing loss - 349223.87500	
8170	 steps: training loss - 91722.23438	, testing loss - 351293.81250	
8171	 steps: training loss - 104937.45312	, testing loss - 353738.03125	
8172	 steps: training loss - 111250.43750	, testing loss - 355562.37500	
8173	 steps: training loss - 100583.72656	, testing loss - 356522.50000	
8174	 steps: training loss - 100108.50000	, testing loss - 357437.53125	
8175	 steps: training loss - 115435.67188	, testing loss - 358548.81250	
8176	 steps: training loss - 110780.67188	, testing loss - 359438.40625	
8177	 steps: training loss - 97521.30469	, testing loss - 359248.65625	
8178	 steps: training loss - 131276.98438	, testing loss - 359374.93750	
8179	 steps: training loss - 111772.25000	, testing loss - 359196.93750	
8180	 steps: training loss - 109748.29688	, testing loss - 358274.09375	
8181	 steps: training loss - 137516.95312	, testing loss - 357488.00000	
8182	 steps: training loss - 88000.25781	, testing loss - 356551.84375	
8183	 steps: training loss - 116437.61719	, testing loss - 355787.75000	
8184	 steps: training loss - 115125.46094	, testing loss - 354883.87500	
8185	 steps: training loss - 115090.26562	, testing loss - 353521.31250	
8186	 steps: training loss - 124221.85938	, testing loss - 352060.31250	
8187	 steps: training loss - 116462.53125	, testing loss - 351646.37500	
8188	 steps: training loss - 93945.61719	, testing loss - 350894.65625	
8189	 steps: training loss - 106178.95312	, testing loss - 350244.96875	
8190	 steps: training loss - 125270.08594	, testing loss - 349903.93750	
8191	 steps: training loss - 116085.28125	, testing loss - 349235.18750	
8192	 steps: training loss - 111001.00000	, testing loss - 348050.65625	
8193	 steps: training loss - 126314.64844	, testing loss - 347053.15625	
8194	 steps: training loss - 103515.02344	, testing loss - 347000.15625	
8195	 steps: training loss - 114133.03125	, testing loss - 347088.75000	
8196	 steps: training loss - 123191.80469	, testing loss - 347126.31250	
8197	 steps: training loss - 113526.13281	, testing loss - 346646.50000	
8198	 steps: training loss - 106557.08594	, testing loss - 346610.81250	
8199	 steps: training loss - 113408.53906	, testing loss - 346009.62500	
8200	 steps: training loss - 132669.65625	, testing loss - 345680.34375	
8201	 steps: training loss - 107745.34375	, testing loss - 345478.87500	
8202	 steps: training loss - 103694.17969	, testing loss - 345334.34375	
8203	 steps: training loss - 110679.32812	, testing loss - 345015.87500	
8204	 steps: training loss - 104563.90625	, testing loss - 345029.71875	
8205	 steps: training loss - 101357.77344	, testing loss - 345732.37500	
8206	 steps: training loss - 114303.00000	, testing loss - 347509.81250	
8207	 steps: training loss - 104691.90625	, testing loss - 350085.34375	
8208	 steps: training loss - 123151.85938	, testing loss - 352660.09375	
8209	 steps: training loss - 108355.35938	, testing loss - 353341.06250	
8210	 steps: training loss - 102869.02344	, testing loss - 352561.62500	
8211	 steps: training loss - 106998.12500	, testing loss - 352320.50000	
8212	 steps: training loss - 107394.83594	, testing loss - 352390.18750	
8213	 steps: training loss - 130939.39062	, testing loss - 352741.40625	
8214	 steps: training loss - 137437.84375	, testing loss - 353212.25000	
8215	 steps: training loss - 132054.14062	, testing loss - 354873.81250	
8216	 steps: training loss - 113172.52344	, testing loss - 357068.46875	
8217	 steps: training loss - 133906.25000	, testing loss - 357995.12500	
8218	 steps: training loss - 87672.35156	, testing loss - 358927.56250	
8219	 steps: training loss - 106826.98438	, testing loss - 359559.65625	
8220	 steps: training loss - 106350.85156	, testing loss - 360140.09375	
8221	 steps: training loss - 108599.89062	, testing loss - 362011.53125	
8222	 steps: training loss - 92320.53906	, testing loss - 363476.31250	
8223	 steps: training loss - 102623.70312	, testing loss - 363767.90625	
8224	 steps: training loss - 111151.10156	, testing loss - 363302.34375	
8225	 steps: training loss - 117651.32031	, testing loss - 361104.87500	
8226	 steps: training loss - 98909.98438	, testing loss - 358249.31250	
8227	 steps: training loss - 108535.32812	, testing loss - 355537.71875	
8228	 steps: training loss - 106616.56250	, testing loss - 353820.09375	
8229	 steps: training loss - 75789.70312	, testing loss - 352984.71875	
8230	 steps: training loss - 104856.53906	, testing loss - 351965.43750	
8231	 steps: training loss - 108921.54688	, testing loss - 350791.68750	
8232	 steps: training loss - 131868.79688	, testing loss - 349889.50000	
8233	 steps: training loss - 116732.73438	, testing loss - 349203.43750	
8234	 steps: training loss - 136427.71875	, testing loss - 348206.25000	
8235	 steps: training loss - 96439.85156	, testing loss - 346906.18750	
8236	 steps: training loss - 114875.95312	, testing loss - 346290.71875	
8237	 steps: training loss - 108353.07031	, testing loss - 346114.59375	
8238	 steps: training loss - 107733.25000	, testing loss - 346640.93750	
8239	 steps: training loss - 116576.63281	, testing loss - 347341.78125	
8240	 steps: training loss - 101099.53906	, testing loss - 348039.15625	
8241	 steps: training loss - 108620.43750	, testing loss - 349647.65625	
8242	 steps: training loss - 118319.35156	, testing loss - 351585.90625	
8243	 steps: training loss - 106840.11719	, testing loss - 353829.96875	
8244	 steps: training loss - 125343.53906	, testing loss - 356073.40625	
8245	 steps: training loss - 123034.96875	, testing loss - 358035.06250	
8246	 steps: training loss - 101872.04688	, testing loss - 358613.28125	
8247	 steps: training loss - 123042.28125	, testing loss - 358575.06250	
8248	 steps: training loss - 118539.52344	, testing loss - 358459.31250	
8249	 steps: training loss - 130939.40625	, testing loss - 359304.15625	
8250	 steps: training loss - 118461.21875	, testing loss - 359609.46875	
8251	 steps: training loss - 117405.17188	, testing loss - 358451.21875	
8252	 steps: training loss - 114490.42969	, testing loss - 357426.43750	
8253	 steps: training loss - 108081.76562	, testing loss - 356134.65625	
8254	 steps: training loss - 98268.71094	, testing loss - 354781.65625	
8255	 steps: training loss - 84443.95312	, testing loss - 353134.87500	
8256	 steps: training loss - 106756.92969	, testing loss - 350979.00000	
8257	 steps: training loss - 131947.54688	, testing loss - 349411.28125	
8258	 steps: training loss - 125004.40625	, testing loss - 348555.56250	
8259	 steps: training loss - 108271.81250	, testing loss - 348249.53125	
8260	 steps: training loss - 110965.87500	, testing loss - 348430.21875	
8261	 steps: training loss - 102903.36719	, testing loss - 348686.84375	
8262	 steps: training loss - 123647.13281	, testing loss - 349591.65625	
8263	 steps: training loss - 97139.40625	, testing loss - 351137.62500	
8264	 steps: training loss - 106116.68750	, testing loss - 353175.62500	
8265	 steps: training loss - 100533.19531	, testing loss - 354509.90625	
8266	 steps: training loss - 116588.17969	, testing loss - 355080.06250	
8267	 steps: training loss - 116239.48438	, testing loss - 355295.21875	
8268	 steps: training loss - 97549.18750	, testing loss - 354710.59375	
8269	 steps: training loss - 109962.92969	, testing loss - 353637.56250	
8270	 steps: training loss - 122411.35938	, testing loss - 353036.03125	
8271	 steps: training loss - 128586.50000	, testing loss - 352227.84375	
8272	 steps: training loss - 114200.77344	, testing loss - 351926.40625	
8273	 steps: training loss - 99457.87500	, testing loss - 351227.09375	
8274	 steps: training loss - 137099.26562	, testing loss - 350356.53125	
8275	 steps: training loss - 93127.76562	, testing loss - 350100.34375	
8276	 steps: training loss - 108527.57031	, testing loss - 349827.12500	
8277	 steps: training loss - 132369.31250	, testing loss - 348866.90625	
8278	 steps: training loss - 97270.24219	, testing loss - 347730.43750	
8279	 steps: training loss - 109534.46875	, testing loss - 347056.65625	
8280	 steps: training loss - 124524.68750	, testing loss - 347822.00000	
8281	 steps: training loss - 132706.87500	, testing loss - 349685.65625	
8282	 steps: training loss - 91475.78906	, testing loss - 350665.34375	
8283	 steps: training loss - 129260.00781	, testing loss - 351375.18750	
8284	 steps: training loss - 139943.71875	, testing loss - 352134.56250	
8285	 steps: training loss - 124049.39062	, testing loss - 352545.62500	
8286	 steps: training loss - 105320.52344	, testing loss - 352346.62500	
8287	 steps: training loss - 100550.30469	, testing loss - 351474.25000	
8288	 steps: training loss - 133883.96875	, testing loss - 350799.68750	
8289	 steps: training loss - 98841.09375	, testing loss - 350748.15625	
8290	 steps: training loss - 85118.97656	, testing loss - 350798.43750	
8291	 steps: training loss - 112264.85156	, testing loss - 350688.75000	
8292	 steps: training loss - 105715.05469	, testing loss - 351052.68750	
8293	 steps: training loss - 108122.02344	, testing loss - 351606.93750	
8294	 steps: training loss - 108601.76562	, testing loss - 351468.59375	
8295	 steps: training loss - 121680.07812	, testing loss - 350749.21875	
8296	 steps: training loss - 111670.96094	, testing loss - 350489.25000	
8297	 steps: training loss - 109362.60938	, testing loss - 350009.71875	
8298	 steps: training loss - 109927.40625	, testing loss - 349443.31250	
8299	 steps: training loss - 95873.23438	, testing loss - 348757.71875	
8300	 steps: training loss - 109483.38281	, testing loss - 347627.21875	
8301	 steps: training loss - 138786.67188	, testing loss - 346275.40625	
8302	 steps: training loss - 113215.60938	, testing loss - 345158.00000	
8303	 steps: training loss - 139432.57812	, testing loss - 344958.40625	
8304	 steps: training loss - 95165.89844	, testing loss - 345187.40625	
8305	 steps: training loss - 102930.50000	, testing loss - 345807.43750	
8306	 steps: training loss - 104831.07031	, testing loss - 346443.75000	
8307	 steps: training loss - 100016.76562	, testing loss - 347302.53125	
8308	 steps: training loss - 88196.34375	, testing loss - 347921.09375	
8309	 steps: training loss - 107226.42188	, testing loss - 348451.40625	
8310	 steps: training loss - 99250.03125	, testing loss - 348120.12500	
8311	 steps: training loss - 108514.02344	, testing loss - 347674.96875	
8312	 steps: training loss - 95559.56250	, testing loss - 347062.81250	
8313	 steps: training loss - 113914.41406	, testing loss - 346023.68750	
8314	 steps: training loss - 77041.91406	, testing loss - 344792.28125	
8315	 steps: training loss - 88096.94531	, testing loss - 343800.09375	
8316	 steps: training loss - 110957.28906	, testing loss - 343454.31250	
8317	 steps: training loss - 125409.39844	, testing loss - 343714.65625	
8318	 steps: training loss - 124350.13281	, testing loss - 344766.62500	
8319	 steps: training loss - 88407.48438	, testing loss - 345519.46875	
8320	 steps: training loss - 105159.64844	, testing loss - 345633.31250	
8321	 steps: training loss - 125117.64062	, testing loss - 345611.93750	
8322	 steps: training loss - 112520.53906	, testing loss - 346314.50000	
8323	 steps: training loss - 107251.78125	, testing loss - 347683.37500	
8324	 steps: training loss - 125115.45312	, testing loss - 348620.50000	
8325	 steps: training loss - 102034.50000	, testing loss - 350160.59375	
8326	 steps: training loss - 102577.56250	, testing loss - 351302.15625	
8327	 steps: training loss - 104038.13281	, testing loss - 352376.84375	
8328	 steps: training loss - 120864.83594	, testing loss - 352679.06250	
8329	 steps: training loss - 75806.78906	, testing loss - 352704.81250	
8330	 steps: training loss - 90425.10156	, testing loss - 353508.15625	
8331	 steps: training loss - 86740.82031	, testing loss - 353808.31250	
8332	 steps: training loss - 128202.38281	, testing loss - 354167.37500	
8333	 steps: training loss - 104040.69531	, testing loss - 354373.34375	
8334	 steps: training loss - 101494.09375	, testing loss - 354327.31250	
8335	 steps: training loss - 99400.85938	, testing loss - 354897.68750	
8336	 steps: training loss - 92299.75781	, testing loss - 354740.31250	
8337	 steps: training loss - 136223.35938	, testing loss - 354876.87500	
8338	 steps: training loss - 108268.04688	, testing loss - 355339.71875	
8339	 steps: training loss - 128427.45312	, testing loss - 355558.40625	
8340	 steps: training loss - 133344.96875	, testing loss - 354695.78125	
8341	 steps: training loss - 132576.03125	, testing loss - 353678.96875	
8342	 steps: training loss - 103848.19531	, testing loss - 353264.12500	
8343	 steps: training loss - 98049.96094	, testing loss - 353666.59375	
8344	 steps: training loss - 95861.43750	, testing loss - 354329.59375	
8345	 steps: training loss - 110623.25000	, testing loss - 354774.37500	
8346	 steps: training loss - 103897.96875	, testing loss - 355271.65625	
8347	 steps: training loss - 147225.92188	, testing loss - 355244.50000	
8348	 steps: training loss - 108774.61719	, testing loss - 354143.25000	
8349	 steps: training loss - 114617.94531	, testing loss - 352476.03125	
8350	 steps: training loss - 101890.08594	, testing loss - 350483.75000	
8351	 steps: training loss - 102494.28125	, testing loss - 348656.34375	
8352	 steps: training loss - 118865.17969	, testing loss - 346918.12500	
8353	 steps: training loss - 102308.62500	, testing loss - 345459.15625	
8354	 steps: training loss - 109878.37500	, testing loss - 344812.78125	
8355	 steps: training loss - 94537.02344	, testing loss - 344807.18750	
8356	 steps: training loss - 93575.21094	, testing loss - 344931.28125	
8357	 steps: training loss - 133268.32812	, testing loss - 345407.96875	
8358	 steps: training loss - 104698.92969	, testing loss - 345750.96875	
8359	 steps: training loss - 112227.53125	, testing loss - 345729.03125	
8360	 steps: training loss - 85031.33594	, testing loss - 345725.28125	
8361	 steps: training loss - 113541.95312	, testing loss - 346094.75000	
8362	 steps: training loss - 95964.15625	, testing loss - 346360.75000	
8363	 steps: training loss - 135014.60938	, testing loss - 346450.56250	
8364	 steps: training loss - 122369.00781	, testing loss - 347130.62500	
8365	 steps: training loss - 102309.44531	, testing loss - 348608.56250	
8366	 steps: training loss - 114118.23438	, testing loss - 349280.71875	
8367	 steps: training loss - 102881.28125	, testing loss - 349895.21875	
8368	 steps: training loss - 124203.64844	, testing loss - 349930.93750	
8369	 steps: training loss - 113030.77344	, testing loss - 349079.59375	
8370	 steps: training loss - 114303.56250	, testing loss - 348413.18750	
8371	 steps: training loss - 123449.57812	, testing loss - 348264.46875	
8372	 steps: training loss - 107662.74219	, testing loss - 347916.78125	
8373	 steps: training loss - 105772.58594	, testing loss - 347176.68750	
8374	 steps: training loss - 104833.58594	, testing loss - 346975.46875	
8375	 steps: training loss - 84025.04688	, testing loss - 346259.28125	
8376	 steps: training loss - 115227.87500	, testing loss - 345606.43750	
8377	 steps: training loss - 108923.19531	, testing loss - 344552.21875	
8378	 steps: training loss - 125965.43750	, testing loss - 343689.93750	
8379	 steps: training loss - 114830.40625	, testing loss - 343258.71875	
8380	 steps: training loss - 87256.34375	, testing loss - 343585.93750	
8381	 steps: training loss - 123203.42188	, testing loss - 343871.06250	
8382	 steps: training loss - 109461.46875	, testing loss - 343644.40625	
8383	 steps: training loss - 110560.91406	, testing loss - 342782.31250	
8384	 steps: training loss - 97125.89062	, testing loss - 341959.84375	
8385	 steps: training loss - 104654.67969	, testing loss - 341794.28125	
8386	 steps: training loss - 117015.38281	, testing loss - 341860.56250	
8387	 steps: training loss - 117061.22656	, testing loss - 342371.78125	
8388	 steps: training loss - 115247.27344	, testing loss - 343161.65625	
8389	 steps: training loss - 100959.34375	, testing loss - 344827.90625	
8390	 steps: training loss - 88174.43750	, testing loss - 347160.46875	
8391	 steps: training loss - 111012.18750	, testing loss - 349340.15625	
8392	 steps: training loss - 116715.44531	, testing loss - 351708.37500	
8393	 steps: training loss - 114178.06250	, testing loss - 353932.06250	
8394	 steps: training loss - 101016.96875	, testing loss - 355669.84375	
8395	 steps: training loss - 107357.59375	, testing loss - 356945.62500	
8396	 steps: training loss - 108466.03125	, testing loss - 356604.34375	
8397	 steps: training loss - 114491.65625	, testing loss - 354395.68750	
8398	 steps: training loss - 114534.69531	, testing loss - 352362.43750	
8399	 steps: training loss - 112181.39062	, testing loss - 349832.56250	
8400	 steps: training loss - 98876.35938	, testing loss - 347999.53125	
8401	 steps: training loss - 131748.34375	, testing loss - 346669.68750	
8402	 steps: training loss - 106373.60938	, testing loss - 345289.34375	
8403	 steps: training loss - 105058.96875	, testing loss - 344568.90625	
8404	 steps: training loss - 125744.71094	, testing loss - 344561.68750	
8405	 steps: training loss - 121108.25000	, testing loss - 345046.53125	
8406	 steps: training loss - 114038.13281	, testing loss - 345315.53125	
8407	 steps: training loss - 112908.17969	, testing loss - 345345.46875	
8408	 steps: training loss - 95300.64062	, testing loss - 346058.62500	
8409	 steps: training loss - 107633.47656	, testing loss - 346938.09375	
8410	 steps: training loss - 119019.26562	, testing loss - 347934.59375	
8411	 steps: training loss - 114733.36719	, testing loss - 348753.40625	
8412	 steps: training loss - 124527.46094	, testing loss - 349469.09375	
8413	 steps: training loss - 132398.60938	, testing loss - 350097.18750	
8414	 steps: training loss - 108759.24219	, testing loss - 351373.93750	
8415	 steps: training loss - 89286.59375	, testing loss - 354026.90625	
8416	 steps: training loss - 98937.48438	, testing loss - 356816.46875	
8417	 steps: training loss - 105938.29688	, testing loss - 358880.90625	
8418	 steps: training loss - 116449.14062	, testing loss - 362549.87500	
8419	 steps: training loss - 109000.96875	, testing loss - 366921.81250	
8420	 steps: training loss - 104603.58594	, testing loss - 370482.15625	
8421	 steps: training loss - 134357.82812	, testing loss - 372564.59375	
8422	 steps: training loss - 117888.26562	, testing loss - 372555.34375	
8423	 steps: training loss - 109786.01562	, testing loss - 370029.06250	
8424	 steps: training loss - 122569.06250	, testing loss - 366874.31250	
8425	 steps: training loss - 73665.85938	, testing loss - 363308.71875	
8426	 steps: training loss - 82965.75781	, testing loss - 360729.65625	
8427	 steps: training loss - 95700.30469	, testing loss - 359214.93750	
8428	 steps: training loss - 121225.71875	, testing loss - 358166.81250	
8429	 steps: training loss - 129071.05469	, testing loss - 357529.65625	
8430	 steps: training loss - 117360.01562	, testing loss - 355796.43750	
8431	 steps: training loss - 121045.02344	, testing loss - 354144.90625	
8432	 steps: training loss - 120148.53125	, testing loss - 352766.78125	
8433	 steps: training loss - 112790.17188	, testing loss - 351091.59375	
8434	 steps: training loss - 136728.75000	, testing loss - 349552.00000	
8435	 steps: training loss - 124356.89844	, testing loss - 347494.59375	
8436	 steps: training loss - 99287.85938	, testing loss - 345361.53125	
8437	 steps: training loss - 100126.96094	, testing loss - 343461.06250	
8438	 steps: training loss - 88341.28125	, testing loss - 342162.50000	
8439	 steps: training loss - 91473.04688	, testing loss - 341615.87500	
8440	 steps: training loss - 116714.61719	, testing loss - 341250.28125	
8441	 steps: training loss - 124745.52344	, testing loss - 341040.59375	
8442	 steps: training loss - 118682.96094	, testing loss - 341129.31250	
8443	 steps: training loss - 82331.77344	, testing loss - 341293.50000	
8444	 steps: training loss - 97665.67188	, testing loss - 341635.84375	
8445	 steps: training loss - 101485.53906	, testing loss - 342479.06250	
8446	 steps: training loss - 127921.07031	, testing loss - 343624.21875	
8447	 steps: training loss - 110826.56250	, testing loss - 344977.50000	
8448	 steps: training loss - 95450.36719	, testing loss - 346438.78125	
8449	 steps: training loss - 99727.99219	, testing loss - 347382.84375	
8450	 steps: training loss - 92779.57031	, testing loss - 347976.03125	
8451	 steps: training loss - 103136.39062	, testing loss - 348427.43750	
8452	 steps: training loss - 109620.14062	, testing loss - 348959.31250	
8453	 steps: training loss - 102906.67969	, testing loss - 349642.00000	
8454	 steps: training loss - 122838.86719	, testing loss - 350888.81250	
8455	 steps: training loss - 107362.42188	, testing loss - 353966.84375	
8456	 steps: training loss - 93167.53906	, testing loss - 356657.75000	
8457	 steps: training loss - 104735.81250	, testing loss - 358595.53125	
8458	 steps: training loss - 126366.71875	, testing loss - 359567.65625	
8459	 steps: training loss - 121390.24219	, testing loss - 359924.96875	
8460	 steps: training loss - 90707.21875	, testing loss - 359068.68750	
8461	 steps: training loss - 125952.38281	, testing loss - 357924.59375	
8462	 steps: training loss - 110916.64844	, testing loss - 356946.53125	
8463	 steps: training loss - 127440.54688	, testing loss - 356614.00000	
8464	 steps: training loss - 109157.86719	, testing loss - 355227.09375	
8465	 steps: training loss - 137091.95312	, testing loss - 352778.21875	
8466	 steps: training loss - 97049.07031	, testing loss - 350481.59375	
8467	 steps: training loss - 116414.03906	, testing loss - 348134.40625	
8468	 steps: training loss - 105663.71094	, testing loss - 346208.09375	
8469	 steps: training loss - 99946.57031	, testing loss - 345443.15625	
8470	 steps: training loss - 105520.33594	, testing loss - 344863.43750	
8471	 steps: training loss - 106613.82031	, testing loss - 344085.87500	
8472	 steps: training loss - 89067.85156	, testing loss - 343343.06250	
8473	 steps: training loss - 115612.59375	, testing loss - 342442.71875	
8474	 steps: training loss - 113969.15625	, testing loss - 341811.28125	
8475	 steps: training loss - 100390.46875	, testing loss - 341416.15625	
8476	 steps: training loss - 112121.86719	, testing loss - 340881.78125	
8477	 steps: training loss - 113954.87500	, testing loss - 340669.15625	
8478	 steps: training loss - 106347.76562	, testing loss - 341103.12500	
8479	 steps: training loss - 101229.75781	, testing loss - 341717.25000	
8480	 steps: training loss - 137017.12500	, testing loss - 342236.93750	
8481	 steps: training loss - 116906.25781	, testing loss - 342220.84375	
8482	 steps: training loss - 103492.05469	, testing loss - 342558.68750	
8483	 steps: training loss - 92655.97656	, testing loss - 343175.40625	
8484	 steps: training loss - 125705.83594	, testing loss - 344430.25000	
8485	 steps: training loss - 104591.07812	, testing loss - 345583.68750	
8486	 steps: training loss - 100286.53125	, testing loss - 347150.15625	
8487	 steps: training loss - 90305.81250	, testing loss - 348871.21875	
8488	 steps: training loss - 119349.78125	, testing loss - 350051.71875	
8489	 steps: training loss - 118662.84375	, testing loss - 351935.15625	
8490	 steps: training loss - 110793.88281	, testing loss - 353114.75000	
8491	 steps: training loss - 111171.40625	, testing loss - 353603.12500	
8492	 steps: training loss - 114001.80469	, testing loss - 354576.65625	
8493	 steps: training loss - 107260.92188	, testing loss - 354991.46875	
8494	 steps: training loss - 119441.12500	, testing loss - 354562.03125	
8495	 steps: training loss - 120416.26562	, testing loss - 353536.87500	
8496	 steps: training loss - 84524.14062	, testing loss - 352930.59375	
8497	 steps: training loss - 121675.77344	, testing loss - 352407.15625	
8498	 steps: training loss - 103655.26562	, testing loss - 350799.03125	
8499	 steps: training loss - 128399.85156	, testing loss - 348266.68750	
8500	 steps: training loss - 127649.47656	, testing loss - 346385.25000	
8501	 steps: training loss - 132657.17188	, testing loss - 345112.28125	
8502	 steps: training loss - 120882.51562	, testing loss - 344823.96875	
8503	 steps: training loss - 96618.34375	, testing loss - 344787.40625	
8504	 steps: training loss - 115085.78906	, testing loss - 344982.71875	
8505	 steps: training loss - 115889.15625	, testing loss - 345348.53125	
8506	 steps: training loss - 107294.31250	, testing loss - 345941.53125	
8507	 steps: training loss - 116599.76562	, testing loss - 346828.87500	
8508	 steps: training loss - 120367.92188	, testing loss - 347825.87500	
8509	 steps: training loss - 116571.24219	, testing loss - 349026.21875	
8510	 steps: training loss - 108368.57812	, testing loss - 350771.53125	
8511	 steps: training loss - 106595.87500	, testing loss - 351724.03125	
8512	 steps: training loss - 113335.57031	, testing loss - 352397.34375	
8513	 steps: training loss - 97962.22656	, testing loss - 352344.65625	
8514	 steps: training loss - 86571.38281	, testing loss - 352944.93750	
8515	 steps: training loss - 103911.24219	, testing loss - 353635.56250	
8516	 steps: training loss - 124441.75781	, testing loss - 353052.93750	
8517	 steps: training loss - 112869.46094	, testing loss - 352061.96875	
8518	 steps: training loss - 96058.35938	, testing loss - 351221.18750	
8519	 steps: training loss - 126761.92969	, testing loss - 349435.90625	
8520	 steps: training loss - 123574.05469	, testing loss - 348441.53125	
8521	 steps: training loss - 98231.99219	, testing loss - 347793.28125	
8522	 steps: training loss - 108096.50781	, testing loss - 346829.28125	
8523	 steps: training loss - 95241.71875	, testing loss - 345918.71875	
8524	 steps: training loss - 109879.91406	, testing loss - 346081.18750	
8525	 steps: training loss - 117855.37500	, testing loss - 347164.21875	
8526	 steps: training loss - 108680.14062	, testing loss - 348891.50000	
8527	 steps: training loss - 110562.67969	, testing loss - 351029.40625	
8528	 steps: training loss - 119369.18750	, testing loss - 353023.87500	
8529	 steps: training loss - 104519.38281	, testing loss - 354974.25000	
8530	 steps: training loss - 117469.02344	, testing loss - 357153.62500	
8531	 steps: training loss - 113967.65625	, testing loss - 359310.68750	
8532	 steps: training loss - 110378.60156	, testing loss - 361585.43750	
8533	 steps: training loss - 97281.22656	, testing loss - 362188.46875	
8534	 steps: training loss - 114436.34375	, testing loss - 361243.84375	
8535	 steps: training loss - 93735.49219	, testing loss - 359601.65625	
8536	 steps: training loss - 101759.01562	, testing loss - 358172.37500	
8537	 steps: training loss - 105815.66406	, testing loss - 355663.96875	
8538	 steps: training loss - 88901.07031	, testing loss - 353192.31250	
8539	 steps: training loss - 119827.90625	, testing loss - 350678.34375	
8540	 steps: training loss - 116991.11719	, testing loss - 348622.43750	
8541	 steps: training loss - 119890.78125	, testing loss - 346927.34375	
8542	 steps: training loss - 107603.55469	, testing loss - 345635.62500	
8543	 steps: training loss - 104827.98438	, testing loss - 344972.03125	
8544	 steps: training loss - 114364.78906	, testing loss - 344266.28125	
8545	 steps: training loss - 109118.94531	, testing loss - 343722.75000	
8546	 steps: training loss - 98747.07031	, testing loss - 343854.21875	
8547	 steps: training loss - 112974.07812	, testing loss - 343915.28125	
8548	 steps: training loss - 140709.89062	, testing loss - 343895.75000	
8549	 steps: training loss - 119912.46875	, testing loss - 343630.25000	
8550	 steps: training loss - 101640.82812	, testing loss - 343416.12500	
8551	 steps: training loss - 120840.12500	, testing loss - 342787.56250	
8552	 steps: training loss - 103789.82812	, testing loss - 342909.15625	
8553	 steps: training loss - 100139.80469	, testing loss - 343227.50000	
8554	 steps: training loss - 106311.40625	, testing loss - 343718.03125	
8555	 steps: training loss - 120342.53125	, testing loss - 344338.65625	
8556	 steps: training loss - 139274.20312	, testing loss - 344322.56250	
8557	 steps: training loss - 87724.42188	, testing loss - 345375.53125	
8558	 steps: training loss - 116880.64062	, testing loss - 346086.96875	
8559	 steps: training loss - 115869.35156	, testing loss - 346784.06250	
8560	 steps: training loss - 109740.90625	, testing loss - 347744.50000	
8561	 steps: training loss - 108979.50781	, testing loss - 348403.50000	
8562	 steps: training loss - 122769.00781	, testing loss - 348386.46875	
8563	 steps: training loss - 94588.00000	, testing loss - 348055.56250	
8564	 steps: training loss - 110326.07031	, testing loss - 347414.96875	
8565	 steps: training loss - 132143.98438	, testing loss - 346642.50000	
8566	 steps: training loss - 120648.03125	, testing loss - 346024.93750	
8567	 steps: training loss - 110331.86719	, testing loss - 345855.28125	
8568	 steps: training loss - 101740.04688	, testing loss - 347475.68750	
8569	 steps: training loss - 103201.32031	, testing loss - 349254.59375	
8570	 steps: training loss - 100166.75000	, testing loss - 350883.40625	
8571	 steps: training loss - 101152.60938	, testing loss - 351736.59375	
8572	 steps: training loss - 97312.99219	, testing loss - 352359.87500	
8573	 steps: training loss - 113659.20312	, testing loss - 352851.53125	
8574	 steps: training loss - 87711.35156	, testing loss - 353832.90625	
8575	 steps: training loss - 127782.69531	, testing loss - 354733.78125	
8576	 steps: training loss - 109903.77344	, testing loss - 354004.71875	
8577	 steps: training loss - 113413.85156	, testing loss - 352246.53125	
8578	 steps: training loss - 111670.94531	, testing loss - 350406.59375	
8579	 steps: training loss - 93574.53125	, testing loss - 348866.87500	
8580	 steps: training loss - 128543.13281	, testing loss - 348469.31250	
8581	 steps: training loss - 88951.30469	, testing loss - 348552.93750	
8582	 steps: training loss - 99444.35938	, testing loss - 348822.87500	
8583	 steps: training loss - 130734.55469	, testing loss - 348496.68750	
8584	 steps: training loss - 128392.23438	, testing loss - 348179.03125	
8585	 steps: training loss - 122276.55469	, testing loss - 347790.81250	
8586	 steps: training loss - 113941.67188	, testing loss - 347810.84375	
8587	 steps: training loss - 107481.10938	, testing loss - 346729.40625	
8588	 steps: training loss - 109236.46875	, testing loss - 345642.75000	
8589	 steps: training loss - 103742.67969	, testing loss - 344819.00000	
8590	 steps: training loss - 98371.48438	, testing loss - 343527.87500	
8591	 steps: training loss - 123921.31250	, testing loss - 343486.71875	
8592	 steps: training loss - 108809.81250	, testing loss - 345157.25000	
8593	 steps: training loss - 123278.94531	, testing loss - 347079.34375	
8594	 steps: training loss - 85746.33594	, testing loss - 347354.78125	
8595	 steps: training loss - 111582.35156	, testing loss - 346978.46875	
8596	 steps: training loss - 116961.99219	, testing loss - 346897.68750	
8597	 steps: training loss - 116850.38281	, testing loss - 347625.50000	
8598	 steps: training loss - 96681.42188	, testing loss - 348293.81250	
8599	 steps: training loss - 106684.49219	, testing loss - 349100.96875	
8600	 steps: training loss - 101014.27344	, testing loss - 349603.28125	
8601	 steps: training loss - 117111.33594	, testing loss - 350535.43750	
8602	 steps: training loss - 110674.99219	, testing loss - 351279.40625	
8603	 steps: training loss - 112932.86719	, testing loss - 351500.68750	
8604	 steps: training loss - 125646.96094	, testing loss - 351008.71875	
8605	 steps: training loss - 121550.40625	, testing loss - 349867.96875	
8606	 steps: training loss - 86472.80469	, testing loss - 349504.87500	
8607	 steps: training loss - 108414.07031	, testing loss - 349593.90625	
8608	 steps: training loss - 117284.05469	, testing loss - 349930.50000	
8609	 steps: training loss - 95688.73438	, testing loss - 351119.15625	
8610	 steps: training loss - 111480.03906	, testing loss - 351956.62500	
8611	 steps: training loss - 112113.42188	, testing loss - 352783.65625	
8612	 steps: training loss - 93199.77344	, testing loss - 353624.15625	
8613	 steps: training loss - 103937.67969	, testing loss - 354215.06250	
8614	 steps: training loss - 125278.31250	, testing loss - 355539.87500	
8615	 steps: training loss - 89891.50781	, testing loss - 355782.50000	
8616	 steps: training loss - 111633.14844	, testing loss - 355092.37500	
8617	 steps: training loss - 106475.13281	, testing loss - 353980.00000	
8618	 steps: training loss - 111581.40625	, testing loss - 352200.75000	
8619	 steps: training loss - 107355.84375	, testing loss - 349891.96875	
8620	 steps: training loss - 109017.14062	, testing loss - 348215.03125	
8621	 steps: training loss - 90483.51562	, testing loss - 348002.21875	
8622	 steps: training loss - 117716.16406	, testing loss - 349025.06250	
8623	 steps: training loss - 117560.32812	, testing loss - 350743.09375	
8624	 steps: training loss - 114482.79688	, testing loss - 353622.65625	
8625	 steps: training loss - 83928.00000	, testing loss - 356688.31250	
8626	 steps: training loss - 119992.22656	, testing loss - 361250.50000	
8627	 steps: training loss - 117774.35938	, testing loss - 366662.00000	
8628	 steps: training loss - 113820.75781	, testing loss - 370146.78125	
8629	 steps: training loss - 110862.12500	, testing loss - 372779.59375	
8630	 steps: training loss - 114521.75000	, testing loss - 375549.59375	
8631	 steps: training loss - 101458.08594	, testing loss - 376971.21875	
8632	 steps: training loss - 115590.08594	, testing loss - 379047.21875	
8633	 steps: training loss - 94760.78125	, testing loss - 380595.25000	
8634	 steps: training loss - 127330.60156	, testing loss - 380459.96875	
8635	 steps: training loss - 119044.29688	, testing loss - 377394.03125	
8636	 steps: training loss - 120964.76562	, testing loss - 372960.21875	
8637	 steps: training loss - 122657.88281	, testing loss - 368301.40625	
8638	 steps: training loss - 104510.96094	, testing loss - 364051.09375	
8639	 steps: training loss - 114156.45312	, testing loss - 359243.65625	
8640	 steps: training loss - 104486.35938	, testing loss - 354000.40625	
8641	 steps: training loss - 117587.87500	, testing loss - 349454.15625	
8642	 steps: training loss - 98523.97656	, testing loss - 347009.53125	
8643	 steps: training loss - 112051.35156	, testing loss - 345341.06250	
8644	 steps: training loss - 104138.10938	, testing loss - 344521.43750	
8645	 steps: training loss - 98490.60156	, testing loss - 344519.68750	
8646	 steps: training loss - 99340.09375	, testing loss - 345232.28125	
8647	 steps: training loss - 98084.11719	, testing loss - 345568.53125	
8648	 steps: training loss - 126718.84375	, testing loss - 345707.06250	
8649	 steps: training loss - 100779.32812	, testing loss - 346176.59375	
8650	 steps: training loss - 114435.71094	, testing loss - 346824.09375	
8651	 steps: training loss - 111984.70312	, testing loss - 347095.15625	
8652	 steps: training loss - 119288.54688	, testing loss - 347408.03125	
8653	 steps: training loss - 104413.64844	, testing loss - 347545.56250	
8654	 steps: training loss - 105672.85938	, testing loss - 347157.84375	
8655	 steps: training loss - 102656.49219	, testing loss - 347072.31250	
8656	 steps: training loss - 120732.07031	, testing loss - 347021.06250	
8657	 steps: training loss - 117020.25000	, testing loss - 346693.84375	
8658	 steps: training loss - 91354.61719	, testing loss - 346563.43750	
8659	 steps: training loss - 127961.98438	, testing loss - 346502.31250	
8660	 steps: training loss - 121411.86719	, testing loss - 348276.84375	
8661	 steps: training loss - 84637.82031	, testing loss - 349917.84375	
8662	 steps: training loss - 109227.64062	, testing loss - 350925.65625	
8663	 steps: training loss - 123190.82031	, testing loss - 351617.78125	
8664	 steps: training loss - 106264.85938	, testing loss - 352714.28125	
8665	 steps: training loss - 122186.30469	, testing loss - 354768.06250	
8666	 steps: training loss - 82252.90625	, testing loss - 357604.21875	
8667	 steps: training loss - 95573.11719	, testing loss - 360605.96875	
8668	 steps: training loss - 101904.92969	, testing loss - 362806.31250	
8669	 steps: training loss - 97804.16406	, testing loss - 363740.90625	
8670	 steps: training loss - 112734.77344	, testing loss - 364080.28125	
8671	 steps: training loss - 103541.81250	, testing loss - 363867.12500	
8672	 steps: training loss - 92144.50000	, testing loss - 364262.84375	
8673	 steps: training loss - 108739.35156	, testing loss - 364106.65625	
8674	 steps: training loss - 101144.60156	, testing loss - 363011.59375	
8675	 steps: training loss - 109069.64062	, testing loss - 360696.93750	
8676	 steps: training loss - 107897.46875	, testing loss - 357502.65625	
8677	 steps: training loss - 91313.90625	, testing loss - 354164.25000	
8678	 steps: training loss - 112335.59375	, testing loss - 351402.96875	
8679	 steps: training loss - 125611.75781	, testing loss - 349963.21875	
8680	 steps: training loss - 108437.62500	, testing loss - 348784.81250	
8681	 steps: training loss - 104091.17969	, testing loss - 348794.90625	
8682	 steps: training loss - 126112.59375	, testing loss - 349229.28125	
8683	 steps: training loss - 110223.85156	, testing loss - 349831.96875	
8684	 steps: training loss - 98461.46875	, testing loss - 350289.59375	
8685	 steps: training loss - 120001.88281	, testing loss - 350602.65625	
8686	 steps: training loss - 105396.13281	, testing loss - 350125.56250	
8687	 steps: training loss - 94559.58594	, testing loss - 348747.28125	
8688	 steps: training loss - 111978.21094	, testing loss - 347307.34375	
8689	 steps: training loss - 98762.51562	, testing loss - 346769.25000	
8690	 steps: training loss - 110331.30469	, testing loss - 347295.43750	
8691	 steps: training loss - 130918.93750	, testing loss - 348372.50000	
8692	 steps: training loss - 126851.48438	, testing loss - 350041.31250	
8693	 steps: training loss - 120255.68750	, testing loss - 350529.78125	
8694	 steps: training loss - 125158.28125	, testing loss - 350541.31250	
8695	 steps: training loss - 113476.15625	, testing loss - 350456.78125	
8696	 steps: training loss - 120452.30469	, testing loss - 349878.00000	
8697	 steps: training loss - 103025.69531	, testing loss - 349745.90625	
8698	 steps: training loss - 105117.71094	, testing loss - 349481.81250	
8699	 steps: training loss - 78759.64062	, testing loss - 348635.75000	
8700	 steps: training loss - 106958.79688	, testing loss - 347131.25000	
8701	 steps: training loss - 124498.25000	, testing loss - 345723.12500	
8702	 steps: training loss - 96190.00781	, testing loss - 345154.37500	
8703	 steps: training loss - 113253.17969	, testing loss - 345158.93750	
8704	 steps: training loss - 113629.71875	, testing loss - 345375.37500	
8705	 steps: training loss - 126522.90625	, testing loss - 345467.75000	
8706	 steps: training loss - 119807.42188	, testing loss - 345071.00000	
8707	 steps: training loss - 106620.17188	, testing loss - 343791.37500	
8708	 steps: training loss - 110725.00781	, testing loss - 342512.90625	
8709	 steps: training loss - 134340.84375	, testing loss - 342027.09375	
8710	 steps: training loss - 96704.83594	, testing loss - 342103.34375	
8711	 steps: training loss - 129073.32812	, testing loss - 342558.43750	
8712	 steps: training loss - 137247.06250	, testing loss - 343136.71875	
8713	 steps: training loss - 113427.28125	, testing loss - 343234.56250	
8714	 steps: training loss - 99969.29688	, testing loss - 343356.53125	
8715	 steps: training loss - 120777.82031	, testing loss - 344284.75000	
8716	 steps: training loss - 111818.15625	, testing loss - 345405.09375	
8717	 steps: training loss - 111240.78125	, testing loss - 346354.71875	
8718	 steps: training loss - 106387.32812	, testing loss - 347262.43750	
8719	 steps: training loss - 98378.12500	, testing loss - 348583.03125	
8720	 steps: training loss - 117294.96875	, testing loss - 350017.21875	
8721	 steps: training loss - 114178.42969	, testing loss - 351369.15625	
8722	 steps: training loss - 92704.47656	, testing loss - 352501.84375	
8723	 steps: training loss - 87210.24219	, testing loss - 354196.18750	
8724	 steps: training loss - 129520.54688	, testing loss - 355899.09375	
8725	 steps: training loss - 102866.40625	, testing loss - 355973.71875	
8726	 steps: training loss - 116181.64062	, testing loss - 355473.00000	
8727	 steps: training loss - 99652.75000	, testing loss - 354908.75000	
8728	 steps: training loss - 108817.89062	, testing loss - 353905.62500	
8729	 steps: training loss - 95262.21094	, testing loss - 352797.78125	
8730	 steps: training loss - 116568.72656	, testing loss - 350838.71875	
8731	 steps: training loss - 120419.41406	, testing loss - 348875.25000	
8732	 steps: training loss - 115209.89062	, testing loss - 347073.18750	
8733	 steps: training loss - 125473.20312	, testing loss - 346691.87500	
8734	 steps: training loss - 100520.90625	, testing loss - 346650.68750	
8735	 steps: training loss - 109674.35156	, testing loss - 347012.31250	
8736	 steps: training loss - 121025.28906	, testing loss - 347754.15625	
8737	 steps: training loss - 119845.91406	, testing loss - 349105.90625	
8738	 steps: training loss - 113570.53125	, testing loss - 350579.46875	
8739	 steps: training loss - 97539.65625	, testing loss - 351986.28125	
8740	 steps: training loss - 94005.38281	, testing loss - 352839.43750	
8741	 steps: training loss - 87564.25000	, testing loss - 353309.87500	
8742	 steps: training loss - 115153.64844	, testing loss - 353333.18750	
8743	 steps: training loss - 121474.00000	, testing loss - 353414.56250	
8744	 steps: training loss - 97860.22656	, testing loss - 354069.68750	
8745	 steps: training loss - 128997.85156	, testing loss - 353907.06250	
8746	 steps: training loss - 104752.82031	, testing loss - 353918.78125	
8747	 steps: training loss - 103035.77344	, testing loss - 353930.25000	
8748	 steps: training loss - 111223.84375	, testing loss - 353022.28125	
8749	 steps: training loss - 113051.53125	, testing loss - 352064.50000	
8750	 steps: training loss - 93354.27344	, testing loss - 350840.06250	
8751	 steps: training loss - 104107.98438	, testing loss - 349523.03125	
8752	 steps: training loss - 142942.93750	, testing loss - 348483.37500	
8753	 steps: training loss - 110601.46094	, testing loss - 347826.90625	
8754	 steps: training loss - 99121.03125	, testing loss - 347627.96875	
8755	 steps: training loss - 138395.00000	, testing loss - 347481.71875	
8756	 steps: training loss - 115275.12500	, testing loss - 347853.43750	
8757	 steps: training loss - 129453.43750	, testing loss - 348901.00000	
8758	 steps: training loss - 113809.24219	, testing loss - 349935.03125	
8759	 steps: training loss - 128107.73438	, testing loss - 351089.68750	
8760	 steps: training loss - 85998.67969	, testing loss - 352268.71875	
8761	 steps: training loss - 118453.62500	, testing loss - 352958.78125	
8762	 steps: training loss - 132439.00000	, testing loss - 353783.28125	
8763	 steps: training loss - 110284.17188	, testing loss - 355405.40625	
8764	 steps: training loss - 102626.39844	, testing loss - 357409.03125	
8765	 steps: training loss - 114989.89844	, testing loss - 360084.31250	
8766	 steps: training loss - 110540.53125	, testing loss - 362852.84375	
8767	 steps: training loss - 107818.60156	, testing loss - 366391.28125	
8768	 steps: training loss - 121881.95312	, testing loss - 369739.40625	
8769	 steps: training loss - 126296.07812	, testing loss - 373795.03125	
8770	 steps: training loss - 101860.99219	, testing loss - 377064.78125	
8771	 steps: training loss - 108922.12500	, testing loss - 378618.93750	
8772	 steps: training loss - 114472.64844	, testing loss - 377454.62500	
8773	 steps: training loss - 114111.11719	, testing loss - 375349.40625	
8774	 steps: training loss - 121165.91406	, testing loss - 372385.68750	
8775	 steps: training loss - 97971.09375	, testing loss - 368775.81250	
8776	 steps: training loss - 89486.10938	, testing loss - 365636.15625	
8777	 steps: training loss - 101884.43750	, testing loss - 362463.25000	
8778	 steps: training loss - 107948.59375	, testing loss - 358639.75000	
8779	 steps: training loss - 103242.96875	, testing loss - 355025.28125	
8780	 steps: training loss - 94957.85156	, testing loss - 352444.59375	
8781	 steps: training loss - 104481.26562	, testing loss - 350743.06250	
8782	 steps: training loss - 106123.99219	, testing loss - 349770.50000	
8783	 steps: training loss - 116478.31250	, testing loss - 349316.15625	
8784	 steps: training loss - 116362.07031	, testing loss - 349225.50000	
8785	 steps: training loss - 104862.84375	, testing loss - 348957.06250	
8786	 steps: training loss - 110530.55469	, testing loss - 349568.31250	
8787	 steps: training loss - 102071.32812	, testing loss - 349698.37500	
8788	 steps: training loss - 82883.53906	, testing loss - 348918.34375	
8789	 steps: training loss - 106407.39844	, testing loss - 348143.84375	
8790	 steps: training loss - 122431.03125	, testing loss - 347722.53125	
8791	 steps: training loss - 106490.21094	, testing loss - 348118.34375	
8792	 steps: training loss - 94484.52344	, testing loss - 348561.96875	
8793	 steps: training loss - 116316.58594	, testing loss - 349293.96875	
8794	 steps: training loss - 111087.53125	, testing loss - 349741.56250	
8795	 steps: training loss - 113527.94531	, testing loss - 349955.65625	
8796	 steps: training loss - 112556.85938	, testing loss - 349872.40625	
8797	 steps: training loss - 108223.79688	, testing loss - 350320.90625	
8798	 steps: training loss - 70998.11719	, testing loss - 351050.09375	
8799	 steps: training loss - 105745.48438	, testing loss - 351035.50000	
8800	 steps: training loss - 91240.46094	, testing loss - 350361.56250	
8801	 steps: training loss - 98218.32812	, testing loss - 349542.53125	
8802	 steps: training loss - 115804.65625	, testing loss - 349029.75000	
8803	 steps: training loss - 132380.65625	, testing loss - 349540.81250	
8804	 steps: training loss - 88511.21875	, testing loss - 349807.00000	
8805	 steps: training loss - 122796.54688	, testing loss - 350348.50000	
8806	 steps: training loss - 98724.21875	, testing loss - 352559.06250	
8807	 steps: training loss - 89584.76562	, testing loss - 353650.00000	
8808	 steps: training loss - 100374.03125	, testing loss - 353711.31250	
8809	 steps: training loss - 129718.65625	, testing loss - 353666.59375	
8810	 steps: training loss - 111495.79688	, testing loss - 353235.21875	
8811	 steps: training loss - 110404.82031	, testing loss - 353442.59375	
8812	 steps: training loss - 102193.19531	, testing loss - 353454.25000	
8813	 steps: training loss - 111009.16406	, testing loss - 352976.65625	
8814	 steps: training loss - 123506.71875	, testing loss - 352249.06250	
8815	 steps: training loss - 124279.74219	, testing loss - 350456.43750	
8816	 steps: training loss - 110511.46875	, testing loss - 347973.15625	
8817	 steps: training loss - 94033.68750	, testing loss - 346355.50000	
8818	 steps: training loss - 110157.27344	, testing loss - 344832.50000	
8819	 steps: training loss - 124102.35938	, testing loss - 342993.65625	
8820	 steps: training loss - 122196.71094	, testing loss - 342172.71875	
8821	 steps: training loss - 119769.03906	, testing loss - 341630.62500	
8822	 steps: training loss - 98400.24219	, testing loss - 341955.25000	
8823	 steps: training loss - 123365.39844	, testing loss - 342413.15625	
8824	 steps: training loss - 121257.25781	, testing loss - 342785.18750	
8825	 steps: training loss - 125305.24219	, testing loss - 343531.93750	
8826	 steps: training loss - 117322.93750	, testing loss - 343905.68750	
8827	 steps: training loss - 109040.85938	, testing loss - 344717.28125	
8828	 steps: training loss - 101384.82812	, testing loss - 345293.15625	
8829	 steps: training loss - 110778.40625	, testing loss - 346251.81250	
8830	 steps: training loss - 96009.57031	, testing loss - 346628.25000	
8831	 steps: training loss - 144111.65625	, testing loss - 347185.37500	
8832	 steps: training loss - 114959.06250	, testing loss - 347309.46875	
8833	 steps: training loss - 105113.70312	, testing loss - 346874.65625	
8834	 steps: training loss - 105194.58594	, testing loss - 346433.12500	
8835	 steps: training loss - 121900.62500	, testing loss - 345702.90625	
8836	 steps: training loss - 133053.65625	, testing loss - 345178.78125	
8837	 steps: training loss - 109789.10156	, testing loss - 345717.40625	
8838	 steps: training loss - 110319.91406	, testing loss - 347060.50000	
8839	 steps: training loss - 121978.75781	, testing loss - 349264.65625	
8840	 steps: training loss - 97846.07031	, testing loss - 351026.59375	
8841	 steps: training loss - 119718.09375	, testing loss - 352411.31250	
8842	 steps: training loss - 105086.30469	, testing loss - 353731.21875	
8843	 steps: training loss - 105702.66406	, testing loss - 354516.03125	
8844	 steps: training loss - 89802.80469	, testing loss - 353594.37500	
8845	 steps: training loss - 108694.82031	, testing loss - 351992.75000	
8846	 steps: training loss - 97129.36719	, testing loss - 349338.59375	
8847	 steps: training loss - 95008.92969	, testing loss - 346741.37500	
8848	 steps: training loss - 112682.69531	, testing loss - 345723.18750	
8849	 steps: training loss - 119425.57031	, testing loss - 345161.31250	
8850	 steps: training loss - 143295.21875	, testing loss - 344746.43750	
8851	 steps: training loss - 121997.92188	, testing loss - 344692.09375	
8852	 steps: training loss - 103272.50781	, testing loss - 345070.31250	
8853	 steps: training loss - 121533.22656	, testing loss - 345024.81250	
8854	 steps: training loss - 123102.37500	, testing loss - 345670.15625	
8855	 steps: training loss - 105714.99219	, testing loss - 346289.50000	
8856	 steps: training loss - 114348.09375	, testing loss - 345572.50000	
8857	 steps: training loss - 125071.12500	, testing loss - 344532.43750	
8858	 steps: training loss - 105435.05469	, testing loss - 344890.34375	
8859	 steps: training loss - 133075.25000	, testing loss - 345318.00000	
8860	 steps: training loss - 106323.64844	, testing loss - 345584.87500	
8861	 steps: training loss - 104138.36719	, testing loss - 345707.93750	
8862	 steps: training loss - 89782.45312	, testing loss - 345570.34375	
8863	 steps: training loss - 101024.10938	, testing loss - 345947.06250	
8864	 steps: training loss - 106249.51562	, testing loss - 346977.31250	
8865	 steps: training loss - 94644.25781	, testing loss - 348199.84375	
8866	 steps: training loss - 94345.18750	, testing loss - 349036.15625	
8867	 steps: training loss - 112629.78906	, testing loss - 349017.31250	
8868	 steps: training loss - 113029.82031	, testing loss - 350621.18750	
8869	 steps: training loss - 86693.21875	, testing loss - 351629.15625	
8870	 steps: training loss - 113657.23438	, testing loss - 352319.40625	
8871	 steps: training loss - 111577.87500	, testing loss - 353364.93750	
8872	 steps: training loss - 89687.74219	, testing loss - 354316.68750	
8873	 steps: training loss - 92878.78125	, testing loss - 355666.00000	
8874	 steps: training loss - 130251.76562	, testing loss - 356285.90625	
8875	 steps: training loss - 92869.89062	, testing loss - 356635.40625	
8876	 steps: training loss - 141271.06250	, testing loss - 356132.68750	
8877	 steps: training loss - 100572.18750	, testing loss - 355179.65625	
8878	 steps: training loss - 121541.17969	, testing loss - 354719.43750	
8879	 steps: training loss - 87834.39844	, testing loss - 353128.34375	
8880	 steps: training loss - 115075.47656	, testing loss - 351457.09375	
8881	 steps: training loss - 104444.39062	, testing loss - 349669.50000	
8882	 steps: training loss - 116983.46875	, testing loss - 347851.06250	
8883	 steps: training loss - 130150.06250	, testing loss - 346768.71875	
8884	 steps: training loss - 101330.87500	, testing loss - 346435.12500	
8885	 steps: training loss - 99286.21875	, testing loss - 347512.46875	
8886	 steps: training loss - 127890.01562	, testing loss - 349207.93750	
8887	 steps: training loss - 116415.23438	, testing loss - 350918.03125	
8888	 steps: training loss - 106970.25781	, testing loss - 351419.84375	
8889	 steps: training loss - 118364.27344	, testing loss - 350878.43750	
8890	 steps: training loss - 106881.67188	, testing loss - 350972.12500	
8891	 steps: training loss - 112581.87500	, testing loss - 351050.18750	
8892	 steps: training loss - 87571.43750	, testing loss - 351000.68750	
8893	 steps: training loss - 108218.20312	, testing loss - 350948.21875	
8894	 steps: training loss - 117373.35938	, testing loss - 351702.87500	
8895	 steps: training loss - 116650.07812	, testing loss - 352886.56250	
8896	 steps: training loss - 96573.35156	, testing loss - 354163.43750	
8897	 steps: training loss - 114983.45312	, testing loss - 355072.09375	
8898	 steps: training loss - 112520.70312	, testing loss - 354669.43750	
8899	 steps: training loss - 86933.68750	, testing loss - 353957.87500	
8900	 steps: training loss - 135455.60938	, testing loss - 353356.65625	
8901	 steps: training loss - 105648.50781	, testing loss - 352177.37500	
8902	 steps: training loss - 116315.13281	, testing loss - 350623.71875	
8903	 steps: training loss - 113646.79688	, testing loss - 349146.03125	
8904	 steps: training loss - 123801.34375	, testing loss - 347584.37500	
8905	 steps: training loss - 114496.42188	, testing loss - 346073.75000	
8906	 steps: training loss - 109394.04688	, testing loss - 345650.59375	
8907	 steps: training loss - 128353.54688	, testing loss - 345609.43750	
8908	 steps: training loss - 122672.15625	, testing loss - 345906.31250	
8909	 steps: training loss - 127793.12500	, testing loss - 346766.37500	
8910	 steps: training loss - 94351.54688	, testing loss - 348242.40625	
8911	 steps: training loss - 117132.31250	, testing loss - 348907.46875	
8912	 steps: training loss - 123234.64844	, testing loss - 349226.43750	
8913	 steps: training loss - 95606.73438	, testing loss - 350089.15625	
8914	 steps: training loss - 114176.93750	, testing loss - 350681.65625	
8915	 steps: training loss - 93955.14844	, testing loss - 351093.31250	
8916	 steps: training loss - 107432.73438	, testing loss - 350898.28125	
8917	 steps: training loss - 133519.23438	, testing loss - 350731.56250	
8918	 steps: training loss - 116525.84375	, testing loss - 350032.09375	
8919	 steps: training loss - 119629.68750	, testing loss - 349671.00000	
8920	 steps: training loss - 117634.88281	, testing loss - 349361.21875	
8921	 steps: training loss - 90058.04688	, testing loss - 348816.06250	
8922	 steps: training loss - 113791.88281	, testing loss - 347954.12500	
8923	 steps: training loss - 116415.65625	, testing loss - 346658.56250	
8924	 steps: training loss - 101063.98438	, testing loss - 345936.06250	
8925	 steps: training loss - 101999.92969	, testing loss - 346094.84375	
8926	 steps: training loss - 124670.25781	, testing loss - 347151.09375	
8927	 steps: training loss - 108047.45312	, testing loss - 348355.43750	
8928	 steps: training loss - 126645.06250	, testing loss - 349263.28125	
8929	 steps: training loss - 116476.89844	, testing loss - 349752.31250	
8930	 steps: training loss - 91967.98438	, testing loss - 350122.40625	
8931	 steps: training loss - 79718.28906	, testing loss - 350387.34375	
8932	 steps: training loss - 132672.53125	, testing loss - 350958.03125	
8933	 steps: training loss - 87944.60156	, testing loss - 352113.71875	
8934	 steps: training loss - 110834.57812	, testing loss - 353480.90625	
8935	 steps: training loss - 123245.99219	, testing loss - 353919.59375	
8936	 steps: training loss - 67978.77344	, testing loss - 354171.50000	
8937	 steps: training loss - 112936.53125	, testing loss - 354684.84375	
8938	 steps: training loss - 119793.64844	, testing loss - 355097.65625	
8939	 steps: training loss - 124006.37500	, testing loss - 354205.09375	
8940	 steps: training loss - 119184.50000	, testing loss - 352525.03125	
8941	 steps: training loss - 130236.96094	, testing loss - 351430.68750	
8942	 steps: training loss - 117868.21875	, testing loss - 349179.21875	
8943	 steps: training loss - 101413.91406	, testing loss - 346310.12500	
8944	 steps: training loss - 119015.05469	, testing loss - 343377.03125	
8945	 steps: training loss - 109170.30469	, testing loss - 340733.37500	
8946	 steps: training loss - 123388.64062	, testing loss - 338507.46875	
8947	 steps: training loss - 126660.68750	, testing loss - 337456.93750	
8948	 steps: training loss - 103740.00781	, testing loss - 336905.43750	
8949	 steps: training loss - 127353.84375	, testing loss - 336444.93750	
8950	 steps: training loss - 99174.03125	, testing loss - 336279.21875	
8951	 steps: training loss - 125215.85938	, testing loss - 336726.00000	
8952	 steps: training loss - 107659.69531	, testing loss - 337709.65625	
8953	 steps: training loss - 117635.04688	, testing loss - 339014.81250	
8954	 steps: training loss - 121105.98438	, testing loss - 340397.93750	
8955	 steps: training loss - 134241.53125	, testing loss - 341652.06250	
8956	 steps: training loss - 134987.78125	, testing loss - 344454.56250	
8957	 steps: training loss - 94337.14844	, testing loss - 349058.06250	
8958	 steps: training loss - 123545.65625	, testing loss - 352824.37500	
8959	 steps: training loss - 98682.60156	, testing loss - 355408.18750	
8960	 steps: training loss - 100067.65625	, testing loss - 357166.34375	
8961	 steps: training loss - 116822.09375	, testing loss - 356904.21875	
8962	 steps: training loss - 115929.60938	, testing loss - 355175.50000	
8963	 steps: training loss - 112935.42969	, testing loss - 353520.40625	
8964	 steps: training loss - 128558.30469	, testing loss - 352374.68750	
8965	 steps: training loss - 101701.36719	, testing loss - 351947.87500	
8966	 steps: training loss - 94488.75781	, testing loss - 350966.84375	
8967	 steps: training loss - 93785.76562	, testing loss - 350407.68750	
8968	 steps: training loss - 115247.65625	, testing loss - 350044.31250	
8969	 steps: training loss - 101113.83594	, testing loss - 350894.12500	
8970	 steps: training loss - 94751.51562	, testing loss - 352329.12500	
8971	 steps: training loss - 127576.19531	, testing loss - 353428.78125	
8972	 steps: training loss - 105788.12500	, testing loss - 354306.15625	
8973	 steps: training loss - 127526.54688	, testing loss - 354332.93750	
8974	 steps: training loss - 108156.62500	, testing loss - 354438.96875	
8975	 steps: training loss - 105667.93750	, testing loss - 354130.06250	
8976	 steps: training loss - 115340.39844	, testing loss - 352847.62500	
8977	 steps: training loss - 84127.21875	, testing loss - 351583.75000	
8978	 steps: training loss - 79050.92188	, testing loss - 350215.90625	
8979	 steps: training loss - 131291.64062	, testing loss - 349262.50000	
8980	 steps: training loss - 119334.99219	, testing loss - 348825.96875	
8981	 steps: training loss - 113818.46875	, testing loss - 349122.53125	
8982	 steps: training loss - 110621.63281	, testing loss - 348918.09375	
8983	 steps: training loss - 120309.19531	, testing loss - 348023.25000	
8984	 steps: training loss - 134458.92188	, testing loss - 347484.81250	
8985	 steps: training loss - 111137.46094	, testing loss - 346706.56250	
8986	 steps: training loss - 99762.16406	, testing loss - 345975.06250	
8987	 steps: training loss - 94029.98438	, testing loss - 346129.59375	
8988	 steps: training loss - 124833.60156	, testing loss - 346856.28125	
8989	 steps: training loss - 111707.97656	, testing loss - 348382.68750	
8990	 steps: training loss - 101564.51562	, testing loss - 349744.68750	
8991	 steps: training loss - 114627.78125	, testing loss - 350106.46875	
8992	 steps: training loss - 121162.59375	, testing loss - 348856.68750	
8993	 steps: training loss - 104098.82812	, testing loss - 347668.87500	
8994	 steps: training loss - 95321.35156	, testing loss - 347472.43750	
8995	 steps: training loss - 142860.76562	, testing loss - 347962.53125	
8996	 steps: training loss - 122567.15625	, testing loss - 348110.00000	
8997	 steps: training loss - 103866.50781	, testing loss - 348411.03125	
8998	 steps: training loss - 106823.16406	, testing loss - 348293.03125	
8999	 steps: training loss - 91512.14844	, testing loss - 348883.43750	
9000	 steps: training loss - 97335.50000	, testing loss - 349535.59375	
9001	 steps: training loss - 97761.25781	, testing loss - 349603.84375	
9002	 steps: training loss - 87323.41406	, testing loss - 350115.18750	
9003	 steps: training loss - 118968.60156	, testing loss - 349867.93750	
9004	 steps: training loss - 92087.89062	, testing loss - 349454.12500	
9005	 steps: training loss - 98841.95312	, testing loss - 349193.15625	
9006	 steps: training loss - 112402.11719	, testing loss - 348839.40625	
9007	 steps: training loss - 91145.07031	, testing loss - 348011.06250	
9008	 steps: training loss - 119436.58594	, testing loss - 347558.62500	
9009	 steps: training loss - 105993.46875	, testing loss - 346699.31250	
9010	 steps: training loss - 91517.13281	, testing loss - 346262.00000	
9011	 steps: training loss - 113382.83594	, testing loss - 345572.03125	
9012	 steps: training loss - 95872.83594	, testing loss - 345790.53125	
9013	 steps: training loss - 113137.14062	, testing loss - 346478.81250	
9014	 steps: training loss - 126172.92969	, testing loss - 347411.28125	
9015	 steps: training loss - 118104.99219	, testing loss - 348393.68750	
9016	 steps: training loss - 106546.65625	, testing loss - 350314.87500	
9017	 steps: training loss - 126833.65625	, testing loss - 352311.81250	
9018	 steps: training loss - 94954.50000	, testing loss - 353344.25000	
9019	 steps: training loss - 115926.93750	, testing loss - 352929.40625	
9020	 steps: training loss - 84810.13281	, testing loss - 351354.43750	
9021	 steps: training loss - 127896.57031	, testing loss - 350519.40625	
9022	 steps: training loss - 126778.78125	, testing loss - 351185.96875	
9023	 steps: training loss - 92249.91406	, testing loss - 352696.31250	
9024	 steps: training loss - 76222.46875	, testing loss - 353551.00000	
9025	 steps: training loss - 98578.09375	, testing loss - 354225.87500	
9026	 steps: training loss - 108831.85156	, testing loss - 354823.09375	
9027	 steps: training loss - 128623.96094	, testing loss - 354598.84375	
9028	 steps: training loss - 101362.77344	, testing loss - 353401.34375	
9029	 steps: training loss - 126408.90625	, testing loss - 352442.84375	
9030	 steps: training loss - 104750.14844	, testing loss - 351009.90625	
9031	 steps: training loss - 124915.55469	, testing loss - 349104.06250	
9032	 steps: training loss - 95289.33594	, testing loss - 346670.78125	
9033	 steps: training loss - 112081.71875	, testing loss - 344621.81250	
9034	 steps: training loss - 118060.05469	, testing loss - 343427.65625	
9035	 steps: training loss - 107624.75000	, testing loss - 342925.78125	
9036	 steps: training loss - 115105.77344	, testing loss - 342940.96875	
9037	 steps: training loss - 100776.40625	, testing loss - 343364.87500	
9038	 steps: training loss - 112344.51562	, testing loss - 343501.34375	
9039	 steps: training loss - 124620.09375	, testing loss - 344119.40625	
9040	 steps: training loss - 104195.91406	, testing loss - 345260.87500	
9041	 steps: training loss - 103433.77344	, testing loss - 346613.93750	
9042	 steps: training loss - 121321.84375	, testing loss - 348279.50000	
9043	 steps: training loss - 91027.99219	, testing loss - 351230.40625	
9044	 steps: training loss - 115516.32031	, testing loss - 353917.25000	
9045	 steps: training loss - 121887.25000	, testing loss - 355005.21875	
9046	 steps: training loss - 108079.14062	, testing loss - 354517.25000	
9047	 steps: training loss - 104539.38281	, testing loss - 354103.37500	
9048	 steps: training loss - 110495.81250	, testing loss - 354492.34375	
9049	 steps: training loss - 106936.15625	, testing loss - 355748.18750	
9050	 steps: training loss - 121011.30469	, testing loss - 356173.43750	
9051	 steps: training loss - 125715.09375	, testing loss - 355307.40625	
9052	 steps: training loss - 101403.10156	, testing loss - 354089.43750	
9053	 steps: training loss - 130667.36719	, testing loss - 352752.09375	
9054	 steps: training loss - 112935.09375	, testing loss - 351769.06250	
9055	 steps: training loss - 103515.42969	, testing loss - 350723.90625	
9056	 steps: training loss - 106488.34375	, testing loss - 350413.37500	
9057	 steps: training loss - 129178.98438	, testing loss - 350348.93750	
9058	 steps: training loss - 104091.72656	, testing loss - 350028.06250	
9059	 steps: training loss - 102774.14062	, testing loss - 349187.81250	
9060	 steps: training loss - 119880.81250	, testing loss - 347666.62500	
9061	 steps: training loss - 85247.28906	, testing loss - 346222.03125	
9062	 steps: training loss - 98493.36719	, testing loss - 344942.21875	
9063	 steps: training loss - 120085.45312	, testing loss - 344152.06250	
9064	 steps: training loss - 114861.53906	, testing loss - 344221.75000	
9065	 steps: training loss - 111901.55469	, testing loss - 344904.25000	
9066	 steps: training loss - 115004.96094	, testing loss - 345826.25000	
9067	 steps: training loss - 127910.87500	, testing loss - 347407.46875	
9068	 steps: training loss - 110891.02344	, testing loss - 348305.50000	
9069	 steps: training loss - 126150.10938	, testing loss - 348916.53125	
9070	 steps: training loss - 96423.43750	, testing loss - 349514.28125	
9071	 steps: training loss - 107097.92188	, testing loss - 350219.40625	
9072	 steps: training loss - 102717.43750	, testing loss - 350668.09375	
9073	 steps: training loss - 99689.18750	, testing loss - 350404.03125	
9074	 steps: training loss - 109281.89062	, testing loss - 349784.12500	
9075	 steps: training loss - 124611.15625	, testing loss - 349933.96875	
9076	 steps: training loss - 89840.17188	, testing loss - 349665.28125	
9077	 steps: training loss - 121803.35938	, testing loss - 349504.28125	
9078	 steps: training loss - 77211.76562	, testing loss - 349769.31250	
9079	 steps: training loss - 130220.10156	, testing loss - 350272.59375	
9080	 steps: training loss - 120279.95312	, testing loss - 351142.40625	
9081	 steps: training loss - 108401.53125	, testing loss - 352419.50000	
9082	 steps: training loss - 94011.86719	, testing loss - 354522.59375	
9083	 steps: training loss - 106867.44531	, testing loss - 356776.18750	
9084	 steps: training loss - 111079.89062	, testing loss - 359230.84375	
9085	 steps: training loss - 104742.57812	, testing loss - 360707.78125	
9086	 steps: training loss - 127680.42969	, testing loss - 361936.12500	
9087	 steps: training loss - 103804.35938	, testing loss - 361918.62500	
9088	 steps: training loss - 119935.72656	, testing loss - 363031.62500	
9089	 steps: training loss - 130291.24219	, testing loss - 363696.03125	
9090	 steps: training loss - 97915.08594	, testing loss - 363544.87500	
9091	 steps: training loss - 115391.94531	, testing loss - 363435.78125	
9092	 steps: training loss - 101593.57031	, testing loss - 363267.15625	
9093	 steps: training loss - 122322.71094	, testing loss - 362247.06250	
9094	 steps: training loss - 99616.88281	, testing loss - 361032.28125	
9095	 steps: training loss - 107246.41406	, testing loss - 359566.21875	
9096	 steps: training loss - 87752.42188	, testing loss - 356979.09375	
9097	 steps: training loss - 120817.82812	, testing loss - 355293.87500	
9098	 steps: training loss - 105885.07812	, testing loss - 354191.03125	
9099	 steps: training loss - 116025.65625	, testing loss - 353931.40625	
9100	 steps: training loss - 123784.25000	, testing loss - 353750.18750	
9101	 steps: training loss - 114050.07812	, testing loss - 353629.34375	
9102	 steps: training loss - 104236.68750	, testing loss - 354334.90625	
9103	 steps: training loss - 116531.17188	, testing loss - 354473.75000	
9104	 steps: training loss - 114384.17969	, testing loss - 354197.37500	
9105	 steps: training loss - 82334.96094	, testing loss - 354051.34375	
9106	 steps: training loss - 101362.42188	, testing loss - 354143.50000	
9107	 steps: training loss - 119457.16406	, testing loss - 354067.15625	
9108	 steps: training loss - 109624.50000	, testing loss - 354079.65625	
9109	 steps: training loss - 93220.98438	, testing loss - 354997.59375	
9110	 steps: training loss - 103182.10156	, testing loss - 355302.50000	
9111	 steps: training loss - 126352.28125	, testing loss - 355008.37500	
9112	 steps: training loss - 121509.84375	, testing loss - 355042.25000	
9113	 steps: training loss - 98385.72656	, testing loss - 354699.81250	
9114	 steps: training loss - 108931.58594	, testing loss - 354139.56250	
9115	 steps: training loss - 102410.75000	, testing loss - 353605.28125	
9116	 steps: training loss - 112686.27344	, testing loss - 352234.96875	
9117	 steps: training loss - 115108.82031	, testing loss - 350586.71875	
9118	 steps: training loss - 92366.96094	, testing loss - 349888.06250	
9119	 steps: training loss - 116166.49219	, testing loss - 349264.62500	
9120	 steps: training loss - 127794.14844	, testing loss - 349126.15625	
9121	 steps: training loss - 104502.07031	, testing loss - 350032.34375	
9122	 steps: training loss - 113550.08594	, testing loss - 351782.21875	
9123	 steps: training loss - 124034.87500	, testing loss - 352540.43750	
9124	 steps: training loss - 106514.12500	, testing loss - 352827.00000	
9125	 steps: training loss - 84773.28125	, testing loss - 353915.78125	
9126	 steps: training loss - 110091.32812	, testing loss - 354565.21875	
9127	 steps: training loss - 105644.15625	, testing loss - 354958.03125	
9128	 steps: training loss - 94371.94531	, testing loss - 355407.09375	
9129	 steps: training loss - 127079.61719	, testing loss - 355665.06250	
9130	 steps: training loss - 114987.34375	, testing loss - 354231.62500	
9131	 steps: training loss - 107886.32031	, testing loss - 352105.40625	
9132	 steps: training loss - 126808.95312	, testing loss - 350557.59375	
9133	 steps: training loss - 115578.85938	, testing loss - 348984.84375	
9134	 steps: training loss - 101884.78906	, testing loss - 348796.53125	
9135	 steps: training loss - 93009.53125	, testing loss - 349026.25000	
9136	 steps: training loss - 116522.50000	, testing loss - 349600.34375	
9137	 steps: training loss - 110917.91406	, testing loss - 349949.71875	
9138	 steps: training loss - 90959.92188	, testing loss - 350247.71875	
9139	 steps: training loss - 123026.07812	, testing loss - 349974.87500	
9140	 steps: training loss - 127183.28125	, testing loss - 349880.87500	
9141	 steps: training loss - 103483.54688	, testing loss - 349845.31250	
9142	 steps: training loss - 109552.99219	, testing loss - 349968.75000	
9143	 steps: training loss - 112115.57812	, testing loss - 350048.06250	
9144	 steps: training loss - 106162.57812	, testing loss - 351204.53125	
9145	 steps: training loss - 121078.25781	, testing loss - 352692.81250	
9146	 steps: training loss - 122056.55469	, testing loss - 354867.59375	
9147	 steps: training loss - 102217.93750	, testing loss - 358604.81250	
9148	 steps: training loss - 116826.70312	, testing loss - 362068.40625	
9149	 steps: training loss - 96530.25781	, testing loss - 363845.81250	
9150	 steps: training loss - 116433.26562	, testing loss - 364616.21875	
9151	 steps: training loss - 110966.88281	, testing loss - 363874.59375	
9152	 steps: training loss - 121806.25000	, testing loss - 363752.37500	
9153	 steps: training loss - 94669.41406	, testing loss - 364194.15625	
9154	 steps: training loss - 89904.28125	, testing loss - 364485.37500	
9155	 steps: training loss - 97305.56250	, testing loss - 364185.25000	
9156	 steps: training loss - 128858.32031	, testing loss - 364862.25000	
9157	 steps: training loss - 85661.07031	, testing loss - 367109.37500	
9158	 steps: training loss - 115182.08594	, testing loss - 367958.15625	
9159	 steps: training loss - 121341.91406	, testing loss - 367646.75000	
9160	 steps: training loss - 117502.10156	, testing loss - 366195.09375	
9161	 steps: training loss - 107455.07812	, testing loss - 363928.21875	
9162	 steps: training loss - 114745.09375	, testing loss - 361613.31250	
9163	 steps: training loss - 123656.86719	, testing loss - 358478.03125	
9164	 steps: training loss - 94485.67188	, testing loss - 355185.03125	
9165	 steps: training loss - 108541.13281	, testing loss - 352999.93750	
9166	 steps: training loss - 94040.62500	, testing loss - 352380.15625	
9167	 steps: training loss - 96188.93750	, testing loss - 352197.40625	
9168	 steps: training loss - 111249.97656	, testing loss - 351606.34375	
9169	 steps: training loss - 110838.28125	, testing loss - 350070.37500	
9170	 steps: training loss - 119078.31250	, testing loss - 348695.37500	
9171	 steps: training loss - 127379.08594	, testing loss - 348469.06250	
9172	 steps: training loss - 121440.39062	, testing loss - 349429.21875	
9173	 steps: training loss - 94069.64062	, testing loss - 351517.37500	
9174	 steps: training loss - 104689.50781	, testing loss - 353583.37500	
9175	 steps: training loss - 98223.08594	, testing loss - 355046.87500	
9176	 steps: training loss - 98545.38281	, testing loss - 356461.50000	
9177	 steps: training loss - 104095.39062	, testing loss - 357715.81250	
9178	 steps: training loss - 102802.44531	, testing loss - 359615.96875	
9179	 steps: training loss - 104408.42969	, testing loss - 360105.96875	
9180	 steps: training loss - 99320.37500	, testing loss - 361058.06250	
9181	 steps: training loss - 103161.25781	, testing loss - 360636.15625	
9182	 steps: training loss - 100796.09375	, testing loss - 359692.21875	
9183	 steps: training loss - 106923.22656	, testing loss - 358426.00000	
9184	 steps: training loss - 124185.40625	, testing loss - 356957.15625	
9185	 steps: training loss - 103701.78125	, testing loss - 355197.40625	
9186	 steps: training loss - 117822.96875	, testing loss - 353315.90625	
9187	 steps: training loss - 105543.90625	, testing loss - 351735.65625	
9188	 steps: training loss - 111399.34375	, testing loss - 351523.06250	
9189	 steps: training loss - 148218.93750	, testing loss - 351291.87500	
9190	 steps: training loss - 124747.69531	, testing loss - 350018.87500	
9191	 steps: training loss - 119376.10156	, testing loss - 348203.06250	
9192	 steps: training loss - 118315.46875	, testing loss - 346819.93750	
9193	 steps: training loss - 115849.06250	, testing loss - 346359.15625	
9194	 steps: training loss - 99619.81250	, testing loss - 346532.93750	
9195	 steps: training loss - 112328.76562	, testing loss - 346609.90625	
9196	 steps: training loss - 118788.60156	, testing loss - 346529.75000	
9197	 steps: training loss - 98042.43750	, testing loss - 346599.68750	
9198	 steps: training loss - 150572.70312	, testing loss - 346904.28125	
9199	 steps: training loss - 117428.28125	, testing loss - 348405.71875	
9200	 steps: training loss - 99609.57812	, testing loss - 351778.53125	
9201	 steps: training loss - 110393.28125	, testing loss - 355765.46875	
9202	 steps: training loss - 102853.39844	, testing loss - 359709.84375	
9203	 steps: training loss - 119266.77344	, testing loss - 363638.75000	
9204	 steps: training loss - 100130.78125	, testing loss - 365675.84375	
9205	 steps: training loss - 117955.07812	, testing loss - 368216.53125	
9206	 steps: training loss - 104317.21875	, testing loss - 369679.53125	
9207	 steps: training loss - 119796.60938	, testing loss - 370149.53125	
9208	 steps: training loss - 89366.48438	, testing loss - 369798.96875	
9209	 steps: training loss - 134199.45312	, testing loss - 369179.18750	
9210	 steps: training loss - 115773.36719	, testing loss - 367605.56250	
9211	 steps: training loss - 101097.14844	, testing loss - 364778.62500	
9212	 steps: training loss - 115474.31250	, testing loss - 362974.18750	
9213	 steps: training loss - 121103.95312	, testing loss - 360564.21875	
9214	 steps: training loss - 115645.61719	, testing loss - 357548.93750	
9215	 steps: training loss - 94198.51562	, testing loss - 353674.18750	
9216	 steps: training loss - 99398.67188	, testing loss - 349604.56250	
9217	 steps: training loss - 99801.33594	, testing loss - 346590.78125	
9218	 steps: training loss - 126773.50000	, testing loss - 344651.96875	
9219	 steps: training loss - 89768.95312	, testing loss - 343895.71875	
9220	 steps: training loss - 106344.46094	, testing loss - 343592.12500	
9221	 steps: training loss - 109281.47656	, testing loss - 343112.65625	
9222	 steps: training loss - 91483.35938	, testing loss - 342608.43750	
9223	 steps: training loss - 100063.82031	, testing loss - 342609.53125	
9224	 steps: training loss - 101496.89844	, testing loss - 343133.18750	
9225	 steps: training loss - 98277.51562	, testing loss - 343784.25000	
9226	 steps: training loss - 115816.93750	, testing loss - 344323.15625	
9227	 steps: training loss - 123068.23438	, testing loss - 345990.96875	
9228	 steps: training loss - 109663.82031	, testing loss - 347648.43750	
9229	 steps: training loss - 124236.02344	, testing loss - 349716.75000	
9230	 steps: training loss - 92193.69531	, testing loss - 351577.93750	
9231	 steps: training loss - 112564.00781	, testing loss - 353223.28125	
9232	 steps: training loss - 142198.57812	, testing loss - 354958.25000	
9233	 steps: training loss - 98753.01562	, testing loss - 356782.03125	
9234	 steps: training loss - 90338.80469	, testing loss - 358584.90625	
9235	 steps: training loss - 111177.64844	, testing loss - 359861.21875	
9236	 steps: training loss - 127080.39844	, testing loss - 359601.65625	
9237	 steps: training loss - 106276.76562	, testing loss - 358083.96875	
9238	 steps: training loss - 116687.00000	, testing loss - 355845.28125	
9239	 steps: training loss - 120269.76562	, testing loss - 354731.37500	
9240	 steps: training loss - 92738.70312	, testing loss - 353467.12500	
9241	 steps: training loss - 113410.33594	, testing loss - 352798.46875	
9242	 steps: training loss - 105171.24219	, testing loss - 351249.87500	
9243	 steps: training loss - 102978.78125	, testing loss - 350234.06250	
9244	 steps: training loss - 118219.16406	, testing loss - 349635.21875	
9245	 steps: training loss - 132050.31250	, testing loss - 349987.75000	
9246	 steps: training loss - 103949.66406	, testing loss - 350125.09375	
9247	 steps: training loss - 116231.69531	, testing loss - 350279.93750	
9248	 steps: training loss - 78182.23438	, testing loss - 349970.50000	
9249	 steps: training loss - 103120.25000	, testing loss - 350027.81250	
9250	 steps: training loss - 109346.49219	, testing loss - 351003.71875	
9251	 steps: training loss - 112246.43750	, testing loss - 352122.90625	
9252	 steps: training loss - 107524.65625	, testing loss - 353026.21875	
9253	 steps: training loss - 122444.34375	, testing loss - 353349.21875	
9254	 steps: training loss - 100662.36719	, testing loss - 353441.65625	
9255	 steps: training loss - 102617.28125	, testing loss - 352843.65625	
9256	 steps: training loss - 103183.02344	, testing loss - 352869.37500	
9257	 steps: training loss - 114888.37500	, testing loss - 352794.50000	
9258	 steps: training loss - 114549.10938	, testing loss - 351902.28125	
9259	 steps: training loss - 105343.05469	, testing loss - 351510.81250	
9260	 steps: training loss - 106665.46094	, testing loss - 350698.06250	
9261	 steps: training loss - 126324.32812	, testing loss - 350482.31250	
9262	 steps: training loss - 112248.08594	, testing loss - 350197.40625	
9263	 steps: training loss - 94508.77344	, testing loss - 349631.28125	
9264	 steps: training loss - 108197.75781	, testing loss - 348988.46875	
9265	 steps: training loss - 112371.39844	, testing loss - 348930.59375	
9266	 steps: training loss - 109380.87500	, testing loss - 348811.75000	
9267	 steps: training loss - 89956.76562	, testing loss - 348963.18750	
9268	 steps: training loss - 107897.65625	, testing loss - 348455.31250	
9269	 steps: training loss - 114978.02344	, testing loss - 347547.93750	
9270	 steps: training loss - 88968.90625	, testing loss - 347814.59375	
9271	 steps: training loss - 111431.57031	, testing loss - 348778.93750	
9272	 steps: training loss - 116557.21094	, testing loss - 350618.68750	
9273	 steps: training loss - 96821.27344	, testing loss - 351705.78125	
9274	 steps: training loss - 114922.78906	, testing loss - 352528.25000	
9275	 steps: training loss - 106790.16406	, testing loss - 352806.00000	
9276	 steps: training loss - 105462.00000	, testing loss - 352391.81250	
9277	 steps: training loss - 127152.77344	, testing loss - 352027.34375	
9278	 steps: training loss - 93515.98438	, testing loss - 351121.31250	
9279	 steps: training loss - 102068.42188	, testing loss - 349868.78125	
9280	 steps: training loss - 113780.53125	, testing loss - 348507.18750	
9281	 steps: training loss - 105780.00000	, testing loss - 347580.78125	
9282	 steps: training loss - 95260.35156	, testing loss - 346912.25000	
9283	 steps: training loss - 97582.87500	, testing loss - 346344.56250	
9284	 steps: training loss - 105027.22656	, testing loss - 346011.87500	
9285	 steps: training loss - 110233.85938	, testing loss - 345757.31250	
9286	 steps: training loss - 104825.00781	, testing loss - 346073.40625	
9287	 steps: training loss - 119929.39844	, testing loss - 346778.62500	
9288	 steps: training loss - 102356.41406	, testing loss - 348231.62500	
9289	 steps: training loss - 112659.92188	, testing loss - 349968.31250	
9290	 steps: training loss - 97529.41406	, testing loss - 352009.75000	
9291	 steps: training loss - 104679.40625	, testing loss - 354591.03125	
9292	 steps: training loss - 103128.27344	, testing loss - 358135.12500	
9293	 steps: training loss - 122399.78125	, testing loss - 362172.00000	
9294	 steps: training loss - 96061.11719	, testing loss - 366765.18750	
9295	 steps: training loss - 96719.18750	, testing loss - 369123.21875	
9296	 steps: training loss - 100621.11719	, testing loss - 369233.90625	
9297	 steps: training loss - 99172.06250	, testing loss - 368076.06250	
9298	 steps: training loss - 92951.32031	, testing loss - 365119.43750	
9299	 steps: training loss - 122612.75781	, testing loss - 363113.31250	
9300	 steps: training loss - 125528.21875	, testing loss - 361379.46875	
9301	 steps: training loss - 100930.10938	, testing loss - 359252.87500	
9302	 steps: training loss - 98339.60156	, testing loss - 357137.12500	
9303	 steps: training loss - 118620.04688	, testing loss - 356779.15625	
9304	 steps: training loss - 119814.99219	, testing loss - 356112.06250	
9305	 steps: training loss - 100675.65625	, testing loss - 355965.15625	
9306	 steps: training loss - 106008.60156	, testing loss - 356352.43750	
9307	 steps: training loss - 94568.42188	, testing loss - 357563.62500	
9308	 steps: training loss - 121368.39844	, testing loss - 357809.65625	
9309	 steps: training loss - 111231.68750	, testing loss - 357880.03125	
9310	 steps: training loss - 80790.85938	, testing loss - 358403.59375	
9311	 steps: training loss - 116204.01562	, testing loss - 358036.46875	
9312	 steps: training loss - 120157.58594	, testing loss - 357471.87500	
9313	 steps: training loss - 99155.85938	, testing loss - 358157.50000	
9314	 steps: training loss - 105452.35156	, testing loss - 358354.18750	
9315	 steps: training loss - 106028.25000	, testing loss - 357938.03125	
9316	 steps: training loss - 110729.27344	, testing loss - 356681.93750	
9317	 steps: training loss - 104006.13281	, testing loss - 355490.15625	
9318	 steps: training loss - 124727.65625	, testing loss - 354594.25000	
9319	 steps: training loss - 73087.23438	, testing loss - 353113.25000	
9320	 steps: training loss - 127215.20312	, testing loss - 352205.28125	
9321	 steps: training loss - 131450.67188	, testing loss - 351604.78125	
9322	 steps: training loss - 118068.17969	, testing loss - 350355.65625	
9323	 steps: training loss - 112102.92188	, testing loss - 349310.09375	
9324	 steps: training loss - 85543.31250	, testing loss - 348510.81250	
9325	 steps: training loss - 105735.74219	, testing loss - 347679.03125	
9326	 steps: training loss - 112793.70312	, testing loss - 347391.56250	
9327	 steps: training loss - 101474.61719	, testing loss - 347091.40625	
9328	 steps: training loss - 95669.04688	, testing loss - 347061.68750	
9329	 steps: training loss - 114488.71094	, testing loss - 347020.00000	
9330	 steps: training loss - 106528.93750	, testing loss - 347363.40625	
9331	 steps: training loss - 100726.10156	, testing loss - 348274.56250	
9332	 steps: training loss - 135349.65625	, testing loss - 349368.21875	
9333	 steps: training loss - 117674.85938	, testing loss - 351259.15625	
9334	 steps: training loss - 98580.74219	, testing loss - 352528.03125	
9335	 steps: training loss - 88888.06250	, testing loss - 352435.62500	
9336	 steps: training loss - 117873.85156	, testing loss - 351895.25000	
9337	 steps: training loss - 110532.26562	, testing loss - 351500.09375	
9338	 steps: training loss - 104969.28906	, testing loss - 350706.03125	
9339	 steps: training loss - 115122.78906	, testing loss - 350051.46875	
9340	 steps: training loss - 82341.15625	, testing loss - 348779.28125	
9341	 steps: training loss - 102139.48438	, testing loss - 346870.56250	
9342	 steps: training loss - 115903.96875	, testing loss - 344887.53125	
9343	 steps: training loss - 107854.67188	, testing loss - 343305.09375	
9344	 steps: training loss - 117657.32031	, testing loss - 342007.37500	
9345	 steps: training loss - 122841.88281	, testing loss - 341393.06250	
9346	 steps: training loss - 117900.32812	, testing loss - 341406.25000	
9347	 steps: training loss - 135393.93750	, testing loss - 341573.00000	
9348	 steps: training loss - 109668.82812	, testing loss - 341962.50000	
9349	 steps: training loss - 104985.67969	, testing loss - 343635.93750	
9350	 steps: training loss - 117434.56250	, testing loss - 345344.18750	
9351	 steps: training loss - 123254.85156	, testing loss - 346667.15625	
9352	 steps: training loss - 120925.39844	, testing loss - 348175.56250	
9353	 steps: training loss - 98719.00000	, testing loss - 350011.87500	
9354	 steps: training loss - 123674.66406	, testing loss - 351882.34375	
9355	 steps: training loss - 105184.01562	, testing loss - 354153.21875	
9356	 steps: training loss - 122798.10938	, testing loss - 355429.50000	
9357	 steps: training loss - 89717.25000	, testing loss - 356597.09375	
9358	 steps: training loss - 85686.64062	, testing loss - 357224.34375	
9359	 steps: training loss - 96012.91406	, testing loss - 357992.40625	
9360	 steps: training loss - 109002.31250	, testing loss - 359791.81250	
9361	 steps: training loss - 117658.94531	, testing loss - 360367.43750	
9362	 steps: training loss - 120529.38281	, testing loss - 359923.96875	
9363	 steps: training loss - 103548.03906	, testing loss - 358320.25000	
9364	 steps: training loss - 120755.53906	, testing loss - 356182.62500	
9365	 steps: training loss - 94171.63281	, testing loss - 354751.84375	
9366	 steps: training loss - 96505.27344	, testing loss - 353753.09375	
9367	 steps: training loss - 80690.77344	, testing loss - 352888.65625	
9368	 steps: training loss - 107167.84375	, testing loss - 352294.21875	
9369	 steps: training loss - 118107.16406	, testing loss - 350752.37500	
9370	 steps: training loss - 106920.96094	, testing loss - 348493.21875	
9371	 steps: training loss - 102379.95312	, testing loss - 346994.81250	
9372	 steps: training loss - 101317.11719	, testing loss - 346038.21875	
9373	 steps: training loss - 96980.00000	, testing loss - 345755.65625	
9374	 steps: training loss - 120245.15625	, testing loss - 345204.75000	
9375	 steps: training loss - 108130.07812	, testing loss - 345230.15625	
9376	 steps: training loss - 100678.07812	, testing loss - 346068.65625	
9377	 steps: training loss - 107851.51562	, testing loss - 347308.75000	
9378	 steps: training loss - 101632.46875	, testing loss - 348795.03125	
9379	 steps: training loss - 107932.27344	, testing loss - 350773.12500	
9380	 steps: training loss - 108656.75781	, testing loss - 352545.25000	
9381	 steps: training loss - 145607.92188	, testing loss - 354210.96875	
9382	 steps: training loss - 97648.09375	, testing loss - 355941.25000	
9383	 steps: training loss - 123442.64844	, testing loss - 356748.06250	
9384	 steps: training loss - 96282.36719	, testing loss - 356079.12500	
9385	 steps: training loss - 93309.58594	, testing loss - 355362.28125	
9386	 steps: training loss - 116667.16406	, testing loss - 354264.34375	
9387	 steps: training loss - 92965.92188	, testing loss - 352405.65625	
9388	 steps: training loss - 91673.38281	, testing loss - 350195.15625	
9389	 steps: training loss - 116416.31250	, testing loss - 348242.12500	
9390	 steps: training loss - 129849.11719	, testing loss - 346590.71875	
9391	 steps: training loss - 122451.15625	, testing loss - 345581.18750	
9392	 steps: training loss - 100436.32812	, testing loss - 345493.46875	
9393	 steps: training loss - 119592.42188	, testing loss - 345303.53125	
9394	 steps: training loss - 95234.39844	, testing loss - 345475.43750	
9395	 steps: training loss - 112881.85938	, testing loss - 345231.15625	
9396	 steps: training loss - 111332.35156	, testing loss - 345177.81250	
9397	 steps: training loss - 119396.03906	, testing loss - 345589.03125	
9398	 steps: training loss - 125670.33594	, testing loss - 346543.71875	
9399	 steps: training loss - 103026.96875	, testing loss - 346756.37500	
9400	 steps: training loss - 114765.23438	, testing loss - 346636.68750	
9401	 steps: training loss - 111837.71875	, testing loss - 347099.21875	
9402	 steps: training loss - 122807.67188	, testing loss - 347684.90625	
9403	 steps: training loss - 95679.82031	, testing loss - 349375.15625	
9404	 steps: training loss - 117581.64844	, testing loss - 351655.71875	
9405	 steps: training loss - 124704.57031	, testing loss - 354150.37500	
9406	 steps: training loss - 106119.07031	, testing loss - 356561.18750	
9407	 steps: training loss - 87738.82031	, testing loss - 358272.84375	
9408	 steps: training loss - 117001.76562	, testing loss - 359369.93750	
9409	 steps: training loss - 120626.70312	, testing loss - 359902.56250	
9410	 steps: training loss - 122738.32812	, testing loss - 358928.62500	
9411	 steps: training loss - 110439.94531	, testing loss - 357073.68750	
9412	 steps: training loss - 81471.51562	, testing loss - 355542.12500	
9413	 steps: training loss - 102261.53906	, testing loss - 354258.65625	
9414	 steps: training loss - 110462.53906	, testing loss - 353665.75000	
9415	 steps: training loss - 116704.20312	, testing loss - 353261.93750	
9416	 steps: training loss - 128127.02344	, testing loss - 352382.46875	
9417	 steps: training loss - 92330.12500	, testing loss - 349876.56250	
9418	 steps: training loss - 128911.15625	, testing loss - 347865.56250	
9419	 steps: training loss - 104992.85156	, testing loss - 346581.78125	
9420	 steps: training loss - 108678.22656	, testing loss - 344891.12500	
9421	 steps: training loss - 79301.62500	, testing loss - 343643.12500	
9422	 steps: training loss - 100707.87500	, testing loss - 342842.90625	
9423	 steps: training loss - 118196.63281	, testing loss - 342765.53125	
9424	 steps: training loss - 98293.14062	, testing loss - 342782.87500	
9425	 steps: training loss - 103578.67969	, testing loss - 342899.00000	
9426	 steps: training loss - 107968.07031	, testing loss - 343011.65625	
9427	 steps: training loss - 96689.42188	, testing loss - 343449.37500	
9428	 steps: training loss - 98929.78906	, testing loss - 344012.65625	
9429	 steps: training loss - 105965.85156	, testing loss - 344906.65625	
9430	 steps: training loss - 107086.39844	, testing loss - 345507.15625	
9431	 steps: training loss - 91967.37500	, testing loss - 345916.46875	
9432	 steps: training loss - 122135.23438	, testing loss - 346747.71875	
9433	 steps: training loss - 92989.87500	, testing loss - 347583.53125	
9434	 steps: training loss - 133851.82812	, testing loss - 347939.71875	
9435	 steps: training loss - 101985.71875	, testing loss - 349479.62500	
9436	 steps: training loss - 106155.36719	, testing loss - 351626.96875	
9437	 steps: training loss - 101695.07812	, testing loss - 352962.78125	
9438	 steps: training loss - 114551.15625	, testing loss - 353788.43750	
9439	 steps: training loss - 102449.02344	, testing loss - 354449.59375	
9440	 steps: training loss - 108271.97656	, testing loss - 354818.56250	
9441	 steps: training loss - 99784.35938	, testing loss - 354474.81250	
9442	 steps: training loss - 105398.84375	, testing loss - 354177.59375	
9443	 steps: training loss - 111373.65625	, testing loss - 353327.15625	
9444	 steps: training loss - 121215.00781	, testing loss - 352404.75000	
9445	 steps: training loss - 96331.99219	, testing loss - 352087.84375	
9446	 steps: training loss - 113114.67969	, testing loss - 351581.68750	
9447	 steps: training loss - 83264.97656	, testing loss - 350694.46875	
9448	 steps: training loss - 120647.53125	, testing loss - 349080.06250	
9449	 steps: training loss - 90606.19531	, testing loss - 348101.18750	
9450	 steps: training loss - 113888.56250	, testing loss - 347905.93750	
9451	 steps: training loss - 99715.82031	, testing loss - 347642.31250	
9452	 steps: training loss - 121411.71094	, testing loss - 347197.96875	
9453	 steps: training loss - 100362.75781	, testing loss - 346487.43750	
9454	 steps: training loss - 108158.41406	, testing loss - 346664.15625	
9455	 steps: training loss - 103852.82812	, testing loss - 346798.18750	
9456	 steps: training loss - 121977.60156	, testing loss - 346999.53125	
9457	 steps: training loss - 101548.60156	, testing loss - 347094.90625	
9458	 steps: training loss - 108681.84375	, testing loss - 347711.90625	
9459	 steps: training loss - 94405.50000	, testing loss - 347770.46875	
9460	 steps: training loss - 84593.62500	, testing loss - 347568.81250	
9461	 steps: training loss - 122359.26562	, testing loss - 347737.65625	
9462	 steps: training loss - 102292.97656	, testing loss - 348320.71875	
9463	 steps: training loss - 104987.18750	, testing loss - 349263.34375	
9464	 steps: training loss - 72548.53906	, testing loss - 349613.03125	
9465	 steps: training loss - 124849.91406	, testing loss - 349712.59375	
9466	 steps: training loss - 105311.96094	, testing loss - 349789.18750	
9467	 steps: training loss - 101083.40625	, testing loss - 349290.21875	
9468	 steps: training loss - 106965.87500	, testing loss - 349053.96875	
9469	 steps: training loss - 88664.85156	, testing loss - 349115.31250	
9470	 steps: training loss - 93800.20312	, testing loss - 349367.28125	
9471	 steps: training loss - 106681.04688	, testing loss - 348802.62500	
9472	 steps: training loss - 102768.96094	, testing loss - 348532.81250	
9473	 steps: training loss - 110405.37500	, testing loss - 348441.59375	
9474	 steps: training loss - 103132.61719	, testing loss - 347654.12500	
9475	 steps: training loss - 95010.61719	, testing loss - 347713.46875	
9476	 steps: training loss - 119119.11719	, testing loss - 347639.84375	
9477	 steps: training loss - 102532.60156	, testing loss - 347227.68750	
9478	 steps: training loss - 106691.24219	, testing loss - 346657.15625	
9479	 steps: training loss - 104223.28125	, testing loss - 345930.68750	
9480	 steps: training loss - 108100.78906	, testing loss - 345711.90625	
9481	 steps: training loss - 110986.77344	, testing loss - 345788.53125	
9482	 steps: training loss - 93050.98438	, testing loss - 345203.00000	
9483	 steps: training loss - 124604.77344	, testing loss - 344378.62500	
9484	 steps: training loss - 112688.77344	, testing loss - 343678.56250	
9485	 steps: training loss - 97954.64062	, testing loss - 343772.03125	
9486	 steps: training loss - 108761.33594	, testing loss - 344450.96875	
9487	 steps: training loss - 117358.00781	, testing loss - 345509.68750	
9488	 steps: training loss - 110341.60156	, testing loss - 347025.12500	
9489	 steps: training loss - 112930.82031	, testing loss - 349362.06250	
9490	 steps: training loss - 104063.48438	, testing loss - 351749.56250	
9491	 steps: training loss - 124078.16406	, testing loss - 354325.21875	
9492	 steps: training loss - 109312.09375	, testing loss - 356866.31250	
9493	 steps: training loss - 115287.23438	, testing loss - 359016.93750	
9494	 steps: training loss - 110272.55469	, testing loss - 359415.03125	
9495	 steps: training loss - 87125.03906	, testing loss - 358744.37500	
9496	 steps: training loss - 118508.33594	, testing loss - 357889.18750	
9497	 steps: training loss - 113825.89062	, testing loss - 357099.25000	
9498	 steps: training loss - 110047.42969	, testing loss - 356403.90625	
9499	 steps: training loss - 103845.25781	, testing loss - 356055.46875	
9500	 steps: training loss - 102816.89844	, testing loss - 355994.18750	
9501	 steps: training loss - 108451.02344	, testing loss - 355457.65625	
9502	 steps: training loss - 105671.32031	, testing loss - 354674.56250	
9503	 steps: training loss - 102977.14844	, testing loss - 355015.71875	
9504	 steps: training loss - 104962.77344	, testing loss - 354570.56250	
9505	 steps: training loss - 122004.46875	, testing loss - 354915.25000	
9506	 steps: training loss - 113188.06250	, testing loss - 356258.21875	
9507	 steps: training loss - 124176.50781	, testing loss - 357259.34375	
9508	 steps: training loss - 119863.26562	, testing loss - 357694.15625	
9509	 steps: training loss - 107399.32812	, testing loss - 355698.59375	
9510	 steps: training loss - 135530.34375	, testing loss - 353373.31250	
9511	 steps: training loss - 139764.71875	, testing loss - 351047.87500	
9512	 steps: training loss - 117073.32812	, testing loss - 349140.12500	
9513	 steps: training loss - 103851.11719	, testing loss - 347068.06250	
9514	 steps: training loss - 107289.66406	, testing loss - 345813.62500	
9515	 steps: training loss - 112152.29688	, testing loss - 344943.31250	
9516	 steps: training loss - 79669.50000	, testing loss - 343763.59375	
9517	 steps: training loss - 106119.88281	, testing loss - 342684.53125	
9518	 steps: training loss - 101404.17188	, testing loss - 342387.75000	
9519	 steps: training loss - 109846.61719	, testing loss - 341664.15625	
9520	 steps: training loss - 159718.95312	, testing loss - 341146.18750	
9521	 steps: training loss - 113947.28906	, testing loss - 341028.59375	
9522	 steps: training loss - 102973.05469	, testing loss - 340663.37500	
9523	 steps: training loss - 104651.66406	, testing loss - 340564.09375	
9524	 steps: training loss - 100722.34375	, testing loss - 341949.06250	
9525	 steps: training loss - 118191.46875	, testing loss - 343594.56250	
9526	 steps: training loss - 141736.96875	, testing loss - 345147.21875	
9527	 steps: training loss - 120869.18750	, testing loss - 346127.75000	
9528	 steps: training loss - 122939.45312	, testing loss - 346823.62500	
9529	 steps: training loss - 111434.91406	, testing loss - 347926.81250	
9530	 steps: training loss - 102905.08594	, testing loss - 349124.84375	
9531	 steps: training loss - 99607.37500	, testing loss - 350268.90625	
9532	 steps: training loss - 103038.81250	, testing loss - 350887.84375	
9533	 steps: training loss - 98187.81250	, testing loss - 350490.28125	
9534	 steps: training loss - 113447.62500	, testing loss - 349298.03125	
9535	 steps: training loss - 106898.41406	, testing loss - 347804.21875	
9536	 steps: training loss - 103660.53125	, testing loss - 346728.50000	
9537	 steps: training loss - 101698.18750	, testing loss - 345337.93750	
9538	 steps: training loss - 140561.20312	, testing loss - 344464.03125	
9539	 steps: training loss - 117480.61719	, testing loss - 344665.65625	
9540	 steps: training loss - 102039.58594	, testing loss - 345132.12500	
9541	 steps: training loss - 90325.63281	, testing loss - 345612.96875	
9542	 steps: training loss - 92881.59375	, testing loss - 346343.15625	
9543	 steps: training loss - 137834.57812	, testing loss - 346867.84375	
9544	 steps: training loss - 111963.17969	, testing loss - 347349.25000	
9545	 steps: training loss - 123600.02344	, testing loss - 347572.71875	
9546	 steps: training loss - 105620.67188	, testing loss - 347565.09375	
9547	 steps: training loss - 109121.46094	, testing loss - 347107.96875	
9548	 steps: training loss - 105050.39844	, testing loss - 346056.00000	
9549	 steps: training loss - 109630.50000	, testing loss - 345671.93750	
9550	 steps: training loss - 114869.49219	, testing loss - 345313.34375	
9551	 steps: training loss - 98033.97656	, testing loss - 344522.34375	
9552	 steps: training loss - 112300.91406	, testing loss - 343532.00000	
9553	 steps: training loss - 99127.43750	, testing loss - 342892.28125	
9554	 steps: training loss - 139379.48438	, testing loss - 342106.21875	
9555	 steps: training loss - 127741.28906	, testing loss - 341923.65625	
9556	 steps: training loss - 98571.26562	, testing loss - 343281.56250	
9557	 steps: training loss - 131029.86719	, testing loss - 345106.31250	
9558	 steps: training loss - 128503.07812	, testing loss - 346602.06250	
9559	 steps: training loss - 134363.90625	, testing loss - 347733.71875	
9560	 steps: training loss - 106141.06250	, testing loss - 349159.09375	
9561	 steps: training loss - 113816.21094	, testing loss - 350855.50000	
9562	 steps: training loss - 120691.83594	, testing loss - 352909.75000	
9563	 steps: training loss - 98013.07031	, testing loss - 354870.75000	
9564	 steps: training loss - 112093.85156	, testing loss - 355665.34375	
9565	 steps: training loss - 119334.35156	, testing loss - 356582.46875	
9566	 steps: training loss - 114370.46875	, testing loss - 356632.56250	
9567	 steps: training loss - 125467.59375	, testing loss - 357222.93750	
9568	 steps: training loss - 135207.87500	, testing loss - 358251.65625	
9569	 steps: training loss - 98138.04688	, testing loss - 359260.59375	
9570	 steps: training loss - 131677.45312	, testing loss - 359862.53125	
9571	 steps: training loss - 130906.70312	, testing loss - 360532.68750	
9572	 steps: training loss - 108354.98438	, testing loss - 361446.28125	
9573	 steps: training loss - 116513.77344	, testing loss - 362003.56250	
9574	 steps: training loss - 114485.42969	, testing loss - 362730.31250	
9575	 steps: training loss - 107138.24219	, testing loss - 364379.50000	
9576	 steps: training loss - 121158.62500	, testing loss - 365009.03125	
9577	 steps: training loss - 134107.46875	, testing loss - 365193.53125	
9578	 steps: training loss - 97428.66406	, testing loss - 364070.12500	
9579	 steps: training loss - 110497.65625	, testing loss - 361008.46875	
9580	 steps: training loss - 97661.21875	, testing loss - 357072.28125	
9581	 steps: training loss - 117133.03906	, testing loss - 352642.71875	
9582	 steps: training loss - 86515.00000	, testing loss - 350096.25000	
9583	 steps: training loss - 117304.92969	, testing loss - 348504.59375	
9584	 steps: training loss - 119020.57812	, testing loss - 348341.25000	
9585	 steps: training loss - 140911.46875	, testing loss - 348277.03125	
9586	 steps: training loss - 110793.20312	, testing loss - 348172.15625	
9587	 steps: training loss - 113928.69531	, testing loss - 347898.28125	
9588	 steps: training loss - 84630.50000	, testing loss - 346573.34375	
9589	 steps: training loss - 121865.73438	, testing loss - 345596.71875	
9590	 steps: training loss - 112875.02344	, testing loss - 345240.56250	
9591	 steps: training loss - 112127.30469	, testing loss - 346136.12500	
9592	 steps: training loss - 126668.03906	, testing loss - 346982.56250	
9593	 steps: training loss - 93597.65625	, testing loss - 348602.31250	
9594	 steps: training loss - 113275.38281	, testing loss - 351022.59375	
9595	 steps: training loss - 96990.07812	, testing loss - 353390.93750	
9596	 steps: training loss - 116745.43750	, testing loss - 355678.37500	
9597	 steps: training loss - 114392.90625	, testing loss - 357172.40625	
9598	 steps: training loss - 102754.81250	, testing loss - 356888.65625	
9599	 steps: training loss - 103764.29688	, testing loss - 356916.34375	
9600	 steps: training loss - 130570.63281	, testing loss - 357040.18750	
9601	 steps: training loss - 111828.35156	, testing loss - 355640.43750	
9602	 steps: training loss - 73717.45312	, testing loss - 353801.96875	
9603	 steps: training loss - 110798.48438	, testing loss - 352303.09375	
9604	 steps: training loss - 100444.57812	, testing loss - 351795.96875	
9605	 steps: training loss - 104004.87500	, testing loss - 350669.28125	
9606	 steps: training loss - 119248.19531	, testing loss - 349585.28125	
9607	 steps: training loss - 83418.97656	, testing loss - 349141.06250	
9608	 steps: training loss - 115420.69531	, testing loss - 348966.37500	
9609	 steps: training loss - 128863.46875	, testing loss - 347956.90625	
9610	 steps: training loss - 107783.65625	, testing loss - 346428.21875	
9611	 steps: training loss - 103349.95312	, testing loss - 345034.37500	
9612	 steps: training loss - 101727.40625	, testing loss - 344798.43750	
9613	 steps: training loss - 112139.15625	, testing loss - 346028.09375	
9614	 steps: training loss - 72349.92188	, testing loss - 346686.18750	
9615	 steps: training loss - 103354.86719	, testing loss - 347323.43750	
9616	 steps: training loss - 117584.17188	, testing loss - 347803.28125	
9617	 steps: training loss - 104654.67969	, testing loss - 348148.21875	
9618	 steps: training loss - 133746.42188	, testing loss - 348059.65625	
9619	 steps: training loss - 96564.57031	, testing loss - 347734.90625	
9620	 steps: training loss - 121164.85938	, testing loss - 347764.37500	
9621	 steps: training loss - 110381.47656	, testing loss - 347771.03125	
9622	 steps: training loss - 121854.03906	, testing loss - 347082.71875	
9623	 steps: training loss - 98878.39844	, testing loss - 346257.68750	
9624	 steps: training loss - 96727.82031	, testing loss - 346387.03125	
9625	 steps: training loss - 137925.40625	, testing loss - 347332.18750	
9626	 steps: training loss - 113988.48438	, testing loss - 348808.31250	
9627	 steps: training loss - 110803.52344	, testing loss - 350226.31250	
9628	 steps: training loss - 92542.25000	, testing loss - 351622.59375	
9629	 steps: training loss - 88229.25781	, testing loss - 353504.18750	
9630	 steps: training loss - 98489.21094	, testing loss - 356468.62500	
9631	 steps: training loss - 109152.04688	, testing loss - 358867.15625	
9632	 steps: training loss - 95211.26562	, testing loss - 359359.28125	
9633	 steps: training loss - 115684.78906	, testing loss - 359899.59375	
9634	 steps: training loss - 117759.35938	, testing loss - 361596.31250	
9635	 steps: training loss - 124447.82812	, testing loss - 363573.00000	
9636	 steps: training loss - 125238.99219	, testing loss - 364172.65625	
9637	 steps: training loss - 113047.56250	, testing loss - 363659.96875	
9638	 steps: training loss - 152607.87500	, testing loss - 361229.37500	
9639	 steps: training loss - 107526.77344	, testing loss - 357940.87500	
9640	 steps: training loss - 96609.28906	, testing loss - 354468.03125	
9641	 steps: training loss - 93537.95312	, testing loss - 351404.31250	
9642	 steps: training loss - 102436.92969	, testing loss - 349823.62500	
9643	 steps: training loss - 129955.73438	, testing loss - 348760.28125	
9644	 steps: training loss - 95411.05469	, testing loss - 346492.31250	
9645	 steps: training loss - 98830.71094	, testing loss - 344231.43750	
9646	 steps: training loss - 101386.89062	, testing loss - 342583.28125	
9647	 steps: training loss - 93975.49219	, testing loss - 341263.96875	
9648	 steps: training loss - 134142.73438	, testing loss - 340218.18750	
9649	 steps: training loss - 119891.49219	, testing loss - 340009.09375	
9650	 steps: training loss - 106365.32812	, testing loss - 340107.03125	
9651	 steps: training loss - 112824.25000	, testing loss - 340520.28125	
9652	 steps: training loss - 97604.39062	, testing loss - 341491.15625	
9653	 steps: training loss - 110306.88281	, testing loss - 342518.87500	
9654	 steps: training loss - 114865.42188	, testing loss - 343336.56250	
9655	 steps: training loss - 120962.75781	, testing loss - 344934.59375	
9656	 steps: training loss - 133354.62500	, testing loss - 346708.65625	
9657	 steps: training loss - 116107.36719	, testing loss - 347806.90625	
9658	 steps: training loss - 98970.61719	, testing loss - 347832.06250	
9659	 steps: training loss - 95254.35938	, testing loss - 348500.00000	
9660	 steps: training loss - 87152.31250	, testing loss - 348796.31250	
9661	 steps: training loss - 114618.74219	, testing loss - 349014.46875	
9662	 steps: training loss - 103531.11719	, testing loss - 349896.46875	
9663	 steps: training loss - 121417.25781	, testing loss - 350756.78125	
9664	 steps: training loss - 121213.94531	, testing loss - 350830.40625	
9665	 steps: training loss - 116173.76562	, testing loss - 350389.31250	
9666	 steps: training loss - 133881.23438	, testing loss - 349751.84375	
9667	 steps: training loss - 120401.01562	, testing loss - 349158.75000	
9668	 steps: training loss - 91270.50000	, testing loss - 348512.75000	
9669	 steps: training loss - 115787.34375	, testing loss - 348351.46875	
9670	 steps: training loss - 128165.26562	, testing loss - 348441.56250	
9671	 steps: training loss - 94153.75781	, testing loss - 349268.56250	
9672	 steps: training loss - 114771.76562	, testing loss - 349605.78125	
9673	 steps: training loss - 118522.42969	, testing loss - 350442.46875	
9674	 steps: training loss - 95144.26562	, testing loss - 350540.87500	
9675	 steps: training loss - 123319.35156	, testing loss - 350105.53125	
9676	 steps: training loss - 106354.57812	, testing loss - 350039.46875	
9677	 steps: training loss - 131968.34375	, testing loss - 349459.59375	
9678	 steps: training loss - 120760.74219	, testing loss - 349780.43750	
9679	 steps: training loss - 89413.36719	, testing loss - 349525.21875	
9680	 steps: training loss - 112708.27344	, testing loss - 348771.28125	
9681	 steps: training loss - 111293.15625	, testing loss - 348290.71875	
9682	 steps: training loss - 88254.85156	, testing loss - 347939.34375	
9683	 steps: training loss - 87946.88281	, testing loss - 347472.21875	
9684	 steps: training loss - 106007.12500	, testing loss - 347246.50000	
9685	 steps: training loss - 120469.89844	, testing loss - 347477.40625	
9686	 steps: training loss - 114131.67969	, testing loss - 347783.53125	
9687	 steps: training loss - 109075.42969	, testing loss - 348843.59375	
9688	 steps: training loss - 107109.63281	, testing loss - 349001.90625	
9689	 steps: training loss - 114296.78906	, testing loss - 349601.12500	
9690	 steps: training loss - 88197.96094	, testing loss - 349076.40625	
9691	 steps: training loss - 100782.02344	, testing loss - 347286.53125	
9692	 steps: training loss - 93152.01562	, testing loss - 345883.96875	
9693	 steps: training loss - 126562.81250	, testing loss - 344661.81250	
9694	 steps: training loss - 100465.69531	, testing loss - 343668.65625	
9695	 steps: training loss - 110649.59375	, testing loss - 342326.87500	
9696	 steps: training loss - 101622.89844	, testing loss - 341741.28125	
9697	 steps: training loss - 91269.25000	, testing loss - 341571.00000	
9698	 steps: training loss - 134846.59375	, testing loss - 341480.15625	
9699	 steps: training loss - 116828.52344	, testing loss - 342242.53125	
9700	 steps: training loss - 116273.91406	, testing loss - 342957.71875	
9701	 steps: training loss - 111831.97656	, testing loss - 343823.71875	
9702	 steps: training loss - 131433.67188	, testing loss - 344881.71875	
9703	 steps: training loss - 110935.71875	, testing loss - 346615.93750	
9704	 steps: training loss - 101557.40625	, testing loss - 348129.56250	
9705	 steps: training loss - 127710.58594	, testing loss - 349686.81250	
9706	 steps: training loss - 111294.70312	, testing loss - 351426.28125	
9707	 steps: training loss - 94880.03906	, testing loss - 352751.09375	
9708	 steps: training loss - 99810.16406	, testing loss - 353044.90625	
9709	 steps: training loss - 97806.21875	, testing loss - 353435.75000	
9710	 steps: training loss - 115964.33594	, testing loss - 353758.18750	
9711	 steps: training loss - 85917.04688	, testing loss - 355300.21875	
9712	 steps: training loss - 110837.22656	, testing loss - 357656.87500	
9713	 steps: training loss - 75924.94531	, testing loss - 359702.75000	
9714	 steps: training loss - 123923.54688	, testing loss - 360668.84375	
9715	 steps: training loss - 121209.70312	, testing loss - 360212.21875	
9716	 steps: training loss - 112144.57031	, testing loss - 359046.81250	
9717	 steps: training loss - 99511.25000	, testing loss - 356866.37500	
9718	 steps: training loss - 123781.57031	, testing loss - 354049.06250	
9719	 steps: training loss - 124778.96875	, testing loss - 351224.96875	
9720	 steps: training loss - 124865.04688	, testing loss - 348241.15625	
9721	 steps: training loss - 96101.00000	, testing loss - 346491.18750	
9722	 steps: training loss - 101663.34375	, testing loss - 345017.37500	
9723	 steps: training loss - 99222.70312	, testing loss - 343441.21875	
9724	 steps: training loss - 120986.42969	, testing loss - 342763.53125	
9725	 steps: training loss - 121982.15625	, testing loss - 342686.43750	
9726	 steps: training loss - 93873.89844	, testing loss - 343334.50000	
9727	 steps: training loss - 110240.23438	, testing loss - 344897.84375	
9728	 steps: training loss - 87737.60938	, testing loss - 346141.96875	
9729	 steps: training loss - 106963.11719	, testing loss - 346707.28125	
9730	 steps: training loss - 110150.11719	, testing loss - 347107.90625	
9731	 steps: training loss - 83771.73438	, testing loss - 347301.81250	
9732	 steps: training loss - 109931.60156	, testing loss - 347372.68750	
9733	 steps: training loss - 123456.89062	, testing loss - 347282.71875	
9734	 steps: training loss - 94918.91406	, testing loss - 348106.21875	
9735	 steps: training loss - 112938.71094	, testing loss - 348928.28125	
9736	 steps: training loss - 112701.10156	, testing loss - 348629.12500	
9737	 steps: training loss - 108579.00000	, testing loss - 348488.59375	
9738	 steps: training loss - 90562.67969	, testing loss - 349063.12500	
9739	 steps: training loss - 100459.88281	, testing loss - 348919.25000	
9740	 steps: training loss - 83026.38281	, testing loss - 348398.75000	
9741	 steps: training loss - 111246.62500	, testing loss - 347778.18750	
9742	 steps: training loss - 108146.54688	, testing loss - 348081.53125	
9743	 steps: training loss - 107845.51562	, testing loss - 348851.93750	
9744	 steps: training loss - 92400.55469	, testing loss - 348180.84375	
9745	 steps: training loss - 93725.85938	, testing loss - 346865.78125	
9746	 steps: training loss - 100612.29688	, testing loss - 347320.34375	
9747	 steps: training loss - 128319.17969	, testing loss - 347760.62500	
9748	 steps: training loss - 116970.32031	, testing loss - 347017.31250	
9749	 steps: training loss - 124587.62500	, testing loss - 347291.15625	
9750	 steps: training loss - 139923.07812	, testing loss - 348108.00000	
9751	 steps: training loss - 109406.81250	, testing loss - 349401.84375	
9752	 steps: training loss - 124371.67969	, testing loss - 351140.90625	
9753	 steps: training loss - 122419.73438	, testing loss - 352107.53125	
9754	 steps: training loss - 101749.13281	, testing loss - 351942.15625	
9755	 steps: training loss - 110427.07031	, testing loss - 352229.87500	
9756	 steps: training loss - 101885.64844	, testing loss - 352926.03125	
9757	 steps: training loss - 116738.51562	, testing loss - 353197.09375	
9758	 steps: training loss - 110197.39062	, testing loss - 352880.06250	
9759	 steps: training loss - 111622.37500	, testing loss - 352480.37500	
9760	 steps: training loss - 78755.60156	, testing loss - 352178.12500	
9761	 steps: training loss - 103585.13281	, testing loss - 352305.40625	
9762	 steps: training loss - 96711.89844	, testing loss - 351979.78125	
9763	 steps: training loss - 133182.40625	, testing loss - 352358.46875	
9764	 steps: training loss - 125662.40625	, testing loss - 352432.40625	
9765	 steps: training loss - 106570.31250	, testing loss - 352006.21875	
9766	 steps: training loss - 89410.36719	, testing loss - 351501.75000	
9767	 steps: training loss - 119635.22656	, testing loss - 350884.31250	
9768	 steps: training loss - 95156.76562	, testing loss - 349933.59375	
9769	 steps: training loss - 122673.57812	, testing loss - 349380.53125	
9770	 steps: training loss - 96313.50000	, testing loss - 348220.90625	
9771	 steps: training loss - 113789.35938	, testing loss - 346961.46875	
9772	 steps: training loss - 121697.90625	, testing loss - 346652.06250	
9773	 steps: training loss - 102915.98438	, testing loss - 346522.43750	
9774	 steps: training loss - 103169.21094	, testing loss - 347126.21875	
9775	 steps: training loss - 122601.34375	, testing loss - 347422.31250	
9776	 steps: training loss - 134602.42188	, testing loss - 347801.68750	
9777	 steps: training loss - 138857.14062	, testing loss - 348550.43750	
9778	 steps: training loss - 141359.78125	, testing loss - 349374.84375	
9779	 steps: training loss - 110915.99219	, testing loss - 350178.93750	
9780	 steps: training loss - 100862.15625	, testing loss - 351545.12500	
9781	 steps: training loss - 109911.17188	, testing loss - 352363.78125	
9782	 steps: training loss - 119519.69531	, testing loss - 353808.09375	
9783	 steps: training loss - 113913.78125	, testing loss - 355330.06250	
9784	 steps: training loss - 104285.83594	, testing loss - 356746.31250	
9785	 steps: training loss - 94770.39062	, testing loss - 358135.12500	
9786	 steps: training loss - 123719.63281	, testing loss - 359174.43750	
9787	 steps: training loss - 83213.37500	, testing loss - 358602.78125	
9788	 steps: training loss - 112485.74219	, testing loss - 358037.75000	
9789	 steps: training loss - 129631.77344	, testing loss - 356487.62500	
9790	 steps: training loss - 117191.32812	, testing loss - 354759.37500	
9791	 steps: training loss - 97704.10156	, testing loss - 353271.31250	
9792	 steps: training loss - 135908.15625	, testing loss - 351729.03125	
9793	 steps: training loss - 123034.43750	, testing loss - 350867.53125	
9794	 steps: training loss - 114260.63281	, testing loss - 350327.93750	
9795	 steps: training loss - 122900.37500	, testing loss - 350025.34375	
9796	 steps: training loss - 106830.23438	, testing loss - 350989.28125	
9797	 steps: training loss - 113343.78906	, testing loss - 352757.46875	
9798	 steps: training loss - 97716.75781	, testing loss - 354382.50000	
9799	 steps: training loss - 105011.40625	, testing loss - 356153.28125	
9800	 steps: training loss - 118076.02344	, testing loss - 357488.65625	
9801	 steps: training loss - 122685.16406	, testing loss - 357404.18750	
9802	 steps: training loss - 121850.81250	, testing loss - 357610.78125	
9803	 steps: training loss - 118154.53906	, testing loss - 357879.78125	
9804	 steps: training loss - 100994.44531	, testing loss - 357126.34375	
9805	 steps: training loss - 107223.02344	, testing loss - 356582.18750	
9806	 steps: training loss - 115565.07812	, testing loss - 357476.50000	
9807	 steps: training loss - 89507.24219	, testing loss - 357138.21875	
9808	 steps: training loss - 95160.74219	, testing loss - 356593.53125	
9809	 steps: training loss - 101151.47656	, testing loss - 356980.65625	
9810	 steps: training loss - 91446.10156	, testing loss - 357884.75000	
9811	 steps: training loss - 123756.19531	, testing loss - 359121.21875	
9812	 steps: training loss - 140271.62500	, testing loss - 359455.50000	
9813	 steps: training loss - 77562.27344	, testing loss - 359026.31250	
9814	 steps: training loss - 114081.09375	, testing loss - 359325.15625	
9815	 steps: training loss - 93279.91406	, testing loss - 360365.06250	
9816	 steps: training loss - 95366.67969	, testing loss - 362214.12500	
9817	 steps: training loss - 134521.75000	, testing loss - 364373.65625	
9818	 steps: training loss - 128307.67188	, testing loss - 365915.31250	
9819	 steps: training loss - 129088.31250	, testing loss - 364595.25000	
9820	 steps: training loss - 104402.09375	, testing loss - 362255.28125	
9821	 steps: training loss - 108480.14062	, testing loss - 360004.12500	
9822	 steps: training loss - 82960.03906	, testing loss - 358616.34375	
9823	 steps: training loss - 118265.68750	, testing loss - 357241.78125	
9824	 steps: training loss - 126681.31250	, testing loss - 355843.03125	
9825	 steps: training loss - 128956.59375	, testing loss - 353791.40625	
9826	 steps: training loss - 119919.47656	, testing loss - 351009.03125	
9827	 steps: training loss - 99797.31250	, testing loss - 347934.18750	
9828	 steps: training loss - 102650.16406	, testing loss - 346603.37500	
9829	 steps: training loss - 95449.76562	, testing loss - 346083.00000	
9830	 steps: training loss - 119090.03125	, testing loss - 345771.75000	
9831	 steps: training loss - 113106.78906	, testing loss - 345853.37500	
9832	 steps: training loss - 121697.23438	, testing loss - 345605.78125	
9833	 steps: training loss - 101450.96875	, testing loss - 344592.00000	
9834	 steps: training loss - 99616.67188	, testing loss - 344538.15625	
9835	 steps: training loss - 118147.25000	, testing loss - 344605.90625	
9836	 steps: training loss - 106318.62500	, testing loss - 343978.15625	
9837	 steps: training loss - 107853.90625	, testing loss - 342792.06250	
9838	 steps: training loss - 130355.92188	, testing loss - 341952.75000	
9839	 steps: training loss - 132812.95312	, testing loss - 341548.31250	
9840	 steps: training loss - 122537.03906	, testing loss - 343297.46875	
9841	 steps: training loss - 96943.82812	, testing loss - 346065.59375	
9842	 steps: training loss - 103634.21875	, testing loss - 348916.87500	
9843	 steps: training loss - 115044.21875	, testing loss - 352124.84375	
9844	 steps: training loss - 95241.92188	, testing loss - 354524.93750	
9845	 steps: training loss - 107646.43750	, testing loss - 355608.37500	
9846	 steps: training loss - 105906.00000	, testing loss - 354938.12500	
9847	 steps: training loss - 107304.38281	, testing loss - 354628.96875	
9848	 steps: training loss - 137727.06250	, testing loss - 354313.59375	
9849	 steps: training loss - 117924.46875	, testing loss - 353769.40625	
9850	 steps: training loss - 110904.46094	, testing loss - 353900.25000	
9851	 steps: training loss - 109834.24219	, testing loss - 354241.09375	
9852	 steps: training loss - 114902.65625	, testing loss - 355966.93750	
9853	 steps: training loss - 106645.71094	, testing loss - 357566.53125	
9854	 steps: training loss - 111965.82812	, testing loss - 357724.09375	
9855	 steps: training loss - 127496.63281	, testing loss - 356715.84375	
9856	 steps: training loss - 129853.93750	, testing loss - 355404.50000	
9857	 steps: training loss - 103807.11719	, testing loss - 354631.87500	
9858	 steps: training loss - 122330.06250	, testing loss - 353607.93750	
9859	 steps: training loss - 122215.09375	, testing loss - 352628.00000	
9860	 steps: training loss - 85510.98438	, testing loss - 353387.40625	
9861	 steps: training loss - 115073.60938	, testing loss - 354207.09375	
9862	 steps: training loss - 104937.73438	, testing loss - 354601.87500	
9863	 steps: training loss - 112613.75781	, testing loss - 356332.84375	
9864	 steps: training loss - 113331.53125	, testing loss - 358257.65625	
9865	 steps: training loss - 104856.08594	, testing loss - 360356.59375	
9866	 steps: training loss - 130295.92969	, testing loss - 361743.03125	
9867	 steps: training loss - 95134.65625	, testing loss - 362458.00000	
9868	 steps: training loss - 94106.53906	, testing loss - 363840.53125	
9869	 steps: training loss - 109549.72656	, testing loss - 363673.75000	
9870	 steps: training loss - 97605.19531	, testing loss - 362807.68750	
9871	 steps: training loss - 103245.48438	, testing loss - 361721.06250	
9872	 steps: training loss - 109879.35938	, testing loss - 360801.78125	
9873	 steps: training loss - 116464.45312	, testing loss - 361483.93750	
9874	 steps: training loss - 108159.37500	, testing loss - 361531.62500	
9875	 steps: training loss - 132089.00000	, testing loss - 361228.03125	
9876	 steps: training loss - 108900.81250	, testing loss - 360797.37500	
9877	 steps: training loss - 92437.82031	, testing loss - 359965.46875	
9878	 steps: training loss - 109770.63281	, testing loss - 359254.37500	
9879	 steps: training loss - 101689.85938	, testing loss - 358016.34375	
9880	 steps: training loss - 115827.26562	, testing loss - 357131.34375	
9881	 steps: training loss - 100721.54688	, testing loss - 356314.21875	
9882	 steps: training loss - 91245.59375	, testing loss - 355791.37500	
9883	 steps: training loss - 106170.42969	, testing loss - 355230.46875	
9884	 steps: training loss - 102550.08594	, testing loss - 354792.71875	
9885	 steps: training loss - 106186.75000	, testing loss - 355484.75000	
9886	 steps: training loss - 99543.52344	, testing loss - 356624.15625	
9887	 steps: training loss - 91171.71094	, testing loss - 358279.31250	
9888	 steps: training loss - 118743.53906	, testing loss - 360076.59375	
9889	 steps: training loss - 129013.90625	, testing loss - 361377.56250	
9890	 steps: training loss - 106798.07812	, testing loss - 362811.12500	
9891	 steps: training loss - 110068.83594	, testing loss - 362985.65625	
9892	 steps: training loss - 116096.11719	, testing loss - 363355.78125	
9893	 steps: training loss - 115777.04688	, testing loss - 363855.62500	
9894	 steps: training loss - 108763.75000	, testing loss - 364248.06250	
9895	 steps: training loss - 99487.16406	, testing loss - 364946.40625	
9896	 steps: training loss - 86434.68750	, testing loss - 365273.75000	
9897	 steps: training loss - 102577.25781	, testing loss - 365494.43750	
9898	 steps: training loss - 104520.80469	, testing loss - 364946.84375	
9899	 steps: training loss - 114605.35938	, testing loss - 364461.90625	
9900	 steps: training loss - 98380.24219	, testing loss - 364712.06250	
9901	 steps: training loss - 104089.21094	, testing loss - 364746.78125	
9902	 steps: training loss - 110423.09375	, testing loss - 364887.56250	
9903	 steps: training loss - 97373.30469	, testing loss - 364133.46875	
9904	 steps: training loss - 112234.00781	, testing loss - 363052.93750	
9905	 steps: training loss - 108401.34375	, testing loss - 361217.00000	
9906	 steps: training loss - 110532.33594	, testing loss - 359228.25000	
9907	 steps: training loss - 107477.48438	, testing loss - 356705.81250	
9908	 steps: training loss - 111748.08594	, testing loss - 353504.87500	
9909	 steps: training loss - 98164.67969	, testing loss - 350608.46875	
9910	 steps: training loss - 115358.82812	, testing loss - 348256.93750	
9911	 steps: training loss - 88049.00781	, testing loss - 346288.31250	
9912	 steps: training loss - 127011.78125	, testing loss - 344782.62500	
9913	 steps: training loss - 118268.85938	, testing loss - 343228.28125	
9914	 steps: training loss - 90986.74219	, testing loss - 342829.34375	
9915	 steps: training loss - 78889.78125	, testing loss - 342647.12500	
9916	 steps: training loss - 110283.19531	, testing loss - 342671.93750	
9917	 steps: training loss - 98401.68750	, testing loss - 343025.59375	
9918	 steps: training loss - 108678.04688	, testing loss - 343226.65625	
9919	 steps: training loss - 113430.57812	, testing loss - 343086.90625	
9920	 steps: training loss - 118520.84375	, testing loss - 342551.96875	
9921	 steps: training loss - 92682.26562	, testing loss - 342160.53125	
9922	 steps: training loss - 142292.64062	, testing loss - 341784.62500	
9923	 steps: training loss - 81159.78906	, testing loss - 341631.96875	
9924	 steps: training loss - 112313.66406	, testing loss - 341561.71875	
9925	 steps: training loss - 96791.39844	, testing loss - 342025.84375	
9926	 steps: training loss - 97207.53906	, testing loss - 342493.87500	
9927	 steps: training loss - 125417.28125	, testing loss - 342634.78125	
9928	 steps: training loss - 124051.75781	, testing loss - 342524.96875	
9929	 steps: training loss - 89230.17969	, testing loss - 342499.43750	
9930	 steps: training loss - 128032.46094	, testing loss - 342491.31250	
9931	 steps: training loss - 121404.68750	, testing loss - 343048.43750	
9932	 steps: training loss - 112871.70312	, testing loss - 343424.15625	
9933	 steps: training loss - 117387.25781	, testing loss - 343500.25000	
9934	 steps: training loss - 129292.78906	, testing loss - 343543.84375	
9935	 steps: training loss - 83772.23438	, testing loss - 344590.06250	
9936	 steps: training loss - 112408.72656	, testing loss - 345666.56250	
9937	 steps: training loss - 114231.82812	, testing loss - 345923.81250	
9938	 steps: training loss - 103661.51562	, testing loss - 346622.21875	
9939	 steps: training loss - 110688.99219	, testing loss - 346938.90625	
9940	 steps: training loss - 119667.65625	, testing loss - 346945.25000	
9941	 steps: training loss - 111852.91406	, testing loss - 347447.93750	
9942	 steps: training loss - 108015.95312	, testing loss - 348547.81250	
9943	 steps: training loss - 102277.91406	, testing loss - 349156.43750	
9944	 steps: training loss - 96424.33594	, testing loss - 350110.90625	
9945	 steps: training loss - 127661.53906	, testing loss - 350591.81250	
9946	 steps: training loss - 122339.04688	, testing loss - 350443.62500	
9947	 steps: training loss - 108813.55469	, testing loss - 349282.37500	
9948	 steps: training loss - 124100.58594	, testing loss - 348163.81250	
9949	 steps: training loss - 107791.92188	, testing loss - 347287.65625	
9950	 steps: training loss - 116135.84375	, testing loss - 346408.93750	
9951	 steps: training loss - 99021.65625	, testing loss - 345711.25000	
9952	 steps: training loss - 98784.79688	, testing loss - 344750.15625	
9953	 steps: training loss - 111383.16406	, testing loss - 343661.34375	
9954	 steps: training loss - 99020.20312	, testing loss - 342960.81250	
9955	 steps: training loss - 122369.39062	, testing loss - 342880.96875	
9956	 steps: training loss - 81011.21094	, testing loss - 342564.84375	
9957	 steps: training loss - 81224.67969	, testing loss - 342389.65625	
9958	 steps: training loss - 96251.21875	, testing loss - 342271.06250	
9959	 steps: training loss - 99998.45312	, testing loss - 342535.15625	
9960	 steps: training loss - 94552.80469	, testing loss - 342994.03125	
9961	 steps: training loss - 108163.46094	, testing loss - 343864.53125	
9962	 steps: training loss - 110841.36719	, testing loss - 345010.75000	
9963	 steps: training loss - 115217.29688	, testing loss - 346918.81250	
9964	 steps: training loss - 108536.38281	, testing loss - 349042.46875	
9965	 steps: training loss - 124671.10156	, testing loss - 351327.43750	
9966	 steps: training loss - 99207.05469	, testing loss - 352767.71875	
9967	 steps: training loss - 115171.73438	, testing loss - 352759.53125	
9968	 steps: training loss - 106953.25000	, testing loss - 352497.43750	
9969	 steps: training loss - 81770.96094	, testing loss - 351994.40625	
9970	 steps: training loss - 111463.73438	, testing loss - 351231.93750	
9971	 steps: training loss - 104390.42188	, testing loss - 350801.93750	
9972	 steps: training loss - 138694.70312	, testing loss - 351079.18750	
9973	 steps: training loss - 118927.12500	, testing loss - 351588.87500	
9974	 steps: training loss - 144723.59375	, testing loss - 352684.34375	
9975	 steps: training loss - 108301.33594	, testing loss - 353728.21875	
9976	 steps: training loss - 106642.66406	, testing loss - 353857.71875	
9977	 steps: training loss - 101139.20312	, testing loss - 353310.56250	
9978	 steps: training loss - 108716.53906	, testing loss - 352267.15625	
9979	 steps: training loss - 111269.49219	, testing loss - 350961.93750	
9980	 steps: training loss - 108569.78906	, testing loss - 349774.31250	
9981	 steps: training loss - 90567.05469	, testing loss - 348581.53125	
9982	 steps: training loss - 108882.71875	, testing loss - 347369.06250	
9983	 steps: training loss - 112635.77344	, testing loss - 346965.06250	
9984	 steps: training loss - 108786.92188	, testing loss - 347135.31250	
9985	 steps: training loss - 117083.62500	, testing loss - 346769.00000	
9986	 steps: training loss - 99548.45312	, testing loss - 346538.28125	
9987	 steps: training loss - 102349.03125	, testing loss - 346114.31250	
9988	 steps: training loss - 121327.17969	, testing loss - 345479.56250	
9989	 steps: training loss - 90252.60156	, testing loss - 344870.37500	
9990	 steps: training loss - 84291.78125	, testing loss - 344389.18750	
9991	 steps: training loss - 138618.45312	, testing loss - 343553.96875	
9992	 steps: training loss - 112700.21094	, testing loss - 342552.87500	
9993	 steps: training loss - 120161.49219	, testing loss - 341433.43750	
9994	 steps: training loss - 126685.07031	, testing loss - 340576.12500	
9995	 steps: training loss - 115102.02344	, testing loss - 341188.18750	
9996	 steps: training loss - 111793.59375	, testing loss - 342104.21875	
9997	 steps: training loss - 103157.82031	, testing loss - 343299.06250	
9998	 steps: training loss - 119175.88281	, testing loss - 345024.43750	
9999	 steps: training loss - 109631.49219	, testing loss - 346767.90625	
10000	 steps: training loss - 114641.01562	, testing loss - 347775.65625	
10001	 steps: training loss - 105863.28125	, testing loss - 348331.25000	
10002	 steps: training loss - 107779.07812	, testing loss - 349132.03125	
10003	 steps: training loss - 120654.30469	, testing loss - 350298.03125	
10004	 steps: training loss - 99999.53906	, testing loss - 350409.93750	
10005	 steps: training loss - 95365.51562	, testing loss - 350143.40625	
10006	 steps: training loss - 128107.25781	, testing loss - 350777.18750	
10007	 steps: training loss - 102215.41406	, testing loss - 351950.75000	
10008	 steps: training loss - 83511.29688	, testing loss - 352790.59375	
10009	 steps: training loss - 96776.05469	, testing loss - 353281.68750	
10010	 steps: training loss - 107062.32812	, testing loss - 354337.43750	
10011	 steps: training loss - 97465.62500	, testing loss - 355331.81250	
10012	 steps: training loss - 91846.47656	, testing loss - 355090.84375	
10013	 steps: training loss - 123735.90625	, testing loss - 354198.28125	
10014	 steps: training loss - 113881.28906	, testing loss - 353875.03125	
10015	 steps: training loss - 108812.28125	, testing loss - 354395.43750	
10016	 steps: training loss - 94934.76562	, testing loss - 354331.21875	
10017	 steps: training loss - 115707.08594	, testing loss - 353941.81250	
10018	 steps: training loss - 134059.37500	, testing loss - 353664.81250	
10019	 steps: training loss - 96794.42188	, testing loss - 352741.15625	
10020	 steps: training loss - 91981.75781	, testing loss - 351309.81250	
10021	 steps: training loss - 108068.10938	, testing loss - 349910.84375	
10022	 steps: training loss - 113550.31250	, testing loss - 348232.40625	
10023	 steps: training loss - 134588.96875	, testing loss - 347282.53125	
10024	 steps: training loss - 95407.31250	, testing loss - 346868.56250	
10025	 steps: training loss - 86397.67969	, testing loss - 346086.18750	
10026	 steps: training loss - 95071.42969	, testing loss - 345119.75000	
10027	 steps: training loss - 102944.14844	, testing loss - 344994.09375	
10028	 steps: training loss - 101760.50000	, testing loss - 345160.56250	
10029	 steps: training loss - 116160.39844	, testing loss - 345574.71875	
10030	 steps: training loss - 120717.77344	, testing loss - 346195.25000	
10031	 steps: training loss - 93754.47656	, testing loss - 347204.28125	
10032	 steps: training loss - 104739.20312	, testing loss - 347961.18750	
10033	 steps: training loss - 115112.25781	, testing loss - 348558.81250	
10034	 steps: training loss - 122685.13281	, testing loss - 350565.84375	
10035	 steps: training loss - 117699.50000	, testing loss - 352800.68750	
10036	 steps: training loss - 89142.87500	, testing loss - 354606.00000	
10037	 steps: training loss - 120868.09375	, testing loss - 356140.75000	
10038	 steps: training loss - 85284.20312	, testing loss - 356299.09375	
10039	 steps: training loss - 109037.49219	, testing loss - 356302.09375	
10040	 steps: training loss - 126190.84375	, testing loss - 354881.15625	
10041	 steps: training loss - 126286.49219	, testing loss - 353108.31250	
10042	 steps: training loss - 92538.71875	, testing loss - 350810.43750	
10043	 steps: training loss - 101838.59375	, testing loss - 348745.15625	
10044	 steps: training loss - 113458.46094	, testing loss - 346973.37500	
10045	 steps: training loss - 108150.89062	, testing loss - 345619.59375	
10046	 steps: training loss - 106724.14062	, testing loss - 344599.53125	
10047	 steps: training loss - 105278.45312	, testing loss - 343509.84375	
10048	 steps: training loss - 109020.86719	, testing loss - 343631.28125	
10049	 steps: training loss - 94643.25000	, testing loss - 344963.15625	
10050	 steps: training loss - 88311.56250	, testing loss - 346416.34375	
10051	 steps: training loss - 119739.34375	, testing loss - 348454.34375	
10052	 steps: training loss - 116486.23438	, testing loss - 350320.40625	
10053	 steps: training loss - 137027.43750	, testing loss - 351616.96875	
10054	 steps: training loss - 123662.18750	, testing loss - 352129.84375	
10055	 steps: training loss - 124705.43750	, testing loss - 352683.65625	
10056	 steps: training loss - 113158.48438	, testing loss - 354693.43750	
10057	 steps: training loss - 92563.00781	, testing loss - 357829.31250	
10058	 steps: training loss - 118398.05469	, testing loss - 360172.96875	
10059	 steps: training loss - 106094.71094	, testing loss - 361006.78125	
10060	 steps: training loss - 95387.96094	, testing loss - 361025.81250	
10061	 steps: training loss - 89798.89844	, testing loss - 360255.59375	
10062	 steps: training loss - 96373.85938	, testing loss - 359088.03125	
10063	 steps: training loss - 124176.89062	, testing loss - 356775.81250	
10064	 steps: training loss - 113259.48438	, testing loss - 354947.62500	
10065	 steps: training loss - 110849.42969	, testing loss - 353817.84375	
10066	 steps: training loss - 101584.61719	, testing loss - 354032.28125	
10067	 steps: training loss - 113197.98438	, testing loss - 354228.81250	
10068	 steps: training loss - 110517.25000	, testing loss - 353527.46875	
10069	 steps: training loss - 123209.85938	, testing loss - 352448.46875	
10070	 steps: training loss - 131092.71875	, testing loss - 352863.62500	
10071	 steps: training loss - 114636.14062	, testing loss - 353102.34375	
10072	 steps: training loss - 108692.25000	, testing loss - 351963.43750	
10073	 steps: training loss - 120629.55469	, testing loss - 350293.87500	
10074	 steps: training loss - 97979.09375	, testing loss - 348901.78125	
10075	 steps: training loss - 93023.42969	, testing loss - 348033.71875	
10076	 steps: training loss - 84627.81250	, testing loss - 347506.43750	
10077	 steps: training loss - 124631.21875	, testing loss - 347508.34375	
10078	 steps: training loss - 94791.95312	, testing loss - 347860.65625	
10079	 steps: training loss - 97332.25781	, testing loss - 348559.56250	
10080	 steps: training loss - 102699.82812	, testing loss - 349104.96875	
10081	 steps: training loss - 99415.73438	, testing loss - 349744.71875	
10082	 steps: training loss - 92997.13281	, testing loss - 350495.46875	
10083	 steps: training loss - 109710.75000	, testing loss - 351317.31250	
10084	 steps: training loss - 108843.02344	, testing loss - 353142.15625	
10085	 steps: training loss - 113347.47656	, testing loss - 354469.12500	
10086	 steps: training loss - 124002.36719	, testing loss - 354946.15625	
10087	 steps: training loss - 90458.72656	, testing loss - 356380.40625	
10088	 steps: training loss - 122036.92969	, testing loss - 358325.75000	
10089	 steps: training loss - 101135.91406	, testing loss - 360856.62500	
10090	 steps: training loss - 98927.76562	, testing loss - 362983.40625	
10091	 steps: training loss - 92891.70312	, testing loss - 362625.43750	
10092	 steps: training loss - 110553.05469	, testing loss - 362069.75000	
10093	 steps: training loss - 111338.19531	, testing loss - 359501.37500	
10094	 steps: training loss - 105109.86719	, testing loss - 355915.28125	
10095	 steps: training loss - 108434.88281	, testing loss - 353908.37500	
10096	 steps: training loss - 100385.56250	, testing loss - 353550.78125	
10097	 steps: training loss - 125198.12500	, testing loss - 353179.81250	
10098	 steps: training loss - 117779.42188	, testing loss - 352078.59375	
10099	 steps: training loss - 121726.97656	, testing loss - 350200.56250	
10100	 steps: training loss - 86449.85156	, testing loss - 347921.56250	
10101	 steps: training loss - 116170.35938	, testing loss - 345633.96875	
10102	 steps: training loss - 106828.29688	, testing loss - 344711.78125	
10103	 steps: training loss - 105433.10938	, testing loss - 344346.00000	
10104	 steps: training loss - 79831.04688	, testing loss - 343810.81250	
10105	 steps: training loss - 111444.38281	, testing loss - 343242.84375	
10106	 steps: training loss - 116951.23438	, testing loss - 342298.18750	
10107	 steps: training loss - 111755.72656	, testing loss - 341982.37500	
10108	 steps: training loss - 121338.21094	, testing loss - 342065.28125	
10109	 steps: training loss - 106080.95312	, testing loss - 342896.65625	
10110	 steps: training loss - 128514.64062	, testing loss - 343998.62500	
10111	 steps: training loss - 88443.17969	, testing loss - 345744.87500	
10112	 steps: training loss - 109760.10938	, testing loss - 348048.46875	
10113	 steps: training loss - 103458.31250	, testing loss - 350259.06250	
10114	 steps: training loss - 108024.04688	, testing loss - 352950.59375	
10115	 steps: training loss - 104655.62500	, testing loss - 356253.71875	
10116	 steps: training loss - 100284.24219	, testing loss - 358856.06250	
10117	 steps: training loss - 123286.78906	, testing loss - 360641.87500	
10118	 steps: training loss - 88736.90625	, testing loss - 361791.78125	
10119	 steps: training loss - 116018.36719	, testing loss - 362735.34375	
10120	 steps: training loss - 136579.17188	, testing loss - 362933.96875	
10121	 steps: training loss - 95843.40625	, testing loss - 362144.03125	
10122	 steps: training loss - 97022.52344	, testing loss - 360441.65625	
10123	 steps: training loss - 148834.28125	, testing loss - 358188.87500	
10124	 steps: training loss - 100468.28125	, testing loss - 355803.65625	
10125	 steps: training loss - 108924.23438	, testing loss - 353569.96875	
10126	 steps: training loss - 100184.89062	, testing loss - 351597.06250	
10127	 steps: training loss - 96449.17188	, testing loss - 349733.31250	
10128	 steps: training loss - 101142.35156	, testing loss - 347964.06250	
10129	 steps: training loss - 111005.98438	, testing loss - 346742.06250	
10130	 steps: training loss - 126390.75000	, testing loss - 346247.56250	
10131	 steps: training loss - 126538.77344	, testing loss - 347123.81250	
10132	 steps: training loss - 107427.13281	, testing loss - 348578.93750	
10133	 steps: training loss - 102547.72656	, testing loss - 350155.59375	
10134	 steps: training loss - 141050.26562	, testing loss - 352528.59375	
10135	 steps: training loss - 98096.16406	, testing loss - 354458.50000	
10136	 steps: training loss - 113160.97656	, testing loss - 356010.46875	
10137	 steps: training loss - 117335.07812	, testing loss - 356277.43750	
10138	 steps: training loss - 95742.82031	, testing loss - 356197.21875	
10139	 steps: training loss - 101938.03906	, testing loss - 355481.25000	
10140	 steps: training loss - 86889.02344	, testing loss - 354185.87500	
10141	 steps: training loss - 88755.71875	, testing loss - 352634.84375	
10142	 steps: training loss - 82093.64062	, testing loss - 350730.40625	
10143	 steps: training loss - 88575.33594	, testing loss - 349666.68750	
10144	 steps: training loss - 100591.67188	, testing loss - 349066.34375	
10145	 steps: training loss - 111136.45312	, testing loss - 349158.65625	
10146	 steps: training loss - 100901.65625	, testing loss - 349230.06250	
10147	 steps: training loss - 100801.82031	, testing loss - 350370.28125	
10148	 steps: training loss - 117577.35938	, testing loss - 352461.21875	
10149	 steps: training loss - 93275.10938	, testing loss - 354009.59375	
10150	 steps: training loss - 125654.63281	, testing loss - 355092.96875	
10151	 steps: training loss - 107156.42188	, testing loss - 356510.81250	
10152	 steps: training loss - 106898.46875	, testing loss - 358547.00000	
10153	 steps: training loss - 113900.59375	, testing loss - 360046.68750	
10154	 steps: training loss - 114723.75781	, testing loss - 360775.31250	
10155	 steps: training loss - 103892.23438	, testing loss - 360776.75000	
10156	 steps: training loss - 121022.14844	, testing loss - 359333.90625	
10157	 steps: training loss - 133150.96875	, testing loss - 356454.50000	
10158	 steps: training loss - 90108.86719	, testing loss - 353438.34375	
10159	 steps: training loss - 111100.52344	, testing loss - 351681.65625	
10160	 steps: training loss - 98469.98438	, testing loss - 350369.75000	
10161	 steps: training loss - 95836.72656	, testing loss - 350131.62500	
10162	 steps: training loss - 110239.77344	, testing loss - 351131.87500	
10163	 steps: training loss - 108012.50000	, testing loss - 351793.93750	
10164	 steps: training loss - 106261.10156	, testing loss - 351924.75000	
10165	 steps: training loss - 126128.64062	, testing loss - 352170.75000	
10166	 steps: training loss - 117016.42969	, testing loss - 353237.43750	
10167	 steps: training loss - 115270.32031	, testing loss - 354286.93750	
10168	 steps: training loss - 109639.23438	, testing loss - 355580.31250	
10169	 steps: training loss - 107695.32031	, testing loss - 356873.62500	
10170	 steps: training loss - 111799.32031	, testing loss - 357587.84375	
10171	 steps: training loss - 110575.89844	, testing loss - 358629.59375	
10172	 steps: training loss - 123087.17188	, testing loss - 360085.03125	
10173	 steps: training loss - 139838.75000	, testing loss - 360944.50000	
10174	 steps: training loss - 125418.65625	, testing loss - 360586.90625	
10175	 steps: training loss - 108955.21875	, testing loss - 359208.28125	
10176	 steps: training loss - 114320.71094	, testing loss - 357405.56250	
10177	 steps: training loss - 99034.60938	, testing loss - 356776.25000	
10178	 steps: training loss - 111557.08594	, testing loss - 355381.15625	
10179	 steps: training loss - 113113.32031	, testing loss - 353123.03125	
10180	 steps: training loss - 92605.42188	, testing loss - 351203.90625	
10181	 steps: training loss - 93733.71875	, testing loss - 349679.59375	
10182	 steps: training loss - 115986.42188	, testing loss - 348087.81250	
10183	 steps: training loss - 82883.92188	, testing loss - 347323.43750	
10184	 steps: training loss - 122713.74219	, testing loss - 346800.12500	
10185	 steps: training loss - 106598.95312	, testing loss - 345723.71875	
10186	 steps: training loss - 135268.12500	, testing loss - 345174.09375	
10187	 steps: training loss - 119811.56250	, testing loss - 345234.68750	
10188	 steps: training loss - 100978.08594	, testing loss - 344887.28125	
10189	 steps: training loss - 126968.54688	, testing loss - 345324.59375	
10190	 steps: training loss - 100357.42188	, testing loss - 347104.40625	
10191	 steps: training loss - 92389.02344	, testing loss - 349704.56250	
10192	 steps: training loss - 101250.58594	, testing loss - 352268.81250	
10193	 steps: training loss - 122942.59375	, testing loss - 353606.15625	
10194	 steps: training loss - 106889.25000	, testing loss - 355195.12500	
10195	 steps: training loss - 107779.17188	, testing loss - 356066.03125	
10196	 steps: training loss - 100403.25000	, testing loss - 355401.15625	
10197	 steps: training loss - 94167.89844	, testing loss - 354187.03125	
10198	 steps: training loss - 119604.10156	, testing loss - 353219.03125	
10199	 steps: training loss - 107178.53906	, testing loss - 352608.37500	
10200	 steps: training loss - 108464.37500	, testing loss - 352709.37500	
10201	 steps: training loss - 110392.62500	, testing loss - 353159.46875	
10202	 steps: training loss - 125485.25000	, testing loss - 353523.43750	
10203	 steps: training loss - 95664.17969	, testing loss - 353694.21875	
10204	 steps: training loss - 120433.50781	, testing loss - 354047.18750	
10205	 steps: training loss - 99132.17969	, testing loss - 355137.84375	
10206	 steps: training loss - 114767.18750	, testing loss - 356109.93750	
10207	 steps: training loss - 111232.80469	, testing loss - 356333.65625	
10208	 steps: training loss - 117974.37500	, testing loss - 356667.65625	
10209	 steps: training loss - 121383.57031	, testing loss - 357031.12500	
10210	 steps: training loss - 127529.47656	, testing loss - 356241.87500	
10211	 steps: training loss - 108671.32812	, testing loss - 355499.53125	
10212	 steps: training loss - 125551.32812	, testing loss - 354222.90625	
10213	 steps: training loss - 85883.76562	, testing loss - 353536.21875	
10214	 steps: training loss - 126381.10938	, testing loss - 353348.78125	
10215	 steps: training loss - 92828.35938	, testing loss - 353328.62500	
10216	 steps: training loss - 106989.60938	, testing loss - 352567.78125	
10217	 steps: training loss - 112214.28906	, testing loss - 351633.65625	
10218	 steps: training loss - 92627.75781	, testing loss - 351273.59375	
10219	 steps: training loss - 99891.54688	, testing loss - 351827.40625	
10220	 steps: training loss - 120471.82812	, testing loss - 352615.84375	
10221	 steps: training loss - 103050.50781	, testing loss - 353288.25000	
10222	 steps: training loss - 103511.62500	, testing loss - 352699.40625	
10223	 steps: training loss - 112467.03906	, testing loss - 352373.56250	
10224	 steps: training loss - 84385.51562	, testing loss - 351907.18750	
10225	 steps: training loss - 118167.74219	, testing loss - 351672.50000	
10226	 steps: training loss - 108592.90625	, testing loss - 351222.37500	
10227	 steps: training loss - 99108.88281	, testing loss - 350070.87500	
10228	 steps: training loss - 129036.12500	, testing loss - 348461.18750	
10229	 steps: training loss - 110047.63281	, testing loss - 347071.46875	
10230	 steps: training loss - 102180.77344	, testing loss - 345484.56250	
10231	 steps: training loss - 105950.56250	, testing loss - 344787.40625	
10232	 steps: training loss - 95371.29688	, testing loss - 344363.43750	
10233	 steps: training loss - 83682.33594	, testing loss - 344071.87500	
10234	 steps: training loss - 106306.76562	, testing loss - 343974.40625	
10235	 steps: training loss - 95035.31250	, testing loss - 343424.40625	
10236	 steps: training loss - 92048.96094	, testing loss - 342667.06250	
10237	 steps: training loss - 98371.45312	, testing loss - 342685.46875	
10238	 steps: training loss - 96151.40625	, testing loss - 342858.00000	
10239	 steps: training loss - 106561.58594	, testing loss - 343241.53125	
10240	 steps: training loss - 121043.57812	, testing loss - 343880.56250	
10241	 steps: training loss - 119409.94531	, testing loss - 344216.75000	
10242	 steps: training loss - 118390.44531	, testing loss - 344591.50000	
10243	 steps: training loss - 110224.57812	, testing loss - 345013.78125	
10244	 steps: training loss - 104131.82812	, testing loss - 345696.84375	
10245	 steps: training loss - 107678.46094	, testing loss - 346337.12500	
10246	 steps: training loss - 105301.67969	, testing loss - 347959.50000	
10247	 steps: training loss - 96913.20312	, testing loss - 349411.28125	
10248	 steps: training loss - 112348.65625	, testing loss - 351378.84375	
10249	 steps: training loss - 116268.36719	, testing loss - 353206.96875	
10250	 steps: training loss - 100089.76562	, testing loss - 355651.25000	
10251	 steps: training loss - 102679.40625	, testing loss - 358093.56250	
10252	 steps: training loss - 124688.46875	, testing loss - 360613.40625	
10253	 steps: training loss - 103301.38281	, testing loss - 361422.68750	
10254	 steps: training loss - 118462.03906	, testing loss - 360691.31250	
10255	 steps: training loss - 110863.39844	, testing loss - 359163.12500	
10256	 steps: training loss - 110237.92188	, testing loss - 357738.71875	
10257	 steps: training loss - 92092.53906	, testing loss - 356389.28125	
10258	 steps: training loss - 134714.39062	, testing loss - 353939.03125	
10259	 steps: training loss - 108975.44531	, testing loss - 352239.71875	
10260	 steps: training loss - 126598.56250	, testing loss - 351254.56250	
10261	 steps: training loss - 121327.66406	, testing loss - 350373.09375	
10262	 steps: training loss - 117267.25000	, testing loss - 348813.25000	
10263	 steps: training loss - 108363.57031	, testing loss - 347563.21875	
10264	 steps: training loss - 93000.50781	, testing loss - 346465.34375	
10265	 steps: training loss - 98475.82812	, testing loss - 345344.56250	
10266	 steps: training loss - 105332.79688	, testing loss - 344384.37500	
10267	 steps: training loss - 113519.60938	, testing loss - 343393.90625	
10268	 steps: training loss - 100512.57812	, testing loss - 342651.59375	
10269	 steps: training loss - 110968.96875	, testing loss - 341925.65625	
10270	 steps: training loss - 100214.85156	, testing loss - 342063.68750	
10271	 steps: training loss - 115836.66406	, testing loss - 342078.09375	
10272	 steps: training loss - 94959.51562	, testing loss - 342263.06250	
10273	 steps: training loss - 105389.86719	, testing loss - 343075.84375	
10274	 steps: training loss - 108197.15625	, testing loss - 344498.84375	
10275	 steps: training loss - 105810.93750	, testing loss - 345795.34375	
10276	 steps: training loss - 97462.61719	, testing loss - 346676.71875	
10277	 steps: training loss - 107872.53906	, testing loss - 347984.53125	
10278	 steps: training loss - 98394.79688	, testing loss - 349107.59375	
10279	 steps: training loss - 110843.25000	, testing loss - 349745.25000	
10280	 steps: training loss - 112324.29688	, testing loss - 349398.68750	
10281	 steps: training loss - 127017.50000	, testing loss - 348590.46875	
10282	 steps: training loss - 75160.57031	, testing loss - 347581.15625	
10283	 steps: training loss - 110383.96875	, testing loss - 346385.84375	
10284	 steps: training loss - 117734.12500	, testing loss - 345152.62500	
10285	 steps: training loss - 120261.00000	, testing loss - 344584.59375	
10286	 steps: training loss - 97836.82812	, testing loss - 344654.90625	
10287	 steps: training loss - 109470.25781	, testing loss - 345552.25000	
10288	 steps: training loss - 115907.77344	, testing loss - 346675.28125	
10289	 steps: training loss - 107961.34375	, testing loss - 347161.40625	
10290	 steps: training loss - 93192.16406	, testing loss - 347502.28125	
10291	 steps: training loss - 118105.36719	, testing loss - 348673.78125	
10292	 steps: training loss - 148836.54688	, testing loss - 349774.75000	
10293	 steps: training loss - 127056.10938	, testing loss - 349658.06250	
10294	 steps: training loss - 104139.96875	, testing loss - 350393.31250	
10295	 steps: training loss - 127812.14844	, testing loss - 352090.21875	
10296	 steps: training loss - 98549.20312	, testing loss - 353283.84375	
10297	 steps: training loss - 104835.06250	, testing loss - 354005.28125	
10298	 steps: training loss - 117449.62500	, testing loss - 354428.65625	
10299	 steps: training loss - 94918.20312	, testing loss - 355043.03125	
10300	 steps: training loss - 106983.83594	, testing loss - 356107.03125	
10301	 steps: training loss - 116628.37500	, testing loss - 358656.84375	
10302	 steps: training loss - 95400.65625	, testing loss - 362052.96875	
10303	 steps: training loss - 120440.96094	, testing loss - 365775.31250	
10304	 steps: training loss - 109754.96094	, testing loss - 367744.25000	
10305	 steps: training loss - 103908.41406	, testing loss - 367446.75000	
10306	 steps: training loss - 107439.03906	, testing loss - 365725.28125	
10307	 steps: training loss - 111598.19531	, testing loss - 363128.25000	
10308	 steps: training loss - 107762.89844	, testing loss - 360715.31250	
10309	 steps: training loss - 104945.10938	, testing loss - 358772.25000	
10310	 steps: training loss - 119543.56250	, testing loss - 356723.62500	
10311	 steps: training loss - 119790.28125	, testing loss - 355951.53125	
10312	 steps: training loss - 107044.27344	, testing loss - 355209.62500	
10313	 steps: training loss - 108970.17188	, testing loss - 354350.03125	
10314	 steps: training loss - 112821.03125	, testing loss - 353544.50000	
10315	 steps: training loss - 107504.32812	, testing loss - 351997.65625	
10316	 steps: training loss - 111053.21875	, testing loss - 351374.00000	
10317	 steps: training loss - 115222.79688	, testing loss - 350910.18750	
10318	 steps: training loss - 119956.01562	, testing loss - 351342.68750	
10319	 steps: training loss - 114954.55469	, testing loss - 351854.53125	
10320	 steps: training loss - 101410.81250	, testing loss - 352753.28125	
10321	 steps: training loss - 118854.12500	, testing loss - 353184.53125	
10322	 steps: training loss - 100804.77344	, testing loss - 354270.46875	
10323	 steps: training loss - 112195.29688	, testing loss - 355696.87500	
10324	 steps: training loss - 122044.60938	, testing loss - 357434.87500	
10325	 steps: training loss - 125320.12500	, testing loss - 358217.21875	
10326	 steps: training loss - 131100.90625	, testing loss - 357612.40625	
10327	 steps: training loss - 106423.15625	, testing loss - 355911.25000	
10328	 steps: training loss - 116671.79688	, testing loss - 354219.87500	
10329	 steps: training loss - 124850.18750	, testing loss - 352013.40625	
10330	 steps: training loss - 121858.89844	, testing loss - 350745.43750	
10331	 steps: training loss - 116001.96094	, testing loss - 350300.50000	
10332	 steps: training loss - 101859.83594	, testing loss - 350524.87500	
10333	 steps: training loss - 97012.60156	, testing loss - 350749.34375	
10334	 steps: training loss - 97583.50000	, testing loss - 350880.87500	
10335	 steps: training loss - 126219.57031	, testing loss - 350906.03125	
10336	 steps: training loss - 122766.04688	, testing loss - 350519.50000	
10337	 steps: training loss - 96524.78906	, testing loss - 349994.25000	
10338	 steps: training loss - 118674.53906	, testing loss - 349826.28125	
10339	 steps: training loss - 140932.60938	, testing loss - 350545.40625	
10340	 steps: training loss - 85190.21094	, testing loss - 351393.62500	
10341	 steps: training loss - 91394.17188	, testing loss - 351958.71875	
10342	 steps: training loss - 82614.07812	, testing loss - 352378.15625	
10343	 steps: training loss - 121544.15625	, testing loss - 352368.78125	
10344	 steps: training loss - 103047.13281	, testing loss - 352811.34375	
10345	 steps: training loss - 102828.37500	, testing loss - 353332.68750	
10346	 steps: training loss - 124400.49219	, testing loss - 353815.93750	
10347	 steps: training loss - 103955.06250	, testing loss - 352814.93750	
10348	 steps: training loss - 119324.83594	, testing loss - 350625.90625	
10349	 steps: training loss - 117533.16406	, testing loss - 349093.18750	
10350	 steps: training loss - 105894.00000	, testing loss - 347555.43750	
10351	 steps: training loss - 100322.89062	, testing loss - 346031.84375	
10352	 steps: training loss - 120888.74219	, testing loss - 344985.25000	
10353	 steps: training loss - 96907.02344	, testing loss - 344125.06250	
10354	 steps: training loss - 119098.97656	, testing loss - 343304.34375	
10355	 steps: training loss - 132580.75000	, testing loss - 342855.09375	
10356	 steps: training loss - 104257.69531	, testing loss - 342632.40625	
10357	 steps: training loss - 112823.85156	, testing loss - 342630.65625	
10358	 steps: training loss - 109632.26562	, testing loss - 342931.56250	
10359	 steps: training loss - 95569.10938	, testing loss - 342955.96875	
10360	 steps: training loss - 101719.41406	, testing loss - 342868.03125	
10361	 steps: training loss - 76631.03906	, testing loss - 343300.31250	
10362	 steps: training loss - 102470.40625	, testing loss - 343501.09375	
10363	 steps: training loss - 115323.89062	, testing loss - 342936.96875	
10364	 steps: training loss - 87382.02344	, testing loss - 343007.75000	
10365	 steps: training loss - 115272.09375	, testing loss - 343060.15625	
10366	 steps: training loss - 92930.51562	, testing loss - 343585.71875	
10367	 steps: training loss - 100377.67969	, testing loss - 345610.96875	
10368	 steps: training loss - 100788.67188	, testing loss - 348311.84375	
10369	 steps: training loss - 147786.57812	, testing loss - 351313.25000	
10370	 steps: training loss - 112035.65625	, testing loss - 354507.87500	
10371	 steps: training loss - 103846.91406	, testing loss - 357746.18750	
10372	 steps: training loss - 106891.07031	, testing loss - 359999.53125	
10373	 steps: training loss - 92392.14844	, testing loss - 360947.46875	
10374	 steps: training loss - 121785.45312	, testing loss - 361801.50000	
10375	 steps: training loss - 98206.36719	, testing loss - 360624.93750	
10376	 steps: training loss - 81445.64062	, testing loss - 357989.15625	
10377	 steps: training loss - 101728.61719	, testing loss - 355650.50000	
10378	 steps: training loss - 105734.60938	, testing loss - 353875.40625	
10379	 steps: training loss - 120820.80469	, testing loss - 352679.03125	
10380	 steps: training loss - 109658.92969	, testing loss - 352930.06250	
10381	 steps: training loss - 95328.47656	, testing loss - 352461.00000	
10382	 steps: training loss - 130993.28906	, testing loss - 351897.31250	
10383	 steps: training loss - 120620.82031	, testing loss - 350818.56250	
10384	 steps: training loss - 117245.38281	, testing loss - 349634.06250	
10385	 steps: training loss - 92344.61719	, testing loss - 349263.50000	
10386	 steps: training loss - 90233.49219	, testing loss - 348582.78125	
10387	 steps: training loss - 120810.32031	, testing loss - 347935.03125	
10388	 steps: training loss - 101113.24219	, testing loss - 347378.28125	
10389	 steps: training loss - 131317.85938	, testing loss - 347182.06250	
10390	 steps: training loss - 121261.91406	, testing loss - 347185.81250	
10391	 steps: training loss - 117832.72656	, testing loss - 347108.96875	
10392	 steps: training loss - 134390.15625	, testing loss - 347304.84375	
10393	 steps: training loss - 102522.11719	, testing loss - 347640.18750	
10394	 steps: training loss - 103898.58594	, testing loss - 348669.18750	
10395	 steps: training loss - 105133.72656	, testing loss - 350486.00000	
10396	 steps: training loss - 84317.82031	, testing loss - 351867.15625	
10397	 steps: training loss - 109143.96094	, testing loss - 353197.28125	
10398	 steps: training loss - 125971.65625	, testing loss - 354223.50000	
10399	 steps: training loss - 114150.00781	, testing loss - 355533.31250	
10400	 steps: training loss - 111535.20312	, testing loss - 356712.25000	
10401	 steps: training loss - 110164.42188	, testing loss - 357444.31250	
10402	 steps: training loss - 124424.50781	, testing loss - 357206.78125	
10403	 steps: training loss - 118961.25000	, testing loss - 356566.00000	
10404	 steps: training loss - 118840.63281	, testing loss - 355754.93750	
10405	 steps: training loss - 103714.39062	, testing loss - 355354.09375	
10406	 steps: training loss - 118080.85938	, testing loss - 355167.21875	
10407	 steps: training loss - 110504.00000	, testing loss - 354992.81250	
10408	 steps: training loss - 118993.39844	, testing loss - 355098.18750	
10409	 steps: training loss - 101950.72656	, testing loss - 354807.25000	
10410	 steps: training loss - 97195.20312	, testing loss - 354304.50000	
10411	 steps: training loss - 107705.78125	, testing loss - 353423.43750	
10412	 steps: training loss - 130610.81250	, testing loss - 351653.78125	
10413	 steps: training loss - 106860.56250	, testing loss - 350122.71875	
10414	 steps: training loss - 118065.05469	, testing loss - 349818.68750	
10415	 steps: training loss - 116581.70312	, testing loss - 349293.15625	
10416	 steps: training loss - 113507.15625	, testing loss - 348634.59375	
10417	 steps: training loss - 117271.04688	, testing loss - 347845.00000	
10418	 steps: training loss - 108341.39062	, testing loss - 347577.43750	
10419	 steps: training loss - 112552.41406	, testing loss - 347464.09375	
10420	 steps: training loss - 118609.83594	, testing loss - 346865.62500	
10421	 steps: training loss - 84993.13281	, testing loss - 345543.56250	
10422	 steps: training loss - 128987.12500	, testing loss - 344271.31250	
10423	 steps: training loss - 114679.24219	, testing loss - 343676.31250	
10424	 steps: training loss - 102943.84375	, testing loss - 343186.18750	
10425	 steps: training loss - 118447.96094	, testing loss - 343145.25000	
10426	 steps: training loss - 113936.09375	, testing loss - 343181.71875	
10427	 steps: training loss - 114259.57812	, testing loss - 342862.71875	
10428	 steps: training loss - 97532.35938	, testing loss - 343369.78125	
10429	 steps: training loss - 93719.75000	, testing loss - 344138.96875	
10430	 steps: training loss - 123887.60156	, testing loss - 345247.78125	
10431	 steps: training loss - 110225.71094	, testing loss - 345992.12500	
10432	 steps: training loss - 103042.21094	, testing loss - 346528.75000	
10433	 steps: training loss - 142697.20312	, testing loss - 346592.34375	
10434	 steps: training loss - 92508.62500	, testing loss - 346173.75000	
10435	 steps: training loss - 96846.99219	, testing loss - 345135.90625	
10436	 steps: training loss - 105007.29688	, testing loss - 344364.96875	
10437	 steps: training loss - 102431.51562	, testing loss - 343989.18750	
10438	 steps: training loss - 127468.35156	, testing loss - 344206.81250	
10439	 steps: training loss - 128020.76562	, testing loss - 344596.78125	
10440	 steps: training loss - 121375.64844	, testing loss - 345087.12500	
10441	 steps: training loss - 101049.71094	, testing loss - 345375.43750	
10442	 steps: training loss - 122036.50781	, testing loss - 346297.21875	
10443	 steps: training loss - 127856.42188	, testing loss - 348123.21875	
10444	 steps: training loss - 94682.32812	, testing loss - 349093.40625	
10445	 steps: training loss - 110462.39844	, testing loss - 348836.25000	
10446	 steps: training loss - 99723.37500	, testing loss - 347980.71875	
10447	 steps: training loss - 113039.78125	, testing loss - 347366.78125	
10448	 steps: training loss - 108917.95312	, testing loss - 346840.56250	
10449	 steps: training loss - 109056.57812	, testing loss - 346219.46875	
10450	 steps: training loss - 110644.25000	, testing loss - 346334.71875	
10451	 steps: training loss - 118773.97656	, testing loss - 346911.03125	
10452	 steps: training loss - 81654.65625	, testing loss - 348260.68750	
10453	 steps: training loss - 134498.32812	, testing loss - 348974.93750	
10454	 steps: training loss - 121660.26562	, testing loss - 349183.03125	
10455	 steps: training loss - 103678.63281	, testing loss - 349739.56250	
10456	 steps: training loss - 95379.60938	, testing loss - 350527.87500	
10457	 steps: training loss - 115337.24219	, testing loss - 350682.25000	
10458	 steps: training loss - 120969.03125	, testing loss - 350441.18750	
10459	 steps: training loss - 110766.58594	, testing loss - 350011.28125	
10460	 steps: training loss - 109759.87500	, testing loss - 349993.43750	
10461	 steps: training loss - 102013.99219	, testing loss - 349713.56250	
10462	 steps: training loss - 88754.39062	, testing loss - 349487.46875	
10463	 steps: training loss - 111749.42969	, testing loss - 349273.21875	
10464	 steps: training loss - 112874.39062	, testing loss - 348581.56250	
10465	 steps: training loss - 124226.53906	, testing loss - 347575.96875	
10466	 steps: training loss - 101048.70312	, testing loss - 345959.18750	
10467	 steps: training loss - 99110.21094	, testing loss - 344054.06250	
10468	 steps: training loss - 103474.07812	, testing loss - 342252.31250	
10469	 steps: training loss - 120078.41406	, testing loss - 340706.43750	
10470	 steps: training loss - 95465.06250	, testing loss - 339913.81250	
10471	 steps: training loss - 129659.28906	, testing loss - 339384.28125	
10472	 steps: training loss - 128383.93750	, testing loss - 339375.71875	
10473	 steps: training loss - 108878.08594	, testing loss - 339149.56250	
10474	 steps: training loss - 125871.75781	, testing loss - 338839.62500	
10475	 steps: training loss - 103987.94531	, testing loss - 337900.34375	
10476	 steps: training loss - 103364.67969	, testing loss - 337764.93750	
10477	 steps: training loss - 99097.32031	, testing loss - 338386.21875	
10478	 steps: training loss - 98224.03125	, testing loss - 338910.09375	
10479	 steps: training loss - 117522.27344	, testing loss - 339440.93750	
10480	 steps: training loss - 109819.25781	, testing loss - 340785.09375	
10481	 steps: training loss - 103601.53906	, testing loss - 341655.62500	
10482	 steps: training loss - 109738.34375	, testing loss - 341969.84375	
10483	 steps: training loss - 125799.60938	, testing loss - 342715.81250	
10484	 steps: training loss - 128750.37500	, testing loss - 344295.09375	
10485	 steps: training loss - 117391.39844	, testing loss - 346438.62500	
10486	 steps: training loss - 78631.31250	, testing loss - 347695.28125	
10487	 steps: training loss - 106581.67969	, testing loss - 347849.78125	
10488	 steps: training loss - 114189.60938	, testing loss - 348040.65625	
10489	 steps: training loss - 119494.22656	, testing loss - 348065.81250	
10490	 steps: training loss - 111332.40625	, testing loss - 347640.90625	
10491	 steps: training loss - 119368.42969	, testing loss - 347400.21875	
10492	 steps: training loss - 105239.98438	, testing loss - 348208.68750	
10493	 steps: training loss - 74903.05469	, testing loss - 348531.21875	
10494	 steps: training loss - 100205.97656	, testing loss - 348631.78125	
10495	 steps: training loss - 96495.42188	, testing loss - 347904.90625	
10496	 steps: training loss - 110623.00000	, testing loss - 347628.25000	
10497	 steps: training loss - 106050.25000	, testing loss - 348102.62500	
10498	 steps: training loss - 113951.90625	, testing loss - 349025.25000	
10499	 steps: training loss - 94934.14844	, testing loss - 350428.50000	
10500	 steps: training loss - 129204.89844	, testing loss - 352318.31250	
10501	 steps: training loss - 141050.09375	, testing loss - 354230.78125	
10502	 steps: training loss - 104418.44531	, testing loss - 354760.18750	
10503	 steps: training loss - 103839.30469	, testing loss - 355532.06250	
10504	 steps: training loss - 116410.83594	, testing loss - 356809.59375	
10505	 steps: training loss - 115370.84375	, testing loss - 357896.03125	
10506	 steps: training loss - 101780.17969	, testing loss - 358954.06250	
10507	 steps: training loss - 115904.79688	, testing loss - 359456.18750	
10508	 steps: training loss - 130326.90625	, testing loss - 359005.71875	
10509	 steps: training loss - 88846.14844	, testing loss - 356966.93750	
10510	 steps: training loss - 120124.12500	, testing loss - 354654.31250	
10511	 steps: training loss - 90661.03906	, testing loss - 352846.25000	
10512	 steps: training loss - 105775.08594	, testing loss - 352176.78125	
10513	 steps: training loss - 113691.22656	, testing loss - 351950.28125	
10514	 steps: training loss - 108272.44531	, testing loss - 350838.28125	
10515	 steps: training loss - 130049.13281	, testing loss - 349139.75000	
10516	 steps: training loss - 105615.32812	, testing loss - 347872.00000	
10517	 steps: training loss - 108143.65625	, testing loss - 347518.75000	
10518	 steps: training loss - 96453.57031	, testing loss - 347157.81250	
10519	 steps: training loss - 102554.19531	, testing loss - 347134.43750	
10520	 steps: training loss - 88309.51562	, testing loss - 347734.40625	
10521	 steps: training loss - 94935.39062	, testing loss - 347818.78125	
10522	 steps: training loss - 114757.72656	, testing loss - 347745.12500	
10523	 steps: training loss - 92003.42969	, testing loss - 348076.93750	
10524	 steps: training loss - 82647.51562	, testing loss - 349034.31250	
10525	 steps: training loss - 124804.82812	, testing loss - 349557.90625	
10526	 steps: training loss - 112109.09375	, testing loss - 350175.06250	
10527	 steps: training loss - 93484.12500	, testing loss - 349922.46875	
10528	 steps: training loss - 108788.79688	, testing loss - 349176.68750	
10529	 steps: training loss - 113494.76562	, testing loss - 348235.78125	
10530	 steps: training loss - 114115.82812	, testing loss - 347733.62500	
10531	 steps: training loss - 104291.96094	, testing loss - 347494.28125	
10532	 steps: training loss - 100417.15625	, testing loss - 347039.00000	
10533	 steps: training loss - 113884.08594	, testing loss - 347154.46875	
10534	 steps: training loss - 96575.35938	, testing loss - 347916.40625	
10535	 steps: training loss - 130339.26562	, testing loss - 348575.43750	
10536	 steps: training loss - 110349.63281	, testing loss - 348195.40625	
10537	 steps: training loss - 115394.62500	, testing loss - 347534.90625	
10538	 steps: training loss - 104742.99219	, testing loss - 347546.75000	
10539	 steps: training loss - 85803.81250	, testing loss - 347706.59375	
10540	 steps: training loss - 105168.25000	, testing loss - 347691.62500	
10541	 steps: training loss - 126797.09375	, testing loss - 348250.25000	
10542	 steps: training loss - 98462.39062	, testing loss - 348914.59375	
10543	 steps: training loss - 112975.68750	, testing loss - 349121.78125	
10544	 steps: training loss - 100229.97656	, testing loss - 349498.06250	
10545	 steps: training loss - 135133.76562	, testing loss - 349547.59375	
10546	 steps: training loss - 120544.07812	, testing loss - 348261.28125	
10547	 steps: training loss - 125373.11719	, testing loss - 346470.34375	
10548	 steps: training loss - 123992.64844	, testing loss - 345683.84375	
10549	 steps: training loss - 88364.72656	, testing loss - 345412.12500	
10550	 steps: training loss - 112581.14844	, testing loss - 345062.53125	
10551	 steps: training loss - 110556.64062	, testing loss - 345501.43750	
10552	 steps: training loss - 127959.36719	, testing loss - 346458.56250	
10553	 steps: training loss - 104724.84375	, testing loss - 347541.75000	
10554	 steps: training loss - 128114.45312	, testing loss - 349356.12500	
10555	 steps: training loss - 118319.10938	, testing loss - 350711.21875	
10556	 steps: training loss - 114563.18750	, testing loss - 351468.93750	
10557	 steps: training loss - 96424.75781	, testing loss - 351867.21875	
10558	 steps: training loss - 111271.96875	, testing loss - 352088.37500	
10559	 steps: training loss - 116349.44531	, testing loss - 352006.21875	
10560	 steps: training loss - 101672.33594	, testing loss - 351381.12500	
10561	 steps: training loss - 98855.21875	, testing loss - 350666.00000	
10562	 steps: training loss - 118219.00000	, testing loss - 350722.00000	
10563	 steps: training loss - 109189.48438	, testing loss - 350619.40625	
10564	 steps: training loss - 98005.92188	, testing loss - 351350.56250	
10565	 steps: training loss - 99481.42969	, testing loss - 352079.46875	
10566	 steps: training loss - 97675.17969	, testing loss - 352976.93750	
10567	 steps: training loss - 69944.44531	, testing loss - 353514.75000	
10568	 steps: training loss - 95827.46094	, testing loss - 353746.78125	
10569	 steps: training loss - 91205.28125	, testing loss - 353687.25000	
10570	 steps: training loss - 104456.89844	, testing loss - 354221.84375	
10571	 steps: training loss - 95332.63281	, testing loss - 355632.53125	
10572	 steps: training loss - 111722.64062	, testing loss - 356772.15625	
10573	 steps: training loss - 98669.14062	, testing loss - 357613.06250	
10574	 steps: training loss - 90191.85156	, testing loss - 357055.21875	
10575	 steps: training loss - 106630.64062	, testing loss - 355304.81250	
10576	 steps: training loss - 76125.73438	, testing loss - 353470.56250	
10577	 steps: training loss - 72390.57031	, testing loss - 351729.50000	
10578	 steps: training loss - 99383.85938	, testing loss - 350613.46875	
10579	 steps: training loss - 126260.76562	, testing loss - 349400.37500	
10580	 steps: training loss - 116754.21094	, testing loss - 348978.90625	
10581	 steps: training loss - 101509.40625	, testing loss - 348852.84375	
10582	 steps: training loss - 111492.34375	, testing loss - 348980.78125	
10583	 steps: training loss - 111725.20312	, testing loss - 348680.96875	
10584	 steps: training loss - 96574.98438	, testing loss - 349212.68750	
10585	 steps: training loss - 129699.30469	, testing loss - 349890.18750	
10586	 steps: training loss - 114339.85938	, testing loss - 350463.40625	
10587	 steps: training loss - 79696.79688	, testing loss - 351672.81250	
10588	 steps: training loss - 134164.46875	, testing loss - 353455.68750	
10589	 steps: training loss - 123454.60938	, testing loss - 353964.40625	
10590	 steps: training loss - 115182.75781	, testing loss - 352480.62500	
10591	 steps: training loss - 101612.92188	, testing loss - 351614.15625	
10592	 steps: training loss - 113474.46875	, testing loss - 351443.37500	
10593	 steps: training loss - 108451.10938	, testing loss - 352168.25000	
10594	 steps: training loss - 95338.47656	, testing loss - 353205.06250	
10595	 steps: training loss - 123090.73438	, testing loss - 353428.43750	
10596	 steps: training loss - 120337.81250	, testing loss - 353901.15625	
10597	 steps: training loss - 104166.05469	, testing loss - 354733.78125	
10598	 steps: training loss - 121957.16406	, testing loss - 355444.46875	
10599	 steps: training loss - 142695.31250	, testing loss - 356315.00000	
10600	 steps: training loss - 85073.58594	, testing loss - 358120.34375	
10601	 steps: training loss - 109934.36719	, testing loss - 360063.12500	
10602	 steps: training loss - 96954.03906	, testing loss - 360977.81250	
10603	 steps: training loss - 107274.56250	, testing loss - 360558.71875	
10604	 steps: training loss - 112891.46875	, testing loss - 358084.68750	
10605	 steps: training loss - 106696.90625	, testing loss - 354894.31250	
10606	 steps: training loss - 100851.47656	, testing loss - 352547.84375	
10607	 steps: training loss - 78298.77344	, testing loss - 350917.65625	
10608	 steps: training loss - 107177.66406	, testing loss - 348985.90625	
10609	 steps: training loss - 105597.82812	, testing loss - 348423.59375	
10610	 steps: training loss - 93190.37500	, testing loss - 348460.34375	
10611	 steps: training loss - 86555.94531	, testing loss - 349641.81250	
10612	 steps: training loss - 112938.82031	, testing loss - 350881.46875	
10613	 steps: training loss - 88252.47656	, testing loss - 352032.18750	
10614	 steps: training loss - 124946.27344	, testing loss - 352460.87500	
10615	 steps: training loss - 106389.86719	, testing loss - 352852.34375	
10616	 steps: training loss - 91735.92969	, testing loss - 352311.62500	
10617	 steps: training loss - 103498.67188	, testing loss - 350911.78125	
10618	 steps: training loss - 117824.79688	, testing loss - 349952.21875	
10619	 steps: training loss - 149500.04688	, testing loss - 349034.90625	
10620	 steps: training loss - 98809.09375	, testing loss - 347536.06250	
10621	 steps: training loss - 117685.83594	, testing loss - 347024.81250	
10622	 steps: training loss - 96429.96875	, testing loss - 346651.43750	
10623	 steps: training loss - 105142.26562	, testing loss - 345958.40625	
10624	 steps: training loss - 88787.73438	, testing loss - 345058.75000	
10625	 steps: training loss - 131147.90625	, testing loss - 344647.03125	
10626	 steps: training loss - 108177.89844	, testing loss - 344413.40625	
10627	 steps: training loss - 106006.68750	, testing loss - 344295.34375	
10628	 steps: training loss - 98867.80469	, testing loss - 344864.50000	
10629	 steps: training loss - 105138.28906	, testing loss - 346238.03125	
10630	 steps: training loss - 121052.52344	, testing loss - 347365.21875	
10631	 steps: training loss - 111274.31250	, testing loss - 348180.15625	
10632	 steps: training loss - 103462.31250	, testing loss - 348581.90625	
10633	 steps: training loss - 86315.87500	, testing loss - 349804.12500	
10634	 steps: training loss - 102648.17969	, testing loss - 350736.71875	
10635	 steps: training loss - 99236.51562	, testing loss - 351452.65625	
10636	 steps: training loss - 101706.94531	, testing loss - 352142.43750	
10637	 steps: training loss - 78151.61719	, testing loss - 353696.53125	
10638	 steps: training loss - 108253.63281	, testing loss - 355547.50000	
10639	 steps: training loss - 110752.87500	, testing loss - 356237.75000	
10640	 steps: training loss - 106324.22656	, testing loss - 355798.18750	
10641	 steps: training loss - 92624.98438	, testing loss - 356282.56250	
10642	 steps: training loss - 103586.20312	, testing loss - 357915.03125	
10643	 steps: training loss - 95424.85938	, testing loss - 359151.75000	
10644	 steps: training loss - 88652.83594	, testing loss - 359603.68750	
10645	 steps: training loss - 102568.07812	, testing loss - 359594.81250	
10646	 steps: training loss - 111718.09375	, testing loss - 358813.15625	
10647	 steps: training loss - 126093.78906	, testing loss - 358135.37500	
10648	 steps: training loss - 108190.10938	, testing loss - 357974.00000	
10649	 steps: training loss - 106897.93750	, testing loss - 357867.18750	
10650	 steps: training loss - 93426.97656	, testing loss - 357009.00000	
10651	 steps: training loss - 120294.71875	, testing loss - 355410.18750	
10652	 steps: training loss - 130025.74219	, testing loss - 353586.00000	
10653	 steps: training loss - 122693.38281	, testing loss - 351036.81250	
10654	 steps: training loss - 113253.35156	, testing loss - 349340.25000	
10655	 steps: training loss - 122371.41406	, testing loss - 348105.62500	
10656	 steps: training loss - 109342.91406	, testing loss - 347373.18750	
10657	 steps: training loss - 92571.93750	, testing loss - 347086.28125	
10658	 steps: training loss - 116056.03906	, testing loss - 347339.06250	
10659	 steps: training loss - 122714.10938	, testing loss - 346979.71875	
10660	 steps: training loss - 100276.75781	, testing loss - 346642.90625	
10661	 steps: training loss - 103252.94531	, testing loss - 346618.87500	
10662	 steps: training loss - 98781.89844	, testing loss - 345992.71875	
10663	 steps: training loss - 88215.03906	, testing loss - 345576.81250	
10664	 steps: training loss - 115157.32031	, testing loss - 345692.40625	
10665	 steps: training loss - 131207.54688	, testing loss - 346486.43750	
10666	 steps: training loss - 98503.10938	, testing loss - 346612.46875	
10667	 steps: training loss - 125197.96094	, testing loss - 347059.96875	
10668	 steps: training loss - 113081.21875	, testing loss - 347094.40625	
10669	 steps: training loss - 118161.22656	, testing loss - 345920.31250	
10670	 steps: training loss - 97982.38281	, testing loss - 345537.81250	
10671	 steps: training loss - 110639.18750	, testing loss - 344648.12500	
10672	 steps: training loss - 96163.90625	, testing loss - 343635.37500	
10673	 steps: training loss - 122487.45312	, testing loss - 342998.21875	
10674	 steps: training loss - 112117.38281	, testing loss - 342448.18750	
10675	 steps: training loss - 107306.79688	, testing loss - 342525.06250	
10676	 steps: training loss - 114626.51562	, testing loss - 343082.90625	
10677	 steps: training loss - 93890.18750	, testing loss - 344349.18750	
10678	 steps: training loss - 95855.93750	, testing loss - 346146.65625	
10679	 steps: training loss - 115536.01562	, testing loss - 348436.06250	
10680	 steps: training loss - 90413.32812	, testing loss - 350838.75000	
10681	 steps: training loss - 137426.21875	, testing loss - 352556.90625	
10682	 steps: training loss - 102991.50000	, testing loss - 351907.96875	
10683	 steps: training loss - 107968.10156	, testing loss - 351677.40625	
10684	 steps: training loss - 103971.56250	, testing loss - 351707.84375	
10685	 steps: training loss - 92921.40625	, testing loss - 351741.75000	
10686	 steps: training loss - 119498.97656	, testing loss - 351336.09375	
10687	 steps: training loss - 104163.53125	, testing loss - 350014.87500	
10688	 steps: training loss - 106428.64062	, testing loss - 348766.81250	
10689	 steps: training loss - 100543.53125	, testing loss - 348143.93750	
10690	 steps: training loss - 130253.92188	, testing loss - 347934.28125	
10691	 steps: training loss - 143065.25000	, testing loss - 347701.50000	
10692	 steps: training loss - 111017.86719	, testing loss - 347642.96875	
10693	 steps: training loss - 100124.03906	, testing loss - 348869.21875	
10694	 steps: training loss - 92874.36719	, testing loss - 349660.12500	
10695	 steps: training loss - 148327.37500	, testing loss - 349560.03125	
10696	 steps: training loss - 126227.59375	, testing loss - 348800.93750	
10697	 steps: training loss - 106452.23438	, testing loss - 349011.84375	
10698	 steps: training loss - 100035.76562	, testing loss - 349668.53125	
10699	 steps: training loss - 99713.34375	, testing loss - 349575.40625	
10700	 steps: training loss - 88498.51562	, testing loss - 349467.43750	
10701	 steps: training loss - 89280.26562	, testing loss - 349508.68750	
10702	 steps: training loss - 109270.93750	, testing loss - 349191.21875	
10703	 steps: training loss - 114913.93750	, testing loss - 348958.25000	
10704	 steps: training loss - 102815.67969	, testing loss - 348671.68750	
10705	 steps: training loss - 96498.66406	, testing loss - 348067.81250	
10706	 steps: training loss - 104995.07812	, testing loss - 347286.09375	
10707	 steps: training loss - 110494.25781	, testing loss - 345664.37500	
10708	 steps: training loss - 93785.44531	, testing loss - 344262.31250	
10709	 steps: training loss - 123704.39062	, testing loss - 343873.62500	
10710	 steps: training loss - 76561.85938	, testing loss - 343340.93750	
10711	 steps: training loss - 100000.15625	, testing loss - 343444.87500	
10712	 steps: training loss - 119778.00781	, testing loss - 343986.37500	
10713	 steps: training loss - 113287.15625	, testing loss - 344710.15625	
10714	 steps: training loss - 125655.80469	, testing loss - 344740.93750	
10715	 steps: training loss - 110741.37500	, testing loss - 344904.43750	
10716	 steps: training loss - 95806.85156	, testing loss - 344454.09375	
10717	 steps: training loss - 94874.69531	, testing loss - 344581.09375	
10718	 steps: training loss - 112294.28906	, testing loss - 345063.00000	
10719	 steps: training loss - 118800.67969	, testing loss - 346215.62500	
10720	 steps: training loss - 115458.71094	, testing loss - 347620.00000	
10721	 steps: training loss - 107998.11719	, testing loss - 348396.46875	
10722	 steps: training loss - 100265.15625	, testing loss - 349174.43750	
10723	 steps: training loss - 126915.08594	, testing loss - 350748.15625	
10724	 steps: training loss - 99985.92188	, testing loss - 353272.93750	
10725	 steps: training loss - 114952.00000	, testing loss - 356095.03125	
10726	 steps: training loss - 97164.79688	, testing loss - 358923.53125	
10727	 steps: training loss - 101591.16406	, testing loss - 360632.28125	
10728	 steps: training loss - 107697.78125	, testing loss - 361619.43750	
10729	 steps: training loss - 117892.41406	, testing loss - 362592.46875	
10730	 steps: training loss - 128031.92188	, testing loss - 363248.50000	
10731	 steps: training loss - 104227.66406	, testing loss - 362055.21875	
10732	 steps: training loss - 106095.64062	, testing loss - 361159.50000	
10733	 steps: training loss - 124037.04688	, testing loss - 359244.90625	
10734	 steps: training loss - 135526.46875	, testing loss - 355884.65625	
10735	 steps: training loss - 132082.51562	, testing loss - 353677.06250	
10736	 steps: training loss - 123476.35938	, testing loss - 350238.06250	
10737	 steps: training loss - 106207.52344	, testing loss - 346551.18750	
10738	 steps: training loss - 103083.97656	, testing loss - 344009.90625	
10739	 steps: training loss - 135618.89062	, testing loss - 343215.56250	
10740	 steps: training loss - 101894.82031	, testing loss - 343364.06250	
10741	 steps: training loss - 92546.35156	, testing loss - 344080.18750	
10742	 steps: training loss - 99591.44531	, testing loss - 344637.84375	
10743	 steps: training loss - 111728.61719	, testing loss - 344884.15625	
10744	 steps: training loss - 111937.90625	, testing loss - 345596.93750	
10745	 steps: training loss - 129566.23438	, testing loss - 347350.96875	
10746	 steps: training loss - 119422.35156	, testing loss - 350921.53125	
10747	 steps: training loss - 113532.65625	, testing loss - 354692.12500	
10748	 steps: training loss - 107365.37500	, testing loss - 358042.00000	
10749	 steps: training loss - 101023.78125	, testing loss - 360008.56250	
10750	 steps: training loss - 130757.83594	, testing loss - 360757.53125	
10751	 steps: training loss - 104793.28125	, testing loss - 361547.28125	
10752	 steps: training loss - 118783.34375	, testing loss - 360763.93750	
10753	 steps: training loss - 119297.53125	, testing loss - 358790.46875	
10754	 steps: training loss - 99595.95312	, testing loss - 356225.06250	
10755	 steps: training loss - 89158.33594	, testing loss - 353860.96875	
10756	 steps: training loss - 114217.58594	, testing loss - 351072.81250	
10757	 steps: training loss - 97740.82812	, testing loss - 347701.56250	
10758	 steps: training loss - 84714.50781	, testing loss - 345846.81250	
10759	 steps: training loss - 92688.06250	, testing loss - 344797.50000	
10760	 steps: training loss - 119927.64844	, testing loss - 344277.37500	
10761	 steps: training loss - 115228.28906	, testing loss - 344673.28125	
10762	 steps: training loss - 100196.22656	, testing loss - 344684.84375	
10763	 steps: training loss - 123389.99219	, testing loss - 343927.65625	
10764	 steps: training loss - 109767.58594	, testing loss - 343030.59375	
10765	 steps: training loss - 97475.12500	, testing loss - 342676.06250	
10766	 steps: training loss - 129763.38281	, testing loss - 342308.75000	
10767	 steps: training loss - 107621.53125	, testing loss - 341821.93750	
10768	 steps: training loss - 106338.26562	, testing loss - 341587.59375	
10769	 steps: training loss - 111983.04688	, testing loss - 341822.46875	
10770	 steps: training loss - 97084.13281	, testing loss - 342447.50000	
10771	 steps: training loss - 130764.92969	, testing loss - 343177.40625	
10772	 steps: training loss - 95954.72656	, testing loss - 344570.40625	
10773	 steps: training loss - 89705.86719	, testing loss - 346657.71875	
10774	 steps: training loss - 121271.55469	, testing loss - 348819.93750	
10775	 steps: training loss - 104496.20312	, testing loss - 350576.84375	
10776	 steps: training loss - 129243.17969	, testing loss - 351688.53125	
10777	 steps: training loss - 115344.45312	, testing loss - 352353.03125	
10778	 steps: training loss - 123538.68750	, testing loss - 352998.31250	
10779	 steps: training loss - 130245.02344	, testing loss - 354319.00000	
10780	 steps: training loss - 128751.81250	, testing loss - 355128.06250	
10781	 steps: training loss - 110999.31250	, testing loss - 355009.78125	
10782	 steps: training loss - 93320.44531	, testing loss - 354726.87500	
10783	 steps: training loss - 115652.96094	, testing loss - 353505.90625	
10784	 steps: training loss - 118389.85938	, testing loss - 352590.68750	
10785	 steps: training loss - 105857.42969	, testing loss - 351774.50000	
10786	 steps: training loss - 107446.98438	, testing loss - 351819.71875	
10787	 steps: training loss - 103523.17969	, testing loss - 352521.03125	
10788	 steps: training loss - 121793.95312	, testing loss - 352448.43750	
10789	 steps: training loss - 119733.03125	, testing loss - 353043.71875	
10790	 steps: training loss - 84127.22656	, testing loss - 353863.00000	
10791	 steps: training loss - 87678.91406	, testing loss - 354883.00000	
10792	 steps: training loss - 109070.84375	, testing loss - 355896.75000	
10793	 steps: training loss - 124531.92969	, testing loss - 356843.46875	
10794	 steps: training loss - 111406.73438	, testing loss - 356449.62500	
10795	 steps: training loss - 104505.77344	, testing loss - 356191.75000	
10796	 steps: training loss - 99859.88281	, testing loss - 355368.96875	
10797	 steps: training loss - 108382.61719	, testing loss - 354300.28125	
10798	 steps: training loss - 104527.27344	, testing loss - 354375.15625	
10799	 steps: training loss - 88001.42969	, testing loss - 354830.34375	
10800	 steps: training loss - 122497.65625	, testing loss - 355476.21875	
10801	 steps: training loss - 111240.80469	, testing loss - 356464.96875	
10802	 steps: training loss - 113319.62500	, testing loss - 357369.78125	
10803	 steps: training loss - 115832.60156	, testing loss - 357060.06250	
10804	 steps: training loss - 117083.01562	, testing loss - 357219.81250	
10805	 steps: training loss - 103668.61719	, testing loss - 356499.12500	
10806	 steps: training loss - 104117.53125	, testing loss - 355522.31250	
10807	 steps: training loss - 113083.49219	, testing loss - 354683.00000	
10808	 steps: training loss - 102984.41406	, testing loss - 354399.18750	
10809	 steps: training loss - 95756.23438	, testing loss - 354261.71875	
10810	 steps: training loss - 94757.30469	, testing loss - 353768.40625	
10811	 steps: training loss - 102743.05469	, testing loss - 353542.28125	
10812	 steps: training loss - 123228.07812	, testing loss - 352674.62500	
10813	 steps: training loss - 123577.44531	, testing loss - 350050.71875	
10814	 steps: training loss - 99250.67969	, testing loss - 348406.00000	
10815	 steps: training loss - 102815.16406	, testing loss - 347510.50000	
10816	 steps: training loss - 105782.67188	, testing loss - 346550.65625	
10817	 steps: training loss - 89552.94531	, testing loss - 345811.62500	
10818	 steps: training loss - 112914.35156	, testing loss - 345656.71875	
10819	 steps: training loss - 128255.47656	, testing loss - 345333.43750	
10820	 steps: training loss - 142082.12500	, testing loss - 344446.46875	
10821	 steps: training loss - 117580.25781	, testing loss - 344277.40625	
10822	 steps: training loss - 97452.69531	, testing loss - 344267.25000	
10823	 steps: training loss - 98583.36719	, testing loss - 344812.96875	
10824	 steps: training loss - 101369.39062	, testing loss - 345700.53125	
10825	 steps: training loss - 135034.21875	, testing loss - 346835.84375	
10826	 steps: training loss - 121805.22656	, testing loss - 347471.56250	
10827	 steps: training loss - 129418.09375	, testing loss - 347597.75000	
10828	 steps: training loss - 102194.49219	, testing loss - 347430.21875	
10829	 steps: training loss - 106545.25000	, testing loss - 347393.28125	
10830	 steps: training loss - 106389.52344	, testing loss - 348103.56250	
10831	 steps: training loss - 116225.03125	, testing loss - 348242.15625	
10832	 steps: training loss - 129681.10156	, testing loss - 347368.09375	
10833	 steps: training loss - 109991.28125	, testing loss - 346353.09375	
10834	 steps: training loss - 103467.30469	, testing loss - 345210.37500	
10835	 steps: training loss - 123245.75781	, testing loss - 343838.25000	
10836	 steps: training loss - 133292.18750	, testing loss - 343015.34375	
10837	 steps: training loss - 118163.81250	, testing loss - 342850.93750	
10838	 steps: training loss - 94812.32031	, testing loss - 342804.93750	
10839	 steps: training loss - 95764.19531	, testing loss - 342381.78125	
10840	 steps: training loss - 93567.03906	, testing loss - 342568.84375	
10841	 steps: training loss - 130903.82031	, testing loss - 343310.78125	
10842	 steps: training loss - 93543.29688	, testing loss - 344819.21875	
10843	 steps: training loss - 109974.67188	, testing loss - 346017.62500	
10844	 steps: training loss - 122009.28125	, testing loss - 346682.71875	
10845	 steps: training loss - 102562.60938	, testing loss - 346900.59375	
10846	 steps: training loss - 103411.28125	, testing loss - 347394.78125	
10847	 steps: training loss - 128626.65625	, testing loss - 349203.40625	
10848	 steps: training loss - 104288.24219	, testing loss - 350838.18750	
10849	 steps: training loss - 107878.44531	, testing loss - 351533.87500	
10850	 steps: training loss - 96446.25781	, testing loss - 351468.71875	
10851	 steps: training loss - 110725.21875	, testing loss - 351241.43750	
10852	 steps: training loss - 132906.95312	, testing loss - 350358.65625	
10853	 steps: training loss - 100458.92969	, testing loss - 348663.59375	
10854	 steps: training loss - 110522.08594	, testing loss - 347042.15625	
10855	 steps: training loss - 116585.88281	, testing loss - 345656.31250	
10856	 steps: training loss - 105597.07031	, testing loss - 344557.71875	
10857	 steps: training loss - 98060.14062	, testing loss - 343360.56250	
10858	 steps: training loss - 130023.97656	, testing loss - 342698.12500	
10859	 steps: training loss - 117903.60156	, testing loss - 342722.62500	
10860	 steps: training loss - 107402.75000	, testing loss - 342678.65625	
10861	 steps: training loss - 111849.66406	, testing loss - 342953.21875	
10862	 steps: training loss - 112362.94531	, testing loss - 343582.15625	
10863	 steps: training loss - 94344.49219	, testing loss - 344962.31250	
10864	 steps: training loss - 123992.06250	, testing loss - 346699.40625	
10865	 steps: training loss - 107479.14844	, testing loss - 348320.37500	
10866	 steps: training loss - 126779.32812	, testing loss - 350284.62500	
10867	 steps: training loss - 134090.03125	, testing loss - 350886.46875	
10868	 steps: training loss - 101493.35938	, testing loss - 349918.93750	
10869	 steps: training loss - 116381.11719	, testing loss - 349563.21875	
10870	 steps: training loss - 98178.75781	, testing loss - 349030.84375	
10871	 steps: training loss - 91616.64062	, testing loss - 348142.68750	
10872	 steps: training loss - 95625.86719	, testing loss - 346190.00000	
10873	 steps: training loss - 73941.67969	, testing loss - 343751.87500	
10874	 steps: training loss - 119007.21094	, testing loss - 342126.65625	
10875	 steps: training loss - 110669.71094	, testing loss - 341069.56250	
10876	 steps: training loss - 101896.59375	, testing loss - 340853.87500	
10877	 steps: training loss - 103416.96875	, testing loss - 341569.28125	
10878	 steps: training loss - 108745.25781	, testing loss - 342195.25000	
10879	 steps: training loss - 105325.25000	, testing loss - 342730.37500	
10880	 steps: training loss - 111348.20312	, testing loss - 343596.78125	
10881	 steps: training loss - 121167.00000	, testing loss - 344618.65625	
10882	 steps: training loss - 106888.34375	, testing loss - 346494.68750	
10883	 steps: training loss - 109343.45312	, testing loss - 348553.75000	
10884	 steps: training loss - 88343.27344	, testing loss - 351086.46875	
10885	 steps: training loss - 75326.59375	, testing loss - 353117.53125	
10886	 steps: training loss - 135943.14062	, testing loss - 354639.18750	
10887	 steps: training loss - 119545.96094	, testing loss - 354872.93750	
10888	 steps: training loss - 85613.25781	, testing loss - 354174.46875	
10889	 steps: training loss - 102971.42969	, testing loss - 352535.56250	
10890	 steps: training loss - 91471.78906	, testing loss - 350199.59375	
10891	 steps: training loss - 90006.30469	, testing loss - 347947.00000	
10892	 steps: training loss - 118905.97656	, testing loss - 345524.00000	
10893	 steps: training loss - 118839.28125	, testing loss - 343765.21875	
10894	 steps: training loss - 126966.89062	, testing loss - 342635.78125	
10895	 steps: training loss - 103452.50000	, testing loss - 342287.65625	
10896	 steps: training loss - 115915.28906	, testing loss - 342921.06250	
10897	 steps: training loss - 142979.56250	, testing loss - 343952.50000	
10898	 steps: training loss - 125985.44531	, testing loss - 345573.68750	
10899	 steps: training loss - 107735.60156	, testing loss - 346776.81250	
10900	 steps: training loss - 111704.98438	, testing loss - 348659.21875	
10901	 steps: training loss - 134737.95312	, testing loss - 349806.75000	
10902	 steps: training loss - 106228.66406	, testing loss - 350582.87500	
10903	 steps: training loss - 89318.39062	, testing loss - 350835.34375	
10904	 steps: training loss - 91531.50000	, testing loss - 350492.03125	
10905	 steps: training loss - 113210.66406	, testing loss - 349709.09375	
10906	 steps: training loss - 119453.07031	, testing loss - 349077.18750	
10907	 steps: training loss - 98714.27344	, testing loss - 349372.81250	
10908	 steps: training loss - 111593.85156	, testing loss - 348950.87500	
10909	 steps: training loss - 112882.73438	, testing loss - 349370.15625	
10910	 steps: training loss - 98540.74219	, testing loss - 349488.12500	
10911	 steps: training loss - 103889.20312	, testing loss - 348464.68750	
10912	 steps: training loss - 110198.97656	, testing loss - 347263.50000	
10913	 steps: training loss - 98196.25000	, testing loss - 346781.03125	
10914	 steps: training loss - 103243.30469	, testing loss - 346529.03125	
10915	 steps: training loss - 102630.72656	, testing loss - 346689.93750	
10916	 steps: training loss - 106441.06250	, testing loss - 346506.21875	
10917	 steps: training loss - 130327.95312	, testing loss - 346511.65625	
10918	 steps: training loss - 101334.23438	, testing loss - 348474.87500	
10919	 steps: training loss - 121507.34375	, testing loss - 351512.68750	
10920	 steps: training loss - 105160.71875	, testing loss - 354056.84375	
10921	 steps: training loss - 109963.54688	, testing loss - 357065.15625	
10922	 steps: training loss - 114238.35156	, testing loss - 362094.68750	
10923	 steps: training loss - 96843.89062	, testing loss - 365924.68750	
10924	 steps: training loss - 112325.80469	, testing loss - 369318.71875	
10925	 steps: training loss - 113791.60156	, testing loss - 370498.31250	
10926	 steps: training loss - 144120.81250	, testing loss - 371072.03125	
10927	 steps: training loss - 105288.59375	, testing loss - 369034.59375	
10928	 steps: training loss - 110110.52344	, testing loss - 367051.81250	
10929	 steps: training loss - 114761.35938	, testing loss - 364423.56250	
10930	 steps: training loss - 109624.10156	, testing loss - 361292.06250	
10931	 steps: training loss - 110485.93750	, testing loss - 357421.40625	
10932	 steps: training loss - 89265.85156	, testing loss - 353012.40625	
10933	 steps: training loss - 98615.50781	, testing loss - 349398.71875	
10934	 steps: training loss - 115712.14062	, testing loss - 346877.90625	
10935	 steps: training loss - 100498.96094	, testing loss - 345117.37500	
10936	 steps: training loss - 90860.06250	, testing loss - 343395.65625	
10937	 steps: training loss - 102021.56250	, testing loss - 341625.43750	
10938	 steps: training loss - 124682.10938	, testing loss - 340285.40625	
10939	 steps: training loss - 121046.39844	, testing loss - 339339.21875	
10940	 steps: training loss - 98590.79688	, testing loss - 339164.43750	
10941	 steps: training loss - 119576.02344	, testing loss - 339295.56250	
10942	 steps: training loss - 92292.79688	, testing loss - 339608.81250	
10943	 steps: training loss - 101068.06250	, testing loss - 339851.59375	
10944	 steps: training loss - 109686.32812	, testing loss - 339946.43750	
10945	 steps: training loss - 97608.12500	, testing loss - 340370.18750	
10946	 steps: training loss - 105255.97656	, testing loss - 341033.87500	
10947	 steps: training loss - 118242.98438	, testing loss - 342254.31250	
10948	 steps: training loss - 93511.41406	, testing loss - 343303.15625	
10949	 steps: training loss - 115184.33594	, testing loss - 343096.81250	
10950	 steps: training loss - 94318.56250	, testing loss - 343277.56250	
10951	 steps: training loss - 114078.14844	, testing loss - 343735.31250	
10952	 steps: training loss - 91556.39062	, testing loss - 344359.18750	
10953	 steps: training loss - 112071.06250	, testing loss - 345441.28125	
10954	 steps: training loss - 99353.12500	, testing loss - 346352.90625	
10955	 steps: training loss - 94782.82812	, testing loss - 346824.15625	
10956	 steps: training loss - 127564.46094	, testing loss - 347416.62500	
10957	 steps: training loss - 117460.92188	, testing loss - 347799.18750	
10958	 steps: training loss - 117844.75000	, testing loss - 347263.25000	
10959	 steps: training loss - 119152.04688	, testing loss - 346225.93750	
10960	 steps: training loss - 125161.97656	, testing loss - 344717.46875	
10961	 steps: training loss - 139710.71875	, testing loss - 343643.56250	
10962	 steps: training loss - 117529.01562	, testing loss - 342301.40625	
10963	 steps: training loss - 103953.35156	, testing loss - 341149.34375	
10964	 steps: training loss - 109489.60938	, testing loss - 340833.62500	
10965	 steps: training loss - 103243.64062	, testing loss - 341384.62500	
10966	 steps: training loss - 91435.21094	, testing loss - 341957.90625	
10967	 steps: training loss - 141331.76562	, testing loss - 342708.21875	
10968	 steps: training loss - 97750.33594	, testing loss - 343801.12500	
10969	 steps: training loss - 86380.09375	, testing loss - 344534.43750	
10970	 steps: training loss - 120523.38281	, testing loss - 344949.53125	
10971	 steps: training loss - 87332.91406	, testing loss - 345426.75000	
10972	 steps: training loss - 110619.84375	, testing loss - 345397.25000	
10973	 steps: training loss - 108049.12500	, testing loss - 345547.50000	
10974	 steps: training loss - 94803.07031	, testing loss - 344865.53125	
10975	 steps: training loss - 105219.28125	, testing loss - 343886.18750	
10976	 steps: training loss - 129236.57812	, testing loss - 343487.28125	
10977	 steps: training loss - 119248.79688	, testing loss - 342971.87500	
10978	 steps: training loss - 86576.68750	, testing loss - 342744.96875	
10979	 steps: training loss - 130079.71875	, testing loss - 342945.62500	
10980	 steps: training loss - 126066.72656	, testing loss - 343236.78125	
10981	 steps: training loss - 88875.38281	, testing loss - 343990.28125	
10982	 steps: training loss - 93672.45312	, testing loss - 345397.18750	
10983	 steps: training loss - 122560.58594	, testing loss - 347346.40625	
10984	 steps: training loss - 111907.79688	, testing loss - 349093.28125	
10985	 steps: training loss - 106130.26562	, testing loss - 350898.87500	
10986	 steps: training loss - 114494.85938	, testing loss - 352100.18750	
10987	 steps: training loss - 92131.46875	, testing loss - 353080.00000	
10988	 steps: training loss - 98591.62500	, testing loss - 353780.84375	
10989	 steps: training loss - 105221.89844	, testing loss - 354042.18750	
10990	 steps: training loss - 110859.28125	, testing loss - 353782.96875	
10991	 steps: training loss - 111502.78906	, testing loss - 352083.12500	
10992	 steps: training loss - 109697.75000	, testing loss - 349817.68750	
10993	 steps: training loss - 107431.39062	, testing loss - 347400.65625	
10994	 steps: training loss - 93223.18750	, testing loss - 345758.68750	
10995	 steps: training loss - 108271.95312	, testing loss - 345712.18750	
10996	 steps: training loss - 102916.85938	, testing loss - 346415.62500	
10997	 steps: training loss - 120130.89062	, testing loss - 346900.15625	
10998	 steps: training loss - 92442.88281	, testing loss - 347790.25000	
10999	 steps: training loss - 83231.75000	, testing loss - 349004.56250	
11000	 steps: training loss - 108875.42188	, testing loss - 350261.84375	
11001	 steps: training loss - 95814.56250	, testing loss - 351117.06250	
11002	 steps: training loss - 124913.47656	, testing loss - 351047.31250	
11003	 steps: training loss - 138368.21875	, testing loss - 350651.75000	
11004	 steps: training loss - 131916.90625	, testing loss - 350332.87500	
11005	 steps: training loss - 113575.03906	, testing loss - 349032.34375	
11006	 steps: training loss - 103926.62500	, testing loss - 348435.81250	
11007	 steps: training loss - 99283.71875	, testing loss - 348007.00000	
11008	 steps: training loss - 98939.88281	, testing loss - 347502.65625	
11009	 steps: training loss - 123919.06250	, testing loss - 347118.56250	
11010	 steps: training loss - 115352.22656	, testing loss - 346699.18750	
11011	 steps: training loss - 90144.85938	, testing loss - 347004.15625	
11012	 steps: training loss - 135829.40625	, testing loss - 348018.34375	
11013	 steps: training loss - 97915.93750	, testing loss - 350112.18750	
11014	 steps: training loss - 115678.99219	, testing loss - 352629.78125	
11015	 steps: training loss - 109525.62500	, testing loss - 353791.65625	
11016	 steps: training loss - 104933.35156	, testing loss - 353507.71875	
11017	 steps: training loss - 104983.97656	, testing loss - 352400.28125	
11018	 steps: training loss - 103387.88281	, testing loss - 351394.18750	
11019	 steps: training loss - 110758.61719	, testing loss - 350678.75000	
11020	 steps: training loss - 112244.03125	, testing loss - 349948.21875	
11021	 steps: training loss - 109502.56250	, testing loss - 348959.71875	
11022	 steps: training loss - 112342.67969	, testing loss - 347699.81250	
11023	 steps: training loss - 119747.51562	, testing loss - 345997.53125	
11024	 steps: training loss - 108260.42969	, testing loss - 344332.15625	
11025	 steps: training loss - 129304.82031	, testing loss - 343240.06250	
11026	 steps: training loss - 95809.19531	, testing loss - 342565.06250	
11027	 steps: training loss - 103556.78125	, testing loss - 342562.46875	
11028	 steps: training loss - 112210.33594	, testing loss - 342163.25000	
11029	 steps: training loss - 93785.30469	, testing loss - 342609.65625	
11030	 steps: training loss - 88611.29688	, testing loss - 343329.43750	
11031	 steps: training loss - 124055.81250	, testing loss - 344205.59375	
11032	 steps: training loss - 140593.64062	, testing loss - 344315.31250	
11033	 steps: training loss - 106640.46875	, testing loss - 344374.25000	
11034	 steps: training loss - 115147.13281	, testing loss - 344988.18750	
11035	 steps: training loss - 106416.82812	, testing loss - 344887.81250	
11036	 steps: training loss - 107763.17188	, testing loss - 344882.34375	
11037	 steps: training loss - 125423.78125	, testing loss - 344979.31250	
11038	 steps: training loss - 107060.78125	, testing loss - 346093.68750	
11039	 steps: training loss - 120264.35938	, testing loss - 346848.18750	
11040	 steps: training loss - 118987.45312	, testing loss - 347244.53125	
11041	 steps: training loss - 121786.77344	, testing loss - 347475.71875	
11042	 steps: training loss - 89663.50000	, testing loss - 347534.18750	
11043	 steps: training loss - 119519.33594	, testing loss - 347274.53125	
11044	 steps: training loss - 99385.46875	, testing loss - 346665.84375	
11045	 steps: training loss - 86239.68750	, testing loss - 346096.71875	
11046	 steps: training loss - 111578.29688	, testing loss - 345295.06250	
11047	 steps: training loss - 110690.82812	, testing loss - 344987.03125	
11048	 steps: training loss - 112668.10156	, testing loss - 344984.37500	
11049	 steps: training loss - 109557.00781	, testing loss - 345779.90625	
11050	 steps: training loss - 105853.37500	, testing loss - 346858.06250	
11051	 steps: training loss - 91688.82812	, testing loss - 347309.81250	
11052	 steps: training loss - 115487.87500	, testing loss - 348383.71875	
11053	 steps: training loss - 105911.71875	, testing loss - 350142.15625	
11054	 steps: training loss - 126670.52344	, testing loss - 352482.40625	
11055	 steps: training loss - 112092.50781	, testing loss - 354452.50000	
11056	 steps: training loss - 110643.28125	, testing loss - 355721.90625	
11057	 steps: training loss - 116661.43750	, testing loss - 356149.43750	
11058	 steps: training loss - 93494.83594	, testing loss - 355569.53125	
11059	 steps: training loss - 117606.81250	, testing loss - 354359.06250	
11060	 steps: training loss - 109593.34375	, testing loss - 352834.65625	
11061	 steps: training loss - 118224.77344	, testing loss - 350726.18750	
11062	 steps: training loss - 119138.94531	, testing loss - 348388.31250	
11063	 steps: training loss - 130017.12500	, testing loss - 346767.31250	
11064	 steps: training loss - 92130.82812	, testing loss - 345204.18750	
11065	 steps: training loss - 97926.25000	, testing loss - 343793.78125	
11066	 steps: training loss - 113691.46875	, testing loss - 342743.78125	
11067	 steps: training loss - 95695.53906	, testing loss - 341944.75000	
11068	 steps: training loss - 123779.35938	, testing loss - 341864.18750	
11069	 steps: training loss - 96312.00781	, testing loss - 342427.18750	
11070	 steps: training loss - 105162.73438	, testing loss - 342489.62500	
11071	 steps: training loss - 103282.28906	, testing loss - 342376.68750	
11072	 steps: training loss - 110322.21094	, testing loss - 342402.12500	
11073	 steps: training loss - 128622.16406	, testing loss - 342626.62500	
11074	 steps: training loss - 121718.53125	, testing loss - 343729.12500	
11075	 steps: training loss - 112568.42188	, testing loss - 344576.65625	
11076	 steps: training loss - 112496.12500	, testing loss - 345804.87500	
11077	 steps: training loss - 119332.64062	, testing loss - 347366.37500	
11078	 steps: training loss - 111960.06250	, testing loss - 348302.65625	
11079	 steps: training loss - 103140.85938	, testing loss - 349574.84375	
11080	 steps: training loss - 106484.53125	, testing loss - 349985.34375	
11081	 steps: training loss - 89679.56250	, testing loss - 349867.93750	
11082	 steps: training loss - 100834.97656	, testing loss - 349930.03125	
11083	 steps: training loss - 139902.57812	, testing loss - 350789.09375	
11084	 steps: training loss - 124658.35156	, testing loss - 350895.25000	
11085	 steps: training loss - 84554.61719	, testing loss - 350228.28125	
11086	 steps: training loss - 85195.93750	, testing loss - 348808.87500	
11087	 steps: training loss - 98278.55469	, testing loss - 347741.56250	
11088	 steps: training loss - 106692.06250	, testing loss - 347149.96875	
11089	 steps: training loss - 100660.64062	, testing loss - 346162.90625	
11090	 steps: training loss - 124801.63281	, testing loss - 345053.00000	
11091	 steps: training loss - 109806.21875	, testing loss - 343847.15625	
11092	 steps: training loss - 118628.71875	, testing loss - 344279.75000	
11093	 steps: training loss - 113447.46875	, testing loss - 345203.06250	
11094	 steps: training loss - 116769.65625	, testing loss - 346349.62500	
11095	 steps: training loss - 114492.99219	, testing loss - 347160.81250	
11096	 steps: training loss - 100397.13281	, testing loss - 348143.15625	
11097	 steps: training loss - 108466.06250	, testing loss - 348549.00000	
11098	 steps: training loss - 113930.74219	, testing loss - 348080.37500	
11099	 steps: training loss - 116022.78125	, testing loss - 347262.37500	
11100	 steps: training loss - 103056.75000	, testing loss - 346303.90625	
11101	 steps: training loss - 122193.78125	, testing loss - 345009.34375	
11102	 steps: training loss - 98997.25000	, testing loss - 343243.81250	
11103	 steps: training loss - 115374.92969	, testing loss - 341552.28125	
11104	 steps: training loss - 108059.36719	, testing loss - 340607.65625	
11105	 steps: training loss - 97658.79688	, testing loss - 340395.34375	
11106	 steps: training loss - 142095.59375	, testing loss - 340489.18750	
11107	 steps: training loss - 127271.60938	, testing loss - 341283.71875	
11108	 steps: training loss - 103275.32031	, testing loss - 342907.31250	
11109	 steps: training loss - 128281.45312	, testing loss - 344980.56250	
11110	 steps: training loss - 98719.13281	, testing loss - 347170.28125	
11111	 steps: training loss - 117445.04688	, testing loss - 349599.84375	
11112	 steps: training loss - 98665.94531	, testing loss - 351474.59375	
11113	 steps: training loss - 109406.27344	, testing loss - 352273.18750	
11114	 steps: training loss - 122032.21094	, testing loss - 352747.37500	
11115	 steps: training loss - 116139.85938	, testing loss - 353594.06250	
11116	 steps: training loss - 91985.46875	, testing loss - 353901.06250	
11117	 steps: training loss - 99131.89062	, testing loss - 353352.31250	
11118	 steps: training loss - 85188.28906	, testing loss - 353053.46875	
11119	 steps: training loss - 128411.91406	, testing loss - 352963.21875	
11120	 steps: training loss - 93221.18750	, testing loss - 353759.53125	
11121	 steps: training loss - 98655.59375	, testing loss - 354929.53125	
11122	 steps: training loss - 109906.97656	, testing loss - 356400.71875	
11123	 steps: training loss - 113792.91406	, testing loss - 358475.34375	
11124	 steps: training loss - 121930.07031	, testing loss - 359584.09375	
11125	 steps: training loss - 112024.23438	, testing loss - 360071.43750	
11126	 steps: training loss - 125280.04688	, testing loss - 361113.56250	
11127	 steps: training loss - 111482.67969	, testing loss - 361459.21875	
11128	 steps: training loss - 100995.07812	, testing loss - 361101.40625	
11129	 steps: training loss - 117526.67188	, testing loss - 359576.18750	
11130	 steps: training loss - 107093.28125	, testing loss - 357594.53125	
11131	 steps: training loss - 110738.21875	, testing loss - 356283.68750	
11132	 steps: training loss - 112446.29688	, testing loss - 354453.65625	
11133	 steps: training loss - 102880.46875	, testing loss - 351802.84375	
11134	 steps: training loss - 124007.21875	, testing loss - 349788.43750	
11135	 steps: training loss - 117655.27344	, testing loss - 348459.40625	
11136	 steps: training loss - 120453.90625	, testing loss - 347430.40625	
11137	 steps: training loss - 119037.91406	, testing loss - 346810.62500	
11138	 steps: training loss - 117210.41406	, testing loss - 347649.00000	
11139	 steps: training loss - 118111.20312	, testing loss - 349310.21875	
11140	 steps: training loss - 91222.89062	, testing loss - 351475.06250	
11141	 steps: training loss - 113162.78906	, testing loss - 354451.75000	
11142	 steps: training loss - 106100.55469	, testing loss - 357233.56250	
11143	 steps: training loss - 92472.17969	, testing loss - 359550.93750	
11144	 steps: training loss - 130384.47656	, testing loss - 361964.09375	
11145	 steps: training loss - 94690.94531	, testing loss - 362702.68750	
11146	 steps: training loss - 112662.29688	, testing loss - 363860.31250	
11147	 steps: training loss - 137259.53125	, testing loss - 363595.43750	
11148	 steps: training loss - 96869.92969	, testing loss - 362298.78125	
11149	 steps: training loss - 112426.42969	, testing loss - 361297.62500	
11150	 steps: training loss - 108906.40625	, testing loss - 360282.50000	
11151	 steps: training loss - 113670.82812	, testing loss - 358820.87500	
11152	 steps: training loss - 135062.70312	, testing loss - 357841.31250	
11153	 steps: training loss - 84263.74219	, testing loss - 356982.21875	
11154	 steps: training loss - 96642.73438	, testing loss - 355500.37500	
11155	 steps: training loss - 93823.89062	, testing loss - 354337.87500	
11156	 steps: training loss - 124104.89844	, testing loss - 353728.93750	
11157	 steps: training loss - 129375.92188	, testing loss - 354327.53125	
11158	 steps: training loss - 98327.19531	, testing loss - 353877.68750	
11159	 steps: training loss - 118945.53125	, testing loss - 353528.81250	
11160	 steps: training loss - 126446.87500	, testing loss - 353291.78125	
11161	 steps: training loss - 131425.89062	, testing loss - 352605.18750	
11162	 steps: training loss - 100824.59375	, testing loss - 352519.43750	
11163	 steps: training loss - 114385.79688	, testing loss - 352019.84375	
11164	 steps: training loss - 112853.42188	, testing loss - 351529.25000	
11165	 steps: training loss - 115515.89844	, testing loss - 351166.37500	
11166	 steps: training loss - 93248.09375	, testing loss - 350091.90625	
11167	 steps: training loss - 141790.01562	, testing loss - 348493.43750	
11168	 steps: training loss - 104042.87500	, testing loss - 347518.15625	
11169	 steps: training loss - 117609.04688	, testing loss - 346920.43750	
11170	 steps: training loss - 120531.75000	, testing loss - 346254.56250	
11171	 steps: training loss - 108160.89062	, testing loss - 346133.37500	
11172	 steps: training loss - 107910.75781	, testing loss - 346833.75000	
11173	 steps: training loss - 106427.06250	, testing loss - 347403.71875	
11174	 steps: training loss - 103537.18750	, testing loss - 347794.09375	
11175	 steps: training loss - 102881.82031	, testing loss - 348189.81250	
11176	 steps: training loss - 99577.25781	, testing loss - 348759.71875	
11177	 steps: training loss - 76573.83594	, testing loss - 349047.15625	
11178	 steps: training loss - 100020.54688	, testing loss - 348899.68750	
11179	 steps: training loss - 126470.39062	, testing loss - 348565.18750	
11180	 steps: training loss - 106131.86719	, testing loss - 347865.12500	
11181	 steps: training loss - 123330.80469	, testing loss - 347016.53125	
11182	 steps: training loss - 93959.50781	, testing loss - 346623.65625	
11183	 steps: training loss - 101354.34375	, testing loss - 346485.90625	
11184	 steps: training loss - 108858.39844	, testing loss - 346277.93750	
11185	 steps: training loss - 104593.12500	, testing loss - 346473.18750	
11186	 steps: training loss - 97565.58594	, testing loss - 346489.31250	
11187	 steps: training loss - 101162.70312	, testing loss - 347146.21875	
11188	 steps: training loss - 126143.31250	, testing loss - 347978.03125	
11189	 steps: training loss - 125337.40625	, testing loss - 349317.34375	
11190	 steps: training loss - 116633.34375	, testing loss - 350877.28125	
11191	 steps: training loss - 129614.34375	, testing loss - 351852.37500	
11192	 steps: training loss - 95491.85156	, testing loss - 352834.18750	
11193	 steps: training loss - 107489.25000	, testing loss - 353212.59375	
11194	 steps: training loss - 133753.26562	, testing loss - 354007.93750	
11195	 steps: training loss - 118886.71875	, testing loss - 354569.78125	
11196	 steps: training loss - 131232.17188	, testing loss - 354330.87500	
11197	 steps: training loss - 113503.53906	, testing loss - 352973.09375	
11198	 steps: training loss - 106304.20312	, testing loss - 352236.09375	
11199	 steps: training loss - 93832.53125	, testing loss - 351374.93750	
11200	 steps: training loss - 102187.45312	, testing loss - 350478.15625	
11201	 steps: training loss - 119179.56250	, testing loss - 349542.21875	
11202	 steps: training loss - 101386.35156	, testing loss - 348583.18750	
11203	 steps: training loss - 126333.62500	, testing loss - 347931.46875	
11204	 steps: training loss - 116233.28125	, testing loss - 346988.96875	
11205	 steps: training loss - 122034.89062	, testing loss - 347214.59375	
11206	 steps: training loss - 121195.85156	, testing loss - 347810.18750	
11207	 steps: training loss - 93720.44531	, testing loss - 348548.15625	
11208	 steps: training loss - 76164.96875	, testing loss - 349066.46875	
11209	 steps: training loss - 119491.91406	, testing loss - 350014.84375	
11210	 steps: training loss - 118325.44531	, testing loss - 351403.25000	
11211	 steps: training loss - 109190.35156	, testing loss - 352203.50000	
11212	 steps: training loss - 107795.88281	, testing loss - 352927.96875	
11213	 steps: training loss - 126599.63281	, testing loss - 353631.65625	
11214	 steps: training loss - 137836.90625	, testing loss - 353932.87500	
11215	 steps: training loss - 119286.27344	, testing loss - 354975.12500	
11216	 steps: training loss - 108871.00000	, testing loss - 356383.75000	
11217	 steps: training loss - 138687.23438	, testing loss - 357179.12500	
11218	 steps: training loss - 108133.25781	, testing loss - 356891.00000	
11219	 steps: training loss - 116908.10156	, testing loss - 355675.31250	
11220	 steps: training loss - 94778.85938	, testing loss - 354665.28125	
11221	 steps: training loss - 116443.79688	, testing loss - 353033.37500	
11222	 steps: training loss - 98395.25781	, testing loss - 351123.78125	
11223	 steps: training loss - 95487.72656	, testing loss - 349226.90625	
11224	 steps: training loss - 116709.09375	, testing loss - 347392.31250	
11225	 steps: training loss - 93731.44531	, testing loss - 346364.87500	
11226	 steps: training loss - 89993.43750	, testing loss - 345240.75000	
11227	 steps: training loss - 134798.85938	, testing loss - 344153.46875	
11228	 steps: training loss - 99999.14844	, testing loss - 344301.00000	
11229	 steps: training loss - 109887.45312	, testing loss - 344766.71875	
11230	 steps: training loss - 87606.03125	, testing loss - 345082.21875	
11231	 steps: training loss - 94146.42969	, testing loss - 345026.93750	
11232	 steps: training loss - 118656.41406	, testing loss - 346432.37500	
11233	 steps: training loss - 100225.88281	, testing loss - 348416.15625	
11234	 steps: training loss - 101490.64844	, testing loss - 350808.81250	
11235	 steps: training loss - 114161.17969	, testing loss - 352518.15625	
11236	 steps: training loss - 126164.25781	, testing loss - 352523.09375	
11237	 steps: training loss - 129709.21875	, testing loss - 351051.06250	
11238	 steps: training loss - 122848.58594	, testing loss - 348442.25000	
11239	 steps: training loss - 117476.96875	, testing loss - 347129.56250	
11240	 steps: training loss - 99155.92188	, testing loss - 346711.21875	
11241	 steps: training loss - 110825.30469	, testing loss - 346688.18750	
11242	 steps: training loss - 116629.95312	, testing loss - 346589.78125	
11243	 steps: training loss - 104576.10938	, testing loss - 346612.59375	
11244	 steps: training loss - 135133.39062	, testing loss - 346216.53125	
11245	 steps: training loss - 109887.30469	, testing loss - 345221.65625	
11246	 steps: training loss - 87567.34375	, testing loss - 344723.62500	
11247	 steps: training loss - 95137.15625	, testing loss - 343769.34375	
11248	 steps: training loss - 82734.51562	, testing loss - 342154.78125	
11249	 steps: training loss - 117622.43750	, testing loss - 340369.43750	
11250	 steps: training loss - 82397.38281	, testing loss - 338494.37500	
11251	 steps: training loss - 102930.00000	, testing loss - 337324.21875	
11252	 steps: training loss - 90758.10156	, testing loss - 336916.21875	
11253	 steps: training loss - 88299.25781	, testing loss - 336734.00000	
11254	 steps: training loss - 121520.64844	, testing loss - 336375.96875	
11255	 steps: training loss - 114805.98438	, testing loss - 336274.00000	
11256	 steps: training loss - 106502.92969	, testing loss - 336448.62500	
11257	 steps: training loss - 117798.08594	, testing loss - 336975.90625	
11258	 steps: training loss - 112841.97656	, testing loss - 337609.21875	
11259	 steps: training loss - 120845.80469	, testing loss - 338658.59375	
11260	 steps: training loss - 114336.29688	, testing loss - 340817.00000	
11261	 steps: training loss - 126053.57031	, testing loss - 343615.46875	
11262	 steps: training loss - 109108.15625	, testing loss - 347685.15625	
11263	 steps: training loss - 102686.94531	, testing loss - 352143.00000	
11264	 steps: training loss - 103881.63281	, testing loss - 356448.28125	
11265	 steps: training loss - 92359.76562	, testing loss - 359216.25000	
11266	 steps: training loss - 105995.31250	, testing loss - 362004.96875	
11267	 steps: training loss - 104451.71875	, testing loss - 364061.06250	
11268	 steps: training loss - 98201.00781	, testing loss - 364705.87500	
11269	 steps: training loss - 129381.78125	, testing loss - 364256.46875	
11270	 steps: training loss - 120542.89844	, testing loss - 361376.65625	
11271	 steps: training loss - 92187.50781	, testing loss - 359458.28125	
11272	 steps: training loss - 86772.19531	, testing loss - 357904.68750	
11273	 steps: training loss - 111035.36719	, testing loss - 357087.34375	
11274	 steps: training loss - 97417.47656	, testing loss - 355357.53125	
11275	 steps: training loss - 118209.78906	, testing loss - 353488.34375	
11276	 steps: training loss - 128157.20312	, testing loss - 352930.62500	
11277	 steps: training loss - 111317.00781	, testing loss - 351071.81250	
11278	 steps: training loss - 131119.98438	, testing loss - 348021.59375	
11279	 steps: training loss - 105298.17969	, testing loss - 344705.37500	
11280	 steps: training loss - 96421.78125	, testing loss - 342623.71875	
11281	 steps: training loss - 113626.89844	, testing loss - 341193.00000	
11282	 steps: training loss - 123288.19531	, testing loss - 340045.62500	
11283	 steps: training loss - 103413.61719	, testing loss - 339797.59375	
11284	 steps: training loss - 90658.56250	, testing loss - 340332.62500	
11285	 steps: training loss - 111752.92188	, testing loss - 341503.56250	
11286	 steps: training loss - 112052.75000	, testing loss - 342946.68750	
11287	 steps: training loss - 92023.00781	, testing loss - 344022.28125	
11288	 steps: training loss - 114056.24219	, testing loss - 345172.00000	
11289	 steps: training loss - 105508.92969	, testing loss - 346166.00000	
11290	 steps: training loss - 112795.06250	, testing loss - 347702.62500	
11291	 steps: training loss - 104249.75000	, testing loss - 349078.68750	
11292	 steps: training loss - 110814.44531	, testing loss - 350561.87500	
11293	 steps: training loss - 90257.46094	, testing loss - 351791.28125	
11294	 steps: training loss - 100081.69531	, testing loss - 352223.00000	
11295	 steps: training loss - 93216.86719	, testing loss - 352224.87500	
11296	 steps: training loss - 126425.85156	, testing loss - 351633.75000	
11297	 steps: training loss - 108103.29688	, testing loss - 349755.87500	
11298	 steps: training loss - 95013.86719	, testing loss - 347186.31250	
11299	 steps: training loss - 107747.75781	, testing loss - 345349.56250	
11300	 steps: training loss - 99237.89844	, testing loss - 344198.12500	
11301	 steps: training loss - 100773.76562	, testing loss - 344158.71875	
11302	 steps: training loss - 112744.39844	, testing loss - 344959.28125	
11303	 steps: training loss - 118181.60156	, testing loss - 345907.81250	
11304	 steps: training loss - 120816.53125	, testing loss - 347452.09375	
11305	 steps: training loss - 119013.55469	, testing loss - 350285.93750	
11306	 steps: training loss - 98566.70312	, testing loss - 353087.06250	
11307	 steps: training loss - 88405.92969	, testing loss - 354997.87500	
11308	 steps: training loss - 112810.42188	, testing loss - 357296.21875	
11309	 steps: training loss - 93889.53906	, testing loss - 358298.56250	
11310	 steps: training loss - 105445.91406	, testing loss - 357792.78125	
11311	 steps: training loss - 113209.08594	, testing loss - 355774.09375	
11312	 steps: training loss - 135082.46875	, testing loss - 353863.25000	
11313	 steps: training loss - 131987.54688	, testing loss - 351880.59375	
11314	 steps: training loss - 107454.84375	, testing loss - 350724.68750	
11315	 steps: training loss - 94207.46875	, testing loss - 349734.09375	
11316	 steps: training loss - 115743.54688	, testing loss - 349319.15625	
11317	 steps: training loss - 110884.92188	, testing loss - 348438.03125	
11318	 steps: training loss - 103516.74219	, testing loss - 348135.28125	
11319	 steps: training loss - 90255.09375	, testing loss - 348008.75000	
11320	 steps: training loss - 116410.58594	, testing loss - 348350.71875	
11321	 steps: training loss - 131485.39062	, testing loss - 348945.18750	
11322	 steps: training loss - 107690.80469	, testing loss - 349905.62500	
11323	 steps: training loss - 116381.06250	, testing loss - 350571.93750	
11324	 steps: training loss - 96318.67969	, testing loss - 351264.09375	
11325	 steps: training loss - 90765.17188	, testing loss - 352420.68750	
11326	 steps: training loss - 113086.04688	, testing loss - 354210.84375	
11327	 steps: training loss - 104176.71875	, testing loss - 355112.15625	
11328	 steps: training loss - 106321.42969	, testing loss - 356170.25000	
11329	 steps: training loss - 104997.42188	, testing loss - 356878.56250	
11330	 steps: training loss - 82427.08594	, testing loss - 356902.53125	
11331	 steps: training loss - 104984.58594	, testing loss - 356546.18750	
11332	 steps: training loss - 110236.42969	, testing loss - 357184.78125	
11333	 steps: training loss - 114434.98438	, testing loss - 357135.50000	
11334	 steps: training loss - 107829.16406	, testing loss - 356337.18750	
11335	 steps: training loss - 120419.92188	, testing loss - 356005.65625	
11336	 steps: training loss - 106591.34375	, testing loss - 355032.25000	
11337	 steps: training loss - 124432.05469	, testing loss - 353922.40625	
11338	 steps: training loss - 96105.34375	, testing loss - 351991.68750	
11339	 steps: training loss - 100152.14062	, testing loss - 350076.68750	
11340	 steps: training loss - 115639.17969	, testing loss - 348648.34375	
11341	 steps: training loss - 104952.57812	, testing loss - 347646.78125	
11342	 steps: training loss - 105000.12500	, testing loss - 347611.93750	
11343	 steps: training loss - 122075.64844	, testing loss - 347765.00000	
11344	 steps: training loss - 100182.21094	, testing loss - 348184.71875	
11345	 steps: training loss - 109436.89844	, testing loss - 348598.09375	
11346	 steps: training loss - 97204.99219	, testing loss - 348474.03125	
11347	 steps: training loss - 97897.86719	, testing loss - 348159.37500	
11348	 steps: training loss - 110999.96875	, testing loss - 347623.28125	
11349	 steps: training loss - 116695.37500	, testing loss - 346282.34375	
11350	 steps: training loss - 102039.40625	, testing loss - 344285.00000	
11351	 steps: training loss - 89194.91406	, testing loss - 342954.03125	
11352	 steps: training loss - 99667.28906	, testing loss - 342113.65625	
11353	 steps: training loss - 106097.67969	, testing loss - 341628.34375	
11354	 steps: training loss - 125357.14062	, testing loss - 341364.28125	
11355	 steps: training loss - 69528.34375	, testing loss - 341408.34375	
11356	 steps: training loss - 120090.74219	, testing loss - 341713.96875	
11357	 steps: training loss - 117906.22656	, testing loss - 341870.59375	
11358	 steps: training loss - 119311.79688	, testing loss - 342530.25000	
11359	 steps: training loss - 96997.03906	, testing loss - 343818.87500	
11360	 steps: training loss - 102805.02344	, testing loss - 344895.09375	
11361	 steps: training loss - 119204.95312	, testing loss - 346181.68750	
11362	 steps: training loss - 155487.70312	, testing loss - 347471.56250	
11363	 steps: training loss - 119254.90625	, testing loss - 350056.53125	
11364	 steps: training loss - 111734.61719	, testing loss - 353315.18750	
11365	 steps: training loss - 103356.53125	, testing loss - 357013.03125	
11366	 steps: training loss - 117847.16406	, testing loss - 360235.68750	
11367	 steps: training loss - 103292.94531	, testing loss - 361166.37500	
11368	 steps: training loss - 102771.22656	, testing loss - 360625.90625	
11369	 steps: training loss - 138298.71875	, testing loss - 358289.09375	
11370	 steps: training loss - 106074.46875	, testing loss - 355326.78125	
11371	 steps: training loss - 120276.31250	, testing loss - 352225.40625	
11372	 steps: training loss - 101864.38281	, testing loss - 350368.62500	
11373	 steps: training loss - 120080.48438	, testing loss - 349584.59375	
11374	 steps: training loss - 108405.89844	, testing loss - 349290.81250	
11375	 steps: training loss - 114896.83594	, testing loss - 349956.28125	
11376	 steps: training loss - 84812.37500	, testing loss - 350608.90625	
11377	 steps: training loss - 103680.85156	, testing loss - 350448.68750	
11378	 steps: training loss - 99725.89844	, testing loss - 350040.90625	
11379	 steps: training loss - 110815.77344	, testing loss - 349545.59375	
11380	 steps: training loss - 96684.43750	, testing loss - 349557.75000	
11381	 steps: training loss - 118363.70312	, testing loss - 349338.90625	
11382	 steps: training loss - 113998.84375	, testing loss - 349145.31250	
11383	 steps: training loss - 74709.53125	, testing loss - 349315.93750	
11384	 steps: training loss - 107150.70312	, testing loss - 349814.62500	
11385	 steps: training loss - 103365.48438	, testing loss - 349836.18750	
11386	 steps: training loss - 101048.53125	, testing loss - 349625.12500	
11387	 steps: training loss - 128804.42969	, testing loss - 349159.03125	
11388	 steps: training loss - 123666.14844	, testing loss - 349704.00000	
11389	 steps: training loss - 103506.62500	, testing loss - 350088.28125	
11390	 steps: training loss - 134153.26562	, testing loss - 350078.00000	
11391	 steps: training loss - 112264.33594	, testing loss - 350588.65625	
11392	 steps: training loss - 127570.34375	, testing loss - 352131.12500	
11393	 steps: training loss - 127007.50781	, testing loss - 353795.12500	
11394	 steps: training loss - 108273.84375	, testing loss - 355444.03125	
11395	 steps: training loss - 125649.57031	, testing loss - 357727.50000	
11396	 steps: training loss - 82035.83594	, testing loss - 359745.87500	
11397	 steps: training loss - 128714.86719	, testing loss - 360426.56250	
11398	 steps: training loss - 96394.30469	, testing loss - 359205.06250	
11399	 steps: training loss - 101350.77344	, testing loss - 356189.21875	
11400	 steps: training loss - 115284.53906	, testing loss - 353345.25000	
11401	 steps: training loss - 110284.68750	, testing loss - 351509.28125	
11402	 steps: training loss - 117016.61719	, testing loss - 349444.81250	
11403	 steps: training loss - 109773.10156	, testing loss - 348231.93750	
11404	 steps: training loss - 97575.42188	, testing loss - 347445.53125	
11405	 steps: training loss - 101950.53125	, testing loss - 348154.25000	
11406	 steps: training loss - 105007.10156	, testing loss - 349721.25000	
11407	 steps: training loss - 82944.36719	, testing loss - 351999.12500	
11408	 steps: training loss - 112915.52344	, testing loss - 354248.53125	
11409	 steps: training loss - 114790.85938	, testing loss - 355662.12500	
11410	 steps: training loss - 94689.78906	, testing loss - 355887.43750	
11411	 steps: training loss - 106184.62500	, testing loss - 354887.06250	
11412	 steps: training loss - 89646.20312	, testing loss - 354117.28125	
11413	 steps: training loss - 100106.30469	, testing loss - 353621.09375	
11414	 steps: training loss - 109279.53906	, testing loss - 353256.40625	
11415	 steps: training loss - 104549.21875	, testing loss - 351968.53125	
11416	 steps: training loss - 140510.92188	, testing loss - 351378.93750	
11417	 steps: training loss - 111533.09375	, testing loss - 350804.87500	
11418	 steps: training loss - 92983.53125	, testing loss - 351136.53125	
11419	 steps: training loss - 105405.01562	, testing loss - 350851.59375	
11420	 steps: training loss - 110836.49219	, testing loss - 350049.75000	
11421	 steps: training loss - 97390.49219	, testing loss - 348445.56250	
11422	 steps: training loss - 107918.74219	, testing loss - 346642.81250	
11423	 steps: training loss - 89930.74219	, testing loss - 345371.06250	
11424	 steps: training loss - 90385.35938	, testing loss - 344194.90625	
11425	 steps: training loss - 97153.53906	, testing loss - 343305.18750	
11426	 steps: training loss - 87911.07812	, testing loss - 342361.59375	
11427	 steps: training loss - 110721.51562	, testing loss - 341788.21875	
11428	 steps: training loss - 70831.46875	, testing loss - 341063.84375	
11429	 steps: training loss - 107622.42188	, testing loss - 340307.81250	
11430	 steps: training loss - 109360.30469	, testing loss - 339881.53125	
11431	 steps: training loss - 124467.83594	, testing loss - 340648.12500	
11432	 steps: training loss - 107334.55469	, testing loss - 342832.46875	
11433	 steps: training loss - 106900.31250	, testing loss - 345507.96875	
11434	 steps: training loss - 92459.42188	, testing loss - 348250.56250	
11435	 steps: training loss - 130438.28125	, testing loss - 350889.56250	
11436	 steps: training loss - 110845.50000	, testing loss - 353341.87500	
11437	 steps: training loss - 123758.91406	, testing loss - 355551.96875	
11438	 steps: training loss - 99528.79688	, testing loss - 358060.15625	
11439	 steps: training loss - 87002.02344	, testing loss - 360073.03125	
11440	 steps: training loss - 101718.13281	, testing loss - 360536.43750	
11441	 steps: training loss - 96480.67188	, testing loss - 359452.31250	
11442	 steps: training loss - 90162.43750	, testing loss - 357470.43750	
11443	 steps: training loss - 120593.80469	, testing loss - 355949.96875	
11444	 steps: training loss - 114274.64844	, testing loss - 353787.65625	
11445	 steps: training loss - 82782.80469	, testing loss - 352640.75000	
11446	 steps: training loss - 87425.53125	, testing loss - 351892.34375	
11447	 steps: training loss - 102995.64062	, testing loss - 351504.53125	
11448	 steps: training loss - 100673.10156	, testing loss - 351405.59375	
11449	 steps: training loss - 107506.57812	, testing loss - 350282.56250	
11450	 steps: training loss - 102440.88281	, testing loss - 349348.75000	
11451	 steps: training loss - 89969.64844	, testing loss - 348672.43750	
11452	 steps: training loss - 110116.47656	, testing loss - 347923.90625	
11453	 steps: training loss - 112615.00000	, testing loss - 347849.21875	
11454	 steps: training loss - 101169.19531	, testing loss - 347942.43750	
11455	 steps: training loss - 97235.92969	, testing loss - 348084.34375	
11456	 steps: training loss - 100164.65625	, testing loss - 348790.62500	
11457	 steps: training loss - 99211.89844	, testing loss - 348818.28125	
11458	 steps: training loss - 131204.29688	, testing loss - 349139.37500	
11459	 steps: training loss - 108099.84375	, testing loss - 349457.34375	
11460	 steps: training loss - 116110.44531	, testing loss - 348892.03125	
11461	 steps: training loss - 95833.53906	, testing loss - 349273.15625	
11462	 steps: training loss - 107970.27344	, testing loss - 350431.06250	
11463	 steps: training loss - 118584.83594	, testing loss - 351646.68750	
11464	 steps: training loss - 87582.60156	, testing loss - 351579.00000	
11465	 steps: training loss - 113716.82031	, testing loss - 350639.09375	
11466	 steps: training loss - 106724.62500	, testing loss - 349242.68750	
11467	 steps: training loss - 107147.67188	, testing loss - 348458.65625	
11468	 steps: training loss - 104537.60156	, testing loss - 347636.00000	
11469	 steps: training loss - 109335.97656	, testing loss - 347371.15625	
11470	 steps: training loss - 108658.17969	, testing loss - 347237.59375	
11471	 steps: training loss - 125924.97656	, testing loss - 346730.96875	
11472	 steps: training loss - 107757.10156	, testing loss - 347031.50000	
11473	 steps: training loss - 98758.64844	, testing loss - 347496.06250	
11474	 steps: training loss - 121389.70312	, testing loss - 347870.28125	
11475	 steps: training loss - 109786.20312	, testing loss - 347185.18750	
11476	 steps: training loss - 109626.69531	, testing loss - 346151.68750	
11477	 steps: training loss - 102891.40625	, testing loss - 345363.37500	
11478	 steps: training loss - 116392.55469	, testing loss - 344731.84375	
11479	 steps: training loss - 130745.77344	, testing loss - 344354.87500	
11480	 steps: training loss - 120887.67969	, testing loss - 343890.06250	
11481	 steps: training loss - 122608.49219	, testing loss - 343681.28125	
11482	 steps: training loss - 100316.97656	, testing loss - 343772.09375	
11483	 steps: training loss - 94739.90625	, testing loss - 344727.18750	
11484	 steps: training loss - 101771.48438	, testing loss - 346008.46875	
11485	 steps: training loss - 84563.65625	, testing loss - 347010.21875	
11486	 steps: training loss - 114728.21875	, testing loss - 348756.56250	
11487	 steps: training loss - 123205.09375	, testing loss - 351025.00000	
11488	 steps: training loss - 110920.03125	, testing loss - 353916.65625	
11489	 steps: training loss - 101102.01562	, testing loss - 356342.18750	
11490	 steps: training loss - 80729.88281	, testing loss - 357313.50000	
11491	 steps: training loss - 87594.96875	, testing loss - 357569.93750	
11492	 steps: training loss - 96588.16406	, testing loss - 357638.18750	
11493	 steps: training loss - 92875.03125	, testing loss - 357340.53125	
11494	 steps: training loss - 98628.49219	, testing loss - 356452.68750	
11495	 steps: training loss - 107047.21094	, testing loss - 355218.62500	
11496	 steps: training loss - 90779.35156	, testing loss - 354029.62500	
11497	 steps: training loss - 122059.38281	, testing loss - 352768.78125	
11498	 steps: training loss - 115180.18750	, testing loss - 351274.37500	
11499	 steps: training loss - 111451.95312	, testing loss - 349919.28125	
11500	 steps: training loss - 115132.28906	, testing loss - 349260.53125	
11501	 steps: training loss - 123651.78906	, testing loss - 348615.46875	
11502	 steps: training loss - 101941.96094	, testing loss - 348583.37500	
11503	 steps: training loss - 87821.77344	, testing loss - 349579.96875	
11504	 steps: training loss - 83394.71094	, testing loss - 351375.87500	
11505	 steps: training loss - 144895.10938	, testing loss - 352935.50000	
11506	 steps: training loss - 97662.69531	, testing loss - 353961.00000	
11507	 steps: training loss - 95296.89062	, testing loss - 353918.40625	
11508	 steps: training loss - 98301.69531	, testing loss - 353336.75000	
11509	 steps: training loss - 110901.36719	, testing loss - 352155.37500	
11510	 steps: training loss - 94783.89062	, testing loss - 351495.28125	
11511	 steps: training loss - 99651.08594	, testing loss - 351092.50000	
11512	 steps: training loss - 119223.00000	, testing loss - 351019.31250	
11513	 steps: training loss - 105587.01562	, testing loss - 350666.90625	
11514	 steps: training loss - 116090.03906	, testing loss - 349864.03125	
11515	 steps: training loss - 100040.33594	, testing loss - 349183.62500	
11516	 steps: training loss - 109205.11719	, testing loss - 349092.12500	
11517	 steps: training loss - 78712.91406	, testing loss - 349620.18750	
11518	 steps: training loss - 85695.62500	, testing loss - 350147.59375	
11519	 steps: training loss - 122190.22656	, testing loss - 351182.15625	
11520	 steps: training loss - 133817.39062	, testing loss - 351730.81250	
11521	 steps: training loss - 101977.12500	, testing loss - 352851.53125	
11522	 steps: training loss - 89312.37500	, testing loss - 353521.56250	
11523	 steps: training loss - 116581.43750	, testing loss - 353510.37500	
11524	 steps: training loss - 87727.36719	, testing loss - 353204.78125	
11525	 steps: training loss - 117199.61719	, testing loss - 352364.34375	
11526	 steps: training loss - 100007.10156	, testing loss - 351141.59375	
11527	 steps: training loss - 104822.86719	, testing loss - 349725.43750	
11528	 steps: training loss - 135361.53125	, testing loss - 348166.03125	
11529	 steps: training loss - 109901.70312	, testing loss - 346260.43750	
11530	 steps: training loss - 115497.53125	, testing loss - 345206.37500	
11531	 steps: training loss - 118256.08594	, testing loss - 344677.56250	
11532	 steps: training loss - 113017.81250	, testing loss - 344310.65625	
11533	 steps: training loss - 99293.41406	, testing loss - 345114.43750	
11534	 steps: training loss - 123248.52344	, testing loss - 345500.93750	
11535	 steps: training loss - 95421.48438	, testing loss - 345606.93750	
11536	 steps: training loss - 101618.53125	, testing loss - 345946.34375	
11537	 steps: training loss - 111907.46875	, testing loss - 345738.78125	
11538	 steps: training loss - 112199.30469	, testing loss - 344987.46875	
11539	 steps: training loss - 138343.46875	, testing loss - 344031.00000	
11540	 steps: training loss - 119674.60156	, testing loss - 343727.53125	
11541	 steps: training loss - 107170.40625	, testing loss - 344116.12500	
11542	 steps: training loss - 74984.80469	, testing loss - 344879.15625	
11543	 steps: training loss - 94274.71094	, testing loss - 346213.25000	
11544	 steps: training loss - 112817.89844	, testing loss - 347895.81250	
11545	 steps: training loss - 121482.32031	, testing loss - 349265.87500	
11546	 steps: training loss - 107793.14062	, testing loss - 350351.87500	
11547	 steps: training loss - 125564.28125	, testing loss - 350825.46875	
11548	 steps: training loss - 110647.70312	, testing loss - 351040.93750	
11549	 steps: training loss - 127849.22656	, testing loss - 352158.75000	
11550	 steps: training loss - 102629.35938	, testing loss - 354087.03125	
11551	 steps: training loss - 103632.42188	, testing loss - 355773.43750	
11552	 steps: training loss - 113274.71875	, testing loss - 356467.90625	
11553	 steps: training loss - 110005.14844	, testing loss - 356120.53125	
11554	 steps: training loss - 99008.44531	, testing loss - 355366.53125	
11555	 steps: training loss - 100829.67969	, testing loss - 355389.78125	
11556	 steps: training loss - 86313.32031	, testing loss - 356433.65625	
11557	 steps: training loss - 105854.67969	, testing loss - 358155.59375	
11558	 steps: training loss - 108287.36719	, testing loss - 358979.68750	
11559	 steps: training loss - 119453.85938	, testing loss - 358928.46875	
11560	 steps: training loss - 109821.89062	, testing loss - 358070.68750	
11561	 steps: training loss - 115182.86719	, testing loss - 356349.37500	
11562	 steps: training loss - 101286.50000	, testing loss - 353638.78125	
11563	 steps: training loss - 132400.03125	, testing loss - 350882.62500	
11564	 steps: training loss - 131428.87500	, testing loss - 347970.03125	
11565	 steps: training loss - 112549.95312	, testing loss - 345112.62500	
11566	 steps: training loss - 104778.40625	, testing loss - 343433.25000	
11567	 steps: training loss - 97927.55469	, testing loss - 342093.71875	
11568	 steps: training loss - 103774.72656	, testing loss - 342149.56250	
11569	 steps: training loss - 107773.10938	, testing loss - 341863.62500	
11570	 steps: training loss - 86334.50781	, testing loss - 341127.25000	
11571	 steps: training loss - 108122.25000	, testing loss - 340819.09375	
11572	 steps: training loss - 129889.26562	, testing loss - 340547.96875	
11573	 steps: training loss - 97624.50000	, testing loss - 340248.18750	
11574	 steps: training loss - 122948.49219	, testing loss - 340002.50000	
11575	 steps: training loss - 100093.69531	, testing loss - 340126.78125	
11576	 steps: training loss - 132431.62500	, testing loss - 340012.34375	
11577	 steps: training loss - 122192.50000	, testing loss - 339111.37500	
11578	 steps: training loss - 114162.31250	, testing loss - 338412.78125	
11579	 steps: training loss - 101302.16406	, testing loss - 337473.46875	
11580	 steps: training loss - 114660.40625	, testing loss - 336774.15625	
11581	 steps: training loss - 125008.12500	, testing loss - 336090.56250	
11582	 steps: training loss - 114482.06250	, testing loss - 336393.65625	
11583	 steps: training loss - 102759.19531	, testing loss - 337049.37500	
11584	 steps: training loss - 112766.76562	, testing loss - 338083.43750	
11585	 steps: training loss - 107735.39844	, testing loss - 339838.87500	
11586	 steps: training loss - 95171.20312	, testing loss - 341437.87500	
11587	 steps: training loss - 114495.60938	, testing loss - 342851.81250	
11588	 steps: training loss - 137503.18750	, testing loss - 344022.90625	
11589	 steps: training loss - 108164.42969	, testing loss - 344826.78125	
11590	 steps: training loss - 104369.21875	, testing loss - 345540.18750	
11591	 steps: training loss - 117856.81250	, testing loss - 346667.15625	
11592	 steps: training loss - 103202.17188	, testing loss - 347884.75000	
11593	 steps: training loss - 100569.03906	, testing loss - 349853.87500	
11594	 steps: training loss - 97397.00781	, testing loss - 351356.06250	
11595	 steps: training loss - 112748.93750	, testing loss - 352476.18750	
11596	 steps: training loss - 122155.99219	, testing loss - 354052.84375	
11597	 steps: training loss - 116233.46094	, testing loss - 355256.46875	
11598	 steps: training loss - 84384.97656	, testing loss - 356522.75000	
11599	 steps: training loss - 99466.70312	, testing loss - 356579.59375	
11600	 steps: training loss - 111686.00000	, testing loss - 356211.15625	
11601	 steps: training loss - 117799.00781	, testing loss - 354825.06250	
11602	 steps: training loss - 113272.65625	, testing loss - 353042.37500	
11603	 steps: training loss - 99034.21094	, testing loss - 351164.06250	
11604	 steps: training loss - 118833.75781	, testing loss - 350178.84375	
11605	 steps: training loss - 120860.71094	, testing loss - 349516.15625	
11606	 steps: training loss - 91826.85156	, testing loss - 350743.65625	
11607	 steps: training loss - 103385.87500	, testing loss - 353111.18750	
11608	 steps: training loss - 99527.77344	, testing loss - 354844.28125	
11609	 steps: training loss - 121538.35156	, testing loss - 356391.25000	
11610	 steps: training loss - 102248.07812	, testing loss - 358641.75000	
11611	 steps: training loss - 106060.82812	, testing loss - 359605.21875	
11612	 steps: training loss - 100873.32031	, testing loss - 358633.34375	
11613	 steps: training loss - 114507.55469	, testing loss - 357346.84375	
11614	 steps: training loss - 110530.35156	, testing loss - 355487.34375	
11615	 steps: training loss - 107959.15625	, testing loss - 352908.81250	
11616	 steps: training loss - 122323.25000	, testing loss - 349650.75000	
11617	 steps: training loss - 107629.75781	, testing loss - 347096.12500	
11618	 steps: training loss - 87154.90625	, testing loss - 345382.84375	
11619	 steps: training loss - 121897.78906	, testing loss - 344702.03125	
11620	 steps: training loss - 95188.38281	, testing loss - 344759.96875	
11621	 steps: training loss - 112248.39062	, testing loss - 345415.59375	
11622	 steps: training loss - 124611.57812	, testing loss - 346187.06250	
11623	 steps: training loss - 99995.37500	, testing loss - 347060.50000	
11624	 steps: training loss - 139950.56250	, testing loss - 347948.43750	
11625	 steps: training loss - 127892.38281	, testing loss - 349113.68750	
11626	 steps: training loss - 119320.25781	, testing loss - 350409.50000	
11627	 steps: training loss - 100389.01562	, testing loss - 352235.75000	
11628	 steps: training loss - 124251.33594	, testing loss - 353588.43750	
11629	 steps: training loss - 100585.01562	, testing loss - 354025.59375	
11630	 steps: training loss - 95521.31250	, testing loss - 353949.43750	
11631	 steps: training loss - 119264.75781	, testing loss - 353204.93750	
11632	 steps: training loss - 117121.07812	, testing loss - 353038.46875	
11633	 steps: training loss - 83828.84375	, testing loss - 353526.78125	
11634	 steps: training loss - 87732.46875	, testing loss - 354509.68750	
11635	 steps: training loss - 88937.60156	, testing loss - 354458.50000	
11636	 steps: training loss - 113730.65625	, testing loss - 353905.96875	
11637	 steps: training loss - 110927.98438	, testing loss - 353377.28125	
11638	 steps: training loss - 105038.63281	, testing loss - 352856.96875	
11639	 steps: training loss - 95632.00781	, testing loss - 352718.62500	
11640	 steps: training loss - 98575.79688	, testing loss - 353238.53125	
11641	 steps: training loss - 127196.17188	, testing loss - 355045.15625	
11642	 steps: training loss - 110832.65625	, testing loss - 356819.37500	
11643	 steps: training loss - 98072.10156	, testing loss - 357997.46875	
11644	 steps: training loss - 125527.90625	, testing loss - 357763.40625	
11645	 steps: training loss - 98216.60938	, testing loss - 357188.12500	
11646	 steps: training loss - 102630.64062	, testing loss - 356227.00000	
11647	 steps: training loss - 79232.38281	, testing loss - 355827.93750	
11648	 steps: training loss - 130083.78125	, testing loss - 354889.75000	
11649	 steps: training loss - 111202.97656	, testing loss - 353384.34375	
11650	 steps: training loss - 126165.55469	, testing loss - 351976.56250	
11651	 steps: training loss - 89488.67188	, testing loss - 350366.56250	
11652	 steps: training loss - 105908.84375	, testing loss - 348246.46875	
11653	 steps: training loss - 111238.44531	, testing loss - 346028.56250	
11654	 steps: training loss - 84608.76562	, testing loss - 344245.43750	
11655	 steps: training loss - 84056.20312	, testing loss - 343334.15625	
11656	 steps: training loss - 128683.16406	, testing loss - 342719.90625	
11657	 steps: training loss - 105509.53906	, testing loss - 343568.46875	
11658	 steps: training loss - 97991.15625	, testing loss - 344879.43750	
11659	 steps: training loss - 120493.35938	, testing loss - 347020.06250	
11660	 steps: training loss - 120129.65625	, testing loss - 348815.06250	
11661	 steps: training loss - 92214.54688	, testing loss - 349593.62500	
11662	 steps: training loss - 109069.84375	, testing loss - 350031.40625	
11663	 steps: training loss - 112409.25781	, testing loss - 350065.21875	
11664	 steps: training loss - 88106.16406	, testing loss - 349558.59375	
11665	 steps: training loss - 120609.76562	, testing loss - 349119.96875	
11666	 steps: training loss - 107503.47656	, testing loss - 349080.53125	
11667	 steps: training loss - 92200.69531	, testing loss - 348551.78125	
11668	 steps: training loss - 125378.14062	, testing loss - 347672.12500	
11669	 steps: training loss - 95494.71094	, testing loss - 347203.37500	
11670	 steps: training loss - 108823.65625	, testing loss - 346772.56250	
11671	 steps: training loss - 94395.54688	, testing loss - 346256.53125	
11672	 steps: training loss - 113378.93750	, testing loss - 345418.37500	
11673	 steps: training loss - 109223.79688	, testing loss - 343991.78125	
11674	 steps: training loss - 112350.57031	, testing loss - 342706.18750	
11675	 steps: training loss - 99025.94531	, testing loss - 342135.93750	
11676	 steps: training loss - 109238.14062	, testing loss - 341202.46875	
11677	 steps: training loss - 108470.22656	, testing loss - 340958.06250	
11678	 steps: training loss - 128350.99219	, testing loss - 341425.15625	
11679	 steps: training loss - 122897.07031	, testing loss - 342345.34375	
11680	 steps: training loss - 108910.23438	, testing loss - 342722.75000	
11681	 steps: training loss - 100640.08594	, testing loss - 343630.37500	
11682	 steps: training loss - 133884.84375	, testing loss - 344451.50000	
11683	 steps: training loss - 84978.87500	, testing loss - 345569.15625	
11684	 steps: training loss - 124094.12500	, testing loss - 346344.68750	
11685	 steps: training loss - 111093.61719	, testing loss - 347947.09375	
11686	 steps: training loss - 143549.29688	, testing loss - 349946.68750	
11687	 steps: training loss - 107331.09375	, testing loss - 351517.78125	
11688	 steps: training loss - 105584.88281	, testing loss - 353480.31250	
11689	 steps: training loss - 126856.67188	, testing loss - 355641.78125	
11690	 steps: training loss - 108644.56250	, testing loss - 357345.90625	
11691	 steps: training loss - 133663.43750	, testing loss - 357711.31250	
11692	 steps: training loss - 102413.95312	, testing loss - 358034.18750	
11693	 steps: training loss - 130832.47656	, testing loss - 357606.37500	
11694	 steps: training loss - 129868.46094	, testing loss - 356133.87500	
11695	 steps: training loss - 100850.42188	, testing loss - 352984.93750	
11696	 steps: training loss - 127006.60938	, testing loss - 350782.09375	
11697	 steps: training loss - 99182.98438	, testing loss - 349313.37500	
11698	 steps: training loss - 105610.76562	, testing loss - 347525.90625	
11699	 steps: training loss - 130385.38281	, testing loss - 346393.65625	
11700	 steps: training loss - 108744.51562	, testing loss - 345188.87500	
11701	 steps: training loss - 118285.59375	, testing loss - 344227.78125	
11702	 steps: training loss - 118914.64062	, testing loss - 344212.50000	
11703	 steps: training loss - 103504.53906	, testing loss - 345699.12500	
11704	 steps: training loss - 96103.43750	, testing loss - 347217.21875	
11705	 steps: training loss - 111027.02344	, testing loss - 348285.18750	
11706	 steps: training loss - 109236.92188	, testing loss - 349030.75000	
11707	 steps: training loss - 109842.32031	, testing loss - 349704.59375	
11708	 steps: training loss - 107825.30469	, testing loss - 350138.71875	
11709	 steps: training loss - 111479.15625	, testing loss - 350179.75000	
11710	 steps: training loss - 120736.30469	, testing loss - 350070.50000	
11711	 steps: training loss - 116347.39844	, testing loss - 349531.21875	
11712	 steps: training loss - 117734.93750	, testing loss - 348991.25000	
11713	 steps: training loss - 132515.39062	, testing loss - 347926.71875	
11714	 steps: training loss - 100591.47656	, testing loss - 348366.06250	
11715	 steps: training loss - 116895.72656	, testing loss - 348464.03125	
11716	 steps: training loss - 140188.40625	, testing loss - 347375.25000	
11717	 steps: training loss - 119985.84375	, testing loss - 346356.31250	
11718	 steps: training loss - 109701.71875	, testing loss - 345991.03125	
11719	 steps: training loss - 112265.98438	, testing loss - 345768.28125	
11720	 steps: training loss - 119573.33594	, testing loss - 345044.43750	
11721	 steps: training loss - 115136.14844	, testing loss - 344156.43750	
11722	 steps: training loss - 135955.12500	, testing loss - 343637.09375	
11723	 steps: training loss - 115289.02344	, testing loss - 343444.25000	
11724	 steps: training loss - 111649.96094	, testing loss - 343787.56250	
11725	 steps: training loss - 127417.12500	, testing loss - 343845.37500	
11726	 steps: training loss - 109143.96094	, testing loss - 344919.78125	
11727	 steps: training loss - 96105.47656	, testing loss - 345515.50000	
11728	 steps: training loss - 116958.78125	, testing loss - 345364.53125	
11729	 steps: training loss - 84330.34375	, testing loss - 345090.71875	
11730	 steps: training loss - 109828.75000	, testing loss - 345119.68750	
11731	 steps: training loss - 104304.04688	, testing loss - 344946.90625	
11732	 steps: training loss - 91824.09375	, testing loss - 345324.87500	
11733	 steps: training loss - 93583.81250	, testing loss - 344935.78125	
11734	 steps: training loss - 114218.87500	, testing loss - 344095.00000	
11735	 steps: training loss - 110593.60156	, testing loss - 343214.43750	
11736	 steps: training loss - 95016.36719	, testing loss - 342412.46875	
11737	 steps: training loss - 117238.72656	, testing loss - 341463.06250	
11738	 steps: training loss - 118524.43750	, testing loss - 340731.37500	
11739	 steps: training loss - 119546.53125	, testing loss - 340550.25000	
11740	 steps: training loss - 89719.88281	, testing loss - 340229.03125	
11741	 steps: training loss - 101174.73438	, testing loss - 339524.53125	
11742	 steps: training loss - 90597.32031	, testing loss - 338431.96875	
11743	 steps: training loss - 93194.29688	, testing loss - 337062.46875	
11744	 steps: training loss - 135075.68750	, testing loss - 335613.06250	
11745	 steps: training loss - 124456.39844	, testing loss - 334632.78125	
11746	 steps: training loss - 106360.28906	, testing loss - 333940.87500	
11747	 steps: training loss - 104696.38281	, testing loss - 333470.90625	
11748	 steps: training loss - 110634.64062	, testing loss - 333368.93750	
11749	 steps: training loss - 95863.25000	, testing loss - 333825.40625	
11750	 steps: training loss - 95855.92969	, testing loss - 334674.25000	
11751	 steps: training loss - 107171.25781	, testing loss - 336029.50000	
11752	 steps: training loss - 113016.61719	, testing loss - 337410.90625	
11753	 steps: training loss - 136726.48438	, testing loss - 337614.46875	
11754	 steps: training loss - 89089.75000	, testing loss - 337713.34375	
11755	 steps: training loss - 97573.44531	, testing loss - 337525.65625	
11756	 steps: training loss - 118600.27344	, testing loss - 337332.75000	
11757	 steps: training loss - 117780.85156	, testing loss - 337429.81250	
11758	 steps: training loss - 110422.73438	, testing loss - 337862.78125	
11759	 steps: training loss - 98445.80469	, testing loss - 338388.71875	
11760	 steps: training loss - 95488.85938	, testing loss - 339315.25000	
11761	 steps: training loss - 111771.01562	, testing loss - 340362.93750	
11762	 steps: training loss - 93074.37500	, testing loss - 341340.00000	
11763	 steps: training loss - 98741.75781	, testing loss - 341234.46875	
11764	 steps: training loss - 113962.39062	, testing loss - 340054.62500	
11765	 steps: training loss - 112120.22656	, testing loss - 338852.28125	
11766	 steps: training loss - 115370.03125	, testing loss - 338082.18750	
11767	 steps: training loss - 90373.83594	, testing loss - 337435.59375	
11768	 steps: training loss - 140472.60938	, testing loss - 337049.56250	
11769	 steps: training loss - 106960.78906	, testing loss - 336649.71875	
11770	 steps: training loss - 133710.85938	, testing loss - 336561.15625	
11771	 steps: training loss - 85440.63281	, testing loss - 337056.65625	
11772	 steps: training loss - 108643.91406	, testing loss - 337474.03125	
11773	 steps: training loss - 116275.02344	, testing loss - 338007.84375	
11774	 steps: training loss - 92006.03125	, testing loss - 339239.15625	
11775	 steps: training loss - 98537.72656	, testing loss - 341137.71875	
11776	 steps: training loss - 123598.42188	, testing loss - 342842.96875	
11777	 steps: training loss - 100639.00781	, testing loss - 344676.18750	
11778	 steps: training loss - 106737.96094	, testing loss - 347175.09375	
11779	 steps: training loss - 107413.28125	, testing loss - 349076.43750	
11780	 steps: training loss - 109108.88281	, testing loss - 350321.78125	
11781	 steps: training loss - 116852.49219	, testing loss - 351751.43750	
11782	 steps: training loss - 116385.40625	, testing loss - 352144.25000	
11783	 steps: training loss - 84149.28906	, testing loss - 351830.03125	
11784	 steps: training loss - 95883.52344	, testing loss - 351671.68750	
11785	 steps: training loss - 104515.39062	, testing loss - 351114.75000	
11786	 steps: training loss - 113807.57812	, testing loss - 350478.90625	
11787	 steps: training loss - 128933.65625	, testing loss - 349814.50000	
11788	 steps: training loss - 99499.87500	, testing loss - 349209.21875	
11789	 steps: training loss - 110420.19531	, testing loss - 348922.90625	
11790	 steps: training loss - 123433.70312	, testing loss - 348438.00000	
11791	 steps: training loss - 122163.02344	, testing loss - 347200.78125	
11792	 steps: training loss - 76704.60938	, testing loss - 346071.50000	
11793	 steps: training loss - 101446.31250	, testing loss - 346269.93750	
11794	 steps: training loss - 115462.37500	, testing loss - 346209.21875	
11795	 steps: training loss - 110229.60156	, testing loss - 346030.28125	
11796	 steps: training loss - 119407.00781	, testing loss - 345695.90625	
11797	 steps: training loss - 131076.93750	, testing loss - 344838.93750	
11798	 steps: training loss - 112233.18750	, testing loss - 343783.62500	
11799	 steps: training loss - 97888.66406	, testing loss - 343502.93750	
11800	 steps: training loss - 103579.21094	, testing loss - 343247.93750	
11801	 steps: training loss - 117513.53906	, testing loss - 342963.25000	
11802	 steps: training loss - 109679.75781	, testing loss - 344445.09375	
11803	 steps: training loss - 96919.24219	, testing loss - 346695.25000	
11804	 steps: training loss - 120036.50781	, testing loss - 348983.12500	
11805	 steps: training loss - 106885.18750	, testing loss - 351753.00000	
11806	 steps: training loss - 113069.46094	, testing loss - 354446.81250	
11807	 steps: training loss - 97995.93750	, testing loss - 356823.78125	
11808	 steps: training loss - 88559.50000	, testing loss - 359214.78125	
11809	 steps: training loss - 99003.37500	, testing loss - 360296.31250	
11810	 steps: training loss - 97722.48438	, testing loss - 361710.65625	
11811	 steps: training loss - 101365.25000	, testing loss - 361636.31250	
11812	 steps: training loss - 104285.28906	, testing loss - 360705.65625	
11813	 steps: training loss - 132720.35938	, testing loss - 359357.50000	
11814	 steps: training loss - 99231.82031	, testing loss - 358263.43750	
11815	 steps: training loss - 93836.26562	, testing loss - 356513.03125	
11816	 steps: training loss - 95014.94531	, testing loss - 354148.15625	
11817	 steps: training loss - 119867.90625	, testing loss - 352179.34375	
11818	 steps: training loss - 88918.35938	, testing loss - 350620.34375	
11819	 steps: training loss - 120216.91406	, testing loss - 349447.21875	
11820	 steps: training loss - 110301.57031	, testing loss - 347571.40625	
11821	 steps: training loss - 111837.41406	, testing loss - 345701.96875	
11822	 steps: training loss - 104649.30469	, testing loss - 344749.28125	
11823	 steps: training loss - 100288.79688	, testing loss - 343775.96875	
11824	 steps: training loss - 126267.41406	, testing loss - 343729.15625	
11825	 steps: training loss - 140415.40625	, testing loss - 344640.28125	
11826	 steps: training loss - 89272.67188	, testing loss - 345106.50000	
11827	 steps: training loss - 113288.60938	, testing loss - 345884.59375	
11828	 steps: training loss - 109807.50000	, testing loss - 346610.96875	
11829	 steps: training loss - 121650.99219	, testing loss - 346158.00000	
11830	 steps: training loss - 110839.25000	, testing loss - 345749.81250	
11831	 steps: training loss - 103043.69531	, testing loss - 345519.62500	
11832	 steps: training loss - 108874.60938	, testing loss - 345198.06250	
11833	 steps: training loss - 107627.18750	, testing loss - 345066.46875	
11834	 steps: training loss - 117479.59375	, testing loss - 345277.68750	
11835	 steps: training loss - 91471.36719	, testing loss - 345399.96875	
11836	 steps: training loss - 102500.63281	, testing loss - 345223.43750	
11837	 steps: training loss - 112595.71875	, testing loss - 344928.31250	
11838	 steps: training loss - 114831.64062	, testing loss - 345208.15625	
11839	 steps: training loss - 107732.67188	, testing loss - 345619.28125	
11840	 steps: training loss - 126195.94531	, testing loss - 346374.46875	
11841	 steps: training loss - 115258.90625	, testing loss - 348057.65625	
11842	 steps: training loss - 110028.25000	, testing loss - 349513.53125	
11843	 steps: training loss - 100432.39844	, testing loss - 350538.90625	
11844	 steps: training loss - 130638.72656	, testing loss - 350331.21875	
11845	 steps: training loss - 95851.24219	, testing loss - 349836.03125	
11846	 steps: training loss - 94801.83594	, testing loss - 349055.81250	
11847	 steps: training loss - 122801.88281	, testing loss - 347941.03125	
11848	 steps: training loss - 97335.46875	, testing loss - 346508.09375	
11849	 steps: training loss - 114924.67188	, testing loss - 344836.56250	
11850	 steps: training loss - 114910.92188	, testing loss - 343544.25000	
11851	 steps: training loss - 120146.42188	, testing loss - 342369.37500	
11852	 steps: training loss - 111368.85156	, testing loss - 341890.28125	
11853	 steps: training loss - 90216.21875	, testing loss - 342084.00000	
11854	 steps: training loss - 116736.89062	, testing loss - 341973.59375	
11855	 steps: training loss - 93981.53906	, testing loss - 341507.06250	
11856	 steps: training loss - 101850.41406	, testing loss - 341031.59375	
11857	 steps: training loss - 86669.73438	, testing loss - 340772.12500	
11858	 steps: training loss - 126315.96875	, testing loss - 340323.03125	
11859	 steps: training loss - 91335.64844	, testing loss - 340240.75000	
11860	 steps: training loss - 92436.35938	, testing loss - 340967.84375	
11861	 steps: training loss - 90866.40625	, testing loss - 342550.09375	
11862	 steps: training loss - 105630.46875	, testing loss - 344222.53125	
11863	 steps: training loss - 126668.30469	, testing loss - 345404.59375	
11864	 steps: training loss - 104829.48438	, testing loss - 346635.34375	
11865	 steps: training loss - 109235.30469	, testing loss - 347182.56250	
11866	 steps: training loss - 112359.82812	, testing loss - 346953.18750	
11867	 steps: training loss - 100662.16406	, testing loss - 346922.37500	
11868	 steps: training loss - 78904.72656	, testing loss - 346803.25000	
11869	 steps: training loss - 90371.82812	, testing loss - 346880.50000	
11870	 steps: training loss - 127692.05469	, testing loss - 346511.00000	
11871	 steps: training loss - 111327.03906	, testing loss - 345423.62500	
11872	 steps: training loss - 90897.19531	, testing loss - 343887.46875	
11873	 steps: training loss - 113865.67188	, testing loss - 342318.87500	
11874	 steps: training loss - 124456.06250	, testing loss - 340981.21875	
11875	 steps: training loss - 128239.53906	, testing loss - 339828.03125	
11876	 steps: training loss - 112578.89844	, testing loss - 339593.28125	
11877	 steps: training loss - 87170.92188	, testing loss - 340363.59375	
11878	 steps: training loss - 102779.53125	, testing loss - 341117.18750	
11879	 steps: training loss - 107885.46875	, testing loss - 341414.21875	
11880	 steps: training loss - 126033.54688	, testing loss - 341988.50000	
11881	 steps: training loss - 91714.67188	, testing loss - 343351.18750	
11882	 steps: training loss - 114904.41406	, testing loss - 345392.25000	
11883	 steps: training loss - 96524.61719	, testing loss - 346956.40625	
11884	 steps: training loss - 87571.81250	, testing loss - 349399.75000	
11885	 steps: training loss - 82922.27344	, testing loss - 352255.25000	
11886	 steps: training loss - 121978.97656	, testing loss - 354692.75000	
11887	 steps: training loss - 114512.53906	, testing loss - 357120.50000	
11888	 steps: training loss - 91132.72656	, testing loss - 357883.71875	
11889	 steps: training loss - 111817.52344	, testing loss - 356947.96875	
11890	 steps: training loss - 96381.03125	, testing loss - 355718.62500	
11891	 steps: training loss - 118577.99219	, testing loss - 354484.53125	
11892	 steps: training loss - 138024.01562	, testing loss - 353171.71875	
11893	 steps: training loss - 123867.46094	, testing loss - 351528.81250	
11894	 steps: training loss - 85505.09375	, testing loss - 349808.12500	
11895	 steps: training loss - 119111.50000	, testing loss - 347945.09375	
11896	 steps: training loss - 92605.25000	, testing loss - 345864.34375	
11897	 steps: training loss - 129504.22656	, testing loss - 343906.93750	
11898	 steps: training loss - 123323.14062	, testing loss - 342360.40625	
11899	 steps: training loss - 117786.34375	, testing loss - 341660.59375	
11900	 steps: training loss - 93439.06250	, testing loss - 341972.06250	
11901	 steps: training loss - 104471.85938	, testing loss - 342252.50000	
11902	 steps: training loss - 103463.06250	, testing loss - 342558.87500	
11903	 steps: training loss - 100301.97656	, testing loss - 343607.59375	
11904	 steps: training loss - 113458.05469	, testing loss - 344843.78125	
11905	 steps: training loss - 109041.17969	, testing loss - 346161.46875	
11906	 steps: training loss - 99276.62500	, testing loss - 346409.90625	
11907	 steps: training loss - 120771.79688	, testing loss - 346579.68750	
11908	 steps: training loss - 118553.12500	, testing loss - 346974.37500	
11909	 steps: training loss - 125501.35938	, testing loss - 347881.40625	
11910	 steps: training loss - 100693.82031	, testing loss - 348703.40625	
11911	 steps: training loss - 120571.09375	, testing loss - 349264.90625	
11912	 steps: training loss - 92699.28906	, testing loss - 350486.59375	
11913	 steps: training loss - 124328.94531	, testing loss - 351556.84375	
11914	 steps: training loss - 115952.85156	, testing loss - 353711.84375	
11915	 steps: training loss - 140887.09375	, testing loss - 355462.00000	
11916	 steps: training loss - 107286.40625	, testing loss - 356992.43750	
11917	 steps: training loss - 104813.70312	, testing loss - 357930.25000	
11918	 steps: training loss - 132616.98438	, testing loss - 358292.87500	
11919	 steps: training loss - 111493.67188	, testing loss - 358222.96875	
11920	 steps: training loss - 80796.81250	, testing loss - 358426.00000	
11921	 steps: training loss - 103750.21875	, testing loss - 357979.31250	
11922	 steps: training loss - 120898.52344	, testing loss - 356639.31250	
11923	 steps: training loss - 120053.53125	, testing loss - 354885.03125	
11924	 steps: training loss - 116186.96094	, testing loss - 353315.53125	
11925	 steps: training loss - 126582.99219	, testing loss - 351794.18750	
11926	 steps: training loss - 134146.21875	, testing loss - 350087.15625	
11927	 steps: training loss - 129127.50781	, testing loss - 348319.40625	
11928	 steps: training loss - 105970.59375	, testing loss - 347971.40625	
11929	 steps: training loss - 83443.46875	, testing loss - 347556.84375	
11930	 steps: training loss - 126765.07812	, testing loss - 346641.03125	
11931	 steps: training loss - 110644.99219	, testing loss - 346931.25000	
11932	 steps: training loss - 100968.68750	, testing loss - 347063.81250	
11933	 steps: training loss - 122100.59375	, testing loss - 346920.96875	
11934	 steps: training loss - 134956.87500	, testing loss - 346834.75000	
11935	 steps: training loss - 103875.91406	, testing loss - 346404.68750	
11936	 steps: training loss - 84037.26562	, testing loss - 346347.00000	
11937	 steps: training loss - 117300.12500	, testing loss - 346114.75000	
11938	 steps: training loss - 116690.55469	, testing loss - 346108.43750	
11939	 steps: training loss - 102679.34375	, testing loss - 345356.34375	
11940	 steps: training loss - 90566.97656	, testing loss - 344755.43750	
11941	 steps: training loss - 129389.66406	, testing loss - 344438.59375	
11942	 steps: training loss - 127629.23438	, testing loss - 344157.93750	
11943	 steps: training loss - 105784.39062	, testing loss - 344474.84375	
11944	 steps: training loss - 97986.00000	, testing loss - 345174.96875	
11945	 steps: training loss - 95359.70312	, testing loss - 345637.78125	
11946	 steps: training loss - 108278.15625	, testing loss - 346569.50000	
11947	 steps: training loss - 134407.20312	, testing loss - 347472.40625	
11948	 steps: training loss - 95590.19531	, testing loss - 350319.18750	
11949	 steps: training loss - 113366.16406	, testing loss - 353784.56250	
11950	 steps: training loss - 131746.14062	, testing loss - 358862.28125	
11951	 steps: training loss - 116492.33594	, testing loss - 364704.62500	
11952	 steps: training loss - 130430.73438	, testing loss - 369083.65625	
11953	 steps: training loss - 105975.52344	, testing loss - 370100.84375	
11954	 steps: training loss - 111459.92969	, testing loss - 369702.18750	
11955	 steps: training loss - 129368.61719	, testing loss - 368878.68750	
11956	 steps: training loss - 115960.96094	, testing loss - 366295.81250	
11957	 steps: training loss - 108392.31250	, testing loss - 361926.62500	
11958	 steps: training loss - 117563.70312	, testing loss - 357350.71875	
11959	 steps: training loss - 109131.10156	, testing loss - 355713.84375	
11960	 steps: training loss - 85982.42188	, testing loss - 354603.50000	
11961	 steps: training loss - 93477.58594	, testing loss - 353239.68750	
11962	 steps: training loss - 98966.37500	, testing loss - 351975.21875	
11963	 steps: training loss - 112758.10938	, testing loss - 350532.62500	
11964	 steps: training loss - 76220.14844	, testing loss - 349904.75000	
11965	 steps: training loss - 106593.68750	, testing loss - 350160.09375	
11966	 steps: training loss - 118395.32031	, testing loss - 350814.96875	
11967	 steps: training loss - 109196.20312	, testing loss - 351057.28125	
11968	 steps: training loss - 94954.41406	, testing loss - 349727.06250	
11969	 steps: training loss - 126081.91406	, testing loss - 348451.25000	
11970	 steps: training loss - 105747.37500	, testing loss - 347133.34375	
11971	 steps: training loss - 114903.32812	, testing loss - 346370.65625	
11972	 steps: training loss - 89399.88281	, testing loss - 346709.40625	
11973	 steps: training loss - 93499.94531	, testing loss - 347348.43750	
11974	 steps: training loss - 89578.80469	, testing loss - 348911.25000	
11975	 steps: training loss - 117158.77344	, testing loss - 349704.00000	
11976	 steps: training loss - 133536.51562	, testing loss - 350522.03125	
11977	 steps: training loss - 106654.71875	, testing loss - 351488.78125	
11978	 steps: training loss - 120259.20312	, testing loss - 351469.65625	
11979	 steps: training loss - 118134.07031	, testing loss - 350860.56250	
11980	 steps: training loss - 98342.32031	, testing loss - 350037.37500	
11981	 steps: training loss - 92419.10156	, testing loss - 349809.25000	
11982	 steps: training loss - 110419.00781	, testing loss - 350342.87500	
11983	 steps: training loss - 91114.83594	, testing loss - 351104.53125	
11984	 steps: training loss - 100352.31250	, testing loss - 350834.75000	
11985	 steps: training loss - 103015.81250	, testing loss - 350046.21875	
11986	 steps: training loss - 87507.64062	, testing loss - 348721.81250	
11987	 steps: training loss - 119385.53125	, testing loss - 347570.18750	
11988	 steps: training loss - 95961.02344	, testing loss - 346462.59375	
11989	 steps: training loss - 130203.02344	, testing loss - 346337.12500	
11990	 steps: training loss - 97275.82812	, testing loss - 346227.53125	
11991	 steps: training loss - 92818.85938	, testing loss - 346331.37500	
11992	 steps: training loss - 92941.64844	, testing loss - 346528.93750	
11993	 steps: training loss - 114049.11719	, testing loss - 346970.90625	
11994	 steps: training loss - 115073.12500	, testing loss - 346825.31250	
11995	 steps: training loss - 123783.02344	, testing loss - 346767.31250	
11996	 steps: training loss - 101928.06250	, testing loss - 347634.62500	
11997	 steps: training loss - 110312.53125	, testing loss - 348077.12500	
11998	 steps: training loss - 122803.57812	, testing loss - 348561.71875	
11999	 steps: training loss - 117980.41406	, testing loss - 349133.56250	
12000	 steps: training loss - 89115.05469	, testing loss - 349722.46875	
12001	 steps: training loss - 110032.42188	, testing loss - 349950.62500	
12002	 steps: training loss - 103219.67969	, testing loss - 349197.93750	
12003	 steps: training loss - 126880.08594	, testing loss - 348048.78125	
12004	 steps: training loss - 104076.36719	, testing loss - 347289.06250	
12005	 steps: training loss - 100496.52344	, testing loss - 346511.21875	
12006	 steps: training loss - 102684.75000	, testing loss - 346126.18750	
12007	 steps: training loss - 93173.31250	, testing loss - 345787.50000	
12008	 steps: training loss - 101042.12500	, testing loss - 345561.62500	
12009	 steps: training loss - 129543.71094	, testing loss - 345806.93750	
12010	 steps: training loss - 87086.60156	, testing loss - 346822.78125	
12011	 steps: training loss - 111191.89844	, testing loss - 347883.87500	
12012	 steps: training loss - 115618.55469	, testing loss - 349129.43750	
12013	 steps: training loss - 106371.27344	, testing loss - 349965.56250	
12014	 steps: training loss - 73811.73438	, testing loss - 349785.06250	
12015	 steps: training loss - 103192.82031	, testing loss - 349104.18750	
12016	 steps: training loss - 112246.00781	, testing loss - 348787.21875	
12017	 steps: training loss - 114582.76562	, testing loss - 347310.18750	
12018	 steps: training loss - 113317.75000	, testing loss - 345411.53125	
12019	 steps: training loss - 143891.04688	, testing loss - 343636.18750	
12020	 steps: training loss - 97355.01562	, testing loss - 341882.09375	
12021	 steps: training loss - 105325.65625	, testing loss - 340880.53125	
12022	 steps: training loss - 100417.96875	, testing loss - 340750.56250	
12023	 steps: training loss - 93182.39062	, testing loss - 341030.09375	
12024	 steps: training loss - 121212.34375	, testing loss - 341163.75000	
12025	 steps: training loss - 114767.95312	, testing loss - 341834.53125	
12026	 steps: training loss - 81136.98438	, testing loss - 342993.18750	
12027	 steps: training loss - 122998.57812	, testing loss - 344138.03125	
12028	 steps: training loss - 109563.72656	, testing loss - 345554.09375	
12029	 steps: training loss - 93855.64844	, testing loss - 346433.40625	
12030	 steps: training loss - 102375.35938	, testing loss - 346759.56250	
12031	 steps: training loss - 121973.94531	, testing loss - 346949.31250	
12032	 steps: training loss - 97424.92969	, testing loss - 346493.65625	
12033	 steps: training loss - 118962.85156	, testing loss - 345981.93750	
12034	 steps: training loss - 128337.22656	, testing loss - 346541.68750	
12035	 steps: training loss - 107646.51562	, testing loss - 347274.78125	
12036	 steps: training loss - 102044.53906	, testing loss - 347910.40625	
12037	 steps: training loss - 103164.84375	, testing loss - 349674.00000	
12038	 steps: training loss - 120241.25000	, testing loss - 352725.53125	
12039	 steps: training loss - 107623.82031	, testing loss - 356720.25000	
12040	 steps: training loss - 130598.16406	, testing loss - 361058.34375	
12041	 steps: training loss - 91627.30469	, testing loss - 364396.50000	
12042	 steps: training loss - 110883.53125	, testing loss - 366644.84375	
12043	 steps: training loss - 91957.39062	, testing loss - 367969.93750	
12044	 steps: training loss - 80097.19531	, testing loss - 367195.93750	
12045	 steps: training loss - 97784.31250	, testing loss - 365076.21875	
12046	 steps: training loss - 108113.32031	, testing loss - 362840.56250	
12047	 steps: training loss - 116296.74219	, testing loss - 361105.84375	
12048	 steps: training loss - 99740.50000	, testing loss - 358527.37500	
12049	 steps: training loss - 120861.18750	, testing loss - 355739.28125	
12050	 steps: training loss - 89014.64844	, testing loss - 352512.90625	
12051	 steps: training loss - 108528.91406	, testing loss - 350091.50000	
12052	 steps: training loss - 81900.53125	, testing loss - 347475.71875	
12053	 steps: training loss - 144350.93750	, testing loss - 345349.90625	
12054	 steps: training loss - 108208.42969	, testing loss - 344283.81250	
12055	 steps: training loss - 125245.91406	, testing loss - 343880.28125	
12056	 steps: training loss - 99149.56250	, testing loss - 343932.93750	
12057	 steps: training loss - 117585.07812	, testing loss - 344027.37500	
12058	 steps: training loss - 92788.27344	, testing loss - 343375.68750	
12059	 steps: training loss - 118947.55469	, testing loss - 343168.68750	
12060	 steps: training loss - 98645.43750	, testing loss - 343668.65625	
12061	 steps: training loss - 105255.67969	, testing loss - 344809.18750	
12062	 steps: training loss - 115643.39062	, testing loss - 346058.03125	
12063	 steps: training loss - 126033.98438	, testing loss - 347408.71875	
12064	 steps: training loss - 124880.01562	, testing loss - 348287.21875	
12065	 steps: training loss - 123712.83594	, testing loss - 349187.15625	
12066	 steps: training loss - 91452.52344	, testing loss - 350526.28125	
12067	 steps: training loss - 145495.14062	, testing loss - 351952.09375	
12068	 steps: training loss - 125603.35156	, testing loss - 353730.31250	
12069	 steps: training loss - 116430.22656	, testing loss - 354542.31250	
12070	 steps: training loss - 127766.43750	, testing loss - 356207.62500	
12071	 steps: training loss - 89474.88281	, testing loss - 357818.59375	
12072	 steps: training loss - 98616.28125	, testing loss - 359061.68750	
12073	 steps: training loss - 105594.49219	, testing loss - 358962.84375	
12074	 steps: training loss - 113344.02344	, testing loss - 356950.87500	
12075	 steps: training loss - 109038.77344	, testing loss - 354404.25000	
12076	 steps: training loss - 108573.85938	, testing loss - 351881.75000	
12077	 steps: training loss - 73053.07031	, testing loss - 349503.25000	
12078	 steps: training loss - 121650.84375	, testing loss - 347248.15625	
12079	 steps: training loss - 101915.37500	, testing loss - 345020.87500	
12080	 steps: training loss - 128349.35156	, testing loss - 343020.96875	
12081	 steps: training loss - 124212.86719	, testing loss - 342303.93750	
12082	 steps: training loss - 128942.78125	, testing loss - 342178.21875	
12083	 steps: training loss - 103070.01562	, testing loss - 342197.12500	
12084	 steps: training loss - 94884.27344	, testing loss - 343058.84375	
12085	 steps: training loss - 91833.07031	, testing loss - 344273.12500	
12086	 steps: training loss - 119628.48438	, testing loss - 345316.84375	
12087	 steps: training loss - 106907.90625	, testing loss - 345454.90625	
12088	 steps: training loss - 101868.96875	, testing loss - 346444.31250	
12089	 steps: training loss - 111053.23438	, testing loss - 347103.81250	
12090	 steps: training loss - 99611.48438	, testing loss - 347532.96875	
12091	 steps: training loss - 98519.07812	, testing loss - 348234.06250	
12092	 steps: training loss - 110935.46875	, testing loss - 348426.03125	
12093	 steps: training loss - 112998.74219	, testing loss - 349100.93750	
12094	 steps: training loss - 114934.40625	, testing loss - 349451.68750	
12095	 steps: training loss - 107326.21875	, testing loss - 350106.84375	
12096	 steps: training loss - 85685.37500	, testing loss - 350487.62500	
12097	 steps: training loss - 101945.31250	, testing loss - 350780.18750	
12098	 steps: training loss - 113321.67969	, testing loss - 350484.09375	
12099	 steps: training loss - 102937.25781	, testing loss - 350587.84375	
12100	 steps: training loss - 118868.33594	, testing loss - 351231.56250	
12101	 steps: training loss - 114939.03125	, testing loss - 352053.12500	
12102	 steps: training loss - 99519.36719	, testing loss - 354344.00000	
12103	 steps: training loss - 93278.17188	, testing loss - 357700.81250	
12104	 steps: training loss - 103062.39062	, testing loss - 360790.96875	
12105	 steps: training loss - 104466.64062	, testing loss - 363699.84375	
12106	 steps: training loss - 106663.93750	, testing loss - 365368.09375	
12107	 steps: training loss - 119764.21875	, testing loss - 366188.34375	
12108	 steps: training loss - 116865.57812	, testing loss - 364896.43750	
12109	 steps: training loss - 128186.03906	, testing loss - 362660.25000	
12110	 steps: training loss - 117048.81250	, testing loss - 359690.06250	
12111	 steps: training loss - 113292.55469	, testing loss - 356069.50000	
12112	 steps: training loss - 95328.34375	, testing loss - 354055.34375	
12113	 steps: training loss - 105325.67969	, testing loss - 352281.31250	
12114	 steps: training loss - 130672.96875	, testing loss - 350593.68750	
12115	 steps: training loss - 141089.00000	, testing loss - 349268.31250	
12116	 steps: training loss - 87326.18750	, testing loss - 349158.46875	
12117	 steps: training loss - 105022.60938	, testing loss - 348906.87500	
12118	 steps: training loss - 113153.94531	, testing loss - 348007.15625	
12119	 steps: training loss - 111069.77344	, testing loss - 346855.96875	
12120	 steps: training loss - 124373.85156	, testing loss - 345442.43750	
12121	 steps: training loss - 104427.74219	, testing loss - 345083.75000	
12122	 steps: training loss - 98122.78125	, testing loss - 345676.03125	
12123	 steps: training loss - 105687.49219	, testing loss - 346660.84375	
12124	 steps: training loss - 120790.76562	, testing loss - 347698.12500	
12125	 steps: training loss - 117247.95312	, testing loss - 347377.28125	
12126	 steps: training loss - 117619.50000	, testing loss - 346437.28125	
12127	 steps: training loss - 97000.30469	, testing loss - 345272.71875	
12128	 steps: training loss - 88561.16406	, testing loss - 344353.12500	
12129	 steps: training loss - 116902.41406	, testing loss - 343349.06250	
12130	 steps: training loss - 95737.21094	, testing loss - 342714.53125	
12131	 steps: training loss - 91198.78906	, testing loss - 342773.37500	
12132	 steps: training loss - 102352.72656	, testing loss - 343305.56250	
12133	 steps: training loss - 85334.76562	, testing loss - 343250.37500	
12134	 steps: training loss - 111301.82812	, testing loss - 343497.78125	
12135	 steps: training loss - 131346.48438	, testing loss - 343842.46875	
12136	 steps: training loss - 123219.98438	, testing loss - 344482.56250	
12137	 steps: training loss - 100644.16406	, testing loss - 345931.15625	
12138	 steps: training loss - 81597.73438	, testing loss - 347367.65625	
12139	 steps: training loss - 107010.48438	, testing loss - 348947.78125	
12140	 steps: training loss - 118006.70312	, testing loss - 350838.37500	
12141	 steps: training loss - 93296.10938	, testing loss - 353256.68750	
12142	 steps: training loss - 83176.30469	, testing loss - 356210.21875	
12143	 steps: training loss - 106994.53125	, testing loss - 358541.25000	
12144	 steps: training loss - 115846.47656	, testing loss - 360796.28125	
12145	 steps: training loss - 108986.71094	, testing loss - 362026.68750	
12146	 steps: training loss - 115158.31250	, testing loss - 362740.96875	
12147	 steps: training loss - 116423.59375	, testing loss - 362113.37500	
12148	 steps: training loss - 117460.17969	, testing loss - 359890.84375	
12149	 steps: training loss - 114570.65625	, testing loss - 358416.15625	
12150	 steps: training loss - 106495.88281	, testing loss - 357002.09375	
12151	 steps: training loss - 104099.55469	, testing loss - 355269.90625	
12152	 steps: training loss - 106979.39844	, testing loss - 353587.40625	
12153	 steps: training loss - 104779.03125	, testing loss - 352451.81250	
12154	 steps: training loss - 114781.03125	, testing loss - 352410.84375	
12155	 steps: training loss - 94778.42188	, testing loss - 352959.06250	
12156	 steps: training loss - 108514.00000	, testing loss - 354419.09375	
12157	 steps: training loss - 97974.96094	, testing loss - 355093.46875	
12158	 steps: training loss - 124060.50781	, testing loss - 355292.12500	
12159	 steps: training loss - 121225.39062	, testing loss - 354908.84375	
12160	 steps: training loss - 109864.29688	, testing loss - 354094.62500	
12161	 steps: training loss - 101979.41406	, testing loss - 353396.84375	
12162	 steps: training loss - 100266.11719	, testing loss - 352377.53125	
12163	 steps: training loss - 110604.21094	, testing loss - 351893.56250	
12164	 steps: training loss - 111292.56250	, testing loss - 351588.28125	
12165	 steps: training loss - 111814.19531	, testing loss - 351525.81250	
12166	 steps: training loss - 84196.62500	, testing loss - 351903.18750	
12167	 steps: training loss - 100815.39844	, testing loss - 352755.40625	
12168	 steps: training loss - 122294.42188	, testing loss - 353351.68750	
12169	 steps: training loss - 91973.33594	, testing loss - 354126.53125	
12170	 steps: training loss - 131623.54688	, testing loss - 354345.87500	
12171	 steps: training loss - 105052.05469	, testing loss - 354205.78125	
12172	 steps: training loss - 95712.92188	, testing loss - 353739.75000	
12173	 steps: training loss - 111501.35156	, testing loss - 353345.59375	
12174	 steps: training loss - 93870.67969	, testing loss - 352030.87500	
12175	 steps: training loss - 99409.94531	, testing loss - 350018.28125	
12176	 steps: training loss - 81422.15625	, testing loss - 348271.46875	
12177	 steps: training loss - 134353.65625	, testing loss - 347062.62500	
12178	 steps: training loss - 132598.70312	, testing loss - 346964.65625	
12179	 steps: training loss - 120722.28906	, testing loss - 347059.31250	
12180	 steps: training loss - 107583.49219	, testing loss - 346949.84375	
12181	 steps: training loss - 101378.91406	, testing loss - 347002.43750	
12182	 steps: training loss - 117025.89844	, testing loss - 346806.78125	
12183	 steps: training loss - 114329.10938	, testing loss - 346444.37500	
12184	 steps: training loss - 119273.56250	, testing loss - 347190.15625	
12185	 steps: training loss - 81972.62500	, testing loss - 349179.56250	
12186	 steps: training loss - 118117.35938	, testing loss - 351065.50000	
12187	 steps: training loss - 116760.50000	, testing loss - 352278.18750	
12188	 steps: training loss - 96875.66406	, testing loss - 354447.68750	
12189	 steps: training loss - 133151.42188	, testing loss - 356747.68750	
12190	 steps: training loss - 103404.49219	, testing loss - 358669.18750	
12191	 steps: training loss - 109837.35156	, testing loss - 359235.75000	
12192	 steps: training loss - 95944.89062	, testing loss - 359592.93750	
12193	 steps: training loss - 129717.56250	, testing loss - 359260.71875	
12194	 steps: training loss - 94883.32812	, testing loss - 358736.87500	
12195	 steps: training loss - 111613.51562	, testing loss - 357749.37500	
12196	 steps: training loss - 89514.82031	, testing loss - 356653.12500	
12197	 steps: training loss - 115859.16406	, testing loss - 355107.62500	
12198	 steps: training loss - 87688.04688	, testing loss - 353523.03125	
12199	 steps: training loss - 99523.42969	, testing loss - 351213.34375	
12200	 steps: training loss - 120334.57812	, testing loss - 348840.71875	
12201	 steps: training loss - 87559.71094	, testing loss - 346404.15625	
12202	 steps: training loss - 104491.98438	, testing loss - 343831.34375	
12203	 steps: training loss - 108515.42969	, testing loss - 341157.90625	
12204	 steps: training loss - 105668.44531	, testing loss - 338827.93750	
12205	 steps: training loss - 122981.55469	, testing loss - 337015.37500	
12206	 steps: training loss - 106403.22656	, testing loss - 335951.03125	
12207	 steps: training loss - 114377.41406	, testing loss - 335878.87500	
12208	 steps: training loss - 85845.41406	, testing loss - 336702.87500	
12209	 steps: training loss - 138988.54688	, testing loss - 337600.75000	
12210	 steps: training loss - 92395.25781	, testing loss - 339033.93750	
12211	 steps: training loss - 113364.78906	, testing loss - 340993.40625	
12212	 steps: training loss - 129871.88281	, testing loss - 342776.71875	
12213	 steps: training loss - 85799.53125	, testing loss - 344419.25000	
12214	 steps: training loss - 108121.27344	, testing loss - 346184.75000	
12215	 steps: training loss - 133465.26562	, testing loss - 347827.06250	
12216	 steps: training loss - 101316.74219	, testing loss - 349661.40625	
12217	 steps: training loss - 102181.62500	, testing loss - 351152.25000	
12218	 steps: training loss - 86125.21094	, testing loss - 352164.25000	
12219	 steps: training loss - 117959.45312	, testing loss - 353986.37500	
12220	 steps: training loss - 95646.87500	, testing loss - 354804.34375	
12221	 steps: training loss - 78999.22656	, testing loss - 355325.34375	
12222	 steps: training loss - 113284.44531	, testing loss - 356641.96875	
12223	 steps: training loss - 79965.92969	, testing loss - 357455.37500	
12224	 steps: training loss - 109507.83594	, testing loss - 358557.68750	
12225	 steps: training loss - 121623.20312	, testing loss - 360162.68750	
12226	 steps: training loss - 122331.21094	, testing loss - 361847.06250	
12227	 steps: training loss - 94253.51562	, testing loss - 364329.87500	
12228	 steps: training loss - 118477.62500	, testing loss - 365167.28125	
12229	 steps: training loss - 114238.17969	, testing loss - 365078.50000	
12230	 steps: training loss - 101479.50781	, testing loss - 364805.59375	
12231	 steps: training loss - 100145.29688	, testing loss - 364499.65625	
12232	 steps: training loss - 115910.28125	, testing loss - 363437.53125	
12233	 steps: training loss - 114029.17188	, testing loss - 361185.25000	
12234	 steps: training loss - 126704.39062	, testing loss - 359291.43750	
12235	 steps: training loss - 123199.59375	, testing loss - 356290.03125	
12236	 steps: training loss - 126327.07031	, testing loss - 352662.18750	
12237	 steps: training loss - 96754.03125	, testing loss - 349752.96875	
12238	 steps: training loss - 93382.85156	, testing loss - 348241.96875	
12239	 steps: training loss - 99283.48438	, testing loss - 346504.81250	
12240	 steps: training loss - 104370.45312	, testing loss - 345313.62500	
12241	 steps: training loss - 117087.68750	, testing loss - 344604.65625	
12242	 steps: training loss - 95617.86719	, testing loss - 343832.03125	
12243	 steps: training loss - 93509.00781	, testing loss - 342933.87500	
12244	 steps: training loss - 111346.81250	, testing loss - 342184.78125	
12245	 steps: training loss - 105073.69531	, testing loss - 341781.18750	
12246	 steps: training loss - 111009.63281	, testing loss - 341450.81250	
12247	 steps: training loss - 127028.65625	, testing loss - 341552.87500	
12248	 steps: training loss - 87222.61719	, testing loss - 342937.50000	
12249	 steps: training loss - 98554.74219	, testing loss - 344477.71875	
12250	 steps: training loss - 107742.41406	, testing loss - 345969.71875	
12251	 steps: training loss - 116603.42188	, testing loss - 347802.87500	
12252	 steps: training loss - 96564.47656	, testing loss - 350620.21875	
12253	 steps: training loss - 81628.14844	, testing loss - 353570.03125	
12254	 steps: training loss - 138097.53125	, testing loss - 355737.34375	
12255	 steps: training loss - 114991.32812	, testing loss - 355709.50000	
12256	 steps: training loss - 102635.69531	, testing loss - 355476.40625	
12257	 steps: training loss - 100935.35156	, testing loss - 355581.43750	
12258	 steps: training loss - 114647.13281	, testing loss - 355699.09375	
12259	 steps: training loss - 99190.76562	, testing loss - 355501.68750	
12260	 steps: training loss - 108798.46875	, testing loss - 354968.87500	
12261	 steps: training loss - 119911.80469	, testing loss - 354632.18750	
12262	 steps: training loss - 107170.97656	, testing loss - 353842.78125	
12263	 steps: training loss - 99702.29688	, testing loss - 353189.28125	
12264	 steps: training loss - 108262.14062	, testing loss - 353470.06250	
12265	 steps: training loss - 96638.12500	, testing loss - 353497.03125	
12266	 steps: training loss - 81870.17188	, testing loss - 353282.06250	
12267	 steps: training loss - 140805.07812	, testing loss - 353068.40625	
12268	 steps: training loss - 87094.87500	, testing loss - 352886.46875	
12269	 steps: training loss - 86897.75781	, testing loss - 352745.21875	
12270	 steps: training loss - 84888.85938	, testing loss - 352743.25000	
12271	 steps: training loss - 111323.72656	, testing loss - 352084.81250	
12272	 steps: training loss - 117099.80469	, testing loss - 351153.71875	
12273	 steps: training loss - 98194.43750	, testing loss - 349877.71875	
12274	 steps: training loss - 96252.71875	, testing loss - 349133.46875	
12275	 steps: training loss - 83613.07031	, testing loss - 349693.71875	
12276	 steps: training loss - 95446.53906	, testing loss - 350634.93750	
12277	 steps: training loss - 109284.07812	, testing loss - 352008.03125	
12278	 steps: training loss - 110403.38281	, testing loss - 352241.15625	
12279	 steps: training loss - 95406.16406	, testing loss - 351838.46875	
12280	 steps: training loss - 113300.30469	, testing loss - 350586.46875	
12281	 steps: training loss - 118011.92969	, testing loss - 348726.46875	
12282	 steps: training loss - 118361.70312	, testing loss - 346665.00000	
12283	 steps: training loss - 118797.01562	, testing loss - 345575.03125	
12284	 steps: training loss - 115176.53906	, testing loss - 346042.31250	
12285	 steps: training loss - 124056.18750	, testing loss - 346698.87500	
12286	 steps: training loss - 96240.92969	, testing loss - 347087.84375	
12287	 steps: training loss - 126438.42188	, testing loss - 347713.96875	
12288	 steps: training loss - 108284.65625	, testing loss - 349047.43750	
12289	 steps: training loss - 116647.13281	, testing loss - 349535.81250	
12290	 steps: training loss - 105271.48438	, testing loss - 349473.31250	
12291	 steps: training loss - 95036.65625	, testing loss - 349544.09375	
12292	 steps: training loss - 102828.39844	, testing loss - 350594.03125	
12293	 steps: training loss - 95450.09375	, testing loss - 351572.68750	
12294	 steps: training loss - 88860.06250	, testing loss - 352688.93750	
12295	 steps: training loss - 110936.35156	, testing loss - 353539.00000	
12296	 steps: training loss - 114891.62500	, testing loss - 354554.18750	
12297	 steps: training loss - 96174.50000	, testing loss - 354739.96875	
12298	 steps: training loss - 85369.55469	, testing loss - 353888.21875	
12299	 steps: training loss - 110676.01562	, testing loss - 352822.34375	
12300	 steps: training loss - 115572.87500	, testing loss - 351488.53125	
12301	 steps: training loss - 113683.08594	, testing loss - 349878.93750	
12302	 steps: training loss - 98121.27344	, testing loss - 348778.43750	
12303	 steps: training loss - 107811.39062	, testing loss - 348440.65625	
12304	 steps: training loss - 92266.64844	, testing loss - 348095.03125	
12305	 steps: training loss - 112627.78906	, testing loss - 347352.90625	
12306	 steps: training loss - 123763.57031	, testing loss - 346150.12500	
12307	 steps: training loss - 100533.10156	, testing loss - 345792.06250	
12308	 steps: training loss - 128958.80469	, testing loss - 345520.96875	
12309	 steps: training loss - 123516.44531	, testing loss - 345180.87500	
12310	 steps: training loss - 80180.74219	, testing loss - 344040.21875	
12311	 steps: training loss - 121516.57812	, testing loss - 343457.37500	
12312	 steps: training loss - 101866.70312	, testing loss - 342878.50000	
12313	 steps: training loss - 93935.83594	, testing loss - 341924.46875	
12314	 steps: training loss - 137429.35938	, testing loss - 341157.75000	
12315	 steps: training loss - 103967.77344	, testing loss - 341078.50000	
12316	 steps: training loss - 99022.57812	, testing loss - 341350.43750	
12317	 steps: training loss - 112879.80469	, testing loss - 342304.87500	
12318	 steps: training loss - 101809.30469	, testing loss - 342674.50000	
12319	 steps: training loss - 89967.07812	, testing loss - 343358.87500	
12320	 steps: training loss - 98623.18750	, testing loss - 343937.34375	
12321	 steps: training loss - 99396.19531	, testing loss - 345036.62500	
12322	 steps: training loss - 80033.22656	, testing loss - 345289.46875	
12323	 steps: training loss - 97079.07031	, testing loss - 345067.84375	
12324	 steps: training loss - 139981.15625	, testing loss - 344835.78125	
12325	 steps: training loss - 105521.51562	, testing loss - 344552.50000	
12326	 steps: training loss - 89768.53906	, testing loss - 344122.40625	
12327	 steps: training loss - 124951.98438	, testing loss - 343592.06250	
12328	 steps: training loss - 99772.76562	, testing loss - 343359.40625	
12329	 steps: training loss - 146749.70312	, testing loss - 342861.25000	
12330	 steps: training loss - 106208.59375	, testing loss - 342526.50000	
12331	 steps: training loss - 115170.09375	, testing loss - 342254.56250	
12332	 steps: training loss - 105565.89844	, testing loss - 341969.62500	
12333	 steps: training loss - 107285.07031	, testing loss - 341705.68750	
12334	 steps: training loss - 141085.75000	, testing loss - 341526.84375	
12335	 steps: training loss - 110693.21875	, testing loss - 340777.90625	
12336	 steps: training loss - 110642.64062	, testing loss - 339872.50000	
12337	 steps: training loss - 112713.10938	, testing loss - 339206.81250	
12338	 steps: training loss - 128026.46094	, testing loss - 338431.25000	
12339	 steps: training loss - 117003.89062	, testing loss - 337707.37500	
12340	 steps: training loss - 122895.13281	, testing loss - 337702.43750	
12341	 steps: training loss - 104798.08594	, testing loss - 338061.00000	
12342	 steps: training loss - 97994.61719	, testing loss - 338852.56250	
12343	 steps: training loss - 149214.07812	, testing loss - 339434.00000	
12344	 steps: training loss - 108943.75000	, testing loss - 340079.87500	
12345	 steps: training loss - 96549.09375	, testing loss - 341393.90625	
12346	 steps: training loss - 98043.78125	, testing loss - 342872.43750	
12347	 steps: training loss - 114035.50000	, testing loss - 344689.75000	
12348	 steps: training loss - 120481.57031	, testing loss - 346654.84375	
12349	 steps: training loss - 107008.28906	, testing loss - 349175.78125	
12350	 steps: training loss - 109683.98438	, testing loss - 352641.12500	
12351	 steps: training loss - 110997.00000	, testing loss - 355269.65625	
12352	 steps: training loss - 126445.28125	, testing loss - 356212.43750	
12353	 steps: training loss - 112988.09375	, testing loss - 356892.78125	
12354	 steps: training loss - 81876.57031	, testing loss - 355936.75000	
12355	 steps: training loss - 115738.61719	, testing loss - 355246.59375	
12356	 steps: training loss - 105051.54688	, testing loss - 356574.37500	
12357	 steps: training loss - 107858.04688	, testing loss - 357300.56250	
12358	 steps: training loss - 97075.38281	, testing loss - 357032.78125	
12359	 steps: training loss - 104272.92969	, testing loss - 356660.65625	
12360	 steps: training loss - 97297.48438	, testing loss - 356095.62500	
12361	 steps: training loss - 104513.53906	, testing loss - 355063.56250	
12362	 steps: training loss - 101585.18750	, testing loss - 353113.15625	
12363	 steps: training loss - 126576.09375	, testing loss - 351745.18750	
12364	 steps: training loss - 119263.32031	, testing loss - 350540.25000	
12365	 steps: training loss - 110449.08594	, testing loss - 349577.43750	
12366	 steps: training loss - 106537.05469	, testing loss - 348767.28125	
12367	 steps: training loss - 91322.63281	, testing loss - 347679.31250	
12368	 steps: training loss - 98720.82812	, testing loss - 346744.71875	
12369	 steps: training loss - 104040.32812	, testing loss - 346734.09375	
12370	 steps: training loss - 113322.21094	, testing loss - 346483.62500	
12371	 steps: training loss - 106044.93750	, testing loss - 346778.00000	
12372	 steps: training loss - 114062.82031	, testing loss - 347083.56250	
12373	 steps: training loss - 125631.90625	, testing loss - 347838.09375	
12374	 steps: training loss - 115990.08594	, testing loss - 348631.53125	
12375	 steps: training loss - 101167.66406	, testing loss - 348569.18750	
12376	 steps: training loss - 93654.71875	, testing loss - 347943.65625	
12377	 steps: training loss - 110378.01562	, testing loss - 347831.96875	
12378	 steps: training loss - 127604.85156	, testing loss - 348362.71875	
12379	 steps: training loss - 103715.74219	, testing loss - 348922.12500	
12380	 steps: training loss - 106826.75000	, testing loss - 349498.28125	
12381	 steps: training loss - 93140.58594	, testing loss - 351581.56250	
12382	 steps: training loss - 107676.05469	, testing loss - 352847.15625	
12383	 steps: training loss - 123245.84375	, testing loss - 354082.78125	
12384	 steps: training loss - 101785.74219	, testing loss - 354458.84375	
12385	 steps: training loss - 115121.97656	, testing loss - 354099.31250	
12386	 steps: training loss - 101500.51562	, testing loss - 353929.09375	
12387	 steps: training loss - 117733.70312	, testing loss - 352642.81250	
12388	 steps: training loss - 120974.99219	, testing loss - 350645.43750	
12389	 steps: training loss - 124207.11719	, testing loss - 348889.06250	
12390	 steps: training loss - 97178.47656	, testing loss - 347879.78125	
12391	 steps: training loss - 118908.02344	, testing loss - 347099.53125	
12392	 steps: training loss - 106875.96875	, testing loss - 346383.93750	
12393	 steps: training loss - 117737.66406	, testing loss - 345243.96875	
12394	 steps: training loss - 93225.83594	, testing loss - 343726.15625	
12395	 steps: training loss - 98010.21875	, testing loss - 343046.43750	
12396	 steps: training loss - 134485.92188	, testing loss - 343618.90625	
12397	 steps: training loss - 92083.08594	, testing loss - 343928.84375	
12398	 steps: training loss - 119118.54688	, testing loss - 343728.62500	
12399	 steps: training loss - 105714.90625	, testing loss - 345358.78125	
12400	 steps: training loss - 100478.04688	, testing loss - 347732.43750	
12401	 steps: training loss - 86330.49219	, testing loss - 350347.90625	
12402	 steps: training loss - 100724.33594	, testing loss - 352251.56250	
12403	 steps: training loss - 83817.80469	, testing loss - 353690.46875	
12404	 steps: training loss - 117340.48438	, testing loss - 354639.90625	
12405	 steps: training loss - 125810.54688	, testing loss - 354534.96875	
12406	 steps: training loss - 105409.14062	, testing loss - 354017.87500	
12407	 steps: training loss - 120415.50781	, testing loss - 353431.96875	
12408	 steps: training loss - 129993.07031	, testing loss - 352335.90625	
12409	 steps: training loss - 111871.18750	, testing loss - 350939.25000	
12410	 steps: training loss - 110565.00781	, testing loss - 351461.43750	
12411	 steps: training loss - 115322.57812	, testing loss - 351249.03125	
12412	 steps: training loss - 97450.75000	, testing loss - 351589.50000	
12413	 steps: training loss - 100819.32031	, testing loss - 352300.81250	
12414	 steps: training loss - 118896.25000	, testing loss - 353059.03125	
12415	 steps: training loss - 98841.53906	, testing loss - 353182.37500	
12416	 steps: training loss - 142820.84375	, testing loss - 353054.40625	
12417	 steps: training loss - 123414.50781	, testing loss - 352336.00000	
12418	 steps: training loss - 100015.69531	, testing loss - 351434.78125	
12419	 steps: training loss - 122954.79688	, testing loss - 352080.28125	
12420	 steps: training loss - 98999.46094	, testing loss - 352890.18750	
12421	 steps: training loss - 110614.25781	, testing loss - 353876.37500	
12422	 steps: training loss - 119473.85938	, testing loss - 353937.25000	
12423	 steps: training loss - 114189.75000	, testing loss - 355001.84375	
12424	 steps: training loss - 106156.18750	, testing loss - 356734.87500	
12425	 steps: training loss - 100034.54688	, testing loss - 357330.31250	
12426	 steps: training loss - 123316.81250	, testing loss - 356278.56250	
12427	 steps: training loss - 117918.14844	, testing loss - 354337.71875	
12428	 steps: training loss - 95705.43750	, testing loss - 351541.56250	
12429	 steps: training loss - 98281.60938	, testing loss - 349164.59375	
12430	 steps: training loss - 101316.60156	, testing loss - 347527.15625	
12431	 steps: training loss - 93112.19531	, testing loss - 345982.68750	
12432	 steps: training loss - 111195.64062	, testing loss - 345528.53125	
12433	 steps: training loss - 112164.25781	, testing loss - 345410.03125	
12434	 steps: training loss - 131157.95312	, testing loss - 344713.46875	
12435	 steps: training loss - 107574.89062	, testing loss - 343394.31250	
12436	 steps: training loss - 104353.49219	, testing loss - 342291.87500	
12437	 steps: training loss - 104312.21094	, testing loss - 341974.25000	
12438	 steps: training loss - 111270.56250	, testing loss - 341131.50000	
12439	 steps: training loss - 108270.10938	, testing loss - 339946.96875	
12440	 steps: training loss - 91159.50000	, testing loss - 339474.96875	
12441	 steps: training loss - 111432.74219	, testing loss - 340031.62500	
12442	 steps: training loss - 112492.35938	, testing loss - 340284.28125	
12443	 steps: training loss - 126038.91406	, testing loss - 340479.87500	
12444	 steps: training loss - 128017.31250	, testing loss - 340557.09375	
12445	 steps: training loss - 104612.75781	, testing loss - 341192.59375	
12446	 steps: training loss - 115764.11719	, testing loss - 341563.43750	
12447	 steps: training loss - 119618.90625	, testing loss - 342140.84375	
12448	 steps: training loss - 106837.12500	, testing loss - 342404.37500	
12449	 steps: training loss - 107171.72656	, testing loss - 342449.43750	
12450	 steps: training loss - 78572.84375	, testing loss - 342873.90625	
12451	 steps: training loss - 114520.98438	, testing loss - 343012.87500	
12452	 steps: training loss - 108050.02344	, testing loss - 343458.78125	
12453	 steps: training loss - 108162.11719	, testing loss - 344377.53125	
12454	 steps: training loss - 123537.54688	, testing loss - 344827.06250	
12455	 steps: training loss - 112975.29688	, testing loss - 344721.62500	
12456	 steps: training loss - 118714.52344	, testing loss - 345596.75000	
12457	 steps: training loss - 91679.10156	, testing loss - 346855.25000	
12458	 steps: training loss - 109399.81250	, testing loss - 347424.56250	
12459	 steps: training loss - 86085.43750	, testing loss - 347497.65625	
12460	 steps: training loss - 125893.07031	, testing loss - 347762.40625	
12461	 steps: training loss - 87487.89062	, testing loss - 348247.40625	
12462	 steps: training loss - 92665.23438	, testing loss - 349002.18750	
12463	 steps: training loss - 117231.42188	, testing loss - 349558.46875	
12464	 steps: training loss - 97016.96875	, testing loss - 349802.53125	
12465	 steps: training loss - 110334.39844	, testing loss - 349524.31250	
12466	 steps: training loss - 87573.57031	, testing loss - 349514.25000	
12467	 steps: training loss - 123631.25781	, testing loss - 350071.87500	
12468	 steps: training loss - 94243.15625	, testing loss - 351781.37500	
12469	 steps: training loss - 76931.73438	, testing loss - 354744.37500	
12470	 steps: training loss - 66536.67969	, testing loss - 358078.12500	
12471	 steps: training loss - 102945.51562	, testing loss - 361119.87500	
12472	 steps: training loss - 121534.76562	, testing loss - 363210.93750	
12473	 steps: training loss - 111027.88281	, testing loss - 362503.81250	
12474	 steps: training loss - 137893.40625	, testing loss - 360463.81250	
12475	 steps: training loss - 128032.85156	, testing loss - 358465.00000	
12476	 steps: training loss - 119997.40625	, testing loss - 357226.18750	
12477	 steps: training loss - 112720.55469	, testing loss - 355969.40625	
12478	 steps: training loss - 100403.53906	, testing loss - 355120.34375	
12479	 steps: training loss - 125972.89062	, testing loss - 353545.65625	
12480	 steps: training loss - 85519.61719	, testing loss - 352174.65625	
12481	 steps: training loss - 87958.79688	, testing loss - 349857.65625	
12482	 steps: training loss - 115020.18750	, testing loss - 347458.18750	
12483	 steps: training loss - 102753.33594	, testing loss - 345768.78125	
12484	 steps: training loss - 101051.33594	, testing loss - 343932.21875	
12485	 steps: training loss - 126498.59375	, testing loss - 342620.96875	
12486	 steps: training loss - 108284.47656	, testing loss - 340792.68750	
12487	 steps: training loss - 127524.94531	, testing loss - 339431.40625	
12488	 steps: training loss - 87770.28125	, testing loss - 339272.56250	
12489	 steps: training loss - 94400.35938	, testing loss - 339615.25000	
12490	 steps: training loss - 120173.68750	, testing loss - 339691.56250	
12491	 steps: training loss - 125614.27344	, testing loss - 339566.75000	
12492	 steps: training loss - 110842.81250	, testing loss - 339090.21875	
12493	 steps: training loss - 88439.77344	, testing loss - 339885.87500	
12494	 steps: training loss - 115301.42969	, testing loss - 340448.15625	
12495	 steps: training loss - 111557.98438	, testing loss - 341889.34375	
12496	 steps: training loss - 113593.79688	, testing loss - 344099.43750	
12497	 steps: training loss - 98047.40625	, testing loss - 346999.12500	
12498	 steps: training loss - 94647.53906	, testing loss - 349016.06250	
12499	 steps: training loss - 119674.98438	, testing loss - 349934.78125	
12500	 steps: training loss - 104085.83594	, testing loss - 349430.25000	
12501	 steps: training loss - 108621.40625	, testing loss - 349452.59375	
12502	 steps: training loss - 81755.89062	, testing loss - 349206.59375	
12503	 steps: training loss - 138474.04688	, testing loss - 348211.31250	
12504	 steps: training loss - 104856.07031	, testing loss - 347150.12500	
12505	 steps: training loss - 111613.31250	, testing loss - 346265.31250	
12506	 steps: training loss - 79235.26562	, testing loss - 345530.34375	
12507	 steps: training loss - 93812.88281	, testing loss - 344963.40625	
12508	 steps: training loss - 132487.98438	, testing loss - 344183.37500	
12509	 steps: training loss - 107678.24219	, testing loss - 344197.65625	
12510	 steps: training loss - 139916.12500	, testing loss - 344811.90625	
12511	 steps: training loss - 127110.65625	, testing loss - 344775.18750	
12512	 steps: training loss - 119287.47656	, testing loss - 345324.53125	
12513	 steps: training loss - 104468.14062	, testing loss - 344814.12500	
12514	 steps: training loss - 120916.15625	, testing loss - 344423.21875	
12515	 steps: training loss - 110000.12500	, testing loss - 344072.03125	
12516	 steps: training loss - 116236.18750	, testing loss - 344312.28125	
12517	 steps: training loss - 131451.32812	, testing loss - 343911.00000	
12518	 steps: training loss - 110075.81250	, testing loss - 343017.59375	
12519	 steps: training loss - 119739.39844	, testing loss - 342287.68750	
12520	 steps: training loss - 107128.65625	, testing loss - 341371.78125	
12521	 steps: training loss - 107861.47656	, testing loss - 340861.46875	
12522	 steps: training loss - 118153.74219	, testing loss - 341038.43750	
12523	 steps: training loss - 117408.97656	, testing loss - 341438.87500	
12524	 steps: training loss - 99632.96875	, testing loss - 342978.21875	
12525	 steps: training loss - 104640.46875	, testing loss - 344823.59375	
12526	 steps: training loss - 115739.25781	, testing loss - 345915.50000	
12527	 steps: training loss - 83438.50000	, testing loss - 347163.03125	
12528	 steps: training loss - 91861.11719	, testing loss - 348598.93750	
12529	 steps: training loss - 99215.67969	, testing loss - 349948.40625	
12530	 steps: training loss - 107475.79688	, testing loss - 351050.81250	
12531	 steps: training loss - 121357.31250	, testing loss - 351020.90625	
12532	 steps: training loss - 158755.87500	, testing loss - 350077.59375	
12533	 steps: training loss - 108545.03906	, testing loss - 349455.93750	
12534	 steps: training loss - 101920.56250	, testing loss - 349065.96875	
12535	 steps: training loss - 112477.88281	, testing loss - 349508.46875	
12536	 steps: training loss - 110594.89062	, testing loss - 349653.21875	
12537	 steps: training loss - 94866.85156	, testing loss - 350374.87500	
12538	 steps: training loss - 109609.71094	, testing loss - 350377.15625	
12539	 steps: training loss - 102894.15625	, testing loss - 349035.37500	
12540	 steps: training loss - 117115.31250	, testing loss - 348176.12500	
12541	 steps: training loss - 99798.76562	, testing loss - 347103.43750	
12542	 steps: training loss - 133159.03125	, testing loss - 346007.03125	
12543	 steps: training loss - 113724.52344	, testing loss - 345075.68750	
12544	 steps: training loss - 127209.35156	, testing loss - 344283.81250	
12545	 steps: training loss - 109964.37500	, testing loss - 343770.68750	
12546	 steps: training loss - 107949.30469	, testing loss - 343185.46875	
12547	 steps: training loss - 117461.98438	, testing loss - 342307.62500	
12548	 steps: training loss - 96499.56250	, testing loss - 341621.78125	
12549	 steps: training loss - 94062.54688	, testing loss - 341074.75000	
12550	 steps: training loss - 101009.14844	, testing loss - 341233.65625	
12551	 steps: training loss - 117508.82031	, testing loss - 341684.40625	
12552	 steps: training loss - 108114.98438	, testing loss - 342330.25000	
12553	 steps: training loss - 117282.22656	, testing loss - 342624.93750	
12554	 steps: training loss - 81854.26562	, testing loss - 342179.15625	
12555	 steps: training loss - 126649.90625	, testing loss - 341930.06250	
12556	 steps: training loss - 83851.22656	, testing loss - 342983.28125	
12557	 steps: training loss - 105337.94531	, testing loss - 343637.62500	
12558	 steps: training loss - 109082.23438	, testing loss - 344149.71875	
12559	 steps: training loss - 93515.90625	, testing loss - 344541.43750	
12560	 steps: training loss - 99834.91406	, testing loss - 344983.68750	
12561	 steps: training loss - 94875.98438	, testing loss - 345935.09375	
12562	 steps: training loss - 115428.30469	, testing loss - 346182.15625	
12563	 steps: training loss - 95791.77344	, testing loss - 346292.96875	
12564	 steps: training loss - 100389.52344	, testing loss - 346876.78125	
12565	 steps: training loss - 106616.60156	, testing loss - 347783.75000	
12566	 steps: training loss - 109075.56250	, testing loss - 347852.56250	
12567	 steps: training loss - 100891.70312	, testing loss - 347315.25000	
12568	 steps: training loss - 120381.57812	, testing loss - 347240.25000	
12569	 steps: training loss - 132132.54688	, testing loss - 347636.12500	
12570	 steps: training loss - 106920.13281	, testing loss - 347673.71875	
12571	 steps: training loss - 108502.21875	, testing loss - 346912.65625	
12572	 steps: training loss - 114754.58594	, testing loss - 346199.81250	
12573	 steps: training loss - 83401.07812	, testing loss - 345643.46875	
12574	 steps: training loss - 104289.60156	, testing loss - 345429.93750	
12575	 steps: training loss - 101196.52344	, testing loss - 345343.62500	
12576	 steps: training loss - 94120.75000	, testing loss - 344861.90625	
12577	 steps: training loss - 102873.26562	, testing loss - 343867.09375	
12578	 steps: training loss - 139577.10938	, testing loss - 342748.53125	
12579	 steps: training loss - 141153.07812	, testing loss - 341940.09375	
12580	 steps: training loss - 102191.42188	, testing loss - 340855.75000	
12581	 steps: training loss - 101343.55469	, testing loss - 340317.71875	
12582	 steps: training loss - 106545.25781	, testing loss - 340713.93750	
12583	 steps: training loss - 122767.25781	, testing loss - 341567.06250	
12584	 steps: training loss - 114037.89062	, testing loss - 341916.09375	
12585	 steps: training loss - 108546.05469	, testing loss - 342182.65625	
12586	 steps: training loss - 89655.22656	, testing loss - 342421.71875	
12587	 steps: training loss - 119340.29688	, testing loss - 342532.03125	
12588	 steps: training loss - 115428.44531	, testing loss - 343532.62500	
12589	 steps: training loss - 91975.38281	, testing loss - 345965.90625	
12590	 steps: training loss - 117060.67188	, testing loss - 348517.75000	
12591	 steps: training loss - 124189.37500	, testing loss - 349483.71875	
12592	 steps: training loss - 114601.52344	, testing loss - 350665.53125	
12593	 steps: training loss - 111529.42188	, testing loss - 352047.43750	
12594	 steps: training loss - 81196.54688	, testing loss - 352960.12500	
12595	 steps: training loss - 135560.10938	, testing loss - 353495.31250	
12596	 steps: training loss - 114969.53125	, testing loss - 352682.93750	
12597	 steps: training loss - 110879.00781	, testing loss - 350645.96875	
12598	 steps: training loss - 124477.83594	, testing loss - 349408.37500	
12599	 steps: training loss - 101478.78125	, testing loss - 348301.00000	
12600	 steps: training loss - 110137.70312	, testing loss - 347699.75000	
12601	 steps: training loss - 112695.14844	, testing loss - 347152.56250	
12602	 steps: training loss - 83893.22656	, testing loss - 346914.81250	
12603	 steps: training loss - 100374.39844	, testing loss - 348409.12500	
12604	 steps: training loss - 102029.71094	, testing loss - 350838.46875	
12605	 steps: training loss - 97034.53125	, testing loss - 353137.00000	
12606	 steps: training loss - 120045.51562	, testing loss - 354912.00000	
12607	 steps: training loss - 133539.56250	, testing loss - 356652.56250	
12608	 steps: training loss - 104449.26562	, testing loss - 357101.00000	
12609	 steps: training loss - 108620.05469	, testing loss - 356048.78125	
12610	 steps: training loss - 110171.87500	, testing loss - 353097.65625	
12611	 steps: training loss - 124105.64062	, testing loss - 349625.40625	
12612	 steps: training loss - 104784.16406	, testing loss - 347763.46875	
12613	 steps: training loss - 108547.69531	, testing loss - 346655.50000	
12614	 steps: training loss - 105383.42188	, testing loss - 345976.37500	
12615	 steps: training loss - 106247.23438	, testing loss - 345223.93750	
12616	 steps: training loss - 114091.10156	, testing loss - 344253.56250	
12617	 steps: training loss - 113741.10156	, testing loss - 343106.84375	
12618	 steps: training loss - 115695.14062	, testing loss - 342403.40625	
12619	 steps: training loss - 104678.89062	, testing loss - 342004.78125	
12620	 steps: training loss - 100895.12500	, testing loss - 342613.34375	
12621	 steps: training loss - 130213.09375	, testing loss - 343497.12500	
12622	 steps: training loss - 94021.42969	, testing loss - 344599.37500	
12623	 steps: training loss - 99303.24219	, testing loss - 345661.18750	
12624	 steps: training loss - 97959.78125	, testing loss - 346510.84375	
12625	 steps: training loss - 90302.90625	, testing loss - 347491.18750	
12626	 steps: training loss - 120446.90625	, testing loss - 348513.93750	
12627	 steps: training loss - 117556.95312	, testing loss - 349192.71875	
12628	 steps: training loss - 113326.45312	, testing loss - 349991.93750	
12629	 steps: training loss - 79843.90625	, testing loss - 349756.21875	
12630	 steps: training loss - 101983.78125	, testing loss - 349371.46875	
12631	 steps: training loss - 106648.82812	, testing loss - 348721.06250	
12632	 steps: training loss - 113333.57031	, testing loss - 348015.59375	
12633	 steps: training loss - 108855.51562	, testing loss - 347483.06250	
12634	 steps: training loss - 106900.06250	, testing loss - 346994.78125	
12635	 steps: training loss - 108050.14844	, testing loss - 346903.46875	
12636	 steps: training loss - 100547.84375	, testing loss - 347579.87500	
12637	 steps: training loss - 119711.91406	, testing loss - 349216.71875	
12638	 steps: training loss - 144284.51562	, testing loss - 350636.59375	
12639	 steps: training loss - 99435.10938	, testing loss - 352076.21875	
12640	 steps: training loss - 96028.28906	, testing loss - 352667.15625	
12641	 steps: training loss - 109504.25000	, testing loss - 352781.59375	
12642	 steps: training loss - 102179.67969	, testing loss - 352029.34375	
12643	 steps: training loss - 88298.69531	, testing loss - 350441.37500	
12644	 steps: training loss - 106113.28906	, testing loss - 349282.75000	
12645	 steps: training loss - 97956.39062	, testing loss - 347775.65625	
12646	 steps: training loss - 111011.03125	, testing loss - 346249.90625	
12647	 steps: training loss - 81427.98438	, testing loss - 345047.18750	
12648	 steps: training loss - 81945.14844	, testing loss - 344016.68750	
12649	 steps: training loss - 123828.32031	, testing loss - 343432.93750	
12650	 steps: training loss - 95696.95312	, testing loss - 342617.21875	
12651	 steps: training loss - 125377.03906	, testing loss - 341744.78125	
12652	 steps: training loss - 109746.89062	, testing loss - 341328.34375	
12653	 steps: training loss - 122120.75000	, testing loss - 341292.09375	
12654	 steps: training loss - 119784.85938	, testing loss - 341285.50000	
12655	 steps: training loss - 121965.08594	, testing loss - 341175.78125	
12656	 steps: training loss - 101951.08594	, testing loss - 340956.37500	
12657	 steps: training loss - 102611.44531	, testing loss - 340911.31250	
12658	 steps: training loss - 115481.97656	, testing loss - 340703.09375	
12659	 steps: training loss - 114637.36719	, testing loss - 340500.12500	
12660	 steps: training loss - 85209.93750	, testing loss - 340742.37500	
12661	 steps: training loss - 118899.59375	, testing loss - 340860.03125	
12662	 steps: training loss - 115115.75000	, testing loss - 341423.93750	
12663	 steps: training loss - 112766.28125	, testing loss - 342262.34375	
12664	 steps: training loss - 111946.60938	, testing loss - 343016.87500	
12665	 steps: training loss - 106777.08594	, testing loss - 344178.87500	
12666	 steps: training loss - 99838.50000	, testing loss - 345971.68750	
12667	 steps: training loss - 133082.78125	, testing loss - 348030.59375	
12668	 steps: training loss - 106675.90625	, testing loss - 349756.40625	
12669	 steps: training loss - 105070.14062	, testing loss - 351334.68750	
12670	 steps: training loss - 136833.92188	, testing loss - 353380.25000	
12671	 steps: training loss - 93699.96094	, testing loss - 355012.25000	
12672	 steps: training loss - 94135.60938	, testing loss - 355654.71875	
12673	 steps: training loss - 93168.69531	, testing loss - 354852.65625	
12674	 steps: training loss - 109872.43750	, testing loss - 353177.00000	
12675	 steps: training loss - 129892.03906	, testing loss - 350851.18750	
12676	 steps: training loss - 105276.45312	, testing loss - 348489.93750	
12677	 steps: training loss - 112761.39062	, testing loss - 346034.09375	
12678	 steps: training loss - 94315.66406	, testing loss - 345339.18750	
12679	 steps: training loss - 124738.04688	, testing loss - 344968.03125	
12680	 steps: training loss - 85918.56250	, testing loss - 344269.96875	
12681	 steps: training loss - 126082.47656	, testing loss - 343687.43750	
12682	 steps: training loss - 121668.35938	, testing loss - 343324.21875	
12683	 steps: training loss - 103450.12500	, testing loss - 343764.12500	
12684	 steps: training loss - 113478.36719	, testing loss - 344345.46875	
12685	 steps: training loss - 115028.07031	, testing loss - 344904.09375	
12686	 steps: training loss - 94409.57031	, testing loss - 345213.62500	
12687	 steps: training loss - 91154.64844	, testing loss - 345491.43750	
12688	 steps: training loss - 95740.69531	, testing loss - 345494.87500	
12689	 steps: training loss - 114012.14062	, testing loss - 344949.96875	
12690	 steps: training loss - 102843.30469	, testing loss - 344140.53125	
12691	 steps: training loss - 114276.27344	, testing loss - 343337.93750	
12692	 steps: training loss - 105758.71875	, testing loss - 343416.53125	
12693	 steps: training loss - 104430.66406	, testing loss - 344272.15625	
12694	 steps: training loss - 125556.53906	, testing loss - 344835.00000	
12695	 steps: training loss - 127934.79688	, testing loss - 344826.81250	
12696	 steps: training loss - 142796.14062	, testing loss - 344094.71875	
12697	 steps: training loss - 114800.64844	, testing loss - 343465.81250	
12698	 steps: training loss - 93122.97656	, testing loss - 343187.96875	
12699	 steps: training loss - 99872.62500	, testing loss - 342692.93750	
12700	 steps: training loss - 118919.51562	, testing loss - 342235.43750	
12701	 steps: training loss - 111424.17188	, testing loss - 342684.46875	
12702	 steps: training loss - 93264.20312	, testing loss - 342543.59375	
12703	 steps: training loss - 108380.38281	, testing loss - 342288.71875	
12704	 steps: training loss - 104016.67969	, testing loss - 342122.09375	
12705	 steps: training loss - 115136.21094	, testing loss - 341948.25000	
12706	 steps: training loss - 140396.14062	, testing loss - 341660.46875	
12707	 steps: training loss - 106013.98438	, testing loss - 341524.81250	
12708	 steps: training loss - 96148.28125	, testing loss - 342331.81250	
12709	 steps: training loss - 117087.50781	, testing loss - 343306.93750	
12710	 steps: training loss - 119932.50781	, testing loss - 344706.68750	
12711	 steps: training loss - 128494.60938	, testing loss - 346037.25000	
12712	 steps: training loss - 113585.71875	, testing loss - 347437.81250	
12713	 steps: training loss - 92087.68750	, testing loss - 348637.93750	
12714	 steps: training loss - 121825.16406	, testing loss - 349248.06250	
12715	 steps: training loss - 97154.54688	, testing loss - 349505.81250	
12716	 steps: training loss - 122256.40625	, testing loss - 348619.62500	
12717	 steps: training loss - 114891.80469	, testing loss - 347367.00000	
12718	 steps: training loss - 119466.32812	, testing loss - 347219.15625	
12719	 steps: training loss - 115505.36719	, testing loss - 347510.43750	
12720	 steps: training loss - 135082.32812	, testing loss - 347682.59375	
12721	 steps: training loss - 114409.60938	, testing loss - 347787.75000	
12722	 steps: training loss - 90017.41406	, testing loss - 348353.00000	
12723	 steps: training loss - 134812.67188	, testing loss - 349929.93750	
12724	 steps: training loss - 95815.14844	, testing loss - 351631.25000	
12725	 steps: training loss - 98184.64844	, testing loss - 353503.18750	
12726	 steps: training loss - 106051.51562	, testing loss - 354221.90625	
12727	 steps: training loss - 114336.71875	, testing loss - 354174.09375	
12728	 steps: training loss - 119099.24219	, testing loss - 353839.00000	
12729	 steps: training loss - 81508.03906	, testing loss - 354082.59375	
12730	 steps: training loss - 108505.79688	, testing loss - 354427.81250	
12731	 steps: training loss - 90876.38281	, testing loss - 354125.40625	
12732	 steps: training loss - 125125.26562	, testing loss - 354133.93750	
12733	 steps: training loss - 119631.77344	, testing loss - 354218.59375	
12734	 steps: training loss - 94459.21094	, testing loss - 353489.15625	
12735	 steps: training loss - 104761.64062	, testing loss - 353069.34375	
12736	 steps: training loss - 113960.91406	, testing loss - 353023.87500	
12737	 steps: training loss - 116080.47656	, testing loss - 352272.53125	
12738	 steps: training loss - 112180.38281	, testing loss - 350693.40625	
12739	 steps: training loss - 120484.82812	, testing loss - 349009.43750	
12740	 steps: training loss - 119757.37500	, testing loss - 348029.59375	
12741	 steps: training loss - 84331.27344	, testing loss - 347087.68750	
12742	 steps: training loss - 117509.73438	, testing loss - 347270.40625	
12743	 steps: training loss - 110081.53906	, testing loss - 347707.03125	
12744	 steps: training loss - 113851.78125	, testing loss - 349086.96875	
12745	 steps: training loss - 117346.30469	, testing loss - 349590.53125	
12746	 steps: training loss - 118782.53906	, testing loss - 349458.31250	
12747	 steps: training loss - 127238.53906	, testing loss - 348722.87500	
12748	 steps: training loss - 102702.14062	, testing loss - 347594.93750	
12749	 steps: training loss - 105150.18750	, testing loss - 346729.34375	
12750	 steps: training loss - 110015.71875	, testing loss - 345364.00000	
12751	 steps: training loss - 97550.80469	, testing loss - 344277.87500	
12752	 steps: training loss - 81169.06250	, testing loss - 343059.90625	
12753	 steps: training loss - 133323.62500	, testing loss - 342694.87500	
12754	 steps: training loss - 114085.11719	, testing loss - 342971.68750	
12755	 steps: training loss - 101206.31250	, testing loss - 343214.12500	
12756	 steps: training loss - 99922.78125	, testing loss - 343181.15625	
12757	 steps: training loss - 102009.41406	, testing loss - 342642.90625	
12758	 steps: training loss - 109325.47656	, testing loss - 342582.68750	
12759	 steps: training loss - 115381.76562	, testing loss - 342714.34375	
12760	 steps: training loss - 111308.98438	, testing loss - 343166.50000	
12761	 steps: training loss - 97788.39844	, testing loss - 343731.37500	
12762	 steps: training loss - 130361.94531	, testing loss - 344494.71875	
12763	 steps: training loss - 85968.89062	, testing loss - 345025.81250	
12764	 steps: training loss - 116574.79688	, testing loss - 345503.56250	
12765	 steps: training loss - 99681.78125	, testing loss - 345817.65625	
12766	 steps: training loss - 108110.21875	, testing loss - 345672.71875	
12767	 steps: training loss - 111931.32812	, testing loss - 344842.56250	
12768	 steps: training loss - 136430.29688	, testing loss - 344727.78125	
12769	 steps: training loss - 122128.37500	, testing loss - 344563.65625	
12770	 steps: training loss - 106091.75000	, testing loss - 344739.37500	
12771	 steps: training loss - 116431.86719	, testing loss - 345330.50000	
12772	 steps: training loss - 112710.28125	, testing loss - 345159.90625	
12773	 steps: training loss - 112241.20312	, testing loss - 344346.50000	
12774	 steps: training loss - 109119.55469	, testing loss - 343671.68750	
12775	 steps: training loss - 115821.42188	, testing loss - 343416.15625	
12776	 steps: training loss - 120281.49219	, testing loss - 344052.78125	
12777	 steps: training loss - 106951.35938	, testing loss - 345534.12500	
12778	 steps: training loss - 101203.57031	, testing loss - 347479.18750	
12779	 steps: training loss - 109105.89062	, testing loss - 349587.40625	
12780	 steps: training loss - 108462.76562	, testing loss - 351546.68750	
12781	 steps: training loss - 99283.08594	, testing loss - 352674.09375	
12782	 steps: training loss - 122733.12500	, testing loss - 353117.40625	
12783	 steps: training loss - 136329.43750	, testing loss - 352584.21875	
12784	 steps: training loss - 93492.95312	, testing loss - 352793.09375	
12785	 steps: training loss - 139299.48438	, testing loss - 353244.03125	
12786	 steps: training loss - 81333.14844	, testing loss - 352533.96875	
12787	 steps: training loss - 119795.82812	, testing loss - 352457.50000	
12788	 steps: training loss - 115988.33594	, testing loss - 352041.21875	
12789	 steps: training loss - 101983.40625	, testing loss - 351454.15625	
12790	 steps: training loss - 115913.42188	, testing loss - 350998.93750	
12791	 steps: training loss - 93227.50781	, testing loss - 349701.21875	
12792	 steps: training loss - 106459.53906	, testing loss - 348270.68750	
12793	 steps: training loss - 97132.92188	, testing loss - 347144.06250	
12794	 steps: training loss - 104847.62500	, testing loss - 346188.93750	
12795	 steps: training loss - 131752.21875	, testing loss - 345419.65625	
12796	 steps: training loss - 116216.59375	, testing loss - 343844.06250	
12797	 steps: training loss - 113565.12500	, testing loss - 343156.71875	
12798	 steps: training loss - 104491.24219	, testing loss - 342871.71875	
12799	 steps: training loss - 108580.85938	, testing loss - 342428.71875	
12800	 steps: training loss - 118044.00000	, testing loss - 342562.59375	
12801	 steps: training loss - 110639.84375	, testing loss - 343234.06250	
12802	 steps: training loss - 103358.35156	, testing loss - 344198.03125	
12803	 steps: training loss - 119009.96875	, testing loss - 344796.96875	
12804	 steps: training loss - 123931.71094	, testing loss - 345261.65625	
12805	 steps: training loss - 101701.82031	, testing loss - 345385.87500	
12806	 steps: training loss - 128987.50781	, testing loss - 346221.31250	
12807	 steps: training loss - 101985.56250	, testing loss - 346366.31250	
12808	 steps: training loss - 132858.48438	, testing loss - 345235.21875	
12809	 steps: training loss - 101163.55469	, testing loss - 343487.53125	
12810	 steps: training loss - 130665.75781	, testing loss - 342178.96875	
12811	 steps: training loss - 111495.44531	, testing loss - 341464.15625	
12812	 steps: training loss - 110030.89062	, testing loss - 341229.87500	
12813	 steps: training loss - 91687.68750	, testing loss - 341236.93750	
12814	 steps: training loss - 89695.05469	, testing loss - 341233.65625	
12815	 steps: training loss - 130603.08594	, testing loss - 340801.84375	
12816	 steps: training loss - 114225.34375	, testing loss - 340435.90625	
12817	 steps: training loss - 92716.71875	, testing loss - 340355.21875	
12818	 steps: training loss - 116524.76562	, testing loss - 340617.59375	
12819	 steps: training loss - 108256.17969	, testing loss - 340452.31250	
12820	 steps: training loss - 107102.97656	, testing loss - 339975.90625	
12821	 steps: training loss - 102050.94531	, testing loss - 339201.62500	
12822	 steps: training loss - 109594.46094	, testing loss - 338241.84375	
12823	 steps: training loss - 102697.75781	, testing loss - 337303.90625	
12824	 steps: training loss - 145040.71875	, testing loss - 336779.96875	
12825	 steps: training loss - 88771.52344	, testing loss - 337414.90625	
12826	 steps: training loss - 93887.92188	, testing loss - 338654.75000	
12827	 steps: training loss - 113067.71094	, testing loss - 339935.75000	
12828	 steps: training loss - 127568.52344	, testing loss - 342011.65625	
12829	 steps: training loss - 124839.13281	, testing loss - 343869.06250	
12830	 steps: training loss - 122725.53125	, testing loss - 345920.81250	
12831	 steps: training loss - 116921.30469	, testing loss - 348036.62500	
12832	 steps: training loss - 95497.87500	, testing loss - 350201.93750	
12833	 steps: training loss - 104403.34375	, testing loss - 352029.15625	
12834	 steps: training loss - 100176.36719	, testing loss - 354068.40625	
12835	 steps: training loss - 109153.91406	, testing loss - 356529.50000	
12836	 steps: training loss - 130818.23438	, testing loss - 358656.09375	
12837	 steps: training loss - 97027.82031	, testing loss - 359596.90625	
12838	 steps: training loss - 107486.38281	, testing loss - 359552.03125	
12839	 steps: training loss - 109554.39062	, testing loss - 360042.50000	
12840	 steps: training loss - 116835.66406	, testing loss - 359231.84375	
12841	 steps: training loss - 98716.96875	, testing loss - 357002.25000	
12842	 steps: training loss - 109276.72656	, testing loss - 353596.59375	
12843	 steps: training loss - 98026.36719	, testing loss - 351144.03125	
12844	 steps: training loss - 126489.99219	, testing loss - 350208.43750	
12845	 steps: training loss - 93300.03906	, testing loss - 349680.87500	
12846	 steps: training loss - 97398.19531	, testing loss - 349955.09375	
12847	 steps: training loss - 135522.67188	, testing loss - 351317.84375	
12848	 steps: training loss - 113225.92969	, testing loss - 351312.09375	
12849	 steps: training loss - 100716.07031	, testing loss - 349730.09375	
12850	 steps: training loss - 100653.27344	, testing loss - 348675.46875	
12851	 steps: training loss - 100896.89844	, testing loss - 348528.06250	
12852	 steps: training loss - 105411.30469	, testing loss - 348047.78125	
12853	 steps: training loss - 111334.31250	, testing loss - 347126.46875	
12854	 steps: training loss - 115313.31250	, testing loss - 345853.93750	
12855	 steps: training loss - 102367.11719	, testing loss - 344341.31250	
12856	 steps: training loss - 98606.72656	, testing loss - 344062.25000	
12857	 steps: training loss - 126120.55469	, testing loss - 343677.62500	
12858	 steps: training loss - 115515.71094	, testing loss - 344169.71875	
12859	 steps: training loss - 101226.82031	, testing loss - 344920.31250	
12860	 steps: training loss - 99707.42188	, testing loss - 346325.62500	
12861	 steps: training loss - 115692.48438	, testing loss - 348917.84375	
12862	 steps: training loss - 100742.68750	, testing loss - 351440.40625	
12863	 steps: training loss - 120332.07031	, testing loss - 353421.78125	
12864	 steps: training loss - 138619.51562	, testing loss - 355005.62500	
12865	 steps: training loss - 115928.81250	, testing loss - 356068.28125	
12866	 steps: training loss - 117169.10156	, testing loss - 356004.06250	
12867	 steps: training loss - 123657.42969	, testing loss - 353947.62500	
12868	 steps: training loss - 114558.84375	, testing loss - 351131.09375	
12869	 steps: training loss - 134961.70312	, testing loss - 348361.53125	
12870	 steps: training loss - 97556.75781	, testing loss - 345633.90625	
12871	 steps: training loss - 117218.28906	, testing loss - 342907.78125	
12872	 steps: training loss - 105453.83594	, testing loss - 340546.59375	
12873	 steps: training loss - 122868.93750	, testing loss - 339783.15625	
12874	 steps: training loss - 124533.91406	, testing loss - 339745.56250	
12875	 steps: training loss - 111269.48438	, testing loss - 339765.62500	
12876	 steps: training loss - 89047.33594	, testing loss - 339222.78125	
12877	 steps: training loss - 124948.54688	, testing loss - 338648.21875	
12878	 steps: training loss - 104016.31250	, testing loss - 339256.71875	
12879	 steps: training loss - 83623.77344	, testing loss - 339851.53125	
12880	 steps: training loss - 110984.03906	, testing loss - 340035.00000	
12881	 steps: training loss - 98877.34375	, testing loss - 340771.25000	
12882	 steps: training loss - 98517.53125	, testing loss - 341151.50000	
12883	 steps: training loss - 107160.04688	, testing loss - 341271.03125	
12884	 steps: training loss - 92038.79688	, testing loss - 341877.65625	
12885	 steps: training loss - 105330.87500	, testing loss - 342191.03125	
12886	 steps: training loss - 84574.85156	, testing loss - 343038.37500	
12887	 steps: training loss - 91563.35938	, testing loss - 344329.90625	
12888	 steps: training loss - 117213.33594	, testing loss - 345209.96875	
12889	 steps: training loss - 113457.00781	, testing loss - 345226.59375	
12890	 steps: training loss - 103655.64844	, testing loss - 345389.25000	
12891	 steps: training loss - 108938.69531	, testing loss - 345830.09375	
12892	 steps: training loss - 106776.73438	, testing loss - 346064.37500	
12893	 steps: training loss - 83089.24219	, testing loss - 347190.87500	
12894	 steps: training loss - 95761.01562	, testing loss - 347995.12500	
12895	 steps: training loss - 95908.53906	, testing loss - 348568.53125	
12896	 steps: training loss - 98669.80469	, testing loss - 349160.59375	
12897	 steps: training loss - 108912.32031	, testing loss - 349738.25000	
12898	 steps: training loss - 114629.01562	, testing loss - 350615.75000	
12899	 steps: training loss - 114262.22656	, testing loss - 352119.59375	
12900	 steps: training loss - 99198.55469	, testing loss - 353779.90625	
12901	 steps: training loss - 86958.84375	, testing loss - 353973.09375	
12902	 steps: training loss - 132560.59375	, testing loss - 352957.34375	
12903	 steps: training loss - 114839.65625	, testing loss - 352526.90625	
12904	 steps: training loss - 110873.47656	, testing loss - 351554.65625	
12905	 steps: training loss - 112683.11719	, testing loss - 349324.21875	
12906	 steps: training loss - 112788.64062	, testing loss - 346531.50000	
12907	 steps: training loss - 99966.86719	, testing loss - 344070.03125	
12908	 steps: training loss - 125682.24219	, testing loss - 342839.15625	
12909	 steps: training loss - 106549.45312	, testing loss - 342354.09375	
12910	 steps: training loss - 138584.64062	, testing loss - 342360.37500	
12911	 steps: training loss - 91632.74219	, testing loss - 342218.25000	
12912	 steps: training loss - 107366.12500	, testing loss - 341834.65625	
12913	 steps: training loss - 115375.25000	, testing loss - 341309.53125	
12914	 steps: training loss - 93545.55469	, testing loss - 341942.00000	
12915	 steps: training loss - 104137.58594	, testing loss - 342720.96875	
12916	 steps: training loss - 138953.87500	, testing loss - 343201.84375	
12917	 steps: training loss - 111377.03125	, testing loss - 343285.84375	
12918	 steps: training loss - 91714.78125	, testing loss - 343687.12500	
12919	 steps: training loss - 129560.87500	, testing loss - 344176.84375	
12920	 steps: training loss - 107595.10156	, testing loss - 344974.43750	
12921	 steps: training loss - 97022.38281	, testing loss - 346152.81250	
12922	 steps: training loss - 100346.75000	, testing loss - 347048.25000	
12923	 steps: training loss - 112683.78125	, testing loss - 347859.62500	
12924	 steps: training loss - 117837.53906	, testing loss - 348296.40625	
12925	 steps: training loss - 112061.83594	, testing loss - 348741.40625	
12926	 steps: training loss - 101974.00781	, testing loss - 349427.12500	
12927	 steps: training loss - 152440.43750	, testing loss - 350974.50000	
12928	 steps: training loss - 118864.25781	, testing loss - 353072.87500	
12929	 steps: training loss - 104855.92188	, testing loss - 354823.40625	
12930	 steps: training loss - 111302.97656	, testing loss - 355874.18750	
12931	 steps: training loss - 100018.96094	, testing loss - 355796.81250	
12932	 steps: training loss - 114923.10156	, testing loss - 354743.09375	
12933	 steps: training loss - 116040.78906	, testing loss - 353994.09375	
12934	 steps: training loss - 90362.74219	, testing loss - 352529.56250	
12935	 steps: training loss - 96095.85156	, testing loss - 350757.31250	
12936	 steps: training loss - 106644.84375	, testing loss - 348956.75000	
12937	 steps: training loss - 106273.60938	, testing loss - 347667.25000	
12938	 steps: training loss - 103213.62500	, testing loss - 346834.31250	
12939	 steps: training loss - 102918.87500	, testing loss - 346174.37500	
12940	 steps: training loss - 113728.01562	, testing loss - 344869.00000	
12941	 steps: training loss - 103444.25781	, testing loss - 343509.40625	
12942	 steps: training loss - 81114.67188	, testing loss - 342304.75000	
12943	 steps: training loss - 114915.35938	, testing loss - 342089.68750	
12944	 steps: training loss - 97449.72656	, testing loss - 342232.06250	
12945	 steps: training loss - 101275.09375	, testing loss - 342273.06250	
12946	 steps: training loss - 113258.05469	, testing loss - 342049.06250	
12947	 steps: training loss - 113453.50781	, testing loss - 342381.25000	
12948	 steps: training loss - 108300.71875	, testing loss - 342070.65625	
12949	 steps: training loss - 96030.79688	, testing loss - 341958.46875	
12950	 steps: training loss - 102165.52344	, testing loss - 342143.43750	
12951	 steps: training loss - 112025.69531	, testing loss - 342124.25000	
12952	 steps: training loss - 115545.84375	, testing loss - 342056.81250	
12953	 steps: training loss - 118950.54688	, testing loss - 341830.59375	
12954	 steps: training loss - 126783.15625	, testing loss - 341571.46875	
12955	 steps: training loss - 118470.53906	, testing loss - 341577.18750	
12956	 steps: training loss - 93678.05469	, testing loss - 341568.65625	
12957	 steps: training loss - 118067.64844	, testing loss - 341831.71875	
12958	 steps: training loss - 114312.92188	, testing loss - 342551.12500	
12959	 steps: training loss - 105342.92188	, testing loss - 342678.50000	
12960	 steps: training loss - 86167.28125	, testing loss - 342520.50000	
12961	 steps: training loss - 109786.67188	, testing loss - 342075.03125	
12962	 steps: training loss - 104668.89844	, testing loss - 341372.00000	
12963	 steps: training loss - 122874.75000	, testing loss - 341048.53125	
12964	 steps: training loss - 94570.15625	, testing loss - 341140.31250	
12965	 steps: training loss - 111654.10938	, testing loss - 341029.56250	
12966	 steps: training loss - 137016.76562	, testing loss - 340902.25000	
12967	 steps: training loss - 117888.92188	, testing loss - 341609.62500	
12968	 steps: training loss - 109854.10938	, testing loss - 342643.28125	
12969	 steps: training loss - 89317.78125	, testing loss - 343512.06250	
12970	 steps: training loss - 94359.17188	, testing loss - 344217.71875	
12971	 steps: training loss - 93597.66406	, testing loss - 344411.65625	
12972	 steps: training loss - 109892.73438	, testing loss - 344113.65625	
12973	 steps: training loss - 105576.67969	, testing loss - 343249.25000	
12974	 steps: training loss - 115125.64062	, testing loss - 343142.21875	
12975	 steps: training loss - 90374.89062	, testing loss - 343135.68750	
12976	 steps: training loss - 107529.07812	, testing loss - 343399.90625	
12977	 steps: training loss - 83787.82812	, testing loss - 343638.75000	
12978	 steps: training loss - 109339.15625	, testing loss - 343830.46875	
12979	 steps: training loss - 115663.73438	, testing loss - 344646.59375	
12980	 steps: training loss - 77116.57031	, testing loss - 345853.40625	
12981	 steps: training loss - 108709.01562	, testing loss - 347029.03125	
12982	 steps: training loss - 109923.46094	, testing loss - 348180.34375	
12983	 steps: training loss - 113921.64844	, testing loss - 348637.59375	
12984	 steps: training loss - 114154.54688	, testing loss - 349095.43750	
12985	 steps: training loss - 116031.16406	, testing loss - 349204.59375	
12986	 steps: training loss - 94332.50000	, testing loss - 349137.34375	
12987	 steps: training loss - 119408.75781	, testing loss - 349442.68750	
12988	 steps: training loss - 100369.11719	, testing loss - 350991.18750	
12989	 steps: training loss - 101424.37500	, testing loss - 353665.96875	
12990	 steps: training loss - 87244.79688	, testing loss - 354973.62500	
12991	 steps: training loss - 103070.56250	, testing loss - 355507.68750	
12992	 steps: training loss - 115526.65625	, testing loss - 355073.62500	
12993	 steps: training loss - 101877.10938	, testing loss - 354368.46875	
12994	 steps: training loss - 97048.90625	, testing loss - 354177.53125	
12995	 steps: training loss - 114613.60156	, testing loss - 353544.68750	
12996	 steps: training loss - 93919.55469	, testing loss - 353637.71875	
12997	 steps: training loss - 112519.11719	, testing loss - 353695.37500	
12998	 steps: training loss - 95071.55469	, testing loss - 353435.78125	
12999	 steps: training loss - 100034.41406	, testing loss - 352690.15625	
13000	 steps: training loss - 107962.89062	, testing loss - 351442.84375	
13001	 steps: training loss - 116609.37500	, testing loss - 350399.28125	
13002	 steps: training loss - 116778.04688	, testing loss - 349543.34375	
13003	 steps: training loss - 100261.00000	, testing loss - 349247.87500	
13004	 steps: training loss - 114505.65625	, testing loss - 350019.03125	
13005	 steps: training loss - 84675.89062	, testing loss - 351538.87500	
13006	 steps: training loss - 110336.00781	, testing loss - 352956.59375	
13007	 steps: training loss - 115554.31250	, testing loss - 353661.34375	
13008	 steps: training loss - 100480.25781	, testing loss - 352892.93750	
13009	 steps: training loss - 79879.79688	, testing loss - 351263.28125	
13010	 steps: training loss - 129315.60938	, testing loss - 349691.93750	
13011	 steps: training loss - 114061.39062	, testing loss - 347217.96875	
13012	 steps: training loss - 134623.56250	, testing loss - 345452.50000	
13013	 steps: training loss - 127312.89844	, testing loss - 344685.06250	
13014	 steps: training loss - 119896.45312	, testing loss - 343688.50000	
13015	 steps: training loss - 110107.18750	, testing loss - 343151.59375	
13016	 steps: training loss - 91193.07812	, testing loss - 343642.75000	
13017	 steps: training loss - 113769.64844	, testing loss - 344639.56250	
13018	 steps: training loss - 105147.56250	, testing loss - 346251.78125	
13019	 steps: training loss - 95559.69531	, testing loss - 347516.34375	
13020	 steps: training loss - 100942.96875	, testing loss - 347946.81250	
13021	 steps: training loss - 106126.29688	, testing loss - 348233.03125	
13022	 steps: training loss - 102326.34375	, testing loss - 348155.59375	
13023	 steps: training loss - 109888.25000	, testing loss - 347140.03125	
13024	 steps: training loss - 95294.41406	, testing loss - 345705.06250	
13025	 steps: training loss - 104896.46875	, testing loss - 344863.06250	
13026	 steps: training loss - 119588.25781	, testing loss - 344859.96875	
13027	 steps: training loss - 123137.39062	, testing loss - 345527.40625	
13028	 steps: training loss - 122596.07031	, testing loss - 346562.37500	
13029	 steps: training loss - 95601.34375	, testing loss - 347550.84375	
13030	 steps: training loss - 128819.81250	, testing loss - 348463.43750	
13031	 steps: training loss - 94253.23438	, testing loss - 348844.87500	
13032	 steps: training loss - 117057.05469	, testing loss - 349348.84375	
13033	 steps: training loss - 124254.88281	, testing loss - 349522.71875	
13034	 steps: training loss - 121764.74219	, testing loss - 349975.56250	
13035	 steps: training loss - 122367.02344	, testing loss - 349607.06250	
13036	 steps: training loss - 84418.67969	, testing loss - 349565.46875	
13037	 steps: training loss - 111352.00000	, testing loss - 349666.31250	
13038	 steps: training loss - 121887.20312	, testing loss - 350262.00000	
13039	 steps: training loss - 106225.46875	, testing loss - 352215.90625	
13040	 steps: training loss - 102632.64844	, testing loss - 355050.46875	
13041	 steps: training loss - 101947.28125	, testing loss - 356274.15625	
13042	 steps: training loss - 137271.31250	, testing loss - 355920.31250	
13043	 steps: training loss - 123993.46875	, testing loss - 355115.50000	
13044	 steps: training loss - 104050.11719	, testing loss - 353527.96875	
13045	 steps: training loss - 103629.60938	, testing loss - 351710.68750	
13046	 steps: training loss - 139957.82812	, testing loss - 350126.59375	
13047	 steps: training loss - 122042.38281	, testing loss - 347790.40625	
13048	 steps: training loss - 123827.85938	, testing loss - 346065.18750	
13049	 steps: training loss - 89630.93750	, testing loss - 345191.00000	
13050	 steps: training loss - 112659.32812	, testing loss - 345270.37500	
13051	 steps: training loss - 132557.87500	, testing loss - 345808.78125	
13052	 steps: training loss - 104875.02344	, testing loss - 347899.87500	
13053	 steps: training loss - 113293.23438	, testing loss - 350888.31250	
13054	 steps: training loss - 116276.04688	, testing loss - 354482.25000	
13055	 steps: training loss - 108232.18750	, testing loss - 356604.40625	
13056	 steps: training loss - 153579.84375	, testing loss - 357034.43750	
13057	 steps: training loss - 91024.51562	, testing loss - 356200.59375	
13058	 steps: training loss - 122001.67969	, testing loss - 355227.81250	
13059	 steps: training loss - 118868.11719	, testing loss - 355720.18750	
13060	 steps: training loss - 116910.16406	, testing loss - 355999.25000	
13061	 steps: training loss - 115760.47656	, testing loss - 357024.25000	
13062	 steps: training loss - 117510.43750	, testing loss - 357917.65625	
13063	 steps: training loss - 99095.30469	, testing loss - 359582.50000	
13064	 steps: training loss - 121415.75000	, testing loss - 360863.96875	
13065	 steps: training loss - 108742.91406	, testing loss - 361740.12500	
13066	 steps: training loss - 100497.39062	, testing loss - 360964.96875	
13067	 steps: training loss - 106207.12500	, testing loss - 359720.46875	
13068	 steps: training loss - 119424.96875	, testing loss - 358147.31250	
13069	 steps: training loss - 117507.79688	, testing loss - 356397.37500	
13070	 steps: training loss - 121824.90625	, testing loss - 354275.90625	
13071	 steps: training loss - 104817.82031	, testing loss - 353080.40625	
13072	 steps: training loss - 92328.96094	, testing loss - 352991.65625	
13073	 steps: training loss - 130167.54688	, testing loss - 352103.62500	
13074	 steps: training loss - 111548.83594	, testing loss - 350137.37500	
13075	 steps: training loss - 116740.50000	, testing loss - 348627.87500	
13076	 steps: training loss - 110034.09375	, testing loss - 347835.56250	
13077	 steps: training loss - 124490.38281	, testing loss - 347806.71875	
13078	 steps: training loss - 110958.78906	, testing loss - 347900.59375	
13079	 steps: training loss - 121438.50781	, testing loss - 347923.34375	
13080	 steps: training loss - 109361.67969	, testing loss - 347721.56250	
13081	 steps: training loss - 108770.82031	, testing loss - 347158.21875	
13082	 steps: training loss - 115743.38281	, testing loss - 347246.28125	
13083	 steps: training loss - 88193.89062	, testing loss - 348224.90625	
13084	 steps: training loss - 103702.78906	, testing loss - 349163.37500	
13085	 steps: training loss - 108946.91406	, testing loss - 349690.18750	
13086	 steps: training loss - 123759.00000	, testing loss - 349683.90625	
13087	 steps: training loss - 95835.69531	, testing loss - 349351.71875	
13088	 steps: training loss - 125313.27344	, testing loss - 349488.46875	
13089	 steps: training loss - 92945.71094	, testing loss - 349206.37500	
13090	 steps: training loss - 96550.46875	, testing loss - 348597.31250	
13091	 steps: training loss - 102645.32812	, testing loss - 347895.43750	
13092	 steps: training loss - 101844.14062	, testing loss - 347615.71875	
13093	 steps: training loss - 106770.57812	, testing loss - 347692.37500	
13094	 steps: training loss - 105196.62500	, testing loss - 347310.34375	
13095	 steps: training loss - 113483.68750	, testing loss - 346414.46875	
13096	 steps: training loss - 137317.78125	, testing loss - 346078.28125	
13097	 steps: training loss - 101424.67969	, testing loss - 346911.09375	
13098	 steps: training loss - 93126.27344	, testing loss - 348708.12500	
13099	 steps: training loss - 110753.19531	, testing loss - 350187.62500	
13100	 steps: training loss - 97851.24219	, testing loss - 351627.81250	
13101	 steps: training loss - 102060.14844	, testing loss - 352894.28125	
13102	 steps: training loss - 101245.84375	, testing loss - 354457.65625	
13103	 steps: training loss - 119068.76562	, testing loss - 355309.62500	
13104	 steps: training loss - 100733.03125	, testing loss - 355255.46875	
13105	 steps: training loss - 114746.46875	, testing loss - 355185.90625	
13106	 steps: training loss - 123981.84375	, testing loss - 354126.68750	
13107	 steps: training loss - 94244.60156	, testing loss - 352782.37500	
13108	 steps: training loss - 108225.92969	, testing loss - 351531.87500	
13109	 steps: training loss - 117041.78906	, testing loss - 350121.93750	
13110	 steps: training loss - 94019.97656	, testing loss - 350318.65625	
13111	 steps: training loss - 93568.57031	, testing loss - 351142.87500	
13112	 steps: training loss - 134483.93750	, testing loss - 352561.46875	
13113	 steps: training loss - 96802.52344	, testing loss - 353536.06250	
13114	 steps: training loss - 101626.18750	, testing loss - 353683.96875	
13115	 steps: training loss - 134190.85938	, testing loss - 353192.87500	
13116	 steps: training loss - 118801.60156	, testing loss - 352664.71875	
13117	 steps: training loss - 86805.54688	, testing loss - 351897.34375	
13118	 steps: training loss - 108244.14844	, testing loss - 350763.81250	
13119	 steps: training loss - 138256.54688	, testing loss - 349317.12500	
13120	 steps: training loss - 116638.09375	, testing loss - 347193.87500	
13121	 steps: training loss - 97539.39844	, testing loss - 345329.40625	
13122	 steps: training loss - 123571.80469	, testing loss - 344556.96875	
13123	 steps: training loss - 116950.22656	, testing loss - 344504.50000	
13124	 steps: training loss - 123120.42188	, testing loss - 344306.93750	
13125	 steps: training loss - 116465.83594	, testing loss - 344546.75000	
13126	 steps: training loss - 112770.98438	, testing loss - 344939.59375	
13127	 steps: training loss - 124332.28906	, testing loss - 344899.81250	
13128	 steps: training loss - 109515.04688	, testing loss - 344148.50000	
13129	 steps: training loss - 129225.05469	, testing loss - 343858.31250	
13130	 steps: training loss - 111501.21094	, testing loss - 343845.46875	
13131	 steps: training loss - 93943.40625	, testing loss - 343503.65625	
13132	 steps: training loss - 99667.75781	, testing loss - 343285.71875	
13133	 steps: training loss - 109632.53906	, testing loss - 344122.40625	
13134	 steps: training loss - 102107.73438	, testing loss - 345182.46875	
13135	 steps: training loss - 88482.91406	, testing loss - 346165.25000	
13136	 steps: training loss - 114373.57031	, testing loss - 346408.40625	
13137	 steps: training loss - 103740.53125	, testing loss - 346351.40625	
13138	 steps: training loss - 113799.82031	, testing loss - 346073.84375	
13139	 steps: training loss - 110378.81250	, testing loss - 345845.71875	
13140	 steps: training loss - 100106.34375	, testing loss - 345803.87500	
13141	 steps: training loss - 115897.17969	, testing loss - 346057.81250	
13142	 steps: training loss - 93290.22656	, testing loss - 346022.18750	
13143	 steps: training loss - 108817.07031	, testing loss - 346119.93750	
13144	 steps: training loss - 106746.00781	, testing loss - 346275.87500	
13145	 steps: training loss - 98608.58594	, testing loss - 346618.56250	
13146	 steps: training loss - 83590.77344	, testing loss - 346497.93750	
13147	 steps: training loss - 102415.28125	, testing loss - 345783.21875	
13148	 steps: training loss - 135482.00000	, testing loss - 345984.84375	
13149	 steps: training loss - 114238.98438	, testing loss - 346866.50000	
13150	 steps: training loss - 137323.57812	, testing loss - 347537.81250	
13151	 steps: training loss - 112337.06250	, testing loss - 348006.93750	
13152	 steps: training loss - 93189.86719	, testing loss - 347820.28125	
13153	 steps: training loss - 112095.96094	, testing loss - 347953.06250	
13154	 steps: training loss - 96160.47656	, testing loss - 347880.25000	
13155	 steps: training loss - 118962.27344	, testing loss - 348134.40625	
13156	 steps: training loss - 106138.76562	, testing loss - 348330.75000	
13157	 steps: training loss - 102290.59375	, testing loss - 348687.75000	
13158	 steps: training loss - 99086.32812	, testing loss - 349594.46875	
13159	 steps: training loss - 98205.46875	, testing loss - 351431.15625	
13160	 steps: training loss - 117133.30469	, testing loss - 353792.46875	
13161	 steps: training loss - 104855.57812	, testing loss - 355059.28125	
13162	 steps: training loss - 103134.92188	, testing loss - 355805.12500	
13163	 steps: training loss - 97869.71094	, testing loss - 357187.56250	
13164	 steps: training loss - 96926.11719	, testing loss - 357939.03125	
13165	 steps: training loss - 113125.50781	, testing loss - 358019.87500	
13166	 steps: training loss - 106921.06250	, testing loss - 358031.31250	
13167	 steps: training loss - 107453.31250	, testing loss - 359104.12500	
13168	 steps: training loss - 98716.50781	, testing loss - 359638.31250	
13169	 steps: training loss - 135904.75000	, testing loss - 359139.81250	
13170	 steps: training loss - 153123.40625	, testing loss - 357239.12500	
13171	 steps: training loss - 120974.09375	, testing loss - 355604.03125	
13172	 steps: training loss - 86372.57812	, testing loss - 353781.78125	
13173	 steps: training loss - 103913.25781	, testing loss - 352270.34375	
13174	 steps: training loss - 108023.29688	, testing loss - 351612.90625	
13175	 steps: training loss - 121678.13281	, testing loss - 352437.93750	
13176	 steps: training loss - 96206.81250	, testing loss - 352852.62500	
13177	 steps: training loss - 117751.47656	, testing loss - 353073.21875	
13178	 steps: training loss - 113088.11719	, testing loss - 354346.09375	
13179	 steps: training loss - 102378.69531	, testing loss - 355007.62500	
13180	 steps: training loss - 106542.04688	, testing loss - 355216.84375	
13181	 steps: training loss - 91361.31250	, testing loss - 355213.31250	
13182	 steps: training loss - 109598.06250	, testing loss - 354681.78125	
13183	 steps: training loss - 106661.03906	, testing loss - 352797.87500	
13184	 steps: training loss - 125247.17188	, testing loss - 350137.90625	
13185	 steps: training loss - 95038.79688	, testing loss - 346638.37500	
13186	 steps: training loss - 110239.92969	, testing loss - 344157.53125	
13187	 steps: training loss - 97008.59375	, testing loss - 342138.03125	
13188	 steps: training loss - 90195.19531	, testing loss - 340806.96875	
13189	 steps: training loss - 116582.14844	, testing loss - 340461.59375	
13190	 steps: training loss - 104875.31250	, testing loss - 340398.40625	
13191	 steps: training loss - 111381.57812	, testing loss - 340876.71875	
13192	 steps: training loss - 98331.96094	, testing loss - 342010.62500	
13193	 steps: training loss - 95361.33594	, testing loss - 343017.37500	
13194	 steps: training loss - 113484.60938	, testing loss - 343976.03125	
13195	 steps: training loss - 111977.14844	, testing loss - 344511.71875	
13196	 steps: training loss - 100611.50781	, testing loss - 345706.75000	
13197	 steps: training loss - 106675.37500	, testing loss - 347085.68750	
13198	 steps: training loss - 85763.35156	, testing loss - 347251.43750	
13199	 steps: training loss - 104540.98438	, testing loss - 347145.21875	
13200	 steps: training loss - 134142.43750	, testing loss - 346435.18750	
13201	 steps: training loss - 117716.28125	, testing loss - 345864.84375	
13202	 steps: training loss - 97951.82812	, testing loss - 344975.25000	
13203	 steps: training loss - 115929.32031	, testing loss - 344198.65625	
13204	 steps: training loss - 123239.29688	, testing loss - 343815.46875	
13205	 steps: training loss - 114900.59375	, testing loss - 343474.81250	
13206	 steps: training loss - 102425.05469	, testing loss - 343685.00000	
13207	 steps: training loss - 94515.46875	, testing loss - 344843.59375	
13208	 steps: training loss - 94013.75781	, testing loss - 345973.81250	
13209	 steps: training loss - 118316.89062	, testing loss - 346430.00000	
13210	 steps: training loss - 97273.71875	, testing loss - 346300.09375	
13211	 steps: training loss - 104980.57812	, testing loss - 346009.00000	
13212	 steps: training loss - 120788.81250	, testing loss - 346349.78125	
13213	 steps: training loss - 121479.06250	, testing loss - 346553.15625	
13214	 steps: training loss - 106900.21094	, testing loss - 346973.84375	
13215	 steps: training loss - 93121.23438	, testing loss - 347741.06250	
13216	 steps: training loss - 114065.57031	, testing loss - 347988.31250	
13217	 steps: training loss - 125582.05469	, testing loss - 347979.50000	
13218	 steps: training loss - 105080.39844	, testing loss - 348247.09375	
13219	 steps: training loss - 129715.61719	, testing loss - 348720.59375	
13220	 steps: training loss - 123608.24219	, testing loss - 350026.75000	
13221	 steps: training loss - 114421.39062	, testing loss - 350706.93750	
13222	 steps: training loss - 116926.12500	, testing loss - 351005.65625	
13223	 steps: training loss - 75160.68750	, testing loss - 350962.15625	
13224	 steps: training loss - 120238.53125	, testing loss - 351347.03125	
13225	 steps: training loss - 104996.04688	, testing loss - 351282.59375	
13226	 steps: training loss - 116865.86719	, testing loss - 350443.00000	
13227	 steps: training loss - 88937.01562	, testing loss - 349598.25000	
13228	 steps: training loss - 124434.33594	, testing loss - 349253.62500	
13229	 steps: training loss - 122787.89844	, testing loss - 349267.93750	
13230	 steps: training loss - 103804.07031	, testing loss - 349487.15625	
13231	 steps: training loss - 114762.91406	, testing loss - 349278.31250	
13232	 steps: training loss - 98065.55469	, testing loss - 349104.15625	
13233	 steps: training loss - 93316.35938	, testing loss - 348420.81250	
13234	 steps: training loss - 129988.07031	, testing loss - 347810.21875	
13235	 steps: training loss - 115317.53125	, testing loss - 346934.96875	
13236	 steps: training loss - 125879.47656	, testing loss - 345816.15625	
13237	 steps: training loss - 121010.19531	, testing loss - 344524.65625	
13238	 steps: training loss - 94388.08594	, testing loss - 344410.09375	
13239	 steps: training loss - 88088.40625	, testing loss - 345068.37500	
13240	 steps: training loss - 120885.31250	, testing loss - 346082.21875	
13241	 steps: training loss - 82537.84375	, testing loss - 346763.59375	
13242	 steps: training loss - 100801.10938	, testing loss - 347116.90625	
13243	 steps: training loss - 108692.00000	, testing loss - 347794.84375	
13244	 steps: training loss - 111412.79688	, testing loss - 348603.31250	
13245	 steps: training loss - 100013.62500	, testing loss - 349615.50000	
13246	 steps: training loss - 100468.40625	, testing loss - 350782.25000	
13247	 steps: training loss - 111736.69531	, testing loss - 351177.21875	
13248	 steps: training loss - 112792.88281	, testing loss - 351716.75000	
13249	 steps: training loss - 116560.12500	, testing loss - 353501.03125	
13250	 steps: training loss - 90617.75000	, testing loss - 355246.09375	
13251	 steps: training loss - 105792.30469	, testing loss - 355386.12500	
13252	 steps: training loss - 92506.79688	, testing loss - 354693.71875	
13253	 steps: training loss - 113742.50781	, testing loss - 354250.53125	
13254	 steps: training loss - 119738.22656	, testing loss - 353616.90625	
13255	 steps: training loss - 102414.92188	, testing loss - 353110.43750	
13256	 steps: training loss - 99924.65625	, testing loss - 353790.75000	
13257	 steps: training loss - 88142.86719	, testing loss - 353953.62500	
13258	 steps: training loss - 103101.58594	, testing loss - 353838.65625	
13259	 steps: training loss - 110674.82031	, testing loss - 353354.15625	
13260	 steps: training loss - 88342.18750	, testing loss - 354024.34375	
13261	 steps: training loss - 140065.64062	, testing loss - 354337.34375	
13262	 steps: training loss - 101926.39844	, testing loss - 353197.12500	
13263	 steps: training loss - 96164.12500	, testing loss - 352605.75000	
13264	 steps: training loss - 80383.75781	, testing loss - 351864.15625	
13265	 steps: training loss - 97438.71875	, testing loss - 351415.18750	
13266	 steps: training loss - 116720.64844	, testing loss - 350899.65625	
13267	 steps: training loss - 118507.96875	, testing loss - 349545.75000	
13268	 steps: training loss - 120221.89062	, testing loss - 347513.81250	
13269	 steps: training loss - 102428.05469	, testing loss - 346406.18750	
13270	 steps: training loss - 95911.27344	, testing loss - 344576.75000	
13271	 steps: training loss - 88067.86719	, testing loss - 342702.03125	
13272	 steps: training loss - 104256.32031	, testing loss - 340870.59375	
13273	 steps: training loss - 95351.60156	, testing loss - 340179.12500	
13274	 steps: training loss - 118498.85156	, testing loss - 339961.78125	
13275	 steps: training loss - 105435.42188	, testing loss - 339810.71875	
13276	 steps: training loss - 117377.58594	, testing loss - 339798.93750	
13277	 steps: training loss - 106761.05469	, testing loss - 339738.06250	
13278	 steps: training loss - 76619.50000	, testing loss - 340819.78125	
13279	 steps: training loss - 72292.74219	, testing loss - 342200.25000	
13280	 steps: training loss - 98112.39844	, testing loss - 342617.65625	
13281	 steps: training loss - 86984.92969	, testing loss - 343486.71875	
13282	 steps: training loss - 111323.57031	, testing loss - 344170.40625	
13283	 steps: training loss - 133286.70312	, testing loss - 344303.68750	
13284	 steps: training loss - 130837.67969	, testing loss - 343319.34375	
13285	 steps: training loss - 105391.05469	, testing loss - 343074.25000	
13286	 steps: training loss - 113216.92188	, testing loss - 342411.50000	
13287	 steps: training loss - 119394.29688	, testing loss - 341635.00000	
13288	 steps: training loss - 115055.71094	, testing loss - 341233.40625	
13289	 steps: training loss - 97075.87500	, testing loss - 341018.21875	
13290	 steps: training loss - 109775.95312	, testing loss - 341585.03125	
13291	 steps: training loss - 118598.04688	, testing loss - 342646.25000	
13292	 steps: training loss - 125418.35938	, testing loss - 343825.71875	
13293	 steps: training loss - 132050.18750	, testing loss - 343901.56250	
13294	 steps: training loss - 103821.78125	, testing loss - 343765.31250	
13295	 steps: training loss - 120957.70312	, testing loss - 343826.21875	
13296	 steps: training loss - 128295.45312	, testing loss - 343520.96875	
13297	 steps: training loss - 88947.35938	, testing loss - 345009.71875	
13298	 steps: training loss - 128381.02344	, testing loss - 347585.46875	
13299	 steps: training loss - 117623.82812	, testing loss - 349920.34375	
13300	 steps: training loss - 116932.15625	, testing loss - 353108.93750	
13301	 steps: training loss - 103905.69531	, testing loss - 355248.43750	
13302	 steps: training loss - 93955.93750	, testing loss - 356216.71875	
13303	 steps: training loss - 92279.07031	, testing loss - 355725.50000	
13304	 steps: training loss - 117680.84375	, testing loss - 354857.25000	
13305	 steps: training loss - 83619.35156	, testing loss - 354091.68750	
13306	 steps: training loss - 103740.39844	, testing loss - 353720.31250	
13307	 steps: training loss - 101903.31250	, testing loss - 353086.96875	
13308	 steps: training loss - 127904.24219	, testing loss - 351907.96875	
13309	 steps: training loss - 112813.27344	, testing loss - 350195.25000	
13310	 steps: training loss - 141303.82812	, testing loss - 348318.56250	
13311	 steps: training loss - 97536.12500	, testing loss - 346887.21875	
13312	 steps: training loss - 115527.99219	, testing loss - 345606.87500	
13313	 steps: training loss - 108111.63281	, testing loss - 345299.62500	
13314	 steps: training loss - 121844.65625	, testing loss - 344977.25000	
13315	 steps: training loss - 108473.70312	, testing loss - 345175.15625	
13316	 steps: training loss - 104271.82031	, testing loss - 346183.62500	
13317	 steps: training loss - 103659.71875	, testing loss - 347139.25000	
13318	 steps: training loss - 111032.21094	, testing loss - 347683.18750	
13319	 steps: training loss - 100880.82031	, testing loss - 348240.75000	
13320	 steps: training loss - 97691.27344	, testing loss - 348470.21875	
13321	 steps: training loss - 86184.62500	, testing loss - 347926.59375	
13322	 steps: training loss - 116199.67969	, testing loss - 346885.34375	
13323	 steps: training loss - 121078.96875	, testing loss - 345512.46875	
13324	 steps: training loss - 114411.59375	, testing loss - 344163.34375	
13325	 steps: training loss - 112394.80469	, testing loss - 343700.00000	
13326	 steps: training loss - 104255.77344	, testing loss - 343871.03125	
13327	 steps: training loss - 142340.73438	, testing loss - 344396.34375	
13328	 steps: training loss - 99637.67188	, testing loss - 344798.90625	
13329	 steps: training loss - 100095.78906	, testing loss - 344751.06250	
13330	 steps: training loss - 132931.01562	, testing loss - 343963.81250	
13331	 steps: training loss - 92996.74219	, testing loss - 344534.96875	
13332	 steps: training loss - 117666.92188	, testing loss - 345092.71875	
13333	 steps: training loss - 127544.64844	, testing loss - 345314.18750	
13334	 steps: training loss - 89638.25000	, testing loss - 345915.31250	
13335	 steps: training loss - 99359.89062	, testing loss - 346609.34375	
13336	 steps: training loss - 93919.75000	, testing loss - 346875.59375	
13337	 steps: training loss - 107371.14062	, testing loss - 346888.75000	
13338	 steps: training loss - 83503.04688	, testing loss - 346370.71875	
13339	 steps: training loss - 98839.89844	, testing loss - 345516.25000	
13340	 steps: training loss - 105262.85156	, testing loss - 345091.15625	
13341	 steps: training loss - 107783.93750	, testing loss - 345730.37500	
13342	 steps: training loss - 77630.25000	, testing loss - 345953.93750	
13343	 steps: training loss - 114732.12500	, testing loss - 346123.15625	
13344	 steps: training loss - 114871.96094	, testing loss - 346208.46875	
13345	 steps: training loss - 111613.71875	, testing loss - 346051.90625	
13346	 steps: training loss - 100533.96094	, testing loss - 345976.90625	
13347	 steps: training loss - 99476.03906	, testing loss - 346474.46875	
13348	 steps: training loss - 106849.22656	, testing loss - 347104.62500	
13349	 steps: training loss - 99778.01562	, testing loss - 347726.31250	
13350	 steps: training loss - 99518.41406	, testing loss - 348273.40625	
13351	 steps: training loss - 107381.04688	, testing loss - 348525.56250	
13352	 steps: training loss - 97089.55469	, testing loss - 348611.28125	
13353	 steps: training loss - 131830.56250	, testing loss - 348669.12500	
13354	 steps: training loss - 117915.01562	, testing loss - 349185.09375	
13355	 steps: training loss - 120198.32031	, testing loss - 349163.81250	
13356	 steps: training loss - 92100.31250	, testing loss - 349182.75000	
13357	 steps: training loss - 113693.08594	, testing loss - 348655.43750	
13358	 steps: training loss - 114241.16406	, testing loss - 348449.75000	
13359	 steps: training loss - 115927.46094	, testing loss - 348307.46875	
13360	 steps: training loss - 109885.96875	, testing loss - 347688.62500	
13361	 steps: training loss - 129916.10938	, testing loss - 347534.43750	
13362	 steps: training loss - 100947.99219	, testing loss - 348566.15625	
13363	 steps: training loss - 95399.43750	, testing loss - 349922.65625	
13364	 steps: training loss - 94151.81250	, testing loss - 349913.21875	
13365	 steps: training loss - 96171.14062	, testing loss - 349692.90625	
13366	 steps: training loss - 92826.11719	, testing loss - 349622.71875	
13367	 steps: training loss - 108993.14062	, testing loss - 349274.09375	
13368	 steps: training loss - 120740.65625	, testing loss - 349362.90625	
13369	 steps: training loss - 116871.36719	, testing loss - 349578.65625	
13370	 steps: training loss - 131042.99219	, testing loss - 349112.65625	
13371	 steps: training loss - 107442.31250	, testing loss - 349148.25000	
13372	 steps: training loss - 136970.68750	, testing loss - 349374.96875	
13373	 steps: training loss - 112666.14844	, testing loss - 349592.62500	
13374	 steps: training loss - 93225.54688	, testing loss - 349905.06250	
13375	 steps: training loss - 109979.37500	, testing loss - 349201.46875	
13376	 steps: training loss - 85800.81250	, testing loss - 349368.50000	
13377	 steps: training loss - 131618.00000	, testing loss - 350165.06250	
13378	 steps: training loss - 123398.56250	, testing loss - 350948.00000	
13379	 steps: training loss - 89863.89062	, testing loss - 351474.50000	
13380	 steps: training loss - 109362.03125	, testing loss - 352482.28125	
13381	 steps: training loss - 118176.89844	, testing loss - 353506.78125	
13382	 steps: training loss - 104793.30469	, testing loss - 354930.50000	
13383	 steps: training loss - 132536.93750	, testing loss - 357496.18750	
13384	 steps: training loss - 119023.64062	, testing loss - 359287.81250	
13385	 steps: training loss - 130080.84375	, testing loss - 360811.46875	
13386	 steps: training loss - 94914.62500	, testing loss - 361666.78125	
13387	 steps: training loss - 109695.53125	, testing loss - 361592.78125	
13388	 steps: training loss - 102340.15625	, testing loss - 360802.12500	
13389	 steps: training loss - 109869.57031	, testing loss - 359941.31250	
13390	 steps: training loss - 113128.57031	, testing loss - 358332.50000	
13391	 steps: training loss - 118104.83594	, testing loss - 354949.75000	
13392	 steps: training loss - 111620.31250	, testing loss - 352759.75000	
13393	 steps: training loss - 87365.59375	, testing loss - 351932.31250	
13394	 steps: training loss - 115073.38281	, testing loss - 351349.93750	
13395	 steps: training loss - 108898.09375	, testing loss - 350952.00000	
13396	 steps: training loss - 127235.96875	, testing loss - 349781.46875	
13397	 steps: training loss - 112993.79688	, testing loss - 348127.34375	
13398	 steps: training loss - 91530.78125	, testing loss - 347736.93750	
13399	 steps: training loss - 95286.55469	, testing loss - 348123.31250	
13400	 steps: training loss - 117587.75000	, testing loss - 348485.18750	
13401	 steps: training loss - 113802.49219	, testing loss - 348917.40625	
13402	 steps: training loss - 150070.46875	, testing loss - 348417.00000	
13403	 steps: training loss - 108359.09375	, testing loss - 348019.25000	
13404	 steps: training loss - 89082.56250	, testing loss - 348366.34375	
13405	 steps: training loss - 107992.75781	, testing loss - 348442.75000	
13406	 steps: training loss - 108092.52344	, testing loss - 348594.71875	
13407	 steps: training loss - 111458.86719	, testing loss - 349418.87500	
13408	 steps: training loss - 81249.50781	, testing loss - 350302.12500	
13409	 steps: training loss - 98835.82031	, testing loss - 350907.81250	
13410	 steps: training loss - 88109.71094	, testing loss - 350649.03125	
13411	 steps: training loss - 108720.14062	, testing loss - 349488.12500	
13412	 steps: training loss - 120352.00000	, testing loss - 348438.62500	
13413	 steps: training loss - 92595.92188	, testing loss - 347057.90625	
13414	 steps: training loss - 97455.46094	, testing loss - 345636.28125	
13415	 steps: training loss - 107304.96875	, testing loss - 344853.28125	
13416	 steps: training loss - 94503.39062	, testing loss - 344565.43750	
13417	 steps: training loss - 95548.89062	, testing loss - 344194.06250	
13418	 steps: training loss - 116000.98438	, testing loss - 344230.75000	
13419	 steps: training loss - 114875.46875	, testing loss - 344352.12500	
13420	 steps: training loss - 89501.57812	, testing loss - 344182.40625	
13421	 steps: training loss - 120830.44531	, testing loss - 343991.18750	
13422	 steps: training loss - 113135.17188	, testing loss - 343232.87500	
13423	 steps: training loss - 129764.37500	, testing loss - 342532.21875	
13424	 steps: training loss - 115075.86719	, testing loss - 343573.06250	
13425	 steps: training loss - 121304.80469	, testing loss - 345607.40625	
13426	 steps: training loss - 115393.45312	, testing loss - 348175.15625	
13427	 steps: training loss - 98143.37500	, testing loss - 350797.84375	
13428	 steps: training loss - 106575.48438	, testing loss - 353250.12500	
13429	 steps: training loss - 98629.92969	, testing loss - 356492.31250	
13430	 steps: training loss - 98642.64844	, testing loss - 359184.65625	
13431	 steps: training loss - 96221.68750	, testing loss - 361088.78125	
13432	 steps: training loss - 97159.67188	, testing loss - 361733.59375	
13433	 steps: training loss - 117456.03125	, testing loss - 361966.15625	
13434	 steps: training loss - 116987.10156	, testing loss - 361662.75000	
13435	 steps: training loss - 103919.45312	, testing loss - 359740.06250	
13436	 steps: training loss - 129622.40625	, testing loss - 357217.28125	
13437	 steps: training loss - 119144.51562	, testing loss - 355699.71875	
13438	 steps: training loss - 123033.28906	, testing loss - 355222.65625	
13439	 steps: training loss - 112912.48438	, testing loss - 354637.25000	
13440	 steps: training loss - 111733.48438	, testing loss - 353955.37500	
13441	 steps: training loss - 111435.28906	, testing loss - 353512.87500	
13442	 steps: training loss - 121162.37500	, testing loss - 354288.50000	
13443	 steps: training loss - 128729.80469	, testing loss - 354654.68750	
13444	 steps: training loss - 110499.73438	, testing loss - 354005.12500	
13445	 steps: training loss - 116361.62500	, testing loss - 354367.09375	
13446	 steps: training loss - 89857.70312	, testing loss - 354316.18750	
13447	 steps: training loss - 112864.98438	, testing loss - 354560.50000	
13448	 steps: training loss - 109776.43750	, testing loss - 355008.18750	
13449	 steps: training loss - 134563.42188	, testing loss - 355272.09375	
13450	 steps: training loss - 103913.60938	, testing loss - 354629.71875	
13451	 steps: training loss - 86268.89062	, testing loss - 352470.34375	
13452	 steps: training loss - 120437.37500	, testing loss - 349831.65625	
13453	 steps: training loss - 105191.44531	, testing loss - 348101.87500	
13454	 steps: training loss - 100847.39062	, testing loss - 346491.56250	
13455	 steps: training loss - 129585.95312	, testing loss - 344695.53125	
13456	 steps: training loss - 110699.67188	, testing loss - 343350.62500	
13457	 steps: training loss - 124155.10938	, testing loss - 342057.71875	
13458	 steps: training loss - 148438.68750	, testing loss - 341371.34375	
13459	 steps: training loss - 91376.76562	, testing loss - 340419.71875	
13460	 steps: training loss - 113463.72656	, testing loss - 339884.46875	
13461	 steps: training loss - 120938.72656	, testing loss - 340281.50000	
13462	 steps: training loss - 121208.21094	, testing loss - 341258.46875	
13463	 steps: training loss - 127240.92188	, testing loss - 342317.75000	
13464	 steps: training loss - 121231.53125	, testing loss - 343250.50000	
13465	 steps: training loss - 122559.58594	, testing loss - 344856.59375	
13466	 steps: training loss - 95530.48438	, testing loss - 346977.15625	
13467	 steps: training loss - 113900.24219	, testing loss - 349315.81250	
13468	 steps: training loss - 118215.10938	, testing loss - 351369.43750	
13469	 steps: training loss - 112806.75000	, testing loss - 353391.09375	
13470	 steps: training loss - 107212.45312	, testing loss - 356609.81250	
13471	 steps: training loss - 131655.96875	, testing loss - 359176.25000	
13472	 steps: training loss - 94661.64062	, testing loss - 360144.78125	
13473	 steps: training loss - 106785.21875	, testing loss - 359471.90625	
13474	 steps: training loss - 109030.01562	, testing loss - 358854.31250	
13475	 steps: training loss - 111419.53125	, testing loss - 356537.06250	
13476	 steps: training loss - 114534.46875	, testing loss - 354630.75000	
13477	 steps: training loss - 141768.25000	, testing loss - 352916.68750	
13478	 steps: training loss - 91969.82812	, testing loss - 350878.53125	
13479	 steps: training loss - 122457.85156	, testing loss - 348991.65625	
13480	 steps: training loss - 115839.49219	, testing loss - 347977.00000	
13481	 steps: training loss - 123891.85156	, testing loss - 347248.09375	
13482	 steps: training loss - 77613.52344	, testing loss - 347193.25000	
13483	 steps: training loss - 127465.97656	, testing loss - 346464.03125	
13484	 steps: training loss - 118380.95312	, testing loss - 346947.50000	
13485	 steps: training loss - 124728.58594	, testing loss - 347915.87500	
13486	 steps: training loss - 104658.51562	, testing loss - 349929.03125	
13487	 steps: training loss - 113732.10156	, testing loss - 351628.43750	
13488	 steps: training loss - 137049.51562	, testing loss - 353322.53125	
13489	 steps: training loss - 111445.46094	, testing loss - 354342.15625	
13490	 steps: training loss - 111784.50781	, testing loss - 354945.59375	
13491	 steps: training loss - 95726.51562	, testing loss - 355084.06250	
13492	 steps: training loss - 106037.95312	, testing loss - 354534.78125	
13493	 steps: training loss - 81844.67969	, testing loss - 353006.93750	
13494	 steps: training loss - 120966.48438	, testing loss - 351864.68750	
13495	 steps: training loss - 83997.39844	, testing loss - 350571.00000	
13496	 steps: training loss - 104701.46094	, testing loss - 348335.56250	
13497	 steps: training loss - 87272.35156	, testing loss - 346723.31250	
13498	 steps: training loss - 112472.60156	, testing loss - 345383.65625	
13499	 steps: training loss - 108993.73438	, testing loss - 343436.15625	
13500	 steps: training loss - 107407.18750	, testing loss - 341578.18750	
13501	 steps: training loss - 99905.50000	, testing loss - 340324.15625	
13502	 steps: training loss - 77305.03906	, testing loss - 339236.90625	
13503	 steps: training loss - 135016.17188	, testing loss - 338063.06250	
13504	 steps: training loss - 110644.35938	, testing loss - 337916.15625	
13505	 steps: training loss - 122602.42188	, testing loss - 338583.59375	
13506	 steps: training loss - 144511.10938	, testing loss - 340586.65625	
13507	 steps: training loss - 113488.91406	, testing loss - 343335.59375	
13508	 steps: training loss - 117479.24219	, testing loss - 346887.53125	
13509	 steps: training loss - 95604.07812	, testing loss - 350195.00000	
13510	 steps: training loss - 94272.74219	, testing loss - 352885.71875	
13511	 steps: training loss - 107189.97656	, testing loss - 354969.25000	
13512	 steps: training loss - 106455.37500	, testing loss - 355360.21875	
13513	 steps: training loss - 123495.97656	, testing loss - 354620.15625	
13514	 steps: training loss - 113579.95312	, testing loss - 353067.25000	
13515	 steps: training loss - 100961.89062	, testing loss - 351715.09375	
13516	 steps: training loss - 113418.89844	, testing loss - 350077.59375	
13517	 steps: training loss - 108663.88281	, testing loss - 348417.62500	
13518	 steps: training loss - 115406.60156	, testing loss - 346817.53125	
13519	 steps: training loss - 107847.50000	, testing loss - 345025.84375	
13520	 steps: training loss - 110743.64062	, testing loss - 343255.12500	
13521	 steps: training loss - 98231.85938	, testing loss - 342187.09375	
13522	 steps: training loss - 142477.09375	, testing loss - 341809.12500	
13523	 steps: training loss - 122726.82031	, testing loss - 342258.15625	
13524	 steps: training loss - 96145.15625	, testing loss - 343005.71875	
13525	 steps: training loss - 103244.42969	, testing loss - 343690.31250	
13526	 steps: training loss - 107806.82031	, testing loss - 344530.68750	
13527	 steps: training loss - 90911.67969	, testing loss - 345727.62500	
13528	 steps: training loss - 98131.27344	, testing loss - 347745.68750	
13529	 steps: training loss - 111340.21094	, testing loss - 349400.68750	
13530	 steps: training loss - 120958.38281	, testing loss - 351239.15625	
13531	 steps: training loss - 111606.66406	, testing loss - 353053.40625	
13532	 steps: training loss - 127337.63281	, testing loss - 353911.28125	
13533	 steps: training loss - 106387.03125	, testing loss - 353768.62500	
13534	 steps: training loss - 136259.64062	, testing loss - 354115.37500	
13535	 steps: training loss - 105915.05469	, testing loss - 354635.12500	
13536	 steps: training loss - 117760.22656	, testing loss - 354757.00000	
13537	 steps: training loss - 87713.48438	, testing loss - 355953.75000	
13538	 steps: training loss - 100795.60156	, testing loss - 357076.09375	
13539	 steps: training loss - 85913.42188	, testing loss - 356488.62500	
13540	 steps: training loss - 147341.32812	, testing loss - 355401.53125	
13541	 steps: training loss - 116723.17969	, testing loss - 354971.28125	
13542	 steps: training loss - 110921.49219	, testing loss - 354829.96875	
13543	 steps: training loss - 116925.36719	, testing loss - 352718.65625	
13544	 steps: training loss - 114004.92969	, testing loss - 351135.34375	
13545	 steps: training loss - 107123.82031	, testing loss - 350067.00000	
13546	 steps: training loss - 107777.16406	, testing loss - 349556.34375	
13547	 steps: training loss - 121303.63281	, testing loss - 350232.43750	
13548	 steps: training loss - 99495.17188	, testing loss - 350613.84375	
13549	 steps: training loss - 101208.02344	, testing loss - 350233.71875	
13550	 steps: training loss - 130112.64844	, testing loss - 350031.93750	
13551	 steps: training loss - 93778.96875	, testing loss - 348600.81250	
13552	 steps: training loss - 111000.30469	, testing loss - 346495.18750	
13553	 steps: training loss - 111353.00000	, testing loss - 344331.21875	
13554	 steps: training loss - 122482.14062	, testing loss - 342492.81250	
13555	 steps: training loss - 92439.15625	, testing loss - 341732.65625	
13556	 steps: training loss - 126754.15625	, testing loss - 340989.21875	
13557	 steps: training loss - 117101.74219	, testing loss - 340635.09375	
13558	 steps: training loss - 114843.42188	, testing loss - 340336.93750	
13559	 steps: training loss - 113876.91406	, testing loss - 340050.56250	
13560	 steps: training loss - 122638.75000	, testing loss - 339887.21875	
13561	 steps: training loss - 119836.43750	, testing loss - 340207.53125	
13562	 steps: training loss - 87428.26562	, testing loss - 340405.65625	
13563	 steps: training loss - 112207.21875	, testing loss - 340683.84375	
13564	 steps: training loss - 107428.11719	, testing loss - 340300.93750	
13565	 steps: training loss - 106960.60938	, testing loss - 340571.50000	
13566	 steps: training loss - 91362.70312	, testing loss - 342058.00000	
13567	 steps: training loss - 118254.65625	, testing loss - 344175.28125	
13568	 steps: training loss - 110756.30469	, testing loss - 347053.21875	
13569	 steps: training loss - 71095.89844	, testing loss - 350327.00000	
13570	 steps: training loss - 93584.91406	, testing loss - 353428.50000	
13571	 steps: training loss - 107110.71875	, testing loss - 356123.53125	
13572	 steps: training loss - 125161.57812	, testing loss - 358677.40625	
13573	 steps: training loss - 94224.09375	, testing loss - 360732.18750	
13574	 steps: training loss - 81328.83594	, testing loss - 362743.03125	
13575	 steps: training loss - 89128.73438	, testing loss - 364731.06250	
13576	 steps: training loss - 132956.56250	, testing loss - 366244.56250	
13577	 steps: training loss - 122396.25781	, testing loss - 365762.12500	
13578	 steps: training loss - 109534.67188	, testing loss - 362836.40625	
13579	 steps: training loss - 100766.84375	, testing loss - 359656.21875	
13580	 steps: training loss - 97787.64844	, testing loss - 355945.78125	
13581	 steps: training loss - 104205.07031	, testing loss - 351953.65625	
13582	 steps: training loss - 116189.35156	, testing loss - 348085.75000	
13583	 steps: training loss - 105637.00000	, testing loss - 345330.12500	
13584	 steps: training loss - 102412.39844	, testing loss - 343143.84375	
13585	 steps: training loss - 84853.85938	, testing loss - 341566.34375	
13586	 steps: training loss - 131774.43750	, testing loss - 340416.09375	
13587	 steps: training loss - 117235.60938	, testing loss - 339568.93750	
13588	 steps: training loss - 135483.12500	, testing loss - 338977.93750	
13589	 steps: training loss - 113065.82812	, testing loss - 338501.46875	
13590	 steps: training loss - 116962.28125	, testing loss - 338288.87500	
13591	 steps: training loss - 117451.93750	, testing loss - 338460.03125	
13592	 steps: training loss - 119243.52344	, testing loss - 338975.06250	
13593	 steps: training loss - 120028.14062	, testing loss - 340334.34375	
13594	 steps: training loss - 99015.68750	, testing loss - 342235.56250	
13595	 steps: training loss - 110466.48438	, testing loss - 343900.28125	
13596	 steps: training loss - 134769.26562	, testing loss - 346406.78125	
13597	 steps: training loss - 98656.94531	, testing loss - 348847.09375	
13598	 steps: training loss - 109271.84375	, testing loss - 350471.84375	
13599	 steps: training loss - 125011.46094	, testing loss - 352198.87500	
13600	 steps: training loss - 127196.93750	, testing loss - 354143.46875	
13601	 steps: training loss - 99156.31250	, testing loss - 355081.75000	
13602	 steps: training loss - 83712.89844	, testing loss - 354245.87500	
13603	 steps: training loss - 99514.08594	, testing loss - 352508.68750	
13604	 steps: training loss - 104150.50781	, testing loss - 350827.75000	
13605	 steps: training loss - 87565.50781	, testing loss - 348493.50000	
13606	 steps: training loss - 128101.24219	, testing loss - 347688.18750	
13607	 steps: training loss - 108996.31250	, testing loss - 346809.34375	
13608	 steps: training loss - 133155.62500	, testing loss - 346310.75000	
13609	 steps: training loss - 115726.73438	, testing loss - 346181.12500	
13610	 steps: training loss - 115793.88281	, testing loss - 347297.71875	
13611	 steps: training loss - 118207.97656	, testing loss - 348066.65625	
13612	 steps: training loss - 124625.80469	, testing loss - 347725.15625	
13613	 steps: training loss - 120489.42969	, testing loss - 346095.87500	
13614	 steps: training loss - 115113.41406	, testing loss - 344482.78125	
13615	 steps: training loss - 105422.54688	, testing loss - 343038.37500	
13616	 steps: training loss - 109914.32812	, testing loss - 341595.31250	
13617	 steps: training loss - 109538.82812	, testing loss - 340314.53125	
13618	 steps: training loss - 119559.61719	, testing loss - 339663.87500	
13619	 steps: training loss - 85602.88281	, testing loss - 338972.56250	
13620	 steps: training loss - 126281.42969	, testing loss - 337868.25000	
13621	 steps: training loss - 122740.03906	, testing loss - 336846.50000	
13622	 steps: training loss - 105798.86719	, testing loss - 336311.00000	
13623	 steps: training loss - 121813.30469	, testing loss - 335877.84375	
13624	 steps: training loss - 112254.48438	, testing loss - 336104.31250	
13625	 steps: training loss - 104654.74219	, testing loss - 336632.34375	
13626	 steps: training loss - 124231.89062	, testing loss - 337195.25000	
13627	 steps: training loss - 106476.25000	, testing loss - 338238.18750	
13628	 steps: training loss - 108166.68750	, testing loss - 339526.15625	
13629	 steps: training loss - 94213.30469	, testing loss - 341216.75000	
13630	 steps: training loss - 104010.48438	, testing loss - 342605.15625	
13631	 steps: training loss - 95180.87500	, testing loss - 343486.59375	
13632	 steps: training loss - 105274.82812	, testing loss - 343752.50000	
13633	 steps: training loss - 119078.18750	, testing loss - 343257.43750	
13634	 steps: training loss - 95809.28906	, testing loss - 342606.87500	
13635	 steps: training loss - 120103.78125	, testing loss - 342139.25000	
13636	 steps: training loss - 110351.82812	, testing loss - 341858.96875	
13637	 steps: training loss - 114905.87500	, testing loss - 341202.03125	
13638	 steps: training loss - 94127.93750	, testing loss - 340389.59375	
13639	 steps: training loss - 110201.21875	, testing loss - 340278.37500	
13640	 steps: training loss - 113261.61719	, testing loss - 340572.09375	
13641	 steps: training loss - 110400.03125	, testing loss - 340695.00000	
13642	 steps: training loss - 85412.51562	, testing loss - 341002.87500	
13643	 steps: training loss - 96700.60156	, testing loss - 341481.50000	
13644	 steps: training loss - 114324.84375	, testing loss - 342033.31250	
13645	 steps: training loss - 128879.77344	, testing loss - 342800.25000	
13646	 steps: training loss - 131530.89062	, testing loss - 344021.93750	
13647	 steps: training loss - 120113.21094	, testing loss - 343746.15625	
13648	 steps: training loss - 118777.95312	, testing loss - 342599.06250	
13649	 steps: training loss - 121096.60938	, testing loss - 341526.90625	
13650	 steps: training loss - 115302.17969	, testing loss - 340279.34375	
13651	 steps: training loss - 111859.80469	, testing loss - 339508.03125	
13652	 steps: training loss - 112861.82812	, testing loss - 339844.34375	
13653	 steps: training loss - 101379.49219	, testing loss - 340685.62500	
13654	 steps: training loss - 111267.33594	, testing loss - 342048.65625	
13655	 steps: training loss - 130303.32031	, testing loss - 344007.28125	
13656	 steps: training loss - 125577.44531	, testing loss - 345726.53125	
13657	 steps: training loss - 93309.95312	, testing loss - 347189.09375	
13658	 steps: training loss - 107170.53125	, testing loss - 347913.96875	
13659	 steps: training loss - 118775.81250	, testing loss - 347840.93750	
13660	 steps: training loss - 109781.43750	, testing loss - 348260.78125	
13661	 steps: training loss - 77798.35156	, testing loss - 349050.06250	
13662	 steps: training loss - 110425.70312	, testing loss - 349393.43750	
13663	 steps: training loss - 94763.40625	, testing loss - 349674.84375	
13664	 steps: training loss - 92394.63281	, testing loss - 350218.00000	
13665	 steps: training loss - 107291.36719	, testing loss - 350084.75000	
13666	 steps: training loss - 113021.17188	, testing loss - 348854.43750	
13667	 steps: training loss - 108762.36719	, testing loss - 347985.25000	
13668	 steps: training loss - 114169.74219	, testing loss - 346934.21875	
13669	 steps: training loss - 124383.53906	, testing loss - 345451.53125	
13670	 steps: training loss - 99393.17969	, testing loss - 344526.84375	
13671	 steps: training loss - 89089.52344	, testing loss - 344323.62500	
13672	 steps: training loss - 109057.48438	, testing loss - 344995.40625	
13673	 steps: training loss - 114425.69531	, testing loss - 345393.56250	
13674	 steps: training loss - 92470.73438	, testing loss - 345401.59375	
13675	 steps: training loss - 86296.54688	, testing loss - 345409.87500	
13676	 steps: training loss - 91364.47656	, testing loss - 346721.93750	
13677	 steps: training loss - 88383.50781	, testing loss - 349058.43750	
13678	 steps: training loss - 120986.38281	, testing loss - 350868.09375	
13679	 steps: training loss - 124275.17188	, testing loss - 352601.87500	
13680	 steps: training loss - 100154.86719	, testing loss - 354376.25000	
13681	 steps: training loss - 106220.46875	, testing loss - 356673.25000	
13682	 steps: training loss - 109096.64844	, testing loss - 358869.78125	
13683	 steps: training loss - 135916.62500	, testing loss - 360421.15625	
13684	 steps: training loss - 102341.85938	, testing loss - 360035.00000	
13685	 steps: training loss - 113085.64062	, testing loss - 358690.12500	
13686	 steps: training loss - 93837.78125	, testing loss - 357170.68750	
13687	 steps: training loss - 112447.59375	, testing loss - 356131.56250	
13688	 steps: training loss - 110685.99219	, testing loss - 354394.65625	
13689	 steps: training loss - 131508.42188	, testing loss - 352742.03125	
13690	 steps: training loss - 102989.37500	, testing loss - 351807.75000	
13691	 steps: training loss - 102667.96875	, testing loss - 350549.68750	
13692	 steps: training loss - 136313.57812	, testing loss - 349362.90625	
13693	 steps: training loss - 122441.83594	, testing loss - 347778.65625	
13694	 steps: training loss - 126057.21094	, testing loss - 345569.06250	
13695	 steps: training loss - 113928.75781	, testing loss - 343680.71875	
13696	 steps: training loss - 117948.49219	, testing loss - 342732.00000	
13697	 steps: training loss - 108188.54688	, testing loss - 341852.81250	
13698	 steps: training loss - 93285.25781	, testing loss - 341087.00000	
13699	 steps: training loss - 90357.32031	, testing loss - 339904.59375	
13700	 steps: training loss - 100151.91406	, testing loss - 339727.96875	
13701	 steps: training loss - 111697.10156	, testing loss - 339757.31250	
13702	 steps: training loss - 104256.57031	, testing loss - 339323.06250	
13703	 steps: training loss - 96515.25000	, testing loss - 339206.81250	
13704	 steps: training loss - 95914.67969	, testing loss - 339297.46875	
13705	 steps: training loss - 96119.66406	, testing loss - 339309.81250	
13706	 steps: training loss - 109392.78906	, testing loss - 338956.59375	
13707	 steps: training loss - 98569.81250	, testing loss - 338799.53125	
13708	 steps: training loss - 92986.44531	, testing loss - 339323.75000	
13709	 steps: training loss - 103055.21875	, testing loss - 339674.03125	
13710	 steps: training loss - 98394.53125	, testing loss - 339971.59375	
13711	 steps: training loss - 99296.32812	, testing loss - 340551.03125	
13712	 steps: training loss - 104677.31250	, testing loss - 341200.71875	
13713	 steps: training loss - 120983.03906	, testing loss - 342020.56250	
13714	 steps: training loss - 122320.51562	, testing loss - 341916.59375	
13715	 steps: training loss - 125037.40625	, testing loss - 342120.50000	
13716	 steps: training loss - 97378.73438	, testing loss - 342627.50000	
13717	 steps: training loss - 124801.14062	, testing loss - 342982.87500	
13718	 steps: training loss - 123101.29688	, testing loss - 343800.43750	
13719	 steps: training loss - 136218.01562	, testing loss - 344593.78125	
13720	 steps: training loss - 123490.57812	, testing loss - 345123.53125	
13721	 steps: training loss - 121492.09375	, testing loss - 345270.18750	
13722	 steps: training loss - 107950.48438	, testing loss - 345615.90625	
13723	 steps: training loss - 115549.67969	, testing loss - 346032.59375	
13724	 steps: training loss - 107257.99219	, testing loss - 345749.40625	
13725	 steps: training loss - 110835.75000	, testing loss - 346815.31250	
13726	 steps: training loss - 104233.94531	, testing loss - 347149.71875	
13727	 steps: training loss - 128473.01562	, testing loss - 346800.37500	
13728	 steps: training loss - 101368.40625	, testing loss - 347295.46875	
13729	 steps: training loss - 115750.54688	, testing loss - 348143.12500	
13730	 steps: training loss - 116573.96875	, testing loss - 348671.40625	
13731	 steps: training loss - 119507.82031	, testing loss - 349534.06250	
13732	 steps: training loss - 115955.31250	, testing loss - 349891.78125	
13733	 steps: training loss - 127624.10938	, testing loss - 350300.78125	
13734	 steps: training loss - 107323.06250	, testing loss - 350865.43750	
13735	 steps: training loss - 91142.82812	, testing loss - 350555.40625	
13736	 steps: training loss - 104535.82031	, testing loss - 349362.43750	
13737	 steps: training loss - 102711.06250	, testing loss - 347291.06250	
13738	 steps: training loss - 115297.31250	, testing loss - 345036.15625	
13739	 steps: training loss - 116457.75781	, testing loss - 342576.62500	
13740	 steps: training loss - 93321.58594	, testing loss - 341296.56250	
13741	 steps: training loss - 98651.52344	, testing loss - 341063.62500	
13742	 steps: training loss - 116078.38281	, testing loss - 340926.18750	
13743	 steps: training loss - 88444.93750	, testing loss - 340845.65625	
13744	 steps: training loss - 97464.09375	, testing loss - 340844.40625	
13745	 steps: training loss - 101722.96094	, testing loss - 341008.12500	
13746	 steps: training loss - 125633.28125	, testing loss - 341805.40625	
13747	 steps: training loss - 96824.40625	, testing loss - 342675.93750	
13748	 steps: training loss - 118308.37500	, testing loss - 343624.68750	
13749	 steps: training loss - 138022.79688	, testing loss - 344442.43750	
13750	 steps: training loss - 84148.17188	, testing loss - 345593.56250	
13751	 steps: training loss - 116539.92188	, testing loss - 347009.09375	
13752	 steps: training loss - 108565.64844	, testing loss - 348105.00000	
13753	 steps: training loss - 118467.47656	, testing loss - 348691.71875	
13754	 steps: training loss - 111832.63281	, testing loss - 349414.71875	
13755	 steps: training loss - 124749.07031	, testing loss - 349413.00000	
13756	 steps: training loss - 114930.85938	, testing loss - 348538.65625	
13757	 steps: training loss - 110864.94531	, testing loss - 347120.78125	
13758	 steps: training loss - 111912.05469	, testing loss - 345644.43750	
13759	 steps: training loss - 121103.54688	, testing loss - 345965.56250	
13760	 steps: training loss - 154870.79688	, testing loss - 347673.96875	
13761	 steps: training loss - 116838.14062	, testing loss - 348708.31250	
13762	 steps: training loss - 114352.85938	, testing loss - 348932.59375	
13763	 steps: training loss - 88504.90625	, testing loss - 348024.56250	
13764	 steps: training loss - 83912.04688	, testing loss - 346787.37500	
13765	 steps: training loss - 107446.29688	, testing loss - 345738.68750	
13766	 steps: training loss - 96467.04688	, testing loss - 344627.09375	
13767	 steps: training loss - 109420.44531	, testing loss - 343478.21875	
13768	 steps: training loss - 122536.75000	, testing loss - 342631.53125	
13769	 steps: training loss - 131035.00781	, testing loss - 341417.96875	
13770	 steps: training loss - 104297.92188	, testing loss - 340283.87500	
13771	 steps: training loss - 94911.68750	, testing loss - 339550.84375	
13772	 steps: training loss - 103738.50000	, testing loss - 339129.37500	
13773	 steps: training loss - 108403.84375	, testing loss - 339105.46875	
13774	 steps: training loss - 106115.06250	, testing loss - 339672.12500	
13775	 steps: training loss - 127103.01562	, testing loss - 340223.87500	
13776	 steps: training loss - 106190.40625	, testing loss - 340447.81250	
13777	 steps: training loss - 102335.46875	, testing loss - 340115.96875	
13778	 steps: training loss - 103450.67969	, testing loss - 340026.68750	
13779	 steps: training loss - 94664.99219	, testing loss - 340660.56250	
13780	 steps: training loss - 107571.08594	, testing loss - 341450.21875	
13781	 steps: training loss - 135133.64062	, testing loss - 342673.68750	
13782	 steps: training loss - 88240.51562	, testing loss - 343928.03125	
13783	 steps: training loss - 127542.22656	, testing loss - 344962.03125	
13784	 steps: training loss - 139762.20312	, testing loss - 345470.18750	
13785	 steps: training loss - 128335.39844	, testing loss - 344495.00000	
13786	 steps: training loss - 104995.62500	, testing loss - 343256.96875	
13787	 steps: training loss - 91018.67969	, testing loss - 341802.43750	
13788	 steps: training loss - 138581.40625	, testing loss - 340807.06250	
13789	 steps: training loss - 83676.94531	, testing loss - 341158.65625	
13790	 steps: training loss - 93904.81250	, testing loss - 341605.81250	
13791	 steps: training loss - 124378.25000	, testing loss - 341773.68750	
13792	 steps: training loss - 107503.12500	, testing loss - 341841.56250	
13793	 steps: training loss - 109688.90625	, testing loss - 342093.87500	
13794	 steps: training loss - 125540.93750	, testing loss - 342440.93750	
13795	 steps: training loss - 118623.15625	, testing loss - 343203.28125	
13796	 steps: training loss - 118697.98438	, testing loss - 343794.43750	
13797	 steps: training loss - 107443.21094	, testing loss - 344213.25000	
13798	 steps: training loss - 102489.15625	, testing loss - 345290.84375	
13799	 steps: training loss - 113981.37500	, testing loss - 346994.43750	
13800	 steps: training loss - 121534.65625	, testing loss - 349742.28125	
13801	 steps: training loss - 128675.64844	, testing loss - 353169.84375	
13802	 steps: training loss - 106433.13281	, testing loss - 355345.06250	
13803	 steps: training loss - 85802.32031	, testing loss - 355820.90625	
13804	 steps: training loss - 103432.80469	, testing loss - 357164.21875	
13805	 steps: training loss - 109525.92188	, testing loss - 358601.59375	
13806	 steps: training loss - 106400.58594	, testing loss - 359453.53125	
13807	 steps: training loss - 117600.64844	, testing loss - 360144.71875	
13808	 steps: training loss - 117737.30469	, testing loss - 361107.28125	
13809	 steps: training loss - 128008.92188	, testing loss - 361372.93750	
13810	 steps: training loss - 124360.54688	, testing loss - 360849.62500	
13811	 steps: training loss - 122340.08594	, testing loss - 358570.90625	
13812	 steps: training loss - 91392.68750	, testing loss - 355982.87500	
13813	 steps: training loss - 114993.90625	, testing loss - 354142.31250	
13814	 steps: training loss - 106563.68750	, testing loss - 352738.06250	
13815	 steps: training loss - 115730.94531	, testing loss - 350333.34375	
13816	 steps: training loss - 121779.60938	, testing loss - 347657.03125	
13817	 steps: training loss - 116406.00781	, testing loss - 345936.21875	
13818	 steps: training loss - 104715.21875	, testing loss - 345103.90625	
13819	 steps: training loss - 112737.07031	, testing loss - 344428.50000	
13820	 steps: training loss - 113973.45312	, testing loss - 343773.18750	
13821	 steps: training loss - 84034.70312	, testing loss - 343076.46875	
13822	 steps: training loss - 113285.59375	, testing loss - 342364.87500	
13823	 steps: training loss - 137518.15625	, testing loss - 342246.59375	
13824	 steps: training loss - 99463.30469	, testing loss - 342089.37500	
13825	 steps: training loss - 118792.76562	, testing loss - 341999.65625	
13826	 steps: training loss - 126442.42969	, testing loss - 342186.62500	
13827	 steps: training loss - 119881.85156	, testing loss - 342851.06250	
13828	 steps: training loss - 91093.56250	, testing loss - 343739.93750	
13829	 steps: training loss - 95142.71875	, testing loss - 345313.00000	
13830	 steps: training loss - 73548.12500	, testing loss - 347135.87500	
13831	 steps: training loss - 128800.74219	, testing loss - 348627.28125	
13832	 steps: training loss - 107656.60938	, testing loss - 348657.21875	
13833	 steps: training loss - 100338.32812	, testing loss - 348192.56250	
13834	 steps: training loss - 92039.38281	, testing loss - 347009.81250	
13835	 steps: training loss - 132289.29688	, testing loss - 345332.50000	
13836	 steps: training loss - 116201.53125	, testing loss - 344607.75000	
13837	 steps: training loss - 96405.15625	, testing loss - 345087.93750	
13838	 steps: training loss - 91276.99219	, testing loss - 346298.09375	
13839	 steps: training loss - 140610.35938	, testing loss - 347421.56250	
13840	 steps: training loss - 109993.48438	, testing loss - 348351.43750	
13841	 steps: training loss - 122358.82031	, testing loss - 349289.15625	
13842	 steps: training loss - 124525.17969	, testing loss - 350552.93750	
13843	 steps: training loss - 109593.36719	, testing loss - 350996.12500	
13844	 steps: training loss - 97688.23438	, testing loss - 351236.68750	
13845	 steps: training loss - 119923.20312	, testing loss - 351027.75000	
13846	 steps: training loss - 121308.84375	, testing loss - 351142.46875	
13847	 steps: training loss - 96107.92188	, testing loss - 350917.15625	
13848	 steps: training loss - 93925.10938	, testing loss - 351121.00000	
13849	 steps: training loss - 102562.10938	, testing loss - 351524.12500	
13850	 steps: training loss - 140411.59375	, testing loss - 350821.43750	
13851	 steps: training loss - 106365.35156	, testing loss - 350674.53125	
13852	 steps: training loss - 70040.64062	, testing loss - 350307.93750	
13853	 steps: training loss - 107945.45312	, testing loss - 350114.18750	
13854	 steps: training loss - 127853.83594	, testing loss - 350419.90625	
13855	 steps: training loss - 126416.32031	, testing loss - 350294.78125	
13856	 steps: training loss - 99130.17969	, testing loss - 349543.25000	
13857	 steps: training loss - 130121.42188	, testing loss - 348731.09375	
13858	 steps: training loss - 114827.07812	, testing loss - 348368.53125	
13859	 steps: training loss - 87004.71094	, testing loss - 348651.28125	
13860	 steps: training loss - 110878.03906	, testing loss - 348764.34375	
13861	 steps: training loss - 110967.39062	, testing loss - 348557.68750	
13862	 steps: training loss - 103611.63281	, testing loss - 349075.03125	
13863	 steps: training loss - 102132.08594	, testing loss - 349671.25000	
13864	 steps: training loss - 91920.16406	, testing loss - 350158.68750	
13865	 steps: training loss - 113808.78906	, testing loss - 350814.00000	
13866	 steps: training loss - 91675.60938	, testing loss - 351202.65625	
13867	 steps: training loss - 83957.42969	, testing loss - 351457.75000	
13868	 steps: training loss - 112934.67188	, testing loss - 350960.09375	
13869	 steps: training loss - 121428.96094	, testing loss - 350393.71875	
13870	 steps: training loss - 94970.59375	, testing loss - 350202.43750	
13871	 steps: training loss - 84902.61719	, testing loss - 350050.03125	
13872	 steps: training loss - 115157.27344	, testing loss - 349203.87500	
13873	 steps: training loss - 120383.43750	, testing loss - 348186.56250	
13874	 steps: training loss - 110339.92188	, testing loss - 347410.15625	
13875	 steps: training loss - 93875.97656	, testing loss - 347845.03125	
13876	 steps: training loss - 93521.69531	, testing loss - 348931.75000	
13877	 steps: training loss - 109848.02344	, testing loss - 349873.50000	
13878	 steps: training loss - 103351.09375	, testing loss - 350717.31250	
13879	 steps: training loss - 118027.89062	, testing loss - 351702.03125	
13880	 steps: training loss - 131821.15625	, testing loss - 353406.34375	
13881	 steps: training loss - 97779.16406	, testing loss - 354692.50000	
13882	 steps: training loss - 99007.99219	, testing loss - 355924.75000	
13883	 steps: training loss - 121746.39844	, testing loss - 355793.15625	
13884	 steps: training loss - 99864.71094	, testing loss - 355576.71875	
13885	 steps: training loss - 90674.17188	, testing loss - 354239.87500	
13886	 steps: training loss - 117691.80469	, testing loss - 352965.00000	
13887	 steps: training loss - 98316.39844	, testing loss - 351958.37500	
13888	 steps: training loss - 114152.93750	, testing loss - 351230.15625	
13889	 steps: training loss - 110887.79688	, testing loss - 351409.93750	
13890	 steps: training loss - 90138.68750	, testing loss - 352010.81250	
13891	 steps: training loss - 82460.56250	, testing loss - 351284.62500	
13892	 steps: training loss - 108105.29688	, testing loss - 349722.68750	
13893	 steps: training loss - 83720.92188	, testing loss - 348403.78125	
13894	 steps: training loss - 105025.60938	, testing loss - 347711.56250	
13895	 steps: training loss - 120165.11719	, testing loss - 346718.03125	
13896	 steps: training loss - 108596.00000	, testing loss - 345616.87500	
13897	 steps: training loss - 133265.12500	, testing loss - 344779.87500	
13898	 steps: training loss - 116079.59375	, testing loss - 345763.59375	
13899	 steps: training loss - 122730.42188	, testing loss - 346963.78125	
13900	 steps: training loss - 110283.28906	, testing loss - 347361.96875	
13901	 steps: training loss - 104508.80469	, testing loss - 347719.84375	
13902	 steps: training loss - 101778.76562	, testing loss - 347203.18750	
13903	 steps: training loss - 98031.87500	, testing loss - 345892.59375	
13904	 steps: training loss - 101573.00000	, testing loss - 344238.56250	
13905	 steps: training loss - 98315.79688	, testing loss - 343761.03125	
13906	 steps: training loss - 116470.27344	, testing loss - 343916.21875	
13907	 steps: training loss - 115496.36719	, testing loss - 345141.59375	
13908	 steps: training loss - 107443.32812	, testing loss - 346423.65625	
13909	 steps: training loss - 86713.35938	, testing loss - 347723.06250	
13910	 steps: training loss - 85544.17969	, testing loss - 349148.50000	
13911	 steps: training loss - 97352.88281	, testing loss - 350555.84375	
13912	 steps: training loss - 92037.95312	, testing loss - 351546.37500	
13913	 steps: training loss - 96992.17188	, testing loss - 351357.81250	
13914	 steps: training loss - 126395.59375	, testing loss - 351232.81250	
13915	 steps: training loss - 135458.15625	, testing loss - 350825.28125	
13916	 steps: training loss - 106042.45312	, testing loss - 349484.68750	
13917	 steps: training loss - 100485.67969	, testing loss - 348502.90625	
13918	 steps: training loss - 94227.64062	, testing loss - 348071.06250	
13919	 steps: training loss - 103572.82031	, testing loss - 348043.46875	
13920	 steps: training loss - 79365.78125	, testing loss - 348416.87500	
13921	 steps: training loss - 99174.95312	, testing loss - 348612.56250	
13922	 steps: training loss - 122943.23438	, testing loss - 348161.25000	
13923	 steps: training loss - 104117.78906	, testing loss - 347818.84375	
13924	 steps: training loss - 101176.67969	, testing loss - 346932.37500	
13925	 steps: training loss - 120921.46875	, testing loss - 345850.15625	
13926	 steps: training loss - 128776.02344	, testing loss - 344825.06250	
13927	 steps: training loss - 110777.07812	, testing loss - 343757.03125	
13928	 steps: training loss - 104003.82031	, testing loss - 342586.06250	
13929	 steps: training loss - 118661.38281	, testing loss - 341552.00000	
13930	 steps: training loss - 97522.50000	, testing loss - 341010.75000	
13931	 steps: training loss - 109273.72656	, testing loss - 340913.87500	
13932	 steps: training loss - 116566.89062	, testing loss - 341801.09375	
13933	 steps: training loss - 93569.36719	, testing loss - 342274.71875	
13934	 steps: training loss - 91707.35938	, testing loss - 342954.71875	
13935	 steps: training loss - 106097.57031	, testing loss - 344529.84375	
13936	 steps: training loss - 106611.50781	, testing loss - 345875.84375	
13937	 steps: training loss - 114422.96875	, testing loss - 346148.71875	
13938	 steps: training loss - 87901.86719	, testing loss - 345582.15625	
13939	 steps: training loss - 98374.46875	, testing loss - 344829.00000	
13940	 steps: training loss - 104910.15625	, testing loss - 343189.21875	
13941	 steps: training loss - 111605.12500	, testing loss - 341440.25000	
13942	 steps: training loss - 98765.14062	, testing loss - 340844.03125	
13943	 steps: training loss - 122366.30469	, testing loss - 341087.62500	
13944	 steps: training loss - 101857.47656	, testing loss - 341335.96875	
13945	 steps: training loss - 118863.67969	, testing loss - 341787.40625	
13946	 steps: training loss - 119080.14844	, testing loss - 342533.46875	
13947	 steps: training loss - 97883.40625	, testing loss - 343380.43750	
13948	 steps: training loss - 126876.04688	, testing loss - 343883.00000	
13949	 steps: training loss - 84193.89062	, testing loss - 343595.90625	
13950	 steps: training loss - 112530.96094	, testing loss - 342540.62500	
13951	 steps: training loss - 105866.11719	, testing loss - 341607.12500	
13952	 steps: training loss - 112144.86719	, testing loss - 340957.75000	
13953	 steps: training loss - 84561.99219	, testing loss - 340712.15625	
13954	 steps: training loss - 103749.47656	, testing loss - 340454.59375	
13955	 steps: training loss - 113532.27344	, testing loss - 340825.93750	
13956	 steps: training loss - 87434.03906	, testing loss - 342050.56250	
13957	 steps: training loss - 108248.97656	, testing loss - 342867.56250	
13958	 steps: training loss - 91971.32031	, testing loss - 343461.28125	
13959	 steps: training loss - 119043.42188	, testing loss - 343886.31250	
13960	 steps: training loss - 115414.96094	, testing loss - 344531.15625	
13961	 steps: training loss - 121240.57812	, testing loss - 344667.18750	
13962	 steps: training loss - 113082.40625	, testing loss - 345256.68750	
13963	 steps: training loss - 114202.69531	, testing loss - 345918.87500	
13964	 steps: training loss - 115351.95312	, testing loss - 347104.96875	
13965	 steps: training loss - 121432.84375	, testing loss - 349309.37500	
13966	 steps: training loss - 90835.42969	, testing loss - 351457.00000	
13967	 steps: training loss - 104333.75000	, testing loss - 353290.84375	
13968	 steps: training loss - 88029.96094	, testing loss - 353660.40625	
13969	 steps: training loss - 125589.50781	, testing loss - 354202.40625	
13970	 steps: training loss - 95457.46875	, testing loss - 354264.65625	
13971	 steps: training loss - 94946.27344	, testing loss - 353270.93750	
13972	 steps: training loss - 121284.26562	, testing loss - 351973.93750	
13973	 steps: training loss - 117743.25000	, testing loss - 351973.31250	
13974	 steps: training loss - 118571.29688	, testing loss - 351551.50000	
13975	 steps: training loss - 95865.55469	, testing loss - 352497.81250	
13976	 steps: training loss - 87156.21875	, testing loss - 354143.62500	
13977	 steps: training loss - 118585.92188	, testing loss - 355555.34375	
13978	 steps: training loss - 98283.60938	, testing loss - 355052.18750	
13979	 steps: training loss - 98625.32031	, testing loss - 355755.71875	
13980	 steps: training loss - 102327.21875	, testing loss - 355675.06250	
13981	 steps: training loss - 117294.94531	, testing loss - 355818.62500	
13982	 steps: training loss - 116271.29688	, testing loss - 356072.68750	
13983	 steps: training loss - 110105.25000	, testing loss - 356200.78125	
13984	 steps: training loss - 101342.25000	, testing loss - 355261.62500	
13985	 steps: training loss - 92650.78906	, testing loss - 353417.62500	
13986	 steps: training loss - 103946.21094	, testing loss - 351300.25000	
13987	 steps: training loss - 101612.32812	, testing loss - 348208.56250	
13988	 steps: training loss - 94616.00781	, testing loss - 345381.18750	
13989	 steps: training loss - 96518.08594	, testing loss - 343421.59375	
13990	 steps: training loss - 108448.78906	, testing loss - 342355.93750	
13991	 steps: training loss - 112166.99219	, testing loss - 342309.25000	
13992	 steps: training loss - 94055.02344	, testing loss - 341770.21875	
13993	 steps: training loss - 93235.06250	, testing loss - 341205.87500	
13994	 steps: training loss - 90829.42969	, testing loss - 340865.68750	
13995	 steps: training loss - 135888.50000	, testing loss - 341006.53125	
13996	 steps: training loss - 106966.08594	, testing loss - 341801.25000	
13997	 steps: training loss - 115323.56250	, testing loss - 343249.46875	
13998	 steps: training loss - 97399.11719	, testing loss - 344854.59375	
13999	 steps: training loss - 127212.13281	, testing loss - 346442.78125	
14000	 steps: training loss - 100006.91406	, testing loss - 347755.93750	
14001	 steps: training loss - 88018.90625	, testing loss - 349241.09375	
14002	 steps: training loss - 95016.84375	, testing loss - 350725.46875	
14003	 steps: training loss - 126832.28125	, testing loss - 351120.21875	
14004	 steps: training loss - 105351.56250	, testing loss - 350748.18750	
14005	 steps: training loss - 112381.47656	, testing loss - 351064.56250	
14006	 steps: training loss - 104851.00781	, testing loss - 352035.18750	
14007	 steps: training loss - 98267.61719	, testing loss - 352488.18750	
14008	 steps: training loss - 85181.40625	, testing loss - 352957.56250	
14009	 steps: training loss - 104679.03906	, testing loss - 353491.87500	
14010	 steps: training loss - 129820.21094	, testing loss - 353777.46875	
14011	 steps: training loss - 102297.79688	, testing loss - 353292.65625	
14012	 steps: training loss - 106744.06250	, testing loss - 352573.81250	
14013	 steps: training loss - 111943.75781	, testing loss - 351216.28125	
14014	 steps: training loss - 121718.25000	, testing loss - 349217.90625	
14015	 steps: training loss - 120081.01562	, testing loss - 347863.31250	
14016	 steps: training loss - 87877.78125	, testing loss - 347437.68750	
14017	 steps: training loss - 118499.01562	, testing loss - 348492.21875	
14018	 steps: training loss - 130706.08594	, testing loss - 350247.53125	
14019	 steps: training loss - 116448.17188	, testing loss - 351679.65625	
14020	 steps: training loss - 96127.87500	, testing loss - 351757.34375	
14021	 steps: training loss - 114406.65625	, testing loss - 351469.09375	
14022	 steps: training loss - 101021.47656	, testing loss - 351319.37500	
14023	 steps: training loss - 107710.57812	, testing loss - 351525.06250	
14024	 steps: training loss - 117480.15625	, testing loss - 351581.25000	
14025	 steps: training loss - 113003.95312	, testing loss - 351271.00000	
14026	 steps: training loss - 91631.61719	, testing loss - 351041.56250	
14027	 steps: training loss - 103530.49219	, testing loss - 350557.71875	
14028	 steps: training loss - 106570.97656	, testing loss - 350196.68750	
14029	 steps: training loss - 101461.24219	, testing loss - 349542.12500	
14030	 steps: training loss - 118280.50000	, testing loss - 348623.84375	
14031	 steps: training loss - 100028.24219	, testing loss - 348129.34375	
14032	 steps: training loss - 102945.64062	, testing loss - 348464.53125	
14033	 steps: training loss - 112263.33594	, testing loss - 349732.68750	
14034	 steps: training loss - 104334.58594	, testing loss - 350607.81250	
14035	 steps: training loss - 111897.21875	, testing loss - 350289.84375	
14036	 steps: training loss - 102189.60156	, testing loss - 350894.59375	
14037	 steps: training loss - 102932.13281	, testing loss - 351208.25000	
14038	 steps: training loss - 137762.09375	, testing loss - 350447.15625	
14039	 steps: training loss - 109258.15625	, testing loss - 350731.59375	
14040	 steps: training loss - 86913.23438	, testing loss - 351134.37500	
14041	 steps: training loss - 122628.56250	, testing loss - 351137.75000	
14042	 steps: training loss - 112261.51562	, testing loss - 351501.03125	
14043	 steps: training loss - 108542.78125	, testing loss - 350473.28125	
14044	 steps: training loss - 99210.35156	, testing loss - 349891.50000	
14045	 steps: training loss - 101793.91406	, testing loss - 349408.75000	
14046	 steps: training loss - 111333.78125	, testing loss - 348647.53125	
14047	 steps: training loss - 134941.81250	, testing loss - 347918.65625	
14048	 steps: training loss - 99937.35938	, testing loss - 346208.93750	
14049	 steps: training loss - 87652.54688	, testing loss - 345442.65625	
14050	 steps: training loss - 129522.10938	, testing loss - 345163.31250	
14051	 steps: training loss - 86655.27344	, testing loss - 344835.96875	
14052	 steps: training loss - 108000.08594	, testing loss - 344880.21875	
14053	 steps: training loss - 95804.67969	, testing loss - 344837.37500	
14054	 steps: training loss - 125567.51562	, testing loss - 344446.40625	
14055	 steps: training loss - 111677.10156	, testing loss - 343908.78125	
14056	 steps: training loss - 107284.61719	, testing loss - 344294.93750	
14057	 steps: training loss - 102883.11719	, testing loss - 344232.59375	
14058	 steps: training loss - 99400.51562	, testing loss - 343931.12500	
14059	 steps: training loss - 89691.64062	, testing loss - 343810.68750	
14060	 steps: training loss - 106632.40625	, testing loss - 343835.50000	
14061	 steps: training loss - 97320.39844	, testing loss - 344009.50000	
14062	 steps: training loss - 102943.51562	, testing loss - 343886.96875	
14063	 steps: training loss - 101507.81250	, testing loss - 344299.00000	
14064	 steps: training loss - 96196.56250	, testing loss - 345148.28125	
14065	 steps: training loss - 106151.88281	, testing loss - 345929.75000	
14066	 steps: training loss - 112566.97656	, testing loss - 346407.93750	
14067	 steps: training loss - 110242.83594	, testing loss - 346464.56250	
14068	 steps: training loss - 93237.67188	, testing loss - 346713.25000	
14069	 steps: training loss - 117761.23438	, testing loss - 346251.40625	
14070	 steps: training loss - 109850.82031	, testing loss - 345859.43750	
14071	 steps: training loss - 103635.31250	, testing loss - 345534.06250	
14072	 steps: training loss - 91630.43750	, testing loss - 345089.62500	
14073	 steps: training loss - 103060.18750	, testing loss - 344903.28125	
14074	 steps: training loss - 94265.04688	, testing loss - 345597.56250	
14075	 steps: training loss - 104441.30469	, testing loss - 346224.34375	
14076	 steps: training loss - 118665.62500	, testing loss - 347202.59375	
14077	 steps: training loss - 106147.81250	, testing loss - 348295.96875	
14078	 steps: training loss - 95694.22656	, testing loss - 348658.37500	
14079	 steps: training loss - 103770.10938	, testing loss - 350396.75000	
14080	 steps: training loss - 93837.13281	, testing loss - 352035.31250	
14081	 steps: training loss - 123122.16406	, testing loss - 353051.12500	
14082	 steps: training loss - 97258.70312	, testing loss - 352807.81250	
14083	 steps: training loss - 90454.92188	, testing loss - 352715.93750	
14084	 steps: training loss - 98959.13281	, testing loss - 352677.90625	
14085	 steps: training loss - 114994.00000	, testing loss - 352340.68750	
14086	 steps: training loss - 105945.87500	, testing loss - 351635.93750	
14087	 steps: training loss - 101422.79688	, testing loss - 351399.18750	
14088	 steps: training loss - 99532.78125	, testing loss - 351000.46875	
14089	 steps: training loss - 107906.61719	, testing loss - 350183.84375	
14090	 steps: training loss - 92319.09375	, testing loss - 349256.28125	
14091	 steps: training loss - 96718.64062	, testing loss - 348732.40625	
14092	 steps: training loss - 135380.75000	, testing loss - 349191.43750	
14093	 steps: training loss - 114718.35156	, testing loss - 349550.65625	
14094	 steps: training loss - 118295.90625	, testing loss - 350753.31250	
14095	 steps: training loss - 113188.26562	, testing loss - 352002.09375	
14096	 steps: training loss - 112772.89062	, testing loss - 352974.53125	
14097	 steps: training loss - 145917.64062	, testing loss - 354103.90625	
14098	 steps: training loss - 98756.86719	, testing loss - 354032.25000	
14099	 steps: training loss - 116196.26562	, testing loss - 354094.34375	
14100	 steps: training loss - 111612.64062	, testing loss - 352890.78125	
14101	 steps: training loss - 93052.25000	, testing loss - 350997.31250	
14102	 steps: training loss - 100795.32812	, testing loss - 349911.75000	
14103	 steps: training loss - 101558.37500	, testing loss - 348943.93750	
14104	 steps: training loss - 133825.56250	, testing loss - 347815.65625	
14105	 steps: training loss - 90144.90625	, testing loss - 346492.75000	
14106	 steps: training loss - 86178.05469	, testing loss - 345831.34375	
14107	 steps: training loss - 128383.90625	, testing loss - 344987.18750	
14108	 steps: training loss - 97602.84375	, testing loss - 344910.81250	
14109	 steps: training loss - 81499.16406	, testing loss - 346271.50000	
14110	 steps: training loss - 105686.40625	, testing loss - 347482.00000	
14111	 steps: training loss - 99615.93750	, testing loss - 349107.46875	
14112	 steps: training loss - 90458.85156	, testing loss - 351694.56250	
14113	 steps: training loss - 85237.87500	, testing loss - 353975.43750	
14114	 steps: training loss - 110745.30469	, testing loss - 355691.18750	
14115	 steps: training loss - 120673.60938	, testing loss - 357164.09375	
14116	 steps: training loss - 126272.55469	, testing loss - 358204.46875	
14117	 steps: training loss - 103698.40625	, testing loss - 358158.18750	
14118	 steps: training loss - 125912.06250	, testing loss - 356613.18750	
14119	 steps: training loss - 122533.48438	, testing loss - 354368.09375	
14120	 steps: training loss - 120733.19531	, testing loss - 351546.65625	
14121	 steps: training loss - 120383.09375	, testing loss - 349142.06250	
14122	 steps: training loss - 114404.53125	, testing loss - 348070.75000	
14123	 steps: training loss - 137922.03125	, testing loss - 348210.71875	
14124	 steps: training loss - 122539.33594	, testing loss - 349696.93750	
14125	 steps: training loss - 92627.78906	, testing loss - 351556.18750	
14126	 steps: training loss - 112090.73438	, testing loss - 352396.90625	
14127	 steps: training loss - 114053.94531	, testing loss - 352085.50000	
14128	 steps: training loss - 101773.01562	, testing loss - 351967.12500	
14129	 steps: training loss - 125887.85938	, testing loss - 350881.03125	
14130	 steps: training loss - 118094.06250	, testing loss - 349807.25000	
14131	 steps: training loss - 108544.27344	, testing loss - 348692.59375	
14132	 steps: training loss - 88697.83594	, testing loss - 347406.90625	
14133	 steps: training loss - 100305.12500	, testing loss - 346274.87500	
14134	 steps: training loss - 108069.47656	, testing loss - 345257.34375	
14135	 steps: training loss - 125889.56250	, testing loss - 344154.09375	
14136	 steps: training loss - 118697.51562	, testing loss - 343380.75000	
14137	 steps: training loss - 90932.52344	, testing loss - 343865.62500	
14138	 steps: training loss - 117808.94531	, testing loss - 344794.40625	
14139	 steps: training loss - 105049.10938	, testing loss - 346524.37500	
14140	 steps: training loss - 117751.97656	, testing loss - 348629.43750	
14141	 steps: training loss - 114767.17188	, testing loss - 349658.56250	
14142	 steps: training loss - 88962.99219	, testing loss - 350932.59375	
14143	 steps: training loss - 92085.94531	, testing loss - 351559.18750	
14144	 steps: training loss - 117939.98438	, testing loss - 350937.62500	
14145	 steps: training loss - 118402.30469	, testing loss - 351189.12500	
14146	 steps: training loss - 111856.22656	, testing loss - 351873.21875	
14147	 steps: training loss - 114330.42188	, testing loss - 352337.81250	
14148	 steps: training loss - 112982.38281	, testing loss - 351649.87500	
14149	 steps: training loss - 102709.56250	, testing loss - 350368.40625	
14150	 steps: training loss - 111948.84375	, testing loss - 348978.00000	
14151	 steps: training loss - 101105.52344	, testing loss - 347064.18750	
14152	 steps: training loss - 106796.78906	, testing loss - 344884.53125	
14153	 steps: training loss - 137368.04688	, testing loss - 343111.15625	
14154	 steps: training loss - 118520.09375	, testing loss - 342589.12500	
14155	 steps: training loss - 123990.63281	, testing loss - 342535.03125	
14156	 steps: training loss - 109902.68750	, testing loss - 342901.06250	
14157	 steps: training loss - 123853.97656	, testing loss - 343559.50000	
14158	 steps: training loss - 88462.52344	, testing loss - 344703.84375	
14159	 steps: training loss - 119430.01562	, testing loss - 345516.12500	
14160	 steps: training loss - 117328.99219	, testing loss - 346083.53125	
14161	 steps: training loss - 116829.64844	, testing loss - 346900.53125	
14162	 steps: training loss - 111165.78906	, testing loss - 348639.87500	
14163	 steps: training loss - 121967.03125	, testing loss - 350643.09375	
14164	 steps: training loss - 102111.01562	, testing loss - 351948.09375	
14165	 steps: training loss - 97388.32812	, testing loss - 353225.90625	
14166	 steps: training loss - 117714.42969	, testing loss - 354204.28125	
14167	 steps: training loss - 115839.55469	, testing loss - 354135.68750	
14168	 steps: training loss - 111759.39844	, testing loss - 352599.37500	
14169	 steps: training loss - 116731.92969	, testing loss - 352797.50000	
14170	 steps: training loss - 103064.74219	, testing loss - 353535.71875	
14171	 steps: training loss - 86105.16406	, testing loss - 352802.81250	
14172	 steps: training loss - 111895.50781	, testing loss - 352526.21875	
14173	 steps: training loss - 84102.31250	, testing loss - 353403.25000	
14174	 steps: training loss - 107746.69531	, testing loss - 354417.21875	
14175	 steps: training loss - 111687.29688	, testing loss - 356174.46875	
14176	 steps: training loss - 112081.52344	, testing loss - 358303.18750	
14177	 steps: training loss - 95877.06250	, testing loss - 358775.15625	
14178	 steps: training loss - 99610.97656	, testing loss - 358736.53125	
14179	 steps: training loss - 127278.17188	, testing loss - 358505.93750	
14180	 steps: training loss - 90177.29688	, testing loss - 358228.96875	
14181	 steps: training loss - 112453.70312	, testing loss - 356794.00000	
14182	 steps: training loss - 103821.48438	, testing loss - 354498.84375	
14183	 steps: training loss - 108533.80469	, testing loss - 352845.34375	
14184	 steps: training loss - 100663.60156	, testing loss - 351928.81250	
14185	 steps: training loss - 105482.75781	, testing loss - 350818.28125	
14186	 steps: training loss - 96568.29688	, testing loss - 348759.09375	
14187	 steps: training loss - 131949.42188	, testing loss - 347802.59375	
14188	 steps: training loss - 90356.67969	, testing loss - 347826.59375	
14189	 steps: training loss - 108711.28906	, testing loss - 348146.75000	
14190	 steps: training loss - 96837.26562	, testing loss - 347975.93750	
14191	 steps: training loss - 114105.46094	, testing loss - 347091.06250	
14192	 steps: training loss - 104328.75000	, testing loss - 345225.46875	
14193	 steps: training loss - 97945.82812	, testing loss - 342348.09375	
14194	 steps: training loss - 111558.28125	, testing loss - 339958.78125	
14195	 steps: training loss - 101492.06250	, testing loss - 338829.37500	
14196	 steps: training loss - 112494.48438	, testing loss - 337722.34375	
14197	 steps: training loss - 89307.84375	, testing loss - 336931.78125	
14198	 steps: training loss - 110144.54688	, testing loss - 336921.40625	
14199	 steps: training loss - 126649.61719	, testing loss - 337421.78125	
14200	 steps: training loss - 99299.04688	, testing loss - 338306.21875	
14201	 steps: training loss - 101935.57031	, testing loss - 339183.21875	
14202	 steps: training loss - 112589.10938	, testing loss - 339591.12500	
14203	 steps: training loss - 96572.38281	, testing loss - 341095.43750	
14204	 steps: training loss - 115028.60156	, testing loss - 342318.53125	
14205	 steps: training loss - 113763.51562	, testing loss - 343264.96875	
14206	 steps: training loss - 93508.32812	, testing loss - 344294.09375	
14207	 steps: training loss - 88542.33594	, testing loss - 345644.50000	
14208	 steps: training loss - 102088.39062	, testing loss - 346945.15625	
14209	 steps: training loss - 151759.04688	, testing loss - 348809.71875	
14210	 steps: training loss - 113659.10156	, testing loss - 350539.21875	
14211	 steps: training loss - 119793.49219	, testing loss - 350700.62500	
14212	 steps: training loss - 90721.82031	, testing loss - 349845.09375	
14213	 steps: training loss - 125722.06250	, testing loss - 348986.87500	
14214	 steps: training loss - 116128.39062	, testing loss - 347907.96875	
14215	 steps: training loss - 121512.69531	, testing loss - 347354.15625	
14216	 steps: training loss - 105864.53906	, testing loss - 347253.28125	
14217	 steps: training loss - 94201.08594	, testing loss - 347211.00000	
14218	 steps: training loss - 121556.67969	, testing loss - 346398.93750	
14219	 steps: training loss - 101133.82031	, testing loss - 345924.09375	
14220	 steps: training loss - 109446.02344	, testing loss - 344950.18750	
14221	 steps: training loss - 126607.06250	, testing loss - 343727.56250	
14222	 steps: training loss - 103292.98438	, testing loss - 343119.78125	
14223	 steps: training loss - 121308.62500	, testing loss - 342439.87500	
14224	 steps: training loss - 100693.53906	, testing loss - 341870.81250	
14225	 steps: training loss - 118704.31250	, testing loss - 341646.65625	
14226	 steps: training loss - 108704.06250	, testing loss - 341746.87500	
14227	 steps: training loss - 90404.39844	, testing loss - 341245.68750	
14228	 steps: training loss - 108713.79688	, testing loss - 340577.81250	
14229	 steps: training loss - 112390.59375	, testing loss - 339757.03125	
14230	 steps: training loss - 112995.57812	, testing loss - 340134.34375	
14231	 steps: training loss - 116819.59375	, testing loss - 340036.25000	
14232	 steps: training loss - 95130.88281	, testing loss - 339581.50000	
14233	 steps: training loss - 116847.80469	, testing loss - 338859.21875	
14234	 steps: training loss - 107633.75781	, testing loss - 338083.59375	
14235	 steps: training loss - 123895.59375	, testing loss - 337115.56250	
14236	 steps: training loss - 80971.94531	, testing loss - 336621.00000	
14237	 steps: training loss - 105806.71094	, testing loss - 336091.81250	
14238	 steps: training loss - 127064.08594	, testing loss - 335948.25000	
14239	 steps: training loss - 111537.03906	, testing loss - 336558.09375	
14240	 steps: training loss - 109743.46875	, testing loss - 337188.53125	
14241	 steps: training loss - 106312.14844	, testing loss - 337779.81250	
14242	 steps: training loss - 112796.23438	, testing loss - 338283.78125	
14243	 steps: training loss - 109333.70312	, testing loss - 338724.18750	
14244	 steps: training loss - 95151.44531	, testing loss - 340195.03125	
14245	 steps: training loss - 117338.47656	, testing loss - 341698.37500	
14246	 steps: training loss - 127678.74219	, testing loss - 341647.87500	
14247	 steps: training loss - 111983.60938	, testing loss - 341057.56250	
14248	 steps: training loss - 96409.21094	, testing loss - 341150.25000	
14249	 steps: training loss - 101512.02344	, testing loss - 341481.18750	
14250	 steps: training loss - 119503.06250	, testing loss - 341407.93750	
14251	 steps: training loss - 103928.67188	, testing loss - 341365.87500	
14252	 steps: training loss - 113092.22656	, testing loss - 341484.21875	
14253	 steps: training loss - 108246.67188	, testing loss - 341414.09375	
14254	 steps: training loss - 90599.87500	, testing loss - 341400.06250	
14255	 steps: training loss - 124519.84375	, testing loss - 340969.40625	
14256	 steps: training loss - 103753.42188	, testing loss - 340139.06250	
14257	 steps: training loss - 122293.62500	, testing loss - 338996.50000	
14258	 steps: training loss - 103327.77344	, testing loss - 338142.15625	
14259	 steps: training loss - 120782.69531	, testing loss - 337470.87500	
14260	 steps: training loss - 135936.20312	, testing loss - 337972.75000	
14261	 steps: training loss - 125642.21875	, testing loss - 338692.75000	
14262	 steps: training loss - 91963.93750	, testing loss - 338643.56250	
14263	 steps: training loss - 125990.41406	, testing loss - 337954.84375	
14264	 steps: training loss - 117613.30469	, testing loss - 337229.96875	
14265	 steps: training loss - 124817.09375	, testing loss - 337097.06250	
14266	 steps: training loss - 92558.13281	, testing loss - 336817.68750	
14267	 steps: training loss - 120753.21094	, testing loss - 336731.12500	
14268	 steps: training loss - 111110.21094	, testing loss - 336723.37500	
14269	 steps: training loss - 116570.07031	, testing loss - 336535.81250	
14270	 steps: training loss - 104180.45312	, testing loss - 337247.53125	
14271	 steps: training loss - 92951.65625	, testing loss - 339376.34375	
14272	 steps: training loss - 111074.87500	, testing loss - 341923.15625	
14273	 steps: training loss - 97801.97656	, testing loss - 344407.15625	
14274	 steps: training loss - 81115.02344	, testing loss - 346252.93750	
14275	 steps: training loss - 129282.81250	, testing loss - 347082.25000	
14276	 steps: training loss - 109307.50781	, testing loss - 347256.18750	
14277	 steps: training loss - 125616.23438	, testing loss - 348235.09375	
14278	 steps: training loss - 99217.31250	, testing loss - 347469.34375	
14279	 steps: training loss - 90963.60938	, testing loss - 346664.00000	
14280	 steps: training loss - 112351.46094	, testing loss - 346509.12500	
14281	 steps: training loss - 86812.59375	, testing loss - 346969.03125	
14282	 steps: training loss - 105555.72656	, testing loss - 347045.78125	
14283	 steps: training loss - 97184.43750	, testing loss - 347123.96875	
14284	 steps: training loss - 118436.96875	, testing loss - 346372.90625	
14285	 steps: training loss - 100458.15625	, testing loss - 345622.15625	
14286	 steps: training loss - 91105.84375	, testing loss - 344845.21875	
14287	 steps: training loss - 105971.03125	, testing loss - 344569.37500	
14288	 steps: training loss - 116074.03906	, testing loss - 344045.25000	
14289	 steps: training loss - 99544.81250	, testing loss - 344402.43750	
14290	 steps: training loss - 94496.81250	, testing loss - 344432.87500	
14291	 steps: training loss - 106355.51562	, testing loss - 343910.21875	
14292	 steps: training loss - 112473.81250	, testing loss - 343644.28125	
14293	 steps: training loss - 108303.66406	, testing loss - 343580.15625	
14294	 steps: training loss - 116995.49219	, testing loss - 342711.25000	
14295	 steps: training loss - 98818.39844	, testing loss - 341867.84375	
14296	 steps: training loss - 110008.10938	, testing loss - 342106.40625	
14297	 steps: training loss - 107899.59375	, testing loss - 341791.12500	
14298	 steps: training loss - 117408.78125	, testing loss - 341128.84375	
14299	 steps: training loss - 99949.14062	, testing loss - 341397.62500	
14300	 steps: training loss - 102861.98438	, testing loss - 342252.93750	
14301	 steps: training loss - 118178.28125	, testing loss - 343132.56250	
14302	 steps: training loss - 96668.08594	, testing loss - 344323.15625	
14303	 steps: training loss - 109316.02344	, testing loss - 345771.81250	
14304	 steps: training loss - 109314.99219	, testing loss - 346911.03125	
14305	 steps: training loss - 113731.76562	, testing loss - 348622.21875	
14306	 steps: training loss - 112523.89062	, testing loss - 349692.18750	
14307	 steps: training loss - 91502.63281	, testing loss - 349692.40625	
14308	 steps: training loss - 102664.97656	, testing loss - 348082.93750	
14309	 steps: training loss - 114775.39062	, testing loss - 346305.71875	
14310	 steps: training loss - 104565.52344	, testing loss - 343905.62500	
14311	 steps: training loss - 119508.85156	, testing loss - 341614.43750	
14312	 steps: training loss - 120605.53125	, testing loss - 339596.71875	
14313	 steps: training loss - 125390.67969	, testing loss - 338603.06250	
14314	 steps: training loss - 112655.04688	, testing loss - 337719.15625	
14315	 steps: training loss - 117849.51562	, testing loss - 337175.06250	
14316	 steps: training loss - 116611.37500	, testing loss - 336727.40625	
14317	 steps: training loss - 110136.63281	, testing loss - 336421.50000	
14318	 steps: training loss - 99273.08594	, testing loss - 336413.06250	
14319	 steps: training loss - 130647.50000	, testing loss - 336367.40625	
14320	 steps: training loss - 114149.01562	, testing loss - 336702.68750	
14321	 steps: training loss - 119478.65625	, testing loss - 336861.43750	
14322	 steps: training loss - 96958.73438	, testing loss - 336763.43750	
14323	 steps: training loss - 106855.78906	, testing loss - 336343.06250	
14324	 steps: training loss - 97003.25000	, testing loss - 335614.81250	
14325	 steps: training loss - 103416.50781	, testing loss - 335041.25000	
14326	 steps: training loss - 132877.57812	, testing loss - 334349.37500	
14327	 steps: training loss - 116232.14844	, testing loss - 334554.81250	
14328	 steps: training loss - 104291.08594	, testing loss - 334998.31250	
14329	 steps: training loss - 113313.85938	, testing loss - 335908.06250	
14330	 steps: training loss - 126839.60938	, testing loss - 337096.00000	
14331	 steps: training loss - 97848.28906	, testing loss - 338239.46875	
14332	 steps: training loss - 94266.67969	, testing loss - 339522.71875	
14333	 steps: training loss - 102785.02344	, testing loss - 342036.12500	
14334	 steps: training loss - 97057.32031	, testing loss - 346112.34375	
14335	 steps: training loss - 94190.71875	, testing loss - 350597.40625	
14336	 steps: training loss - 135704.45312	, testing loss - 354362.00000	
14337	 steps: training loss - 100820.22656	, testing loss - 356592.15625	
14338	 steps: training loss - 99314.75781	, testing loss - 357689.78125	
14339	 steps: training loss - 87862.30469	, testing loss - 357607.56250	
14340	 steps: training loss - 111077.10938	, testing loss - 356957.31250	
14341	 steps: training loss - 100466.50781	, testing loss - 355590.56250	
14342	 steps: training loss - 108297.71875	, testing loss - 353903.09375	
14343	 steps: training loss - 109867.98438	, testing loss - 351634.40625	
14344	 steps: training loss - 111045.15625	, testing loss - 349494.93750	
14345	 steps: training loss - 95076.87500	, testing loss - 348642.09375	
14346	 steps: training loss - 84907.89062	, testing loss - 347680.84375	
14347	 steps: training loss - 98417.57031	, testing loss - 347460.03125	
14348	 steps: training loss - 115858.71094	, testing loss - 347831.31250	
14349	 steps: training loss - 111191.96094	, testing loss - 348810.09375	
14350	 steps: training loss - 116235.18750	, testing loss - 350075.25000	
14351	 steps: training loss - 112542.49219	, testing loss - 351748.56250	
14352	 steps: training loss - 131076.93750	, testing loss - 352696.78125	
14353	 steps: training loss - 109452.45312	, testing loss - 353315.75000	
14354	 steps: training loss - 108130.94531	, testing loss - 353113.37500	
14355	 steps: training loss - 113432.74219	, testing loss - 351483.12500	
14356	 steps: training loss - 101870.24219	, testing loss - 351029.25000	
14357	 steps: training loss - 102621.85938	, testing loss - 351045.62500	
14358	 steps: training loss - 92847.96094	, testing loss - 350623.03125	
14359	 steps: training loss - 110771.74219	, testing loss - 349834.87500	
14360	 steps: training loss - 117511.75781	, testing loss - 348142.28125	
14361	 steps: training loss - 113260.25781	, testing loss - 346319.37500	
14362	 steps: training loss - 116078.94531	, testing loss - 344926.18750	
14363	 steps: training loss - 121011.31250	, testing loss - 344314.31250	
14364	 steps: training loss - 101390.67969	, testing loss - 343952.21875	
14365	 steps: training loss - 89168.00000	, testing loss - 344025.56250	
14366	 steps: training loss - 106603.82812	, testing loss - 344140.90625	
14367	 steps: training loss - 103051.26562	, testing loss - 344392.12500	
14368	 steps: training loss - 87785.73438	, testing loss - 344822.34375	
14369	 steps: training loss - 121478.92969	, testing loss - 344836.59375	
14370	 steps: training loss - 105770.93750	, testing loss - 344411.15625	
14371	 steps: training loss - 113287.41406	, testing loss - 343220.46875	
14372	 steps: training loss - 133914.81250	, testing loss - 342465.62500	
14373	 steps: training loss - 103715.20312	, testing loss - 342238.25000	
14374	 steps: training loss - 102692.88281	, testing loss - 341850.40625	
14375	 steps: training loss - 92772.65625	, testing loss - 341501.15625	
14376	 steps: training loss - 92900.10938	, testing loss - 341542.93750	
14377	 steps: training loss - 114086.38281	, testing loss - 342188.90625	
14378	 steps: training loss - 125049.03906	, testing loss - 342210.31250	
14379	 steps: training loss - 113350.75781	, testing loss - 341767.65625	
14380	 steps: training loss - 104059.45312	, testing loss - 341879.90625	
14381	 steps: training loss - 85970.26562	, testing loss - 341424.31250	
14382	 steps: training loss - 95614.45312	, testing loss - 341111.96875	
14383	 steps: training loss - 96172.67188	, testing loss - 340904.81250	
14384	 steps: training loss - 116242.25781	, testing loss - 340740.46875	
14385	 steps: training loss - 114365.25000	, testing loss - 341005.81250	
14386	 steps: training loss - 112944.62500	, testing loss - 341303.65625	
14387	 steps: training loss - 90857.18750	, testing loss - 341953.28125	
14388	 steps: training loss - 134514.43750	, testing loss - 342226.71875	
14389	 steps: training loss - 130823.89062	, testing loss - 343578.12500	
14390	 steps: training loss - 97976.60156	, testing loss - 345869.09375	
14391	 steps: training loss - 112227.38281	, testing loss - 348376.93750	
14392	 steps: training loss - 107489.12500	, testing loss - 350511.96875	
14393	 steps: training loss - 120106.57031	, testing loss - 352539.78125	
14394	 steps: training loss - 106467.03906	, testing loss - 354981.34375	
14395	 steps: training loss - 143500.79688	, testing loss - 357649.31250	
14396	 steps: training loss - 92795.13281	, testing loss - 359483.50000	
14397	 steps: training loss - 118731.10156	, testing loss - 359378.34375	
14398	 steps: training loss - 106765.95312	, testing loss - 358426.81250	
14399	 steps: training loss - 99553.02344	, testing loss - 357978.93750	
14400	 steps: training loss - 103072.99219	, testing loss - 356678.71875	
14401	 steps: training loss - 91441.07812	, testing loss - 355728.37500	
14402	 steps: training loss - 100401.02344	, testing loss - 355187.34375	
14403	 steps: training loss - 88616.59375	, testing loss - 354037.18750	
14404	 steps: training loss - 118827.46094	, testing loss - 354006.12500	
14405	 steps: training loss - 117826.17188	, testing loss - 354406.43750	
14406	 steps: training loss - 139855.15625	, testing loss - 353327.81250	
14407	 steps: training loss - 107009.78125	, testing loss - 351611.75000	
14408	 steps: training loss - 91925.63281	, testing loss - 349891.15625	
14409	 steps: training loss - 91425.17188	, testing loss - 348132.15625	
14410	 steps: training loss - 99028.10938	, testing loss - 347190.68750	
14411	 steps: training loss - 126721.62500	, testing loss - 346478.43750	
14412	 steps: training loss - 102530.89062	, testing loss - 346094.84375	
14413	 steps: training loss - 106279.32812	, testing loss - 345886.03125	
14414	 steps: training loss - 105234.59375	, testing loss - 346278.81250	
14415	 steps: training loss - 88711.38281	, testing loss - 346601.46875	
14416	 steps: training loss - 113267.39844	, testing loss - 346447.34375	
14417	 steps: training loss - 84653.33594	, testing loss - 347256.25000	
14418	 steps: training loss - 101425.64844	, testing loss - 347406.90625	
14419	 steps: training loss - 101794.97656	, testing loss - 346832.84375	
14420	 steps: training loss - 99383.11719	, testing loss - 346787.56250	
14421	 steps: training loss - 120646.14844	, testing loss - 347009.06250	
14422	 steps: training loss - 98032.82031	, testing loss - 346838.93750	
14423	 steps: training loss - 116828.41406	, testing loss - 346942.96875	
14424	 steps: training loss - 108753.99219	, testing loss - 347207.78125	
14425	 steps: training loss - 120835.14062	, testing loss - 347319.28125	
14426	 steps: training loss - 102285.31250	, testing loss - 347356.62500	
14427	 steps: training loss - 89377.03125	, testing loss - 346730.59375	
14428	 steps: training loss - 130109.58594	, testing loss - 345435.90625	
14429	 steps: training loss - 104219.16406	, testing loss - 344965.25000	
14430	 steps: training loss - 133514.87500	, testing loss - 344786.15625	
14431	 steps: training loss - 109338.80469	, testing loss - 344339.65625	
14432	 steps: training loss - 95572.13281	, testing loss - 344227.40625	
14433	 steps: training loss - 113863.46875	, testing loss - 343853.75000	
14434	 steps: training loss - 108666.63281	, testing loss - 344007.43750	
14435	 steps: training loss - 95826.94531	, testing loss - 344741.78125	
14436	 steps: training loss - 97364.72656	, testing loss - 344555.09375	
14437	 steps: training loss - 100467.89062	, testing loss - 344014.53125	
14438	 steps: training loss - 94969.97656	, testing loss - 343540.03125	
14439	 steps: training loss - 99504.89062	, testing loss - 343570.71875	
14440	 steps: training loss - 122046.32812	, testing loss - 344578.28125	
14441	 steps: training loss - 106179.54688	, testing loss - 345385.40625	
14442	 steps: training loss - 113996.96094	, testing loss - 345691.71875	
14443	 steps: training loss - 107424.47656	, testing loss - 345459.37500	
14444	 steps: training loss - 99134.60156	, testing loss - 344576.53125	
14445	 steps: training loss - 131535.34375	, testing loss - 343921.59375	
14446	 steps: training loss - 108069.03125	, testing loss - 342987.71875	
14447	 steps: training loss - 101298.81250	, testing loss - 342858.43750	
14448	 steps: training loss - 102392.00000	, testing loss - 343168.40625	
14449	 steps: training loss - 88630.42188	, testing loss - 343006.53125	
14450	 steps: training loss - 129377.62500	, testing loss - 343047.12500	
14451	 steps: training loss - 102745.62500	, testing loss - 343250.62500	
14452	 steps: training loss - 117847.82812	, testing loss - 343903.40625	
14453	 steps: training loss - 101675.84375	, testing loss - 345453.93750	
14454	 steps: training loss - 114798.29688	, testing loss - 346919.31250	
14455	 steps: training loss - 100310.77344	, testing loss - 348268.03125	
14456	 steps: training loss - 102728.09375	, testing loss - 349442.43750	
14457	 steps: training loss - 108878.77344	, testing loss - 351007.31250	
14458	 steps: training loss - 98192.57812	, testing loss - 352768.31250	
14459	 steps: training loss - 96400.27344	, testing loss - 355123.53125	
14460	 steps: training loss - 94769.03906	, testing loss - 357573.00000	
14461	 steps: training loss - 87143.07031	, testing loss - 359099.62500	
14462	 steps: training loss - 116646.94531	, testing loss - 360560.28125	
14463	 steps: training loss - 106374.25781	, testing loss - 360611.25000	
14464	 steps: training loss - 121734.01562	, testing loss - 358585.43750	
14465	 steps: training loss - 109972.28906	, testing loss - 356771.62500	
14466	 steps: training loss - 77399.28906	, testing loss - 355590.75000	
14467	 steps: training loss - 109496.37500	, testing loss - 354481.50000	
14468	 steps: training loss - 109670.67969	, testing loss - 352567.56250	
14469	 steps: training loss - 109472.68750	, testing loss - 351362.40625	
14470	 steps: training loss - 124595.96875	, testing loss - 351173.21875	
14471	 steps: training loss - 133691.06250	, testing loss - 350569.56250	
14472	 steps: training loss - 121574.39844	, testing loss - 348988.46875	
14473	 steps: training loss - 116337.36719	, testing loss - 346866.34375	
14474	 steps: training loss - 122533.54688	, testing loss - 343929.00000	
14475	 steps: training loss - 108317.04688	, testing loss - 341955.96875	
14476	 steps: training loss - 92839.26562	, testing loss - 340030.06250	
14477	 steps: training loss - 86869.48438	, testing loss - 339045.62500	
14478	 steps: training loss - 123589.82812	, testing loss - 338526.93750	
14479	 steps: training loss - 106402.28125	, testing loss - 338784.43750	
14480	 steps: training loss - 96276.96875	, testing loss - 340012.81250	
14481	 steps: training loss - 122566.65625	, testing loss - 341037.09375	
14482	 steps: training loss - 93699.27344	, testing loss - 342414.06250	
14483	 steps: training loss - 96346.07812	, testing loss - 344089.09375	
14484	 steps: training loss - 97152.00781	, testing loss - 345263.34375	
14485	 steps: training loss - 89821.29688	, testing loss - 345654.40625	
14486	 steps: training loss - 108291.56250	, testing loss - 345638.71875	
14487	 steps: training loss - 113022.61719	, testing loss - 345990.62500	
14488	 steps: training loss - 99710.92969	, testing loss - 346357.81250	
14489	 steps: training loss - 116262.50000	, testing loss - 346728.65625	
14490	 steps: training loss - 102653.69531	, testing loss - 348743.84375	
14491	 steps: training loss - 94787.44531	, testing loss - 351880.81250	
14492	 steps: training loss - 91636.44531	, testing loss - 356146.93750	
14493	 steps: training loss - 127852.19531	, testing loss - 360931.40625	
14494	 steps: training loss - 91324.10938	, testing loss - 364121.56250	
14495	 steps: training loss - 101886.41406	, testing loss - 366057.34375	
14496	 steps: training loss - 119751.68750	, testing loss - 368406.34375	
14497	 steps: training loss - 125519.09375	, testing loss - 369026.68750	
14498	 steps: training loss - 119663.21875	, testing loss - 367709.25000	
14499	 steps: training loss - 101435.41406	, testing loss - 366164.81250	
14500	 steps: training loss - 120523.10938	, testing loss - 364472.43750	
14501	 steps: training loss - 109695.42188	, testing loss - 361148.65625	
14502	 steps: training loss - 94548.17188	, testing loss - 356393.62500	
14503	 steps: training loss - 118063.67969	, testing loss - 351490.15625	
14504	 steps: training loss - 106082.69531	, testing loss - 348292.46875	
14505	 steps: training loss - 95598.00000	, testing loss - 346493.18750	
14506	 steps: training loss - 101369.45312	, testing loss - 345035.34375	
14507	 steps: training loss - 105263.34375	, testing loss - 343659.21875	
14508	 steps: training loss - 94098.07031	, testing loss - 343565.06250	
14509	 steps: training loss - 111774.54688	, testing loss - 343550.71875	
14510	 steps: training loss - 144858.25000	, testing loss - 343988.90625	
14511	 steps: training loss - 91608.26562	, testing loss - 344820.43750	
14512	 steps: training loss - 101168.99219	, testing loss - 345596.68750	
14513	 steps: training loss - 88412.08594	, testing loss - 346944.28125	
14514	 steps: training loss - 97220.66406	, testing loss - 347737.03125	
14515	 steps: training loss - 116105.24219	, testing loss - 348918.28125	
14516	 steps: training loss - 107999.18750	, testing loss - 350869.65625	
14517	 steps: training loss - 121800.79688	, testing loss - 353119.87500	
14518	 steps: training loss - 123496.66406	, testing loss - 353858.93750	
14519	 steps: training loss - 97927.78125	, testing loss - 353261.84375	
14520	 steps: training loss - 147291.96875	, testing loss - 352541.18750	
14521	 steps: training loss - 92839.79688	, testing loss - 353100.09375	
14522	 steps: training loss - 93293.42188	, testing loss - 353864.37500	
14523	 steps: training loss - 99098.89844	, testing loss - 355161.81250	
14524	 steps: training loss - 105125.00781	, testing loss - 354888.34375	
14525	 steps: training loss - 91651.16406	, testing loss - 353490.78125	
14526	 steps: training loss - 99813.28125	, testing loss - 352617.12500	
14527	 steps: training loss - 134892.20312	, testing loss - 352312.78125	
14528	 steps: training loss - 112266.84375	, testing loss - 353465.50000	
14529	 steps: training loss - 96552.12500	, testing loss - 353537.03125	
14530	 steps: training loss - 106339.53125	, testing loss - 353060.43750	
14531	 steps: training loss - 114349.40625	, testing loss - 352641.28125	
14532	 steps: training loss - 81139.97656	, testing loss - 352573.00000	
14533	 steps: training loss - 116759.98438	, testing loss - 351652.81250	
14534	 steps: training loss - 99382.35156	, testing loss - 350336.37500	
14535	 steps: training loss - 103032.54688	, testing loss - 348819.09375	
14536	 steps: training loss - 113740.00781	, testing loss - 347085.90625	
14537	 steps: training loss - 100853.76562	, testing loss - 345492.53125	
14538	 steps: training loss - 81786.69531	, testing loss - 344201.12500	
14539	 steps: training loss - 118176.09375	, testing loss - 343495.06250	
14540	 steps: training loss - 120638.70312	, testing loss - 342429.25000	
14541	 steps: training loss - 94502.50781	, testing loss - 342201.93750	
14542	 steps: training loss - 132798.18750	, testing loss - 342444.03125	
14543	 steps: training loss - 89187.78906	, testing loss - 343024.62500	
14544	 steps: training loss - 108910.13281	, testing loss - 344246.00000	
14545	 steps: training loss - 106868.95312	, testing loss - 345843.65625	
14546	 steps: training loss - 96752.33594	, testing loss - 347612.12500	
14547	 steps: training loss - 123294.14844	, testing loss - 348947.31250	
14548	 steps: training loss - 80520.90625	, testing loss - 349849.65625	
14549	 steps: training loss - 88800.30469	, testing loss - 350589.56250	
14550	 steps: training loss - 113371.78125	, testing loss - 351051.28125	
14551	 steps: training loss - 90162.19531	, testing loss - 351333.81250	
14552	 steps: training loss - 127232.65625	, testing loss - 351400.03125	
14553	 steps: training loss - 103508.39844	, testing loss - 351023.34375	
14554	 steps: training loss - 104353.90625	, testing loss - 350484.65625	
14555	 steps: training loss - 101260.46094	, testing loss - 350047.40625	
14556	 steps: training loss - 113227.47656	, testing loss - 350712.25000	
14557	 steps: training loss - 114577.18750	, testing loss - 351610.43750	
14558	 steps: training loss - 103985.45312	, testing loss - 352425.25000	
14559	 steps: training loss - 106021.51562	, testing loss - 352477.56250	
14560	 steps: training loss - 112648.29688	, testing loss - 351505.15625	
14561	 steps: training loss - 92387.53125	, testing loss - 351005.81250	
14562	 steps: training loss - 84062.46875	, testing loss - 351455.96875	
14563	 steps: training loss - 134073.18750	, testing loss - 351630.84375	
14564	 steps: training loss - 112024.71875	, testing loss - 350553.56250	
14565	 steps: training loss - 93692.15625	, testing loss - 350118.31250	
14566	 steps: training loss - 99258.96875	, testing loss - 350109.12500	
14567	 steps: training loss - 119729.97656	, testing loss - 350822.93750	
14568	 steps: training loss - 132247.17188	, testing loss - 351108.12500	
14569	 steps: training loss - 115359.71094	, testing loss - 351419.56250	
14570	 steps: training loss - 91355.45312	, testing loss - 351063.31250	
14571	 steps: training loss - 118763.42188	, testing loss - 350163.43750	
14572	 steps: training loss - 77235.11719	, testing loss - 349124.81250	
14573	 steps: training loss - 106586.76562	, testing loss - 349154.53125	
14574	 steps: training loss - 112176.21875	, testing loss - 350136.31250	
14575	 steps: training loss - 101513.69531	, testing loss - 351435.78125	
14576	 steps: training loss - 105873.19531	, testing loss - 352548.68750	
14577	 steps: training loss - 112446.46094	, testing loss - 353136.59375	
14578	 steps: training loss - 120147.81250	, testing loss - 353154.50000	
14579	 steps: training loss - 123033.65625	, testing loss - 351924.40625	
14580	 steps: training loss - 94209.63281	, testing loss - 349652.40625	
14581	 steps: training loss - 134166.70312	, testing loss - 347120.65625	
14582	 steps: training loss - 103904.30469	, testing loss - 344578.09375	
14583	 steps: training loss - 115248.49219	, testing loss - 342588.50000	
14584	 steps: training loss - 105852.82031	, testing loss - 341029.78125	
14585	 steps: training loss - 101759.51562	, testing loss - 340885.87500	
14586	 steps: training loss - 123155.46094	, testing loss - 340794.75000	
14587	 steps: training loss - 115146.61719	, testing loss - 341375.40625	
14588	 steps: training loss - 71497.58594	, testing loss - 342642.78125	
14589	 steps: training loss - 122255.88281	, testing loss - 344116.59375	
14590	 steps: training loss - 124006.07031	, testing loss - 345253.03125	
14591	 steps: training loss - 98276.58594	, testing loss - 346016.06250	
14592	 steps: training loss - 105799.89844	, testing loss - 346304.03125	
14593	 steps: training loss - 106301.38281	, testing loss - 346191.46875	
14594	 steps: training loss - 79859.39844	, testing loss - 346017.96875	
14595	 steps: training loss - 136090.53125	, testing loss - 345274.25000	
14596	 steps: training loss - 101243.32031	, testing loss - 344182.09375	
14597	 steps: training loss - 102614.47656	, testing loss - 343691.71875	
14598	 steps: training loss - 100319.75000	, testing loss - 344290.78125	
14599	 steps: training loss - 124300.63281	, testing loss - 344828.59375	
14600	 steps: training loss - 99063.42188	, testing loss - 346734.90625	
14601	 steps: training loss - 90020.95312	, testing loss - 348309.15625	
14602	 steps: training loss - 108182.03906	, testing loss - 349081.78125	
14603	 steps: training loss - 91332.75781	, testing loss - 349226.50000	
14604	 steps: training loss - 80555.41406	, testing loss - 349469.18750	
14605	 steps: training loss - 119254.89062	, testing loss - 349110.56250	
14606	 steps: training loss - 125747.82031	, testing loss - 348186.09375	
14607	 steps: training loss - 112512.53906	, testing loss - 347639.65625	
14608	 steps: training loss - 105256.75781	, testing loss - 347494.53125	
14609	 steps: training loss - 104740.87500	, testing loss - 347814.25000	
14610	 steps: training loss - 119110.66406	, testing loss - 348145.09375	
14611	 steps: training loss - 133530.40625	, testing loss - 348443.56250	
14612	 steps: training loss - 137293.62500	, testing loss - 349151.96875	
14613	 steps: training loss - 117360.16406	, testing loss - 349960.34375	
14614	 steps: training loss - 90255.08594	, testing loss - 350140.53125	
14615	 steps: training loss - 104797.23438	, testing loss - 349815.78125	
14616	 steps: training loss - 94040.65625	, testing loss - 349454.59375	
14617	 steps: training loss - 123733.37500	, testing loss - 349467.37500	
14618	 steps: training loss - 104098.58594	, testing loss - 350316.71875	
14619	 steps: training loss - 108472.85938	, testing loss - 351787.15625	
14620	 steps: training loss - 99469.12500	, testing loss - 352629.96875	
14621	 steps: training loss - 85109.64844	, testing loss - 352319.25000	
14622	 steps: training loss - 102035.00781	, testing loss - 351954.00000	
14623	 steps: training loss - 96307.53906	, testing loss - 351618.18750	
14624	 steps: training loss - 116090.44531	, testing loss - 352226.28125	
14625	 steps: training loss - 106679.20312	, testing loss - 353279.12500	
14626	 steps: training loss - 88387.28125	, testing loss - 353619.18750	
14627	 steps: training loss - 127908.66406	, testing loss - 353553.06250	
14628	 steps: training loss - 113612.79688	, testing loss - 353524.37500	
14629	 steps: training loss - 99198.73438	, testing loss - 353699.81250	
14630	 steps: training loss - 128039.94531	, testing loss - 353439.25000	
14631	 steps: training loss - 101822.04688	, testing loss - 354039.78125	
14632	 steps: training loss - 132755.14062	, testing loss - 355241.93750	
14633	 steps: training loss - 116052.96094	, testing loss - 355009.71875	
14634	 steps: training loss - 90558.80469	, testing loss - 354008.65625	
14635	 steps: training loss - 105562.92188	, testing loss - 354132.62500	
14636	 steps: training loss - 73345.14844	, testing loss - 354275.93750	
14637	 steps: training loss - 93183.25781	, testing loss - 353702.84375	
14638	 steps: training loss - 112917.90625	, testing loss - 353116.09375	
14639	 steps: training loss - 109341.13281	, testing loss - 351307.59375	
14640	 steps: training loss - 85581.71875	, testing loss - 348727.87500	
14641	 steps: training loss - 111060.60938	, testing loss - 347228.37500	
14642	 steps: training loss - 107890.36719	, testing loss - 346265.09375	
14643	 steps: training loss - 92667.82812	, testing loss - 345881.75000	
14644	 steps: training loss - 120050.85156	, testing loss - 346004.59375	
14645	 steps: training loss - 94000.34375	, testing loss - 345672.46875	
14646	 steps: training loss - 104506.15625	, testing loss - 345401.21875	
14647	 steps: training loss - 111331.66406	, testing loss - 344858.75000	
14648	 steps: training loss - 99176.10938	, testing loss - 343987.90625	
14649	 steps: training loss - 87439.73438	, testing loss - 342794.53125	
14650	 steps: training loss - 125696.03125	, testing loss - 341575.90625	
14651	 steps: training loss - 108110.64062	, testing loss - 340759.28125	
14652	 steps: training loss - 79921.91406	, testing loss - 340510.21875	
14653	 steps: training loss - 89850.25000	, testing loss - 340807.87500	
14654	 steps: training loss - 125913.41406	, testing loss - 341910.68750	
14655	 steps: training loss - 88371.40625	, testing loss - 343875.31250	
14656	 steps: training loss - 111870.79688	, testing loss - 345732.46875	
14657	 steps: training loss - 120310.56250	, testing loss - 347129.59375	
14658	 steps: training loss - 101381.71094	, testing loss - 347712.90625	
14659	 steps: training loss - 118685.89844	, testing loss - 347401.15625	
14660	 steps: training loss - 92048.42188	, testing loss - 347431.03125	
14661	 steps: training loss - 91633.53906	, testing loss - 347730.56250	
14662	 steps: training loss - 136824.34375	, testing loss - 348520.00000	
14663	 steps: training loss - 114459.57812	, testing loss - 348628.53125	
14664	 steps: training loss - 104562.68750	, testing loss - 348042.65625	
14665	 steps: training loss - 117749.35156	, testing loss - 348326.90625	
14666	 steps: training loss - 113372.21875	, testing loss - 348525.06250	
14667	 steps: training loss - 121584.59375	, testing loss - 349604.15625	
14668	 steps: training loss - 106582.90625	, testing loss - 350974.84375	
14669	 steps: training loss - 117820.06250	, testing loss - 353504.31250	
14670	 steps: training loss - 104817.74219	, testing loss - 355060.90625	
14671	 steps: training loss - 94620.90625	, testing loss - 356303.43750	
14672	 steps: training loss - 107465.60156	, testing loss - 357346.65625	
14673	 steps: training loss - 125604.58594	, testing loss - 356658.71875	
14674	 steps: training loss - 95907.61719	, testing loss - 355401.56250	
14675	 steps: training loss - 131649.53125	, testing loss - 353764.84375	
14676	 steps: training loss - 121310.27344	, testing loss - 352030.46875	
14677	 steps: training loss - 100244.66406	, testing loss - 350197.00000	
14678	 steps: training loss - 98018.75000	, testing loss - 348719.96875	
14679	 steps: training loss - 102035.75781	, testing loss - 346714.59375	
14680	 steps: training loss - 104413.07812	, testing loss - 344781.65625	
14681	 steps: training loss - 122929.27344	, testing loss - 343710.06250	
14682	 steps: training loss - 123323.03125	, testing loss - 343851.75000	
14683	 steps: training loss - 94117.71875	, testing loss - 344159.21875	
14684	 steps: training loss - 120738.60156	, testing loss - 344865.25000	
14685	 steps: training loss - 103076.33594	, testing loss - 345356.37500	
14686	 steps: training loss - 111885.60938	, testing loss - 345758.37500	
14687	 steps: training loss - 92260.01562	, testing loss - 346095.06250	
14688	 steps: training loss - 115784.50781	, testing loss - 346067.50000	
14689	 steps: training loss - 84554.00781	, testing loss - 346120.40625	
14690	 steps: training loss - 113441.55469	, testing loss - 346001.31250	
14691	 steps: training loss - 110720.42188	, testing loss - 345243.43750	
14692	 steps: training loss - 99704.87500	, testing loss - 343776.53125	
14693	 steps: training loss - 93129.73438	, testing loss - 342231.12500	
14694	 steps: training loss - 105941.02344	, testing loss - 340553.65625	
14695	 steps: training loss - 100398.50000	, testing loss - 339321.37500	
14696	 steps: training loss - 96762.14062	, testing loss - 338552.90625	
14697	 steps: training loss - 135537.57812	, testing loss - 338131.21875	
14698	 steps: training loss - 121477.71094	, testing loss - 337932.81250	
14699	 steps: training loss - 121175.18750	, testing loss - 338172.06250	
14700	 steps: training loss - 98780.34375	, testing loss - 339177.81250	
14701	 steps: training loss - 91600.42188	, testing loss - 340711.81250	
14702	 steps: training loss - 88247.33594	, testing loss - 342132.18750	
14703	 steps: training loss - 110723.03906	, testing loss - 343225.21875	
14704	 steps: training loss - 108255.14062	, testing loss - 343470.46875	
14705	 steps: training loss - 127574.23438	, testing loss - 343599.25000	
14706	 steps: training loss - 101166.77344	, testing loss - 344276.96875	
14707	 steps: training loss - 125450.96875	, testing loss - 345659.06250	
14708	 steps: training loss - 101369.55469	, testing loss - 346544.59375	
14709	 steps: training loss - 118468.70312	, testing loss - 346904.62500	
14710	 steps: training loss - 109808.75000	, testing loss - 347587.43750	
14711	 steps: training loss - 141639.00000	, testing loss - 348369.65625	
14712	 steps: training loss - 108500.36719	, testing loss - 349336.28125	
14713	 steps: training loss - 110307.51562	, testing loss - 349736.40625	
14714	 steps: training loss - 103733.27344	, testing loss - 351610.78125	
14715	 steps: training loss - 80430.70312	, testing loss - 353610.06250	
14716	 steps: training loss - 105723.64062	, testing loss - 354561.93750	
14717	 steps: training loss - 111705.82031	, testing loss - 354778.18750	
14718	 steps: training loss - 95207.53125	, testing loss - 353462.68750	
14719	 steps: training loss - 93713.10156	, testing loss - 351416.03125	
14720	 steps: training loss - 94391.82031	, testing loss - 349744.18750	
14721	 steps: training loss - 110211.28906	, testing loss - 348374.46875	
14722	 steps: training loss - 104723.16406	, testing loss - 347112.68750	
14723	 steps: training loss - 122135.35938	, testing loss - 346268.65625	
14724	 steps: training loss - 121186.32031	, testing loss - 346368.62500	
14725	 steps: training loss - 111048.31250	, testing loss - 346910.78125	
14726	 steps: training loss - 115019.86719	, testing loss - 347271.34375	
14727	 steps: training loss - 77466.83594	, testing loss - 347776.00000	
14728	 steps: training loss - 93332.03125	, testing loss - 348041.00000	
14729	 steps: training loss - 104615.20312	, testing loss - 347828.06250	
14730	 steps: training loss - 117347.55469	, testing loss - 347863.93750	
14731	 steps: training loss - 114262.28906	, testing loss - 347101.53125	
14732	 steps: training loss - 119192.59375	, testing loss - 346255.59375	
14733	 steps: training loss - 90595.94531	, testing loss - 346918.00000	
14734	 steps: training loss - 117949.05469	, testing loss - 347892.96875	
14735	 steps: training loss - 105267.68750	, testing loss - 349664.50000	
14736	 steps: training loss - 82806.52344	, testing loss - 351211.46875	
14737	 steps: training loss - 109472.25781	, testing loss - 352482.06250	
14738	 steps: training loss - 88164.15625	, testing loss - 353194.40625	
14739	 steps: training loss - 103558.10938	, testing loss - 352985.09375	
14740	 steps: training loss - 104135.83594	, testing loss - 353082.81250	
14741	 steps: training loss - 114877.04688	, testing loss - 353458.40625	
14742	 steps: training loss - 81073.53125	, testing loss - 353648.43750	
14743	 steps: training loss - 114930.35156	, testing loss - 353011.65625	
14744	 steps: training loss - 121371.96094	, testing loss - 351678.34375	
14745	 steps: training loss - 110666.32031	, testing loss - 350810.25000	
14746	 steps: training loss - 112105.70312	, testing loss - 350471.28125	
14747	 steps: training loss - 111175.58594	, testing loss - 350888.90625	
14748	 steps: training loss - 113015.60938	, testing loss - 350535.68750	
14749	 steps: training loss - 94129.07031	, testing loss - 349301.09375	
14750	 steps: training loss - 88112.41406	, testing loss - 348133.06250	
14751	 steps: training loss - 88188.55469	, testing loss - 347472.18750	
14752	 steps: training loss - 124599.47656	, testing loss - 346745.90625	
14753	 steps: training loss - 103496.96094	, testing loss - 346467.46875	
14754	 steps: training loss - 105611.00781	, testing loss - 346242.12500	
14755	 steps: training loss - 112579.50000	, testing loss - 346307.15625	
14756	 steps: training loss - 103029.70312	, testing loss - 346105.56250	
14757	 steps: training loss - 121069.49219	, testing loss - 345472.37500	
14758	 steps: training loss - 104286.68750	, testing loss - 344542.43750	
14759	 steps: training loss - 107370.85938	, testing loss - 343545.75000	
14760	 steps: training loss - 117682.52344	, testing loss - 343318.65625	
14761	 steps: training loss - 105412.16406	, testing loss - 343306.59375	
14762	 steps: training loss - 110519.03906	, testing loss - 342767.28125	
14763	 steps: training loss - 92343.51562	, testing loss - 342530.84375	
14764	 steps: training loss - 102626.92188	, testing loss - 342816.56250	
14765	 steps: training loss - 115408.00000	, testing loss - 343257.75000	
14766	 steps: training loss - 115369.63281	, testing loss - 343152.21875	
14767	 steps: training loss - 110821.35938	, testing loss - 342786.34375	
14768	 steps: training loss - 96302.75000	, testing loss - 342086.96875	
14769	 steps: training loss - 93314.31250	, testing loss - 341261.93750	
14770	 steps: training loss - 109667.73438	, testing loss - 341146.18750	
14771	 steps: training loss - 132281.46875	, testing loss - 341464.81250	
14772	 steps: training loss - 84543.73438	, testing loss - 342264.34375	
14773	 steps: training loss - 112001.88281	, testing loss - 343790.46875	
14774	 steps: training loss - 109570.09375	, testing loss - 345181.21875	
14775	 steps: training loss - 114262.30469	, testing loss - 346289.53125	
14776	 steps: training loss - 103802.34375	, testing loss - 347322.00000	
14777	 steps: training loss - 123026.07031	, testing loss - 349073.09375	
14778	 steps: training loss - 104062.39844	, testing loss - 350261.21875	
14779	 steps: training loss - 123384.13281	, testing loss - 350953.68750	
14780	 steps: training loss - 138735.25000	, testing loss - 351928.81250	
14781	 steps: training loss - 96431.42188	, testing loss - 352708.81250	
14782	 steps: training loss - 83884.87500	, testing loss - 352468.43750	
14783	 steps: training loss - 137705.01562	, testing loss - 352081.62500	
14784	 steps: training loss - 119936.28125	, testing loss - 350710.34375	
14785	 steps: training loss - 124426.96094	, testing loss - 349832.93750	
14786	 steps: training loss - 132691.98438	, testing loss - 349711.25000	
14787	 steps: training loss - 103744.88281	, testing loss - 350307.37500	
14788	 steps: training loss - 124116.84375	, testing loss - 350577.50000	
14789	 steps: training loss - 78904.96094	, testing loss - 350676.25000	
14790	 steps: training loss - 88423.53906	, testing loss - 350776.81250	
14791	 steps: training loss - 121245.46875	, testing loss - 350493.90625	
14792	 steps: training loss - 124934.88281	, testing loss - 349905.00000	
14793	 steps: training loss - 114941.98438	, testing loss - 349440.75000	
14794	 steps: training loss - 110565.36719	, testing loss - 348899.46875	
14795	 steps: training loss - 105335.31250	, testing loss - 348252.75000	
14796	 steps: training loss - 118680.58594	, testing loss - 346582.09375	
14797	 steps: training loss - 97691.51562	, testing loss - 344910.03125	
14798	 steps: training loss - 102256.29688	, testing loss - 343519.31250	
14799	 steps: training loss - 109557.64062	, testing loss - 342892.65625	
14800	 steps: training loss - 114432.95312	, testing loss - 342118.34375	
14801	 steps: training loss - 123310.35938	, testing loss - 341734.81250	
14802	 steps: training loss - 100009.01562	, testing loss - 341967.68750	
14803	 steps: training loss - 109593.78125	, testing loss - 342235.53125	
14804	 steps: training loss - 99057.42969	, testing loss - 342611.87500	
14805	 steps: training loss - 102910.13281	, testing loss - 342554.25000	
14806	 steps: training loss - 105558.54688	, testing loss - 343117.21875	
14807	 steps: training loss - 100038.81250	, testing loss - 343301.28125	
14808	 steps: training loss - 105036.52344	, testing loss - 343390.21875	
14809	 steps: training loss - 94036.07031	, testing loss - 342848.56250	
14810	 steps: training loss - 108226.11719	, testing loss - 343239.93750	
14811	 steps: training loss - 124893.62500	, testing loss - 343987.37500	
14812	 steps: training loss - 127481.32031	, testing loss - 343979.50000	
14813	 steps: training loss - 118616.30469	, testing loss - 344011.59375	
14814	 steps: training loss - 130839.86719	, testing loss - 343689.81250	
14815	 steps: training loss - 112614.09375	, testing loss - 343636.40625	
14816	 steps: training loss - 142585.98438	, testing loss - 343970.93750	
14817	 steps: training loss - 120482.57031	, testing loss - 344432.87500	
14818	 steps: training loss - 78123.66406	, testing loss - 345846.43750	
14819	 steps: training loss - 112071.75781	, testing loss - 346698.28125	
14820	 steps: training loss - 113091.85156	, testing loss - 347344.25000	
14821	 steps: training loss - 119569.81250	, testing loss - 347488.84375	
14822	 steps: training loss - 127611.83594	, testing loss - 347097.81250	
14823	 steps: training loss - 118599.64062	, testing loss - 347013.81250	
14824	 steps: training loss - 105762.87500	, testing loss - 347564.56250	
14825	 steps: training loss - 95752.24219	, testing loss - 348211.90625	
14826	 steps: training loss - 119591.89062	, testing loss - 348012.96875	
14827	 steps: training loss - 138978.60938	, testing loss - 347217.87500	
14828	 steps: training loss - 107891.14062	, testing loss - 346013.25000	
14829	 steps: training loss - 102275.11719	, testing loss - 344661.18750	
14830	 steps: training loss - 109300.14062	, testing loss - 344203.15625	
14831	 steps: training loss - 99286.00781	, testing loss - 344807.65625	
14832	 steps: training loss - 93780.85156	, testing loss - 345892.93750	
14833	 steps: training loss - 90787.22656	, testing loss - 346639.40625	
14834	 steps: training loss - 117016.82031	, testing loss - 347357.09375	
14835	 steps: training loss - 98368.46094	, testing loss - 347951.75000	
14836	 steps: training loss - 104224.82031	, testing loss - 349281.53125	
14837	 steps: training loss - 117754.90625	, testing loss - 350975.40625	
14838	 steps: training loss - 105782.73438	, testing loss - 351543.56250	
14839	 steps: training loss - 109920.04688	, testing loss - 351714.40625	
14840	 steps: training loss - 96428.49219	, testing loss - 350695.25000	
14841	 steps: training loss - 114018.71875	, testing loss - 348843.71875	
14842	 steps: training loss - 122106.28125	, testing loss - 346905.68750	
14843	 steps: training loss - 115293.45312	, testing loss - 345420.06250	
14844	 steps: training loss - 101009.21094	, testing loss - 344336.40625	
14845	 steps: training loss - 104546.29688	, testing loss - 343390.68750	
14846	 steps: training loss - 113797.75000	, testing loss - 342544.84375	
14847	 steps: training loss - 101635.91406	, testing loss - 341606.18750	
14848	 steps: training loss - 125558.11719	, testing loss - 340828.93750	
14849	 steps: training loss - 121853.00000	, testing loss - 340958.18750	
14850	 steps: training loss - 114610.15625	, testing loss - 342226.40625	
14851	 steps: training loss - 118434.90625	, testing loss - 343398.46875	
14852	 steps: training loss - 120798.17188	, testing loss - 344829.84375	
14853	 steps: training loss - 120106.32031	, testing loss - 346555.87500	
14854	 steps: training loss - 88934.86719	, testing loss - 348469.68750	
14855	 steps: training loss - 104508.98438	, testing loss - 349760.50000	
14856	 steps: training loss - 80116.36719	, testing loss - 351533.59375	
14857	 steps: training loss - 129530.91406	, testing loss - 353002.65625	
14858	 steps: training loss - 116237.62500	, testing loss - 353279.84375	
14859	 steps: training loss - 119530.42969	, testing loss - 352616.46875	
14860	 steps: training loss - 107386.54688	, testing loss - 352052.75000	
14861	 steps: training loss - 106735.82031	, testing loss - 351098.71875	
14862	 steps: training loss - 112304.81250	, testing loss - 349808.93750	
14863	 steps: training loss - 111071.24219	, testing loss - 349498.59375	
14864	 steps: training loss - 108796.94531	, testing loss - 349019.56250	
14865	 steps: training loss - 100513.86719	, testing loss - 349348.31250	
14866	 steps: training loss - 133269.98438	, testing loss - 348862.18750	
14867	 steps: training loss - 118619.57812	, testing loss - 348137.40625	
14868	 steps: training loss - 128983.62500	, testing loss - 347545.87500	
14869	 steps: training loss - 95584.42969	, testing loss - 347336.62500	
14870	 steps: training loss - 86844.95312	, testing loss - 347781.84375	
14871	 steps: training loss - 97700.85156	, testing loss - 348195.68750	
14872	 steps: training loss - 121237.94531	, testing loss - 348854.84375	
14873	 steps: training loss - 110103.25000	, testing loss - 349251.96875	
14874	 steps: training loss - 120405.00000	, testing loss - 349603.34375	
14875	 steps: training loss - 95899.64844	, testing loss - 349254.90625	
14876	 steps: training loss - 108758.14844	, testing loss - 348518.75000	
14877	 steps: training loss - 110091.56250	, testing loss - 347418.93750	
14878	 steps: training loss - 116286.78125	, testing loss - 346904.34375	
14879	 steps: training loss - 103012.13281	, testing loss - 347100.93750	
14880	 steps: training loss - 105682.39844	, testing loss - 348093.71875	
14881	 steps: training loss - 132651.68750	, testing loss - 349207.87500	
14882	 steps: training loss - 120249.70312	, testing loss - 350756.18750	
14883	 steps: training loss - 143711.71875	, testing loss - 352062.90625	
14884	 steps: training loss - 105087.31250	, testing loss - 352552.84375	
14885	 steps: training loss - 121740.78125	, testing loss - 354034.84375	
14886	 steps: training loss - 112074.44531	, testing loss - 355296.93750	
14887	 steps: training loss - 119862.64844	, testing loss - 355873.12500	
14888	 steps: training loss - 112262.83594	, testing loss - 356046.06250	
14889	 steps: training loss - 94651.38281	, testing loss - 354898.18750	
14890	 steps: training loss - 116021.14062	, testing loss - 354099.65625	
14891	 steps: training loss - 119878.75781	, testing loss - 353902.56250	
14892	 steps: training loss - 108807.59375	, testing loss - 353354.37500	
14893	 steps: training loss - 117547.92188	, testing loss - 352607.06250	
14894	 steps: training loss - 109298.75000	, testing loss - 352460.09375	
14895	 steps: training loss - 122033.82031	, testing loss - 352027.93750	
14896	 steps: training loss - 109471.32812	, testing loss - 351678.56250	
14897	 steps: training loss - 101367.73438	, testing loss - 350792.78125	
14898	 steps: training loss - 98829.30469	, testing loss - 350481.00000	
14899	 steps: training loss - 118286.03906	, testing loss - 351076.87500	
14900	 steps: training loss - 110962.78125	, testing loss - 350997.46875	
14901	 steps: training loss - 93708.85938	, testing loss - 351110.62500	
14902	 steps: training loss - 110872.07812	, testing loss - 352296.78125	
14903	 steps: training loss - 112965.87500	, testing loss - 354536.34375	
14904	 steps: training loss - 94018.26562	, testing loss - 356553.00000	
14905	 steps: training loss - 109439.89844	, testing loss - 357881.03125	
14906	 steps: training loss - 124861.41406	, testing loss - 359196.50000	
14907	 steps: training loss - 130462.96094	, testing loss - 359846.46875	
14908	 steps: training loss - 106575.46875	, testing loss - 360067.87500	
14909	 steps: training loss - 110656.81250	, testing loss - 360078.93750	
14910	 steps: training loss - 116222.46094	, testing loss - 358668.71875	
14911	 steps: training loss - 94946.33594	, testing loss - 356421.50000	
14912	 steps: training loss - 113385.46875	, testing loss - 353817.06250	
14913	 steps: training loss - 129381.89062	, testing loss - 352619.00000	
14914	 steps: training loss - 103360.27344	, testing loss - 352014.50000	
14915	 steps: training loss - 90805.42969	, testing loss - 350843.15625	
14916	 steps: training loss - 91055.41406	, testing loss - 350608.34375	
14917	 steps: training loss - 101481.99219	, testing loss - 350320.68750	
14918	 steps: training loss - 117099.76562	, testing loss - 350079.12500	
14919	 steps: training loss - 114609.92969	, testing loss - 351101.21875	
14920	 steps: training loss - 100830.30469	, testing loss - 352120.31250	
14921	 steps: training loss - 133997.23438	, testing loss - 352416.87500	
14922	 steps: training loss - 114436.47656	, testing loss - 352103.78125	
14923	 steps: training loss - 108980.78906	, testing loss - 351366.46875	
14924	 steps: training loss - 83069.89062	, testing loss - 350782.59375	
14925	 steps: training loss - 103592.27344	, testing loss - 351197.90625	
14926	 steps: training loss - 109490.87500	, testing loss - 351384.68750	
14927	 steps: training loss - 87892.84375	, testing loss - 352219.46875	
14928	 steps: training loss - 140575.15625	, testing loss - 353253.40625	
14929	 steps: training loss - 107681.64844	, testing loss - 352575.15625	
14930	 steps: training loss - 99553.57812	, testing loss - 350828.03125	
14931	 steps: training loss - 120651.23438	, testing loss - 349512.40625	
14932	 steps: training loss - 99385.04688	, testing loss - 349099.87500	
14933	 steps: training loss - 109139.32812	, testing loss - 349644.06250	
14934	 steps: training loss - 108257.17188	, testing loss - 350496.12500	
14935	 steps: training loss - 106466.31250	, testing loss - 351145.18750	
14936	 steps: training loss - 104770.76562	, testing loss - 351308.59375	
14937	 steps: training loss - 92818.74219	, testing loss - 351918.09375	
14938	 steps: training loss - 118251.39844	, testing loss - 352296.00000	
14939	 steps: training loss - 102778.08594	, testing loss - 353155.62500	
14940	 steps: training loss - 79840.32031	, testing loss - 353761.56250	
14941	 steps: training loss - 99263.60938	, testing loss - 354491.15625	
14942	 steps: training loss - 97163.62500	, testing loss - 356257.12500	
14943	 steps: training loss - 110245.01562	, testing loss - 357437.56250	
14944	 steps: training loss - 124919.76562	, testing loss - 355699.75000	
14945	 steps: training loss - 118130.37500	, testing loss - 352495.18750	
14946	 steps: training loss - 121340.39844	, testing loss - 348853.59375	
14947	 steps: training loss - 120262.20312	, testing loss - 345450.84375	
14948	 steps: training loss - 142194.40625	, testing loss - 343832.06250	
14949	 steps: training loss - 140315.20312	, testing loss - 343287.62500	
14950	 steps: training loss - 111660.77344	, testing loss - 343188.62500	
14951	 steps: training loss - 107702.09375	, testing loss - 343568.93750	
14952	 steps: training loss - 140488.93750	, testing loss - 343777.65625	
14953	 steps: training loss - 119074.17188	, testing loss - 343954.46875	
14954	 steps: training loss - 93003.28125	, testing loss - 343527.75000	
14955	 steps: training loss - 111844.00781	, testing loss - 342773.75000	
14956	 steps: training loss - 116449.64062	, testing loss - 342588.65625	
14957	 steps: training loss - 94885.06250	, testing loss - 342790.37500	
14958	 steps: training loss - 101303.23438	, testing loss - 343088.84375	
14959	 steps: training loss - 104796.96875	, testing loss - 343121.46875	
14960	 steps: training loss - 100123.96094	, testing loss - 343252.68750	
14961	 steps: training loss - 119225.26562	, testing loss - 343332.56250	
14962	 steps: training loss - 102181.45312	, testing loss - 343497.43750	
14963	 steps: training loss - 112869.89062	, testing loss - 343744.96875	
14964	 steps: training loss - 104375.22656	, testing loss - 343700.15625	
14965	 steps: training loss - 89781.45312	, testing loss - 343996.34375	
14966	 steps: training loss - 129666.43750	, testing loss - 344900.31250	
14967	 steps: training loss - 121259.10156	, testing loss - 345613.00000	
14968	 steps: training loss - 100908.44531	, testing loss - 346653.06250	
14969	 steps: training loss - 100507.79688	, testing loss - 347975.06250	
14970	 steps: training loss - 136603.15625	, testing loss - 348981.15625	
14971	 steps: training loss - 100867.47656	, testing loss - 350365.34375	
14972	 steps: training loss - 101388.94531	, testing loss - 352374.31250	
14973	 steps: training loss - 116339.89844	, testing loss - 353656.28125	
14974	 steps: training loss - 79974.58594	, testing loss - 354439.40625	
14975	 steps: training loss - 107836.97656	, testing loss - 355323.56250	
14976	 steps: training loss - 104611.44531	, testing loss - 354936.12500	
14977	 steps: training loss - 111496.43750	, testing loss - 353859.56250	
14978	 steps: training loss - 116286.44531	, testing loss - 352164.56250	
14979	 steps: training loss - 121811.35156	, testing loss - 351118.31250	
14980	 steps: training loss - 94343.20312	, testing loss - 350638.78125	
14981	 steps: training loss - 111316.67969	, testing loss - 349870.96875	
14982	 steps: training loss - 94723.36719	, testing loss - 349796.84375	
14983	 steps: training loss - 125339.90625	, testing loss - 349868.28125	
14984	 steps: training loss - 111274.98438	, testing loss - 349703.81250	
14985	 steps: training loss - 116228.87500	, testing loss - 350154.25000	
14986	 steps: training loss - 108537.89844	, testing loss - 350796.03125	
14987	 steps: training loss - 129359.28125	, testing loss - 351006.93750	
14988	 steps: training loss - 92877.56250	, testing loss - 350466.43750	
14989	 steps: training loss - 92711.59375	, testing loss - 350551.87500	
14990	 steps: training loss - 110143.88281	, testing loss - 350661.53125	
14991	 steps: training loss - 109952.64062	, testing loss - 350845.12500	
14992	 steps: training loss - 112118.17969	, testing loss - 351502.12500	
14993	 steps: training loss - 115552.75781	, testing loss - 351798.87500	
14994	 steps: training loss - 123086.52344	, testing loss - 351934.28125	
14995	 steps: training loss - 98007.79688	, testing loss - 350834.62500	
14996	 steps: training loss - 117507.10938	, testing loss - 349788.90625	
14997	 steps: training loss - 94049.10938	, testing loss - 348999.81250	
14998	 steps: training loss - 98587.68750	, testing loss - 348350.53125	
14999	 steps: training loss - 113531.26562	, testing loss - 347646.71875	
EVALUATION
----------
Test loss: 26977.79492
MIMO Accuracies: 0.15585

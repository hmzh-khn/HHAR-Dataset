
LOOCV TRAINING INFO - is_lstm? True
LOOCV? -  True
-------------
TRAINING USERS -  ['a', 'b', 'e', 'g', 'h', 'i']
LEFT OUT -  c
-------------
actions ['bike', 'sit']
devices ['samsungold_1', 'samsungold_2']
step size 10
num_epochs 1000
batch size 12
feature size (x,y,z) 3
hidden size 20
number recurrent layers 2
number of classes 2
writing pickle to run9_model.p
writing accuracy + pickle to acc_run9_model.p
------------------------------------------------
0	 steps: training loss - 0.69533	, testing loss - 0.68728	
1	 steps: training loss - 0.68813	, testing loss - 0.68693	
2	 steps: training loss - 0.68023	, testing loss - 0.68683	
3	 steps: training loss - 0.68891	, testing loss - 0.68683	
4	 steps: training loss - 0.69243	, testing loss - 0.68677	
5	 steps: training loss - 0.69276	, testing loss - 0.68659	
6	 steps: training loss - 0.68996	, testing loss - 0.68630	
7	 steps: training loss - 0.68997	, testing loss - 0.68602	
8	 steps: training loss - 0.68010	, testing loss - 0.68570	
9	 steps: training loss - 0.68560	, testing loss - 0.68545	
10	 steps: training loss - 0.68886	, testing loss - 0.68527	
11	 steps: training loss - 0.68603	, testing loss - 0.68521	
12	 steps: training loss - 0.68055	, testing loss - 0.68516	
13	 steps: training loss - 0.68418	, testing loss - 0.68505	
14	 steps: training loss - 0.67888	, testing loss - 0.68493	
15	 steps: training loss - 0.67852	, testing loss - 0.68483	
16	 steps: training loss - 0.67598	, testing loss - 0.68474	
17	 steps: training loss - 0.68298	, testing loss - 0.68464	
18	 steps: training loss - 0.65491	, testing loss - 0.68459	
19	 steps: training loss - 0.67466	, testing loss - 0.68453	
20	 steps: training loss - 0.69063	, testing loss - 0.68451	
21	 steps: training loss - 0.67568	, testing loss - 0.68454	
22	 steps: training loss - 0.66529	, testing loss - 0.68459	
23	 steps: training loss - 0.66661	, testing loss - 0.68464	
24	 steps: training loss - 0.66990	, testing loss - 0.68471	
25	 steps: training loss - 0.68524	, testing loss - 0.68479	
26	 steps: training loss - 0.68650	, testing loss - 0.68488	
27	 steps: training loss - 0.65736	, testing loss - 0.68495	
28	 steps: training loss - 0.68796	, testing loss - 0.68503	
29	 steps: training loss - 0.65312	, testing loss - 0.68511	
30	 steps: training loss - 0.66105	, testing loss - 0.68520	
31	 steps: training loss - 0.68570	, testing loss - 0.68529	
32	 steps: training loss - 0.66700	, testing loss - 0.68539	
33	 steps: training loss - 0.67348	, testing loss - 0.68548	
34	 steps: training loss - 0.63991	, testing loss - 0.68557	
35	 steps: training loss - 0.67224	, testing loss - 0.68569	
36	 steps: training loss - 0.68212	, testing loss - 0.68582	
37	 steps: training loss - 0.66114	, testing loss - 0.68593	
38	 steps: training loss - 0.67049	, testing loss - 0.68607	
39	 steps: training loss - 0.69615	, testing loss - 0.68621	
40	 steps: training loss - 0.72341	, testing loss - 0.68631	
41	 steps: training loss - 0.65047	, testing loss - 0.68633	
42	 steps: training loss - 0.67479	, testing loss - 0.68636	
43	 steps: training loss - 0.70152	, testing loss - 0.68641	
44	 steps: training loss - 0.62779	, testing loss - 0.68642	
45	 steps: training loss - 0.66345	, testing loss - 0.68649	
46	 steps: training loss - 0.64647	, testing loss - 0.68656	
47	 steps: training loss - 0.67696	, testing loss - 0.68667	
48	 steps: training loss - 0.66371	, testing loss - 0.68678	
49	 steps: training loss - 0.67581	, testing loss - 0.68689	
50	 steps: training loss - 0.66968	, testing loss - 0.68697	
51	 steps: training loss - 0.71138	, testing loss - 0.68706	
52	 steps: training loss - 0.66265	, testing loss - 0.68706	
53	 steps: training loss - 0.68207	, testing loss - 0.68707	
54	 steps: training loss - 0.68599	, testing loss - 0.68707	
55	 steps: training loss - 0.66064	, testing loss - 0.68706	
56	 steps: training loss - 0.69817	, testing loss - 0.68705	
57	 steps: training loss - 0.66863	, testing loss - 0.68704	
58	 steps: training loss - 0.64348	, testing loss - 0.68703	
59	 steps: training loss - 0.67653	, testing loss - 0.68707	
60	 steps: training loss - 0.67744	, testing loss - 0.68713	
61	 steps: training loss - 0.67122	, testing loss - 0.68719	
62	 steps: training loss - 0.65474	, testing loss - 0.68725	
63	 steps: training loss - 0.66622	, testing loss - 0.68731	
64	 steps: training loss - 0.68084	, testing loss - 0.68737	
65	 steps: training loss - 0.66114	, testing loss - 0.68743	
66	 steps: training loss - 0.65828	, testing loss - 0.68748	
67	 steps: training loss - 0.67344	, testing loss - 0.68755	
68	 steps: training loss - 0.66430	, testing loss - 0.68762	
69	 steps: training loss - 0.66701	, testing loss - 0.68767	
70	 steps: training loss - 0.68285	, testing loss - 0.68772	
71	 steps: training loss - 0.64389	, testing loss - 0.68777	
72	 steps: training loss - 0.67572	, testing loss - 0.68784	
73	 steps: training loss - 0.64326	, testing loss - 0.68789	
74	 steps: training loss - 0.65366	, testing loss - 0.68797	
75	 steps: training loss - 0.67078	, testing loss - 0.68806	
76	 steps: training loss - 0.66991	, testing loss - 0.68813	
77	 steps: training loss - 0.66687	, testing loss - 0.68818	
78	 steps: training loss - 0.66671	, testing loss - 0.68823	
79	 steps: training loss - 0.65751	, testing loss - 0.68830	
80	 steps: training loss - 0.67005	, testing loss - 0.68839	
81	 steps: training loss - 0.64939	, testing loss - 0.68845	
82	 steps: training loss - 0.67302	, testing loss - 0.68853	
83	 steps: training loss - 0.64352	, testing loss - 0.68861	
84	 steps: training loss - 0.64178	, testing loss - 0.68870	
85	 steps: training loss - 0.66207	, testing loss - 0.68884	
86	 steps: training loss - 0.66564	, testing loss - 0.68897	
87	 steps: training loss - 0.67068	, testing loss - 0.68912	
88	 steps: training loss - 0.65466	, testing loss - 0.68925	
89	 steps: training loss - 0.66874	, testing loss - 0.68940	
90	 steps: training loss - 0.61966	, testing loss - 0.68955	
91	 steps: training loss - 0.65518	, testing loss - 0.68974	
92	 steps: training loss - 0.64924	, testing loss - 0.68992	
93	 steps: training loss - 0.64378	, testing loss - 0.69009	
94	 steps: training loss - 0.63481	, testing loss - 0.69028	
95	 steps: training loss - 0.67928	, testing loss - 0.69051	
96	 steps: training loss - 0.61877	, testing loss - 0.69067	
97	 steps: training loss - 0.67432	, testing loss - 0.69086	
98	 steps: training loss - 0.65827	, testing loss - 0.69102	
99	 steps: training loss - 0.67463	, testing loss - 0.69112	
100	 steps: training loss - 0.68918	, testing loss - 0.69116	
101	 steps: training loss - 0.66489	, testing loss - 0.69114	
102	 steps: training loss - 0.66819	, testing loss - 0.69113	
103	 steps: training loss - 0.65092	, testing loss - 0.69110	
104	 steps: training loss - 0.63469	, testing loss - 0.69109	
105	 steps: training loss - 0.62756	, testing loss - 0.69111	
106	 steps: training loss - 0.66585	, testing loss - 0.69122	
107	 steps: training loss - 0.65997	, testing loss - 0.69134	
108	 steps: training loss - 0.61355	, testing loss - 0.69145	
109	 steps: training loss - 0.63949	, testing loss - 0.69167	
110	 steps: training loss - 0.63638	, testing loss - 0.69196	
111	 steps: training loss - 0.66906	, testing loss - 0.69230	
112	 steps: training loss - 0.69960	, testing loss - 0.69259	
113	 steps: training loss - 0.61962	, testing loss - 0.69275	
114	 steps: training loss - 0.70619	, testing loss - 0.69297	
115	 steps: training loss - 0.62966	, testing loss - 0.69304	
116	 steps: training loss - 0.67573	, testing loss - 0.69310	
117	 steps: training loss - 0.63294	, testing loss - 0.69314	
118	 steps: training loss - 0.63942	, testing loss - 0.69322	
119	 steps: training loss - 0.64980	, testing loss - 0.69333	
120	 steps: training loss - 0.67009	, testing loss - 0.69345	
121	 steps: training loss - 0.67146	, testing loss - 0.69352	
122	 steps: training loss - 0.62683	, testing loss - 0.69353	
123	 steps: training loss - 0.65928	, testing loss - 0.69358	
124	 steps: training loss - 0.67198	, testing loss - 0.69362	
125	 steps: training loss - 0.64843	, testing loss - 0.69363	
126	 steps: training loss - 0.63091	, testing loss - 0.69364	
127	 steps: training loss - 0.63510	, testing loss - 0.69370	
128	 steps: training loss - 0.62072	, testing loss - 0.69381	
129	 steps: training loss - 0.66770	, testing loss - 0.69398	
130	 steps: training loss - 0.61216	, testing loss - 0.69412	
131	 steps: training loss - 0.68908	, testing loss - 0.69433	
132	 steps: training loss - 0.68434	, testing loss - 0.69447	
133	 steps: training loss - 0.63773	, testing loss - 0.69447	
134	 steps: training loss - 0.66947	, testing loss - 0.69445	
135	 steps: training loss - 0.67239	, testing loss - 0.69441	
136	 steps: training loss - 0.60430	, testing loss - 0.69436	
137	 steps: training loss - 0.67512	, testing loss - 0.69440	
138	 steps: training loss - 0.62060	, testing loss - 0.69441	
139	 steps: training loss - 0.64112	, testing loss - 0.69444	
140	 steps: training loss - 0.66764	, testing loss - 0.69451	
141	 steps: training loss - 0.63733	, testing loss - 0.69457	
142	 steps: training loss - 0.64193	, testing loss - 0.69462	
143	 steps: training loss - 0.67075	, testing loss - 0.69467	
144	 steps: training loss - 0.63154	, testing loss - 0.69467	
145	 steps: training loss - 0.66532	, testing loss - 0.69467	
146	 steps: training loss - 0.64540	, testing loss - 0.69468	
147	 steps: training loss - 0.65098	, testing loss - 0.69470	
148	 steps: training loss - 0.60260	, testing loss - 0.69473	
149	 steps: training loss - 0.66008	, testing loss - 0.69488	
150	 steps: training loss - 0.62351	, testing loss - 0.69497	
151	 steps: training loss - 0.66099	, testing loss - 0.69506	
152	 steps: training loss - 0.64990	, testing loss - 0.69513	
153	 steps: training loss - 0.63852	, testing loss - 0.69522	
154	 steps: training loss - 0.62509	, testing loss - 0.69533	
155	 steps: training loss - 0.60534	, testing loss - 0.69545	
156	 steps: training loss - 0.63286	, testing loss - 0.69565	
157	 steps: training loss - 0.62465	, testing loss - 0.69588	
158	 steps: training loss - 0.61261	, testing loss - 0.69612	
159	 steps: training loss - 0.62891	, testing loss - 0.69642	
160	 steps: training loss - 0.61527	, testing loss - 0.69676	
161	 steps: training loss - 0.64545	, testing loss - 0.69710	
162	 steps: training loss - 0.60794	, testing loss - 0.69738	
163	 steps: training loss - 0.61245	, testing loss - 0.69769	
164	 steps: training loss - 0.64048	, testing loss - 0.69805	
165	 steps: training loss - 0.61201	, testing loss - 0.69841	
166	 steps: training loss - 0.66803	, testing loss - 0.69879	
167	 steps: training loss - 0.62443	, testing loss - 0.69909	
168	 steps: training loss - 0.60969	, testing loss - 0.69933	
169	 steps: training loss - 0.60692	, testing loss - 0.69965	
170	 steps: training loss - 0.59010	, testing loss - 0.70004	
171	 steps: training loss - 0.63954	, testing loss - 0.70047	
172	 steps: training loss - 0.66184	, testing loss - 0.70084	
173	 steps: training loss - 0.62537	, testing loss - 0.70106	
174	 steps: training loss - 0.67053	, testing loss - 0.70131	
175	 steps: training loss - 0.65848	, testing loss - 0.70142	
176	 steps: training loss - 0.61968	, testing loss - 0.70144	
177	 steps: training loss - 0.66001	, testing loss - 0.70143	
178	 steps: training loss - 0.60665	, testing loss - 0.70138	
179	 steps: training loss - 0.62031	, testing loss - 0.70139	
180	 steps: training loss - 0.61293	, testing loss - 0.70149	
181	 steps: training loss - 0.62630	, testing loss - 0.70170	
182	 steps: training loss - 0.61502	, testing loss - 0.70188	
183	 steps: training loss - 0.63043	, testing loss - 0.70211	
184	 steps: training loss - 0.65325	, testing loss - 0.70232	
185	 steps: training loss - 0.56739	, testing loss - 0.70244	
186	 steps: training loss - 0.62877	, testing loss - 0.70272	
187	 steps: training loss - 0.65883	, testing loss - 0.70304	
188	 steps: training loss - 0.61952	, testing loss - 0.70323	
189	 steps: training loss - 0.58951	, testing loss - 0.70346	
190	 steps: training loss - 0.67047	, testing loss - 0.70381	
191	 steps: training loss - 0.58742	, testing loss - 0.70397	
192	 steps: training loss - 0.70569	, testing loss - 0.70415	
193	 steps: training loss - 0.69202	, testing loss - 0.70417	
194	 steps: training loss - 0.66075	, testing loss - 0.70398	
195	 steps: training loss - 0.62353	, testing loss - 0.70366	
196	 steps: training loss - 0.60206	, testing loss - 0.70334	
197	 steps: training loss - 0.57397	, testing loss - 0.70314	
198	 steps: training loss - 0.63859	, testing loss - 0.70315	
199	 steps: training loss - 0.62405	, testing loss - 0.70319	
200	 steps: training loss - 0.63813	, testing loss - 0.70322	
201	 steps: training loss - 0.61383	, testing loss - 0.70320	
202	 steps: training loss - 0.67286	, testing loss - 0.70318	
203	 steps: training loss - 0.60499	, testing loss - 0.70313	
204	 steps: training loss - 0.61944	, testing loss - 0.70317	
205	 steps: training loss - 0.64059	, testing loss - 0.70329	
206	 steps: training loss - 0.59899	, testing loss - 0.70339	
207	 steps: training loss - 0.63876	, testing loss - 0.70348	
208	 steps: training loss - 0.63421	, testing loss - 0.70350	
209	 steps: training loss - 0.64618	, testing loss - 0.70347	
210	 steps: training loss - 0.64266	, testing loss - 0.70340	
211	 steps: training loss - 0.57593	, testing loss - 0.70329	
212	 steps: training loss - 0.64236	, testing loss - 0.70331	
213	 steps: training loss - 0.59397	, testing loss - 0.70328	
214	 steps: training loss - 0.61768	, testing loss - 0.70333	
215	 steps: training loss - 0.65377	, testing loss - 0.70348	
216	 steps: training loss - 0.61139	, testing loss - 0.70358	
217	 steps: training loss - 0.59546	, testing loss - 0.70360	
218	 steps: training loss - 0.60307	, testing loss - 0.70366	
219	 steps: training loss - 0.59832	, testing loss - 0.70377	
220	 steps: training loss - 0.65676	, testing loss - 0.70388	
221	 steps: training loss - 0.60371	, testing loss - 0.70381	
222	 steps: training loss - 0.65590	, testing loss - 0.70382	
223	 steps: training loss - 0.57058	, testing loss - 0.70381	
224	 steps: training loss - 0.60783	, testing loss - 0.70394	
225	 steps: training loss - 0.62790	, testing loss - 0.70413	
226	 steps: training loss - 0.60033	, testing loss - 0.70431	
227	 steps: training loss - 0.59001	, testing loss - 0.70453	
228	 steps: training loss - 0.58230	, testing loss - 0.70479	
229	 steps: training loss - 0.60491	, testing loss - 0.70509	
230	 steps: training loss - 0.60291	, testing loss - 0.70537	
231	 steps: training loss - 0.63409	, testing loss - 0.70562	
232	 steps: training loss - 0.59444	, testing loss - 0.70578	
233	 steps: training loss - 0.61031	, testing loss - 0.70598	
234	 steps: training loss - 0.59137	, testing loss - 0.70626	
235	 steps: training loss - 0.66543	, testing loss - 0.70663	
236	 steps: training loss - 0.62259	, testing loss - 0.70682	
237	 steps: training loss - 0.64711	, testing loss - 0.70691	
238	 steps: training loss - 0.62660	, testing loss - 0.70688	
239	 steps: training loss - 0.59340	, testing loss - 0.70677	
240	 steps: training loss - 0.60297	, testing loss - 0.70673	
241	 steps: training loss - 0.65629	, testing loss - 0.70685	
242	 steps: training loss - 0.61219	, testing loss - 0.70690	
243	 steps: training loss - 0.60065	, testing loss - 0.70692	
244	 steps: training loss - 0.67355	, testing loss - 0.70705	
245	 steps: training loss - 0.59868	, testing loss - 0.70710	
246	 steps: training loss - 0.60836	, testing loss - 0.70708	
247	 steps: training loss - 0.60990	, testing loss - 0.70709	
248	 steps: training loss - 0.61156	, testing loss - 0.70713	
249	 steps: training loss - 0.67336	, testing loss - 0.70718	
250	 steps: training loss - 0.60988	, testing loss - 0.70714	
251	 steps: training loss - 0.60059	, testing loss - 0.70710	
252	 steps: training loss - 0.58651	, testing loss - 0.70717	
253	 steps: training loss - 0.64922	, testing loss - 0.70733	
254	 steps: training loss - 0.60712	, testing loss - 0.70743	
255	 steps: training loss - 0.61315	, testing loss - 0.70757	
256	 steps: training loss - 0.60111	, testing loss - 0.70776	
257	 steps: training loss - 0.62494	, testing loss - 0.70793	
258	 steps: training loss - 0.60676	, testing loss - 0.70803	
259	 steps: training loss - 0.61765	, testing loss - 0.70806	
260	 steps: training loss - 0.58992	, testing loss - 0.70804	
261	 steps: training loss - 0.58383	, testing loss - 0.70814	
262	 steps: training loss - 0.61661	, testing loss - 0.70834	
263	 steps: training loss - 0.57700	, testing loss - 0.70855	
264	 steps: training loss - 0.57541	, testing loss - 0.70875	
265	 steps: training loss - 0.61901	, testing loss - 0.70904	
266	 steps: training loss - 0.61276	, testing loss - 0.70931	
267	 steps: training loss - 0.59470	, testing loss - 0.70958	
268	 steps: training loss - 0.59791	, testing loss - 0.70984	
269	 steps: training loss - 0.59778	, testing loss - 0.71006	
270	 steps: training loss - 0.60003	, testing loss - 0.71036	
271	 steps: training loss - 0.60843	, testing loss - 0.71071	
272	 steps: training loss - 0.57563	, testing loss - 0.71105	
273	 steps: training loss - 0.61569	, testing loss - 0.71141	
274	 steps: training loss - 0.55373	, testing loss - 0.71171	
275	 steps: training loss - 0.63267	, testing loss - 0.71210	
276	 steps: training loss - 0.62256	, testing loss - 0.71242	
277	 steps: training loss - 0.61911	, testing loss - 0.71267	
278	 steps: training loss - 0.61264	, testing loss - 0.71283	
279	 steps: training loss - 0.64799	, testing loss - 0.71298	
280	 steps: training loss - 0.60534	, testing loss - 0.71304	
281	 steps: training loss - 0.61396	, testing loss - 0.71315	
282	 steps: training loss - 0.60583	, testing loss - 0.71322	
283	 steps: training loss - 0.56182	, testing loss - 0.71337	
284	 steps: training loss - 0.63888	, testing loss - 0.71370	
285	 steps: training loss - 0.56541	, testing loss - 0.71398	
286	 steps: training loss - 0.61503	, testing loss - 0.71436	
287	 steps: training loss - 0.56841	, testing loss - 0.71476	
288	 steps: training loss - 0.58496	, testing loss - 0.71511	
289	 steps: training loss - 0.58768	, testing loss - 0.71549	
290	 steps: training loss - 0.58721	, testing loss - 0.71575	
291	 steps: training loss - 0.58712	, testing loss - 0.71594	
292	 steps: training loss - 0.59485	, testing loss - 0.71613	
293	 steps: training loss - 0.62322	, testing loss - 0.71625	
294	 steps: training loss - 0.63153	, testing loss - 0.71617	
295	 steps: training loss - 0.54090	, testing loss - 0.71599	
296	 steps: training loss - 0.67515	, testing loss - 0.71600	
297	 steps: training loss - 0.62802	, testing loss - 0.71576	
298	 steps: training loss - 0.60133	, testing loss - 0.71541	
299	 steps: training loss - 0.62262	, testing loss - 0.71506	
300	 steps: training loss - 0.63400	, testing loss - 0.71469	
301	 steps: training loss - 0.63771	, testing loss - 0.71424	
302	 steps: training loss - 0.60706	, testing loss - 0.71383	
303	 steps: training loss - 0.67403	, testing loss - 0.71346	
304	 steps: training loss - 0.60744	, testing loss - 0.71307	
305	 steps: training loss - 0.60192	, testing loss - 0.71279	
306	 steps: training loss - 0.61439	, testing loss - 0.71257	
307	 steps: training loss - 0.60983	, testing loss - 0.71240	
308	 steps: training loss - 0.59029	, testing loss - 0.71231	
309	 steps: training loss - 0.58531	, testing loss - 0.71225	
310	 steps: training loss - 0.64083	, testing loss - 0.71217	
311	 steps: training loss - 0.62765	, testing loss - 0.71205	
312	 steps: training loss - 0.59924	, testing loss - 0.71198	
313	 steps: training loss - 0.58623	, testing loss - 0.71195	
314	 steps: training loss - 0.61088	, testing loss - 0.71196	
315	 steps: training loss - 0.58667	, testing loss - 0.71205	
316	 steps: training loss - 0.57033	, testing loss - 0.71218	
317	 steps: training loss - 0.59306	, testing loss - 0.71240	
318	 steps: training loss - 0.59171	, testing loss - 0.71270	
319	 steps: training loss - 0.60921	, testing loss - 0.71308	
320	 steps: training loss - 0.60661	, testing loss - 0.71347	
321	 steps: training loss - 0.57502	, testing loss - 0.71380	
322	 steps: training loss - 0.59666	, testing loss - 0.71414	
323	 steps: training loss - 0.59534	, testing loss - 0.71442	
324	 steps: training loss - 0.63231	, testing loss - 0.71460	
325	 steps: training loss - 0.58179	, testing loss - 0.71475	
326	 steps: training loss - 0.61102	, testing loss - 0.71497	
327	 steps: training loss - 0.59118	, testing loss - 0.71510	
328	 steps: training loss - 0.57124	, testing loss - 0.71531	
329	 steps: training loss - 0.55019	, testing loss - 0.71560	
330	 steps: training loss - 0.58986	, testing loss - 0.71602	
331	 steps: training loss - 0.62762	, testing loss - 0.71642	
332	 steps: training loss - 0.59134	, testing loss - 0.71684	
333	 steps: training loss - 0.61483	, testing loss - 0.71733	
334	 steps: training loss - 0.61614	, testing loss - 0.71775	
335	 steps: training loss - 0.55890	, testing loss - 0.71806	
336	 steps: training loss - 0.58397	, testing loss - 0.71834	
337	 steps: training loss - 0.58507	, testing loss - 0.71867	
338	 steps: training loss - 0.55289	, testing loss - 0.71904	
339	 steps: training loss - 0.56942	, testing loss - 0.71953	
340	 steps: training loss - 0.65264	, testing loss - 0.72010	
341	 steps: training loss - 0.59596	, testing loss - 0.72039	
342	 steps: training loss - 0.57116	, testing loss - 0.72060	
343	 steps: training loss - 0.57026	, testing loss - 0.72087	
344	 steps: training loss - 0.60101	, testing loss - 0.72114	
345	 steps: training loss - 0.62712	, testing loss - 0.72139	
346	 steps: training loss - 0.57413	, testing loss - 0.72153	
347	 steps: training loss - 0.63467	, testing loss - 0.72154	
348	 steps: training loss - 0.54405	, testing loss - 0.72139	
349	 steps: training loss - 0.61229	, testing loss - 0.72131	
350	 steps: training loss - 0.58913	, testing loss - 0.72125	
351	 steps: training loss - 0.55375	, testing loss - 0.72115	
352	 steps: training loss - 0.58396	, testing loss - 0.72116	
353	 steps: training loss - 0.63869	, testing loss - 0.72130	
354	 steps: training loss - 0.57829	, testing loss - 0.72147	
355	 steps: training loss - 0.60805	, testing loss - 0.72171	
356	 steps: training loss - 0.64396	, testing loss - 0.72198	
357	 steps: training loss - 0.57462	, testing loss - 0.72206	
358	 steps: training loss - 0.62027	, testing loss - 0.72208	
359	 steps: training loss - 0.61441	, testing loss - 0.72196	
360	 steps: training loss - 0.65383	, testing loss - 0.72184	
361	 steps: training loss - 0.59507	, testing loss - 0.72156	
362	 steps: training loss - 0.57132	, testing loss - 0.72125	
363	 steps: training loss - 0.61219	, testing loss - 0.72100	
364	 steps: training loss - 0.64475	, testing loss - 0.72083	
365	 steps: training loss - 0.63205	, testing loss - 0.72061	
366	 steps: training loss - 0.56750	, testing loss - 0.72026	
367	 steps: training loss - 0.56865	, testing loss - 0.72001	
368	 steps: training loss - 0.53010	, testing loss - 0.71994	
369	 steps: training loss - 0.55141	, testing loss - 0.72000	
370	 steps: training loss - 0.56456	, testing loss - 0.72020	
371	 steps: training loss - 0.58041	, testing loss - 0.72047	
372	 steps: training loss - 0.58329	, testing loss - 0.72074	
373	 steps: training loss - 0.55284	, testing loss - 0.72104	
374	 steps: training loss - 0.54029	, testing loss - 0.72140	
375	 steps: training loss - 0.53463	, testing loss - 0.72193	
376	 steps: training loss - 0.59654	, testing loss - 0.72249	
377	 steps: training loss - 0.57784	, testing loss - 0.72305	
378	 steps: training loss - 0.53921	, testing loss - 0.72356	
379	 steps: training loss - 0.56713	, testing loss - 0.72410	
380	 steps: training loss - 0.60045	, testing loss - 0.72464	
381	 steps: training loss - 0.55126	, testing loss - 0.72497	
382	 steps: training loss - 0.56432	, testing loss - 0.72524	
383	 steps: training loss - 0.57079	, testing loss - 0.72547	
384	 steps: training loss - 0.60822	, testing loss - 0.72561	
385	 steps: training loss - 0.51905	, testing loss - 0.72562	
386	 steps: training loss - 0.57832	, testing loss - 0.72570	
387	 steps: training loss - 0.60628	, testing loss - 0.72583	
388	 steps: training loss - 0.61435	, testing loss - 0.72588	
389	 steps: training loss - 0.56189	, testing loss - 0.72583	
390	 steps: training loss - 0.55889	, testing loss - 0.72597	
391	 steps: training loss - 0.58861	, testing loss - 0.72623	
392	 steps: training loss - 0.58307	, testing loss - 0.72641	
393	 steps: training loss - 0.61262	, testing loss - 0.72647	
394	 steps: training loss - 0.59224	, testing loss - 0.72644	
395	 steps: training loss - 0.56735	, testing loss - 0.72643	
396	 steps: training loss - 0.58217	, testing loss - 0.72654	
397	 steps: training loss - 0.59391	, testing loss - 0.72668	
398	 steps: training loss - 0.56503	, testing loss - 0.72679	
399	 steps: training loss - 0.60052	, testing loss - 0.72681	
400	 steps: training loss - 0.60727	, testing loss - 0.72669	
401	 steps: training loss - 0.61544	, testing loss - 0.72654	
402	 steps: training loss - 0.56810	, testing loss - 0.72646	
403	 steps: training loss - 0.55507	, testing loss - 0.72647	
404	 steps: training loss - 0.58733	, testing loss - 0.72667	
405	 steps: training loss - 0.56344	, testing loss - 0.72684	
406	 steps: training loss - 0.55562	, testing loss - 0.72703	
407	 steps: training loss - 0.63385	, testing loss - 0.72730	
408	 steps: training loss - 0.58483	, testing loss - 0.72735	
409	 steps: training loss - 0.50168	, testing loss - 0.72733	
410	 steps: training loss - 0.58572	, testing loss - 0.72748	
411	 steps: training loss - 0.55174	, testing loss - 0.72763	
412	 steps: training loss - 0.58643	, testing loss - 0.72782	
413	 steps: training loss - 0.58482	, testing loss - 0.72802	
414	 steps: training loss - 0.58350	, testing loss - 0.72833	
415	 steps: training loss - 0.57762	, testing loss - 0.72856	
416	 steps: training loss - 0.56138	, testing loss - 0.72883	
417	 steps: training loss - 0.57145	, testing loss - 0.72913	
418	 steps: training loss - 0.58999	, testing loss - 0.72943	
419	 steps: training loss - 0.55403	, testing loss - 0.72967	
420	 steps: training loss - 0.55767	, testing loss - 0.72991	
421	 steps: training loss - 0.55346	, testing loss - 0.73026	
422	 steps: training loss - 0.54366	, testing loss - 0.73056	
423	 steps: training loss - 0.59293	, testing loss - 0.73085	
424	 steps: training loss - 0.57574	, testing loss - 0.73107	
425	 steps: training loss - 0.57004	, testing loss - 0.73124	
426	 steps: training loss - 0.55030	, testing loss - 0.73148	
427	 steps: training loss - 0.59336	, testing loss - 0.73190	
428	 steps: training loss - 0.53577	, testing loss - 0.73236	
429	 steps: training loss - 0.57383	, testing loss - 0.73291	
430	 steps: training loss - 0.57185	, testing loss - 0.73344	
431	 steps: training loss - 0.62315	, testing loss - 0.73394	
432	 steps: training loss - 0.48526	, testing loss - 0.73427	
433	 steps: training loss - 0.56859	, testing loss - 0.73479	
434	 steps: training loss - 0.54897	, testing loss - 0.73530	
435	 steps: training loss - 0.56321	, testing loss - 0.73573	
436	 steps: training loss - 0.55140	, testing loss - 0.73607	
437	 steps: training loss - 0.53762	, testing loss - 0.73648	
438	 steps: training loss - 0.59675	, testing loss - 0.73692	
439	 steps: training loss - 0.54881	, testing loss - 0.73733	
440	 steps: training loss - 0.52562	, testing loss - 0.73756	
441	 steps: training loss - 0.54999	, testing loss - 0.73783	
442	 steps: training loss - 0.63518	, testing loss - 0.73822	
443	 steps: training loss - 0.61309	, testing loss - 0.73849	
444	 steps: training loss - 0.54164	, testing loss - 0.73862	
445	 steps: training loss - 0.57478	, testing loss - 0.73888	
446	 steps: training loss - 0.54598	, testing loss - 0.73921	
447	 steps: training loss - 0.59086	, testing loss - 0.73959	
448	 steps: training loss - 0.58033	, testing loss - 0.74006	
449	 steps: training loss - 0.56895	, testing loss - 0.74045	
450	 steps: training loss - 0.49963	, testing loss - 0.74074	
451	 steps: training loss - 0.57158	, testing loss - 0.74116	
452	 steps: training loss - 0.60208	, testing loss - 0.74163	
453	 steps: training loss - 0.54374	, testing loss - 0.74198	
454	 steps: training loss - 0.60142	, testing loss - 0.74232	
455	 steps: training loss - 0.57730	, testing loss - 0.74255	
456	 steps: training loss - 0.50342	, testing loss - 0.74275	
457	 steps: training loss - 0.52883	, testing loss - 0.74298	
458	 steps: training loss - 0.54192	, testing loss - 0.74323	
459	 steps: training loss - 0.58441	, testing loss - 0.74352	
460	 steps: training loss - 0.52676	, testing loss - 0.74371	
461	 steps: training loss - 0.60672	, testing loss - 0.74386	
462	 steps: training loss - 0.61600	, testing loss - 0.74375	
463	 steps: training loss - 0.51348	, testing loss - 0.74335	
464	 steps: training loss - 0.56345	, testing loss - 0.74305	
465	 steps: training loss - 0.50814	, testing loss - 0.74299	
466	 steps: training loss - 0.56519	, testing loss - 0.74309	
467	 steps: training loss - 0.57038	, testing loss - 0.74321	
468	 steps: training loss - 0.59051	, testing loss - 0.74333	
469	 steps: training loss - 0.56704	, testing loss - 0.74340	
470	 steps: training loss - 0.62167	, testing loss - 0.74322	
471	 steps: training loss - 0.58644	, testing loss - 0.74285	
472	 steps: training loss - 0.56705	, testing loss - 0.74251	
473	 steps: training loss - 0.54377	, testing loss - 0.74226	
474	 steps: training loss - 0.53597	, testing loss - 0.74225	
475	 steps: training loss - 0.57220	, testing loss - 0.74250	
476	 steps: training loss - 0.50592	, testing loss - 0.74274	
477	 steps: training loss - 0.56931	, testing loss - 0.74320	
478	 steps: training loss - 0.67329	, testing loss - 0.74364	
479	 steps: training loss - 0.54751	, testing loss - 0.74357	
480	 steps: training loss - 0.55465	, testing loss - 0.74345	
481	 steps: training loss - 0.55714	, testing loss - 0.74347	
482	 steps: training loss - 0.55417	, testing loss - 0.74354	
483	 steps: training loss - 0.51748	, testing loss - 0.74365	
484	 steps: training loss - 0.57266	, testing loss - 0.74378	
485	 steps: training loss - 0.57629	, testing loss - 0.74383	
486	 steps: training loss - 0.59450	, testing loss - 0.74390	
487	 steps: training loss - 0.53982	, testing loss - 0.74389	
488	 steps: training loss - 0.62651	, testing loss - 0.74401	
489	 steps: training loss - 0.56942	, testing loss - 0.74400	
490	 steps: training loss - 0.51550	, testing loss - 0.74384	
491	 steps: training loss - 0.59083	, testing loss - 0.74389	
492	 steps: training loss - 0.57847	, testing loss - 0.74394	
493	 steps: training loss - 0.57295	, testing loss - 0.74391	
494	 steps: training loss - 0.57036	, testing loss - 0.74389	
495	 steps: training loss - 0.52021	, testing loss - 0.74380	
496	 steps: training loss - 0.65715	, testing loss - 0.74389	
497	 steps: training loss - 0.59612	, testing loss - 0.74361	
498	 steps: training loss - 0.47382	, testing loss - 0.74330	
499	 steps: training loss - 0.54652	, testing loss - 0.74327	
500	 steps: training loss - 0.57290	, testing loss - 0.74342	
501	 steps: training loss - 0.58865	, testing loss - 0.74356	
502	 steps: training loss - 0.53283	, testing loss - 0.74359	
503	 steps: training loss - 0.54779	, testing loss - 0.74360	
504	 steps: training loss - 0.54950	, testing loss - 0.74359	
505	 steps: training loss - 0.56567	, testing loss - 0.74361	
506	 steps: training loss - 0.51062	, testing loss - 0.74365	
507	 steps: training loss - 0.58961	, testing loss - 0.74375	
508	 steps: training loss - 0.52756	, testing loss - 0.74373	
509	 steps: training loss - 0.57053	, testing loss - 0.74371	
510	 steps: training loss - 0.54953	, testing loss - 0.74364	
511	 steps: training loss - 0.53782	, testing loss - 0.74353	
512	 steps: training loss - 0.54432	, testing loss - 0.74352	
513	 steps: training loss - 0.54862	, testing loss - 0.74370	
514	 steps: training loss - 0.55811	, testing loss - 0.74395	
515	 steps: training loss - 0.57191	, testing loss - 0.74426	
516	 steps: training loss - 0.55359	, testing loss - 0.74466	
517	 steps: training loss - 0.60903	, testing loss - 0.74502	
518	 steps: training loss - 0.61145	, testing loss - 0.74529	
519	 steps: training loss - 0.59560	, testing loss - 0.74539	
520	 steps: training loss - 0.57823	, testing loss - 0.74540	
521	 steps: training loss - 0.53702	, testing loss - 0.74554	
522	 steps: training loss - 0.55297	, testing loss - 0.74572	
523	 steps: training loss - 0.59220	, testing loss - 0.74608	
524	 steps: training loss - 0.55130	, testing loss - 0.74647	
525	 steps: training loss - 0.53658	, testing loss - 0.74686	
526	 steps: training loss - 0.62405	, testing loss - 0.74723	
527	 steps: training loss - 0.56072	, testing loss - 0.74752	
528	 steps: training loss - 0.55756	, testing loss - 0.74781	
529	 steps: training loss - 0.59270	, testing loss - 0.74828	
530	 steps: training loss - 0.56131	, testing loss - 0.74876	
531	 steps: training loss - 0.53921	, testing loss - 0.74926	
532	 steps: training loss - 0.55903	, testing loss - 0.74975	
533	 steps: training loss - 0.53465	, testing loss - 0.75031	
534	 steps: training loss - 0.54546	, testing loss - 0.75104	
535	 steps: training loss - 0.56534	, testing loss - 0.75180	
536	 steps: training loss - 0.53667	, testing loss - 0.75236	
537	 steps: training loss - 0.49803	, testing loss - 0.75277	
538	 steps: training loss - 0.53843	, testing loss - 0.75318	
539	 steps: training loss - 0.47056	, testing loss - 0.75376	
540	 steps: training loss - 0.61420	, testing loss - 0.75452	
541	 steps: training loss - 0.49289	, testing loss - 0.75524	
542	 steps: training loss - 0.59336	, testing loss - 0.75602	
543	 steps: training loss - 0.54458	, testing loss - 0.75639	
544	 steps: training loss - 0.65199	, testing loss - 0.75658	
545	 steps: training loss - 0.52745	, testing loss - 0.75662	
546	 steps: training loss - 0.53140	, testing loss - 0.75673	
547	 steps: training loss - 0.52801	, testing loss - 0.75662	
548	 steps: training loss - 0.46412	, testing loss - 0.75646	
549	 steps: training loss - 0.53193	, testing loss - 0.75671	
550	 steps: training loss - 0.52233	, testing loss - 0.75706	
551	 steps: training loss - 0.51716	, testing loss - 0.75755	
552	 steps: training loss - 0.57225	, testing loss - 0.75813	
553	 steps: training loss - 0.59253	, testing loss - 0.75867	
554	 steps: training loss - 0.57337	, testing loss - 0.75893	
555	 steps: training loss - 0.56730	, testing loss - 0.75895	
556	 steps: training loss - 0.51980	, testing loss - 0.75874	
557	 steps: training loss - 0.52670	, testing loss - 0.75852	
558	 steps: training loss - 0.53979	, testing loss - 0.75843	
559	 steps: training loss - 0.63703	, testing loss - 0.75842	
560	 steps: training loss - 0.49129	, testing loss - 0.75819	
561	 steps: training loss - 0.55288	, testing loss - 0.75805	
562	 steps: training loss - 0.52567	, testing loss - 0.75782	
563	 steps: training loss - 0.47522	, testing loss - 0.75751	
564	 steps: training loss - 0.52573	, testing loss - 0.75755	
565	 steps: training loss - 0.61160	, testing loss - 0.75774	
566	 steps: training loss - 0.61074	, testing loss - 0.75773	
567	 steps: training loss - 0.45856	, testing loss - 0.75765	
568	 steps: training loss - 0.63993	, testing loss - 0.75779	
569	 steps: training loss - 0.56086	, testing loss - 0.75778	
570	 steps: training loss - 0.54650	, testing loss - 0.75767	
571	 steps: training loss - 0.56884	, testing loss - 0.75759	
572	 steps: training loss - 0.55227	, testing loss - 0.75735	
573	 steps: training loss - 0.59385	, testing loss - 0.75720	
574	 steps: training loss - 0.50953	, testing loss - 0.75707	
575	 steps: training loss - 0.52064	, testing loss - 0.75695	
576	 steps: training loss - 0.56131	, testing loss - 0.75701	
577	 steps: training loss - 0.58890	, testing loss - 0.75710	
578	 steps: training loss - 0.56071	, testing loss - 0.75707	
579	 steps: training loss - 0.57942	, testing loss - 0.75690	
580	 steps: training loss - 0.56864	, testing loss - 0.75662	
581	 steps: training loss - 0.52660	, testing loss - 0.75634	
582	 steps: training loss - 0.57506	, testing loss - 0.75603	
583	 steps: training loss - 0.60414	, testing loss - 0.75587	
584	 steps: training loss - 0.52029	, testing loss - 0.75571	
585	 steps: training loss - 0.52073	, testing loss - 0.75563	
586	 steps: training loss - 0.55740	, testing loss - 0.75567	
587	 steps: training loss - 0.53548	, testing loss - 0.75568	
588	 steps: training loss - 0.51672	, testing loss - 0.75571	
589	 steps: training loss - 0.62951	, testing loss - 0.75604	
590	 steps: training loss - 0.53029	, testing loss - 0.75637	
591	 steps: training loss - 0.55155	, testing loss - 0.75666	
592	 steps: training loss - 0.48334	, testing loss - 0.75694	
593	 steps: training loss - 0.53295	, testing loss - 0.75722	
594	 steps: training loss - 0.53936	, testing loss - 0.75754	
595	 steps: training loss - 0.56602	, testing loss - 0.75766	
596	 steps: training loss - 0.52868	, testing loss - 0.75775	
597	 steps: training loss - 0.56386	, testing loss - 0.75780	
598	 steps: training loss - 0.61202	, testing loss - 0.75775	
599	 steps: training loss - 0.53118	, testing loss - 0.75731	
600	 steps: training loss - 0.52792	, testing loss - 0.75685	
601	 steps: training loss - 0.51023	, testing loss - 0.75660	
602	 steps: training loss - 0.49785	, testing loss - 0.75665	
603	 steps: training loss - 0.55809	, testing loss - 0.75694	
604	 steps: training loss - 0.56909	, testing loss - 0.75725	
605	 steps: training loss - 0.58516	, testing loss - 0.75752	
606	 steps: training loss - 0.54083	, testing loss - 0.75782	
607	 steps: training loss - 0.56111	, testing loss - 0.75827	
608	 steps: training loss - 0.54553	, testing loss - 0.75865	
609	 steps: training loss - 0.61507	, testing loss - 0.75887	
610	 steps: training loss - 0.61942	, testing loss - 0.75913	
611	 steps: training loss - 0.53293	, testing loss - 0.75931	
612	 steps: training loss - 0.50479	, testing loss - 0.75939	
613	 steps: training loss - 0.47285	, testing loss - 0.75942	
614	 steps: training loss - 0.56984	, testing loss - 0.75957	
615	 steps: training loss - 0.50429	, testing loss - 0.75956	
616	 steps: training loss - 0.53793	, testing loss - 0.75948	
617	 steps: training loss - 0.55869	, testing loss - 0.75947	
618	 steps: training loss - 0.59027	, testing loss - 0.75938	
619	 steps: training loss - 0.61828	, testing loss - 0.75935	
620	 steps: training loss - 0.49411	, testing loss - 0.75927	
621	 steps: training loss - 0.52442	, testing loss - 0.75937	
622	 steps: training loss - 0.55568	, testing loss - 0.75974	
623	 steps: training loss - 0.59872	, testing loss - 0.76006	
624	 steps: training loss - 0.54050	, testing loss - 0.76029	
625	 steps: training loss - 0.53565	, testing loss - 0.76041	
626	 steps: training loss - 0.58012	, testing loss - 0.76039	
627	 steps: training loss - 0.57413	, testing loss - 0.76030	
628	 steps: training loss - 0.52287	, testing loss - 0.76015	
629	 steps: training loss - 0.52100	, testing loss - 0.75994	
630	 steps: training loss - 0.53801	, testing loss - 0.75978	
631	 steps: training loss - 0.57578	, testing loss - 0.75970	
632	 steps: training loss - 0.56161	, testing loss - 0.75962	
633	 steps: training loss - 0.60722	, testing loss - 0.75960	
634	 steps: training loss - 0.58485	, testing loss - 0.75948	
635	 steps: training loss - 0.49468	, testing loss - 0.75938	
636	 steps: training loss - 0.58273	, testing loss - 0.75936	
637	 steps: training loss - 0.52709	, testing loss - 0.75949	
638	 steps: training loss - 0.52371	, testing loss - 0.75967	
639	 steps: training loss - 0.54813	, testing loss - 0.75995	
640	 steps: training loss - 0.53999	, testing loss - 0.76027	
641	 steps: training loss - 0.51451	, testing loss - 0.76070	
642	 steps: training loss - 0.52503	, testing loss - 0.76114	
643	 steps: training loss - 0.49558	, testing loss - 0.76143	
644	 steps: training loss - 0.48435	, testing loss - 0.76176	
645	 steps: training loss - 0.52038	, testing loss - 0.76222	
646	 steps: training loss - 0.54563	, testing loss - 0.76276	
647	 steps: training loss - 0.58392	, testing loss - 0.76342	
648	 steps: training loss - 0.54995	, testing loss - 0.76397	
649	 steps: training loss - 0.52906	, testing loss - 0.76441	
650	 steps: training loss - 0.54740	, testing loss - 0.76481	
651	 steps: training loss - 0.55346	, testing loss - 0.76530	
652	 steps: training loss - 0.47525	, testing loss - 0.76581	
653	 steps: training loss - 0.48756	, testing loss - 0.76651	
654	 steps: training loss - 0.63202	, testing loss - 0.76739	
655	 steps: training loss - 0.52548	, testing loss - 0.76813	
656	 steps: training loss - 0.48977	, testing loss - 0.76887	
657	 steps: training loss - 0.56760	, testing loss - 0.76965	
658	 steps: training loss - 0.56536	, testing loss - 0.77029	
659	 steps: training loss - 0.53214	, testing loss - 0.77072	
660	 steps: training loss - 0.55836	, testing loss - 0.77099	
661	 steps: training loss - 0.52860	, testing loss - 0.77124	
662	 steps: training loss - 0.52679	, testing loss - 0.77150	
663	 steps: training loss - 0.50415	, testing loss - 0.77197	
664	 steps: training loss - 0.53978	, testing loss - 0.77239	
665	 steps: training loss - 0.52737	, testing loss - 0.77282	
666	 steps: training loss - 0.54823	, testing loss - 0.77309	
667	 steps: training loss - 0.52573	, testing loss - 0.77334	
668	 steps: training loss - 0.60930	, testing loss - 0.77357	
669	 steps: training loss - 0.59564	, testing loss - 0.77362	
670	 steps: training loss - 0.52619	, testing loss - 0.77340	
671	 steps: training loss - 0.55408	, testing loss - 0.77315	
672	 steps: training loss - 0.56158	, testing loss - 0.77287	
673	 steps: training loss - 0.51450	, testing loss - 0.77264	
674	 steps: training loss - 0.56549	, testing loss - 0.77246	
675	 steps: training loss - 0.58490	, testing loss - 0.77234	
676	 steps: training loss - 0.54839	, testing loss - 0.77208	
677	 steps: training loss - 0.55289	, testing loss - 0.77200	
678	 steps: training loss - 0.57327	, testing loss - 0.77195	
679	 steps: training loss - 0.51812	, testing loss - 0.77198	
680	 steps: training loss - 0.51806	, testing loss - 0.77192	
681	 steps: training loss - 0.54317	, testing loss - 0.77200	
682	 steps: training loss - 0.50384	, testing loss - 0.77225	
683	 steps: training loss - 0.53893	, testing loss - 0.77266	
684	 steps: training loss - 0.53735	, testing loss - 0.77299	
685	 steps: training loss - 0.46107	, testing loss - 0.77324	
686	 steps: training loss - 0.49331	, testing loss - 0.77370	
687	 steps: training loss - 0.52359	, testing loss - 0.77418	
688	 steps: training loss - 0.56247	, testing loss - 0.77472	
689	 steps: training loss - 0.54464	, testing loss - 0.77536	
690	 steps: training loss - 0.51215	, testing loss - 0.77594	
691	 steps: training loss - 0.49163	, testing loss - 0.77632	
692	 steps: training loss - 0.51339	, testing loss - 0.77689	
693	 steps: training loss - 0.54200	, testing loss - 0.77768	
694	 steps: training loss - 0.48349	, testing loss - 0.77843	
695	 steps: training loss - 0.58680	, testing loss - 0.77935	
696	 steps: training loss - 0.51323	, testing loss - 0.77998	
697	 steps: training loss - 0.48233	, testing loss - 0.78044	
698	 steps: training loss - 0.49792	, testing loss - 0.78105	
699	 steps: training loss - 0.51154	, testing loss - 0.78151	
700	 steps: training loss - 0.50216	, testing loss - 0.78195	
701	 steps: training loss - 0.51105	, testing loss - 0.78242	
702	 steps: training loss - 0.51028	, testing loss - 0.78293	
703	 steps: training loss - 0.51888	, testing loss - 0.78353	
704	 steps: training loss - 0.48560	, testing loss - 0.78413	
705	 steps: training loss - 0.48571	, testing loss - 0.78477	
706	 steps: training loss - 0.46520	, testing loss - 0.78540	
707	 steps: training loss - 0.49672	, testing loss - 0.78607	
708	 steps: training loss - 0.50786	, testing loss - 0.78679	
709	 steps: training loss - 0.45821	, testing loss - 0.78735	
710	 steps: training loss - 0.50607	, testing loss - 0.78781	
711	 steps: training loss - 0.53579	, testing loss - 0.78841	
712	 steps: training loss - 0.50722	, testing loss - 0.78893	
713	 steps: training loss - 0.44933	, testing loss - 0.78921	
714	 steps: training loss - 0.47291	, testing loss - 0.78966	
715	 steps: training loss - 0.50187	, testing loss - 0.79035	
716	 steps: training loss - 0.47420	, testing loss - 0.79077	
717	 steps: training loss - 0.60131	, testing loss - 0.79119	
718	 steps: training loss - 0.56830	, testing loss - 0.79136	
719	 steps: training loss - 0.40877	, testing loss - 0.79140	
720	 steps: training loss - 0.51260	, testing loss - 0.79180	
721	 steps: training loss - 0.47529	, testing loss - 0.79229	
722	 steps: training loss - 0.45553	, testing loss - 0.79278	
723	 steps: training loss - 0.50166	, testing loss - 0.79365	
724	 steps: training loss - 0.57523	, testing loss - 0.79453	
725	 steps: training loss - 0.61325	, testing loss - 0.79489	
726	 steps: training loss - 0.46624	, testing loss - 0.79474	
727	 steps: training loss - 0.51088	, testing loss - 0.79440	
728	 steps: training loss - 0.56972	, testing loss - 0.79415	
729	 steps: training loss - 0.47725	, testing loss - 0.79370	
730	 steps: training loss - 0.51625	, testing loss - 0.79342	
731	 steps: training loss - 0.58983	, testing loss - 0.79329	
732	 steps: training loss - 0.46315	, testing loss - 0.79303	
733	 steps: training loss - 0.53331	, testing loss - 0.79305	
734	 steps: training loss - 0.47090	, testing loss - 0.79317	
735	 steps: training loss - 0.53091	, testing loss - 0.79336	
736	 steps: training loss - 0.50057	, testing loss - 0.79359	
737	 steps: training loss - 0.53488	, testing loss - 0.79372	
738	 steps: training loss - 0.52413	, testing loss - 0.79372	
739	 steps: training loss - 0.44167	, testing loss - 0.79378	
740	 steps: training loss - 0.54580	, testing loss - 0.79417	
741	 steps: training loss - 0.59535	, testing loss - 0.79470	
742	 steps: training loss - 0.51151	, testing loss - 0.79482	
743	 steps: training loss - 0.58121	, testing loss - 0.79491	
744	 steps: training loss - 0.52012	, testing loss - 0.79489	
745	 steps: training loss - 0.51309	, testing loss - 0.79491	
746	 steps: training loss - 0.61144	, testing loss - 0.79499	
747	 steps: training loss - 0.42005	, testing loss - 0.79487	
748	 steps: training loss - 0.57705	, testing loss - 0.79484	
749	 steps: training loss - 0.53812	, testing loss - 0.79466	
750	 steps: training loss - 0.48429	, testing loss - 0.79452	
751	 steps: training loss - 0.48030	, testing loss - 0.79458	
752	 steps: training loss - 0.47663	, testing loss - 0.79456	
753	 steps: training loss - 0.45766	, testing loss - 0.79465	
754	 steps: training loss - 0.45326	, testing loss - 0.79499	
755	 steps: training loss - 0.55185	, testing loss - 0.79528	
756	 steps: training loss - 0.53715	, testing loss - 0.79549	
757	 steps: training loss - 0.52178	, testing loss - 0.79549	
758	 steps: training loss - 0.50355	, testing loss - 0.79551	
759	 steps: training loss - 0.52072	, testing loss - 0.79550	
760	 steps: training loss - 0.55075	, testing loss - 0.79549	
761	 steps: training loss - 0.52757	, testing loss - 0.79528	
762	 steps: training loss - 0.49716	, testing loss - 0.79494	
763	 steps: training loss - 0.50743	, testing loss - 0.79453	
764	 steps: training loss - 0.58692	, testing loss - 0.79441	
765	 steps: training loss - 0.50221	, testing loss - 0.79399	
766	 steps: training loss - 0.52392	, testing loss - 0.79340	
767	 steps: training loss - 0.50904	, testing loss - 0.79284	
768	 steps: training loss - 0.51975	, testing loss - 0.79263	
769	 steps: training loss - 0.54721	, testing loss - 0.79259	
770	 steps: training loss - 0.51856	, testing loss - 0.79244	
771	 steps: training loss - 0.51445	, testing loss - 0.79216	
772	 steps: training loss - 0.51922	, testing loss - 0.79190	
773	 steps: training loss - 0.49970	, testing loss - 0.79176	
774	 steps: training loss - 0.48938	, testing loss - 0.79184	
775	 steps: training loss - 0.51104	, testing loss - 0.79202	
776	 steps: training loss - 0.63851	, testing loss - 0.79220	
777	 steps: training loss - 0.49609	, testing loss - 0.79199	
778	 steps: training loss - 0.48435	, testing loss - 0.79168	
779	 steps: training loss - 0.48769	, testing loss - 0.79135	
780	 steps: training loss - 0.51414	, testing loss - 0.79136	
781	 steps: training loss - 0.50192	, testing loss - 0.79144	
782	 steps: training loss - 0.49631	, testing loss - 0.79153	
783	 steps: training loss - 0.46172	, testing loss - 0.79149	
784	 steps: training loss - 0.52324	, testing loss - 0.79135	
785	 steps: training loss - 0.57191	, testing loss - 0.79126	
786	 steps: training loss - 0.56559	, testing loss - 0.79086	
787	 steps: training loss - 0.50234	, testing loss - 0.79042	
788	 steps: training loss - 0.49624	, testing loss - 0.79014	
789	 steps: training loss - 0.52274	, testing loss - 0.79018	
790	 steps: training loss - 0.52906	, testing loss - 0.79033	
791	 steps: training loss - 0.49022	, testing loss - 0.79054	
792	 steps: training loss - 0.50358	, testing loss - 0.79078	
793	 steps: training loss - 0.52262	, testing loss - 0.79121	
794	 steps: training loss - 0.54690	, testing loss - 0.79167	
795	 steps: training loss - 0.49931	, testing loss - 0.79201	
796	 steps: training loss - 0.51699	, testing loss - 0.79235	
797	 steps: training loss - 0.47577	, testing loss - 0.79260	
798	 steps: training loss - 0.46187	, testing loss - 0.79306	
799	 steps: training loss - 0.54072	, testing loss - 0.79353	
800	 steps: training loss - 0.52308	, testing loss - 0.79392	
801	 steps: training loss - 0.46032	, testing loss - 0.79428	
802	 steps: training loss - 0.49038	, testing loss - 0.79474	
803	 steps: training loss - 0.49999	, testing loss - 0.79537	
804	 steps: training loss - 0.49515	, testing loss - 0.79601	
805	 steps: training loss - 0.50790	, testing loss - 0.79669	
806	 steps: training loss - 0.53076	, testing loss - 0.79748	
807	 steps: training loss - 0.54736	, testing loss - 0.79796	
808	 steps: training loss - 0.49643	, testing loss - 0.79820	
809	 steps: training loss - 0.51356	, testing loss - 0.79831	
810	 steps: training loss - 0.47782	, testing loss - 0.79848	
811	 steps: training loss - 0.46600	, testing loss - 0.79874	
812	 steps: training loss - 0.50823	, testing loss - 0.79913	
813	 steps: training loss - 0.49405	, testing loss - 0.79933	
814	 steps: training loss - 0.51517	, testing loss - 0.79939	
815	 steps: training loss - 0.48083	, testing loss - 0.79923	
816	 steps: training loss - 0.50644	, testing loss - 0.79903	
817	 steps: training loss - 0.46418	, testing loss - 0.79876	
818	 steps: training loss - 0.47937	, testing loss - 0.79865	
819	 steps: training loss - 0.53331	, testing loss - 0.79858	
820	 steps: training loss - 0.46445	, testing loss - 0.79873	
821	 steps: training loss - 0.52456	, testing loss - 0.79916	
822	 steps: training loss - 0.56537	, testing loss - 0.79934	
823	 steps: training loss - 0.45789	, testing loss - 0.79944	
824	 steps: training loss - 0.48180	, testing loss - 0.79975	
825	 steps: training loss - 0.42863	, testing loss - 0.80008	
826	 steps: training loss - 0.53343	, testing loss - 0.80066	
827	 steps: training loss - 0.51452	, testing loss - 0.80117	
828	 steps: training loss - 0.47957	, testing loss - 0.80159	
829	 steps: training loss - 0.44056	, testing loss - 0.80193	
830	 steps: training loss - 0.45504	, testing loss - 0.80230	
831	 steps: training loss - 0.47918	, testing loss - 0.80271	
832	 steps: training loss - 0.52354	, testing loss - 0.80312	
833	 steps: training loss - 0.54418	, testing loss - 0.80353	
834	 steps: training loss - 0.51245	, testing loss - 0.80380	
835	 steps: training loss - 0.42518	, testing loss - 0.80415	
836	 steps: training loss - 0.43209	, testing loss - 0.80481	
837	 steps: training loss - 0.56788	, testing loss - 0.80557	
838	 steps: training loss - 0.50964	, testing loss - 0.80624	
839	 steps: training loss - 0.46801	, testing loss - 0.80685	
840	 steps: training loss - 0.49592	, testing loss - 0.80741	
841	 steps: training loss - 0.45370	, testing loss - 0.80804	
842	 steps: training loss - 0.50013	, testing loss - 0.80859	
843	 steps: training loss - 0.52524	, testing loss - 0.80887	
844	 steps: training loss - 0.57482	, testing loss - 0.80910	
845	 steps: training loss - 0.47969	, testing loss - 0.80899	
846	 steps: training loss - 0.44911	, testing loss - 0.80884	
847	 steps: training loss - 0.53693	, testing loss - 0.80900	
848	 steps: training loss - 0.49699	, testing loss - 0.80927	
849	 steps: training loss - 0.50508	, testing loss - 0.80957	
850	 steps: training loss - 0.46741	, testing loss - 0.80990	
851	 steps: training loss - 0.53118	, testing loss - 0.81051	
852	 steps: training loss - 0.52148	, testing loss - 0.81113	
853	 steps: training loss - 0.51042	, testing loss - 0.81141	
854	 steps: training loss - 0.48769	, testing loss - 0.81159	
855	 steps: training loss - 0.56726	, testing loss - 0.81148	
856	 steps: training loss - 0.51577	, testing loss - 0.81123	
857	 steps: training loss - 0.52319	, testing loss - 0.81098	
858	 steps: training loss - 0.47900	, testing loss - 0.81074	
859	 steps: training loss - 0.55501	, testing loss - 0.81064	
860	 steps: training loss - 0.49260	, testing loss - 0.81050	
861	 steps: training loss - 0.51370	, testing loss - 0.81032	
862	 steps: training loss - 0.41860	, testing loss - 0.81019	
863	 steps: training loss - 0.50226	, testing loss - 0.81031	
864	 steps: training loss - 0.48652	, testing loss - 0.81063	
865	 steps: training loss - 0.43827	, testing loss - 0.81072	
866	 steps: training loss - 0.45034	, testing loss - 0.81075	
867	 steps: training loss - 0.48046	, testing loss - 0.81087	
868	 steps: training loss - 0.49436	, testing loss - 0.81115	
869	 steps: training loss - 0.51638	, testing loss - 0.81139	
870	 steps: training loss - 0.45859	, testing loss - 0.81174	
871	 steps: training loss - 0.56381	, testing loss - 0.81234	
872	 steps: training loss - 0.46792	, testing loss - 0.81263	
873	 steps: training loss - 0.50477	, testing loss - 0.81278	
874	 steps: training loss - 0.40785	, testing loss - 0.81284	
875	 steps: training loss - 0.51760	, testing loss - 0.81316	
876	 steps: training loss - 0.43270	, testing loss - 0.81365	
877	 steps: training loss - 0.46208	, testing loss - 0.81433	
878	 steps: training loss - 0.47882	, testing loss - 0.81513	
879	 steps: training loss - 0.53654	, testing loss - 0.81583	
880	 steps: training loss - 0.53954	, testing loss - 0.81642	
881	 steps: training loss - 0.47005	, testing loss - 0.81649	
882	 steps: training loss - 0.53600	, testing loss - 0.81664	
883	 steps: training loss - 0.46509	, testing loss - 0.81667	
884	 steps: training loss - 0.52971	, testing loss - 0.81655	
885	 steps: training loss - 0.49613	, testing loss - 0.81606	
886	 steps: training loss - 0.48443	, testing loss - 0.81553	
887	 steps: training loss - 0.56603	, testing loss - 0.81494	
888	 steps: training loss - 0.51256	, testing loss - 0.81411	
889	 steps: training loss - 0.50966	, testing loss - 0.81332	
890	 steps: training loss - 0.52332	, testing loss - 0.81268	
891	 steps: training loss - 0.48896	, testing loss - 0.81217	
892	 steps: training loss - 0.46523	, testing loss - 0.81180	
893	 steps: training loss - 0.53747	, testing loss - 0.81153	
894	 steps: training loss - 0.52696	, testing loss - 0.81100	
895	 steps: training loss - 0.46077	, testing loss - 0.81039	
896	 steps: training loss - 0.47652	, testing loss - 0.80995	
897	 steps: training loss - 0.46494	, testing loss - 0.80971	
898	 steps: training loss - 0.51271	, testing loss - 0.80965	
899	 steps: training loss - 0.46814	, testing loss - 0.80977	
900	 steps: training loss - 0.57675	, testing loss - 0.80994	
901	 steps: training loss - 0.49018	, testing loss - 0.81005	
902	 steps: training loss - 0.54859	, testing loss - 0.81029	
903	 steps: training loss - 0.51192	, testing loss - 0.81070	
904	 steps: training loss - 0.47165	, testing loss - 0.81100	
905	 steps: training loss - 0.45583	, testing loss - 0.81126	
906	 steps: training loss - 0.41093	, testing loss - 0.81171	
907	 steps: training loss - 0.49535	, testing loss - 0.81245	
908	 steps: training loss - 0.45947	, testing loss - 0.81307	
909	 steps: training loss - 0.47081	, testing loss - 0.81355	
910	 steps: training loss - 0.46875	, testing loss - 0.81394	
911	 steps: training loss - 0.49948	, testing loss - 0.81425	
912	 steps: training loss - 0.52426	, testing loss - 0.81432	
913	 steps: training loss - 0.54354	, testing loss - 0.81438	
914	 steps: training loss - 0.46226	, testing loss - 0.81447	
915	 steps: training loss - 0.55416	, testing loss - 0.81444	
916	 steps: training loss - 0.52301	, testing loss - 0.81435	
917	 steps: training loss - 0.51647	, testing loss - 0.81431	
918	 steps: training loss - 0.50656	, testing loss - 0.81416	
919	 steps: training loss - 0.50348	, testing loss - 0.81432	
920	 steps: training loss - 0.49315	, testing loss - 0.81447	
921	 steps: training loss - 0.52099	, testing loss - 0.81471	
922	 steps: training loss - 0.40663	, testing loss - 0.81511	
923	 steps: training loss - 0.59070	, testing loss - 0.81574	
924	 steps: training loss - 0.46752	, testing loss - 0.81637	
925	 steps: training loss - 0.48583	, testing loss - 0.81694	
926	 steps: training loss - 0.48573	, testing loss - 0.81750	
927	 steps: training loss - 0.52905	, testing loss - 0.81795	
928	 steps: training loss - 0.48742	, testing loss - 0.81829	
929	 steps: training loss - 0.51202	, testing loss - 0.81843	
930	 steps: training loss - 0.50832	, testing loss - 0.81855	
931	 steps: training loss - 0.47179	, testing loss - 0.81858	
932	 steps: training loss - 0.56604	, testing loss - 0.81851	
933	 steps: training loss - 0.48247	, testing loss - 0.81831	
934	 steps: training loss - 0.46144	, testing loss - 0.81817	
935	 steps: training loss - 0.50174	, testing loss - 0.81801	
936	 steps: training loss - 0.43884	, testing loss - 0.81792	
937	 steps: training loss - 0.42552	, testing loss - 0.81797	
938	 steps: training loss - 0.52592	, testing loss - 0.81823	
939	 steps: training loss - 0.49804	, testing loss - 0.81849	
940	 steps: training loss - 0.47291	, testing loss - 0.81856	
941	 steps: training loss - 0.42727	, testing loss - 0.81881	
942	 steps: training loss - 0.52514	, testing loss - 0.81917	
943	 steps: training loss - 0.52829	, testing loss - 0.81950	
944	 steps: training loss - 0.53043	, testing loss - 0.81996	
945	 steps: training loss - 0.40865	, testing loss - 0.82047	
946	 steps: training loss - 0.49775	, testing loss - 0.82107	
947	 steps: training loss - 0.49051	, testing loss - 0.82164	
948	 steps: training loss - 0.52034	, testing loss - 0.82205	
949	 steps: training loss - 0.48922	, testing loss - 0.82251	
950	 steps: training loss - 0.49070	, testing loss - 0.82299	
951	 steps: training loss - 0.54306	, testing loss - 0.82345	
952	 steps: training loss - 0.49721	, testing loss - 0.82342	
953	 steps: training loss - 0.46184	, testing loss - 0.82324	
954	 steps: training loss - 0.53605	, testing loss - 0.82310	
955	 steps: training loss - 0.48320	, testing loss - 0.82274	
956	 steps: training loss - 0.43765	, testing loss - 0.82236	
957	 steps: training loss - 0.43811	, testing loss - 0.82218	
958	 steps: training loss - 0.43662	, testing loss - 0.82212	
959	 steps: training loss - 0.45623	, testing loss - 0.82211	
960	 steps: training loss - 0.50811	, testing loss - 0.82230	
961	 steps: training loss - 0.49525	, testing loss - 0.82261	
962	 steps: training loss - 0.41959	, testing loss - 0.82281	
963	 steps: training loss - 0.48986	, testing loss - 0.82304	
964	 steps: training loss - 0.43548	, testing loss - 0.82333	
965	 steps: training loss - 0.51746	, testing loss - 0.82355	
966	 steps: training loss - 0.44559	, testing loss - 0.82362	
967	 steps: training loss - 0.45516	, testing loss - 0.82380	
968	 steps: training loss - 0.45203	, testing loss - 0.82422	
969	 steps: training loss - 0.47847	, testing loss - 0.82467	
970	 steps: training loss - 0.43639	, testing loss - 0.82527	
971	 steps: training loss - 0.49751	, testing loss - 0.82605	
972	 steps: training loss - 0.57909	, testing loss - 0.82669	
973	 steps: training loss - 0.53368	, testing loss - 0.82714	
974	 steps: training loss - 0.51946	, testing loss - 0.82752	
975	 steps: training loss - 0.53119	, testing loss - 0.82771	
976	 steps: training loss - 0.59874	, testing loss - 0.82744	
977	 steps: training loss - 0.53344	, testing loss - 0.82689	
978	 steps: training loss - 0.46778	, testing loss - 0.82627	
979	 steps: training loss - 0.53940	, testing loss - 0.82579	
980	 steps: training loss - 0.48668	, testing loss - 0.82557	
981	 steps: training loss - 0.50301	, testing loss - 0.82572	
982	 steps: training loss - 0.46678	, testing loss - 0.82609	
983	 steps: training loss - 0.52155	, testing loss - 0.82643	
984	 steps: training loss - 0.45166	, testing loss - 0.82659	
985	 steps: training loss - 0.49198	, testing loss - 0.82675	
986	 steps: training loss - 0.44932	, testing loss - 0.82692	
987	 steps: training loss - 0.47052	, testing loss - 0.82707	
988	 steps: training loss - 0.52110	, testing loss - 0.82739	
989	 steps: training loss - 0.51219	, testing loss - 0.82727	
990	 steps: training loss - 0.54824	, testing loss - 0.82710	
991	 steps: training loss - 0.52351	, testing loss - 0.82705	
992	 steps: training loss - 0.42619	, testing loss - 0.82701	
993	 steps: training loss - 0.45924	, testing loss - 0.82714	
994	 steps: training loss - 0.45522	, testing loss - 0.82732	
995	 steps: training loss - 0.43964	, testing loss - 0.82757	
996	 steps: training loss - 0.46886	, testing loss - 0.82791	
997	 steps: training loss - 0.54147	, testing loss - 0.82848	
998	 steps: training loss - 0.51538	, testing loss - 0.82906	
999	 steps: training loss - 0.44129	, testing loss - 0.82968	
EVALUATION
----------
Test loss: 0.56104
MIMO Accuracies: 0.99878

LOOCV TRAINING INFO - is_lstm? True
LOOCV? -  True
-------------
TRAINING USERS -  ['a', 'b', 'c', 'g', 'h', 'i']
LEFT OUT -  e
-------------
actions ['bike', 'sit']
devices ['samsungold_1', 'samsungold_2']
step size 10
num_epochs 1000
batch size 12
feature size (x,y,z) 3
hidden size 20
number recurrent layers 2
number of classes 2
writing pickle to run9_model.p
writing accuracy + pickle to acc_run9_model.p
------------------------------------------------
0	 steps: training loss - 0.67485	, testing loss - 0.70516	
1	 steps: training loss - 0.70575	, testing loss - 0.70568	
2	 steps: training loss - 0.71155	, testing loss - 0.70458	
3	 steps: training loss - 0.70031	, testing loss - 0.70302	
4	 steps: training loss - 0.66829	, testing loss - 0.70135	
5	 steps: training loss - 0.67632	, testing loss - 0.69970	
6	 steps: training loss - 0.68444	, testing loss - 0.69813	
7	 steps: training loss - 0.67320	, testing loss - 0.69663	
8	 steps: training loss - 0.65855	, testing loss - 0.69515	
9	 steps: training loss - 0.67001	, testing loss - 0.69367	
10	 steps: training loss - 0.66244	, testing loss - 0.69228	
11	 steps: training loss - 0.65401	, testing loss - 0.69090	
12	 steps: training loss - 0.66728	, testing loss - 0.68952	
13	 steps: training loss - 0.66749	, testing loss - 0.68806	
14	 steps: training loss - 0.67385	, testing loss - 0.68671	
15	 steps: training loss - 0.64969	, testing loss - 0.68551	
16	 steps: training loss - 0.67118	, testing loss - 0.68455	
17	 steps: training loss - 0.65987	, testing loss - 0.68362	
18	 steps: training loss - 0.66106	, testing loss - 0.68260	
19	 steps: training loss - 0.64385	, testing loss - 0.68137	
20	 steps: training loss - 0.66117	, testing loss - 0.68019	
21	 steps: training loss - 0.66196	, testing loss - 0.67916	
22	 steps: training loss - 0.64943	, testing loss - 0.67806	
23	 steps: training loss - 0.65692	, testing loss - 0.67710	
24	 steps: training loss - 0.65398	, testing loss - 0.67614	
25	 steps: training loss - 0.64100	, testing loss - 0.67531	
26	 steps: training loss - 0.66909	, testing loss - 0.67443	
27	 steps: training loss - 0.63878	, testing loss - 0.67356	
28	 steps: training loss - 0.64583	, testing loss - 0.67294	
29	 steps: training loss - 0.63280	, testing loss - 0.67234	
30	 steps: training loss - 0.65719	, testing loss - 0.67146	
31	 steps: training loss - 0.64128	, testing loss - 0.67044	
32	 steps: training loss - 0.63004	, testing loss - 0.66932	
33	 steps: training loss - 0.65734	, testing loss - 0.66810	
34	 steps: training loss - 0.64019	, testing loss - 0.66679	
35	 steps: training loss - 0.65022	, testing loss - 0.66548	
36	 steps: training loss - 0.65281	, testing loss - 0.66427	
37	 steps: training loss - 0.64138	, testing loss - 0.66326	
38	 steps: training loss - 0.65127	, testing loss - 0.66252	
39	 steps: training loss - 0.62422	, testing loss - 0.66172	
40	 steps: training loss - 0.64705	, testing loss - 0.66101	
41	 steps: training loss - 0.61460	, testing loss - 0.66035	
42	 steps: training loss - 0.64357	, testing loss - 0.65964	
43	 steps: training loss - 0.61215	, testing loss - 0.65893	
44	 steps: training loss - 0.60619	, testing loss - 0.65811	
45	 steps: training loss - 0.61450	, testing loss - 0.65728	
46	 steps: training loss - 0.63881	, testing loss - 0.65639	
47	 steps: training loss - 0.61646	, testing loss - 0.65550	
48	 steps: training loss - 0.63939	, testing loss - 0.65449	
49	 steps: training loss - 0.60122	, testing loss - 0.65354	
50	 steps: training loss - 0.61924	, testing loss - 0.65259	
51	 steps: training loss - 0.62230	, testing loss - 0.65155	
52	 steps: training loss - 0.65273	, testing loss - 0.65047	
53	 steps: training loss - 0.62807	, testing loss - 0.64952	
54	 steps: training loss - 0.61208	, testing loss - 0.64859	
55	 steps: training loss - 0.63815	, testing loss - 0.64763	
56	 steps: training loss - 0.58672	, testing loss - 0.64675	
57	 steps: training loss - 0.61653	, testing loss - 0.64585	
58	 steps: training loss - 0.59751	, testing loss - 0.64494	
59	 steps: training loss - 0.58759	, testing loss - 0.64405	
60	 steps: training loss - 0.66098	, testing loss - 0.64308	
61	 steps: training loss - 0.59767	, testing loss - 0.64221	
62	 steps: training loss - 0.66845	, testing loss - 0.64135	
63	 steps: training loss - 0.55796	, testing loss - 0.64066	
64	 steps: training loss - 0.59332	, testing loss - 0.63992	
65	 steps: training loss - 0.52898	, testing loss - 0.63913	
66	 steps: training loss - 0.61883	, testing loss - 0.63819	
67	 steps: training loss - 0.66102	, testing loss - 0.63734	
68	 steps: training loss - 0.57513	, testing loss - 0.63667	
69	 steps: training loss - 0.58880	, testing loss - 0.63597	
70	 steps: training loss - 0.61089	, testing loss - 0.63523	
71	 steps: training loss - 0.60859	, testing loss - 0.63450	
72	 steps: training loss - 0.61930	, testing loss - 0.63376	
73	 steps: training loss - 0.71232	, testing loss - 0.63308	
74	 steps: training loss - 0.59957	, testing loss - 0.63258	
75	 steps: training loss - 0.60418	, testing loss - 0.63214	
76	 steps: training loss - 0.61207	, testing loss - 0.63170	
77	 steps: training loss - 0.62926	, testing loss - 0.63125	
78	 steps: training loss - 0.61961	, testing loss - 0.63084	
79	 steps: training loss - 0.59260	, testing loss - 0.63046	
80	 steps: training loss - 0.64847	, testing loss - 0.63004	
81	 steps: training loss - 0.61602	, testing loss - 0.62969	
82	 steps: training loss - 0.61970	, testing loss - 0.62939	
83	 steps: training loss - 0.57881	, testing loss - 0.62910	
84	 steps: training loss - 0.64922	, testing loss - 0.62870	
85	 steps: training loss - 0.59200	, testing loss - 0.62833	
86	 steps: training loss - 0.63316	, testing loss - 0.62803	
87	 steps: training loss - 0.60606	, testing loss - 0.62774	
88	 steps: training loss - 0.60436	, testing loss - 0.62749	
89	 steps: training loss - 0.62585	, testing loss - 0.62720	
90	 steps: training loss - 0.57334	, testing loss - 0.62694	
91	 steps: training loss - 0.55080	, testing loss - 0.62655	
92	 steps: training loss - 0.61739	, testing loss - 0.62598	
93	 steps: training loss - 0.59563	, testing loss - 0.62545	
94	 steps: training loss - 0.62123	, testing loss - 0.62493	
95	 steps: training loss - 0.56646	, testing loss - 0.62438	
96	 steps: training loss - 0.64785	, testing loss - 0.62368	
97	 steps: training loss - 0.54624	, testing loss - 0.62317	
98	 steps: training loss - 0.61663	, testing loss - 0.62258	
99	 steps: training loss - 0.55636	, testing loss - 0.62199	
100	 steps: training loss - 0.59385	, testing loss - 0.62141	
101	 steps: training loss - 0.56545	, testing loss - 0.62089	
102	 steps: training loss - 0.61360	, testing loss - 0.62025	
103	 steps: training loss - 0.64252	, testing loss - 0.61956	
104	 steps: training loss - 0.56590	, testing loss - 0.61902	
105	 steps: training loss - 0.60148	, testing loss - 0.61843	
106	 steps: training loss - 0.59637	, testing loss - 0.61780	
107	 steps: training loss - 0.55718	, testing loss - 0.61725	
108	 steps: training loss - 0.60620	, testing loss - 0.61665	
109	 steps: training loss - 0.58089	, testing loss - 0.61611	
110	 steps: training loss - 0.57240	, testing loss - 0.61561	
111	 steps: training loss - 0.54006	, testing loss - 0.61511	
112	 steps: training loss - 0.55132	, testing loss - 0.61450	
113	 steps: training loss - 0.59655	, testing loss - 0.61381	
114	 steps: training loss - 0.58635	, testing loss - 0.61321	
115	 steps: training loss - 0.56597	, testing loss - 0.61266	
116	 steps: training loss - 0.61278	, testing loss - 0.61209	
117	 steps: training loss - 0.58093	, testing loss - 0.61160	
118	 steps: training loss - 0.57137	, testing loss - 0.61112	
119	 steps: training loss - 0.58398	, testing loss - 0.61065	
120	 steps: training loss - 0.67686	, testing loss - 0.61017	
121	 steps: training loss - 0.51845	, testing loss - 0.60986	
122	 steps: training loss - 0.59040	, testing loss - 0.60946	
123	 steps: training loss - 0.55227	, testing loss - 0.60900	
124	 steps: training loss - 0.59178	, testing loss - 0.60856	
125	 steps: training loss - 0.56917	, testing loss - 0.60820	
126	 steps: training loss - 0.51663	, testing loss - 0.60788	
127	 steps: training loss - 0.58617	, testing loss - 0.60745	
128	 steps: training loss - 0.63255	, testing loss - 0.60700	
129	 steps: training loss - 0.55564	, testing loss - 0.60660	
130	 steps: training loss - 0.59145	, testing loss - 0.60613	
131	 steps: training loss - 0.55176	, testing loss - 0.60561	
132	 steps: training loss - 0.54813	, testing loss - 0.60511	
133	 steps: training loss - 0.50522	, testing loss - 0.60462	
134	 steps: training loss - 0.57310	, testing loss - 0.60399	
135	 steps: training loss - 0.56693	, testing loss - 0.60333	
136	 steps: training loss - 0.54560	, testing loss - 0.60275	
137	 steps: training loss - 0.58382	, testing loss - 0.60232	
138	 steps: training loss - 0.59259	, testing loss - 0.60193	
139	 steps: training loss - 0.60296	, testing loss - 0.60159	
140	 steps: training loss - 0.53225	, testing loss - 0.60135	
141	 steps: training loss - 0.57873	, testing loss - 0.60101	
142	 steps: training loss - 0.60675	, testing loss - 0.60072	
143	 steps: training loss - 0.57587	, testing loss - 0.60051	
144	 steps: training loss - 0.54772	, testing loss - 0.60029	
145	 steps: training loss - 0.53395	, testing loss - 0.59999	
146	 steps: training loss - 0.62425	, testing loss - 0.59965	
147	 steps: training loss - 0.61325	, testing loss - 0.59938	
148	 steps: training loss - 0.55805	, testing loss - 0.59923	
149	 steps: training loss - 0.62493	, testing loss - 0.59911	
150	 steps: training loss - 0.54910	, testing loss - 0.59908	
151	 steps: training loss - 0.55551	, testing loss - 0.59900	
152	 steps: training loss - 0.59294	, testing loss - 0.59893	
153	 steps: training loss - 0.52210	, testing loss - 0.59906	
154	 steps: training loss - 0.66687	, testing loss - 0.59920	
155	 steps: training loss - 0.57489	, testing loss - 0.59969	
156	 steps: training loss - 0.54113	, testing loss - 0.60015	
157	 steps: training loss - 0.58537	, testing loss - 0.60043	
158	 steps: training loss - 0.61858	, testing loss - 0.60036	
159	 steps: training loss - 0.61813	, testing loss - 0.60032	
160	 steps: training loss - 0.58986	, testing loss - 0.60024	
161	 steps: training loss - 0.55483	, testing loss - 0.60022	
162	 steps: training loss - 0.55070	, testing loss - 0.60001	
163	 steps: training loss - 0.53258	, testing loss - 0.59991	
164	 steps: training loss - 0.61437	, testing loss - 0.59963	
165	 steps: training loss - 0.61673	, testing loss - 0.59935	
166	 steps: training loss - 0.54293	, testing loss - 0.59911	
167	 steps: training loss - 0.50563	, testing loss - 0.59872	
168	 steps: training loss - 0.54331	, testing loss - 0.59815	
169	 steps: training loss - 0.51023	, testing loss - 0.59741	
170	 steps: training loss - 0.52985	, testing loss - 0.59666	
171	 steps: training loss - 0.53948	, testing loss - 0.59581	
172	 steps: training loss - 0.49118	, testing loss - 0.59485	
173	 steps: training loss - 0.55160	, testing loss - 0.59374	
174	 steps: training loss - 0.51048	, testing loss - 0.59262	
175	 steps: training loss - 0.56289	, testing loss - 0.59163	
176	 steps: training loss - 0.53981	, testing loss - 0.59084	
177	 steps: training loss - 0.60675	, testing loss - 0.58997	
178	 steps: training loss - 0.50203	, testing loss - 0.58933	
179	 steps: training loss - 0.57698	, testing loss - 0.58886	
180	 steps: training loss - 0.62407	, testing loss - 0.58831	
181	 steps: training loss - 0.64873	, testing loss - 0.58784	
182	 steps: training loss - 0.53721	, testing loss - 0.58762	
183	 steps: training loss - 0.56209	, testing loss - 0.58751	
184	 steps: training loss - 0.49627	, testing loss - 0.58735	
185	 steps: training loss - 0.53967	, testing loss - 0.58700	
186	 steps: training loss - 0.56034	, testing loss - 0.58677	
187	 steps: training loss - 0.60629	, testing loss - 0.58641	
188	 steps: training loss - 0.55109	, testing loss - 0.58593	
189	 steps: training loss - 0.57229	, testing loss - 0.58540	
190	 steps: training loss - 0.54100	, testing loss - 0.58481	
191	 steps: training loss - 0.51384	, testing loss - 0.58417	
192	 steps: training loss - 0.55482	, testing loss - 0.58354	
193	 steps: training loss - 0.54652	, testing loss - 0.58271	
194	 steps: training loss - 0.48617	, testing loss - 0.58200	
195	 steps: training loss - 0.56668	, testing loss - 0.58116	
196	 steps: training loss - 0.57501	, testing loss - 0.58029	
197	 steps: training loss - 0.50635	, testing loss - 0.57947	
198	 steps: training loss - 0.48072	, testing loss - 0.57870	
199	 steps: training loss - 0.60964	, testing loss - 0.57778	
200	 steps: training loss - 0.43265	, testing loss - 0.57699	
201	 steps: training loss - 0.57131	, testing loss - 0.57623	
202	 steps: training loss - 0.53287	, testing loss - 0.57564	
203	 steps: training loss - 0.46705	, testing loss - 0.57504	
204	 steps: training loss - 0.54415	, testing loss - 0.57441	
205	 steps: training loss - 0.51289	, testing loss - 0.57376	
206	 steps: training loss - 0.53023	, testing loss - 0.57326	
207	 steps: training loss - 0.54122	, testing loss - 0.57281	
208	 steps: training loss - 0.49443	, testing loss - 0.57240	
209	 steps: training loss - 0.58339	, testing loss - 0.57197	
210	 steps: training loss - 0.53125	, testing loss - 0.57155	
211	 steps: training loss - 0.51493	, testing loss - 0.57102	
212	 steps: training loss - 0.54737	, testing loss - 0.57050	
213	 steps: training loss - 0.48857	, testing loss - 0.57009	
214	 steps: training loss - 0.48960	, testing loss - 0.56967	
215	 steps: training loss - 0.53443	, testing loss - 0.56923	
216	 steps: training loss - 0.47596	, testing loss - 0.56888	
217	 steps: training loss - 0.56013	, testing loss - 0.56859	
218	 steps: training loss - 0.58250	, testing loss - 0.56830	
219	 steps: training loss - 0.54408	, testing loss - 0.56800	
220	 steps: training loss - 0.51805	, testing loss - 0.56759	
221	 steps: training loss - 0.50917	, testing loss - 0.56715	
222	 steps: training loss - 0.61275	, testing loss - 0.56680	
223	 steps: training loss - 0.54435	, testing loss - 0.56665	
224	 steps: training loss - 0.48915	, testing loss - 0.56654	
225	 steps: training loss - 0.49915	, testing loss - 0.56644	
226	 steps: training loss - 0.58440	, testing loss - 0.56631	
227	 steps: training loss - 0.54598	, testing loss - 0.56624	
228	 steps: training loss - 0.50035	, testing loss - 0.56631	
229	 steps: training loss - 0.61574	, testing loss - 0.56632	
230	 steps: training loss - 0.58129	, testing loss - 0.56651	
231	 steps: training loss - 0.48230	, testing loss - 0.56667	
232	 steps: training loss - 0.62209	, testing loss - 0.56679	
233	 steps: training loss - 0.53413	, testing loss - 0.56689	
234	 steps: training loss - 0.62733	, testing loss - 0.56681	
235	 steps: training loss - 0.54985	, testing loss - 0.56682	
236	 steps: training loss - 0.54202	, testing loss - 0.56667	
237	 steps: training loss - 0.52734	, testing loss - 0.56667	
238	 steps: training loss - 0.62180	, testing loss - 0.56655	
239	 steps: training loss - 0.51032	, testing loss - 0.56628	
240	 steps: training loss - 0.57998	, testing loss - 0.56579	
241	 steps: training loss - 0.53406	, testing loss - 0.56514	
242	 steps: training loss - 0.50133	, testing loss - 0.56458	
243	 steps: training loss - 0.53281	, testing loss - 0.56408	
244	 steps: training loss - 0.55676	, testing loss - 0.56360	
245	 steps: training loss - 0.51813	, testing loss - 0.56328	
246	 steps: training loss - 0.45301	, testing loss - 0.56304	
247	 steps: training loss - 0.55408	, testing loss - 0.56272	
248	 steps: training loss - 0.50983	, testing loss - 0.56238	
249	 steps: training loss - 0.59628	, testing loss - 0.56203	
250	 steps: training loss - 0.57117	, testing loss - 0.56165	
251	 steps: training loss - 0.49892	, testing loss - 0.56148	
252	 steps: training loss - 0.44873	, testing loss - 0.56119	
253	 steps: training loss - 0.47253	, testing loss - 0.56088	
254	 steps: training loss - 0.52628	, testing loss - 0.56036	
255	 steps: training loss - 0.60836	, testing loss - 0.55966	
256	 steps: training loss - 0.57937	, testing loss - 0.55918	
257	 steps: training loss - 0.56039	, testing loss - 0.55898	
258	 steps: training loss - 0.54570	, testing loss - 0.55890	
259	 steps: training loss - 0.47683	, testing loss - 0.55869	
260	 steps: training loss - 0.50856	, testing loss - 0.55827	
261	 steps: training loss - 0.48799	, testing loss - 0.55776	
262	 steps: training loss - 0.41254	, testing loss - 0.55730	
263	 steps: training loss - 0.51830	, testing loss - 0.55671	
264	 steps: training loss - 0.55335	, testing loss - 0.55607	
265	 steps: training loss - 0.41763	, testing loss - 0.55548	
266	 steps: training loss - 0.47120	, testing loss - 0.55466	
267	 steps: training loss - 0.47957	, testing loss - 0.55414	
268	 steps: training loss - 0.55999	, testing loss - 0.55374	
269	 steps: training loss - 0.45092	, testing loss - 0.55349	
270	 steps: training loss - 0.56641	, testing loss - 0.55335	
271	 steps: training loss - 0.58805	, testing loss - 0.55309	
272	 steps: training loss - 0.43041	, testing loss - 0.55287	
273	 steps: training loss - 0.41495	, testing loss - 0.55263	
274	 steps: training loss - 0.52452	, testing loss - 0.55233	
275	 steps: training loss - 0.50545	, testing loss - 0.55201	
276	 steps: training loss - 0.51938	, testing loss - 0.55157	
277	 steps: training loss - 0.48480	, testing loss - 0.55152	
278	 steps: training loss - 0.45303	, testing loss - 0.55146	
279	 steps: training loss - 0.54868	, testing loss - 0.55132	
280	 steps: training loss - 0.65267	, testing loss - 0.55101	
281	 steps: training loss - 0.59691	, testing loss - 0.55111	
282	 steps: training loss - 0.60522	, testing loss - 0.55138	
283	 steps: training loss - 0.55549	, testing loss - 0.55158	
284	 steps: training loss - 0.59502	, testing loss - 0.55145	
285	 steps: training loss - 0.56026	, testing loss - 0.55119	
286	 steps: training loss - 0.51620	, testing loss - 0.55105	
287	 steps: training loss - 0.61159	, testing loss - 0.55093	
288	 steps: training loss - 0.48225	, testing loss - 0.55084	
289	 steps: training loss - 0.52661	, testing loss - 0.55081	
290	 steps: training loss - 0.50375	, testing loss - 0.55080	
291	 steps: training loss - 0.56775	, testing loss - 0.55070	
292	 steps: training loss - 0.51682	, testing loss - 0.55060	
293	 steps: training loss - 0.53726	, testing loss - 0.55042	
294	 steps: training loss - 0.48370	, testing loss - 0.55023	
295	 steps: training loss - 0.46401	, testing loss - 0.55006	
296	 steps: training loss - 0.51189	, testing loss - 0.54982	
297	 steps: training loss - 0.50626	, testing loss - 0.54945	
298	 steps: training loss - 0.40099	, testing loss - 0.54891	
299	 steps: training loss - 0.46898	, testing loss - 0.54797	
300	 steps: training loss - 0.55321	, testing loss - 0.54696	
301	 steps: training loss - 0.51169	, testing loss - 0.54621	
302	 steps: training loss - 0.55610	, testing loss - 0.54564	
303	 steps: training loss - 0.46215	, testing loss - 0.54530	
304	 steps: training loss - 0.52711	, testing loss - 0.54492	
305	 steps: training loss - 0.40821	, testing loss - 0.54502	
306	 steps: training loss - 0.44818	, testing loss - 0.54511	
307	 steps: training loss - 0.50377	, testing loss - 0.54504	
308	 steps: training loss - 0.46508	, testing loss - 0.54509	
309	 steps: training loss - 0.46924	, testing loss - 0.54505	
310	 steps: training loss - 0.46843	, testing loss - 0.54503	
311	 steps: training loss - 0.44053	, testing loss - 0.54514	
312	 steps: training loss - 0.49903	, testing loss - 0.54507	
313	 steps: training loss - 0.45737	, testing loss - 0.54488	
314	 steps: training loss - 0.44884	, testing loss - 0.54476	
315	 steps: training loss - 0.54389	, testing loss - 0.54453	
316	 steps: training loss - 0.46213	, testing loss - 0.54449	
317	 steps: training loss - 0.55420	, testing loss - 0.54459	
318	 steps: training loss - 0.58218	, testing loss - 0.54471	
319	 steps: training loss - 0.43058	, testing loss - 0.54496	
320	 steps: training loss - 0.47370	, testing loss - 0.54505	
321	 steps: training loss - 0.52814	, testing loss - 0.54520	
322	 steps: training loss - 0.60093	, testing loss - 0.54506	
323	 steps: training loss - 0.54918	, testing loss - 0.54463	
324	 steps: training loss - 0.57929	, testing loss - 0.54391	
325	 steps: training loss - 0.50944	, testing loss - 0.54321	
326	 steps: training loss - 0.49847	, testing loss - 0.54224	
327	 steps: training loss - 0.47366	, testing loss - 0.54130	
328	 steps: training loss - 0.37825	, testing loss - 0.54020	
329	 steps: training loss - 0.53652	, testing loss - 0.53912	
330	 steps: training loss - 0.37431	, testing loss - 0.53789	
331	 steps: training loss - 0.55290	, testing loss - 0.53652	
332	 steps: training loss - 0.40747	, testing loss - 0.53521	
333	 steps: training loss - 0.45918	, testing loss - 0.53407	
334	 steps: training loss - 0.34394	, testing loss - 0.53304	
335	 steps: training loss - 0.47880	, testing loss - 0.53197	
336	 steps: training loss - 0.48435	, testing loss - 0.53120	
337	 steps: training loss - 0.50930	, testing loss - 0.53072	
338	 steps: training loss - 0.61565	, testing loss - 0.53013	
339	 steps: training loss - 0.54508	, testing loss - 0.52965	
340	 steps: training loss - 0.60861	, testing loss - 0.52922	
341	 steps: training loss - 0.45558	, testing loss - 0.52903	
342	 steps: training loss - 0.52118	, testing loss - 0.52874	
343	 steps: training loss - 0.46364	, testing loss - 0.52852	
344	 steps: training loss - 0.47417	, testing loss - 0.52857	
345	 steps: training loss - 0.42848	, testing loss - 0.52865	
346	 steps: training loss - 0.51385	, testing loss - 0.52848	
347	 steps: training loss - 0.56500	, testing loss - 0.52828	
348	 steps: training loss - 0.54273	, testing loss - 0.52822	
349	 steps: training loss - 0.52658	, testing loss - 0.52804	
350	 steps: training loss - 0.53437	, testing loss - 0.52795	
351	 steps: training loss - 0.50543	, testing loss - 0.52788	
352	 steps: training loss - 0.58705	, testing loss - 0.52761	
353	 steps: training loss - 0.43567	, testing loss - 0.52753	
354	 steps: training loss - 0.51354	, testing loss - 0.52721	
355	 steps: training loss - 0.49229	, testing loss - 0.52688	
356	 steps: training loss - 0.48372	, testing loss - 0.52628	
357	 steps: training loss - 0.51093	, testing loss - 0.52572	
358	 steps: training loss - 0.47158	, testing loss - 0.52528	
359	 steps: training loss - 0.43926	, testing loss - 0.52505	
360	 steps: training loss - 0.48987	, testing loss - 0.52473	
361	 steps: training loss - 0.43376	, testing loss - 0.52435	
362	 steps: training loss - 0.51846	, testing loss - 0.52401	
363	 steps: training loss - 0.42624	, testing loss - 0.52363	
364	 steps: training loss - 0.37868	, testing loss - 0.52309	
365	 steps: training loss - 0.46655	, testing loss - 0.52231	
366	 steps: training loss - 0.48435	, testing loss - 0.52149	
367	 steps: training loss - 0.56665	, testing loss - 0.52093	
368	 steps: training loss - 0.55965	, testing loss - 0.52071	
369	 steps: training loss - 0.55020	, testing loss - 0.52075	
370	 steps: training loss - 0.51351	, testing loss - 0.52080	
371	 steps: training loss - 0.49290	, testing loss - 0.52068	
372	 steps: training loss - 0.43091	, testing loss - 0.52032	
373	 steps: training loss - 0.46331	, testing loss - 0.51977	
374	 steps: training loss - 0.58238	, testing loss - 0.51918	
375	 steps: training loss - 0.51255	, testing loss - 0.51895	
376	 steps: training loss - 0.48607	, testing loss - 0.51875	
377	 steps: training loss - 0.56319	, testing loss - 0.51864	
378	 steps: training loss - 0.53789	, testing loss - 0.51851	
379	 steps: training loss - 0.48517	, testing loss - 0.51856	
380	 steps: training loss - 0.42463	, testing loss - 0.51883	
381	 steps: training loss - 0.54203	, testing loss - 0.51885	
382	 steps: training loss - 0.54515	, testing loss - 0.51876	
383	 steps: training loss - 0.51963	, testing loss - 0.51859	
384	 steps: training loss - 0.62654	, testing loss - 0.51842	
385	 steps: training loss - 0.53263	, testing loss - 0.51838	
386	 steps: training loss - 0.40386	, testing loss - 0.51826	
387	 steps: training loss - 0.44711	, testing loss - 0.51820	
388	 steps: training loss - 0.44633	, testing loss - 0.51819	
389	 steps: training loss - 0.58482	, testing loss - 0.51805	
390	 steps: training loss - 0.43131	, testing loss - 0.51808	
391	 steps: training loss - 0.52753	, testing loss - 0.51801	
392	 steps: training loss - 0.61869	, testing loss - 0.51810	
393	 steps: training loss - 0.54481	, testing loss - 0.51847	
394	 steps: training loss - 0.66306	, testing loss - 0.51873	
395	 steps: training loss - 0.51058	, testing loss - 0.51931	
396	 steps: training loss - 0.44333	, testing loss - 0.52004	
397	 steps: training loss - 0.46256	, testing loss - 0.52075	
398	 steps: training loss - 0.28626	, testing loss - 0.52122	
399	 steps: training loss - 0.43802	, testing loss - 0.52125	
400	 steps: training loss - 0.53359	, testing loss - 0.52134	
401	 steps: training loss - 0.47564	, testing loss - 0.52121	
402	 steps: training loss - 0.61309	, testing loss - 0.52091	
403	 steps: training loss - 0.53394	, testing loss - 0.52066	
404	 steps: training loss - 0.45707	, testing loss - 0.52063	
405	 steps: training loss - 0.36995	, testing loss - 0.52058	
406	 steps: training loss - 0.36398	, testing loss - 0.52026	
407	 steps: training loss - 0.54390	, testing loss - 0.51978	
408	 steps: training loss - 0.43026	, testing loss - 0.51942	
409	 steps: training loss - 0.48637	, testing loss - 0.51911	
410	 steps: training loss - 0.42202	, testing loss - 0.51865	
411	 steps: training loss - 0.43875	, testing loss - 0.51826	
412	 steps: training loss - 0.46800	, testing loss - 0.51765	
413	 steps: training loss - 0.48129	, testing loss - 0.51688	
414	 steps: training loss - 0.48067	, testing loss - 0.51577	
415	 steps: training loss - 0.55605	, testing loss - 0.51468	
416	 steps: training loss - 0.48675	, testing loss - 0.51392	
417	 steps: training loss - 0.45950	, testing loss - 0.51337	
418	 steps: training loss - 0.41710	, testing loss - 0.51304	
419	 steps: training loss - 0.45895	, testing loss - 0.51262	
420	 steps: training loss - 0.56756	, testing loss - 0.51212	
421	 steps: training loss - 0.51018	, testing loss - 0.51182	
422	 steps: training loss - 0.44552	, testing loss - 0.51173	
423	 steps: training loss - 0.55960	, testing loss - 0.51154	
424	 steps: training loss - 0.48349	, testing loss - 0.51152	
425	 steps: training loss - 0.46176	, testing loss - 0.51158	
426	 steps: training loss - 0.38054	, testing loss - 0.51166	
427	 steps: training loss - 0.44754	, testing loss - 0.51172	
428	 steps: training loss - 0.60431	, testing loss - 0.51186	
429	 steps: training loss - 0.39337	, testing loss - 0.51230	
430	 steps: training loss - 0.52809	, testing loss - 0.51262	
431	 steps: training loss - 0.43895	, testing loss - 0.51286	
432	 steps: training loss - 0.50713	, testing loss - 0.51319	
433	 steps: training loss - 0.54169	, testing loss - 0.51332	
434	 steps: training loss - 0.54801	, testing loss - 0.51337	
435	 steps: training loss - 0.44038	, testing loss - 0.51352	
436	 steps: training loss - 0.62530	, testing loss - 0.51344	
437	 steps: training loss - 0.43193	, testing loss - 0.51324	
438	 steps: training loss - 0.49230	, testing loss - 0.51287	
439	 steps: training loss - 0.46108	, testing loss - 0.51263	
440	 steps: training loss - 0.51239	, testing loss - 0.51248	
441	 steps: training loss - 0.56776	, testing loss - 0.51245	
442	 steps: training loss - 0.52828	, testing loss - 0.51273	
443	 steps: training loss - 0.49733	, testing loss - 0.51297	
444	 steps: training loss - 0.49908	, testing loss - 0.51305	
445	 steps: training loss - 0.43104	, testing loss - 0.51324	
446	 steps: training loss - 0.54209	, testing loss - 0.51332	
447	 steps: training loss - 0.60635	, testing loss - 0.51373	
448	 steps: training loss - 0.39759	, testing loss - 0.51437	
449	 steps: training loss - 0.52669	, testing loss - 0.51500	
450	 steps: training loss - 0.58352	, testing loss - 0.51569	
451	 steps: training loss - 0.49465	, testing loss - 0.51667	
452	 steps: training loss - 0.58687	, testing loss - 0.51735	
453	 steps: training loss - 0.55965	, testing loss - 0.51776	
454	 steps: training loss - 0.44021	, testing loss - 0.51795	
455	 steps: training loss - 0.40045	, testing loss - 0.51788	
456	 steps: training loss - 0.40368	, testing loss - 0.51790	
457	 steps: training loss - 0.52311	, testing loss - 0.51774	
458	 steps: training loss - 0.51069	, testing loss - 0.51766	
459	 steps: training loss - 0.51916	, testing loss - 0.51777	
460	 steps: training loss - 0.41814	, testing loss - 0.51801	
461	 steps: training loss - 0.56231	, testing loss - 0.51803	
462	 steps: training loss - 0.55587	, testing loss - 0.51796	
463	 steps: training loss - 0.43553	, testing loss - 0.51790	
464	 steps: training loss - 0.35281	, testing loss - 0.51811	
465	 steps: training loss - 0.56689	, testing loss - 0.51835	
466	 steps: training loss - 0.64570	, testing loss - 0.51857	
467	 steps: training loss - 0.43227	, testing loss - 0.51883	
468	 steps: training loss - 0.41164	, testing loss - 0.51914	
469	 steps: training loss - 0.41781	, testing loss - 0.51910	
470	 steps: training loss - 0.33450	, testing loss - 0.51871	
471	 steps: training loss - 0.65730	, testing loss - 0.51829	
472	 steps: training loss - 0.46062	, testing loss - 0.51796	
473	 steps: training loss - 0.40536	, testing loss - 0.51768	
474	 steps: training loss - 0.46614	, testing loss - 0.51756	
475	 steps: training loss - 0.52333	, testing loss - 0.51741	
476	 steps: training loss - 0.53417	, testing loss - 0.51736	
477	 steps: training loss - 0.28408	, testing loss - 0.51738	
478	 steps: training loss - 0.40409	, testing loss - 0.51712	
479	 steps: training loss - 0.56990	, testing loss - 0.51684	
480	 steps: training loss - 0.36293	, testing loss - 0.51680	
481	 steps: training loss - 0.48202	, testing loss - 0.51689	
482	 steps: training loss - 0.61450	, testing loss - 0.51685	
483	 steps: training loss - 0.46075	, testing loss - 0.51665	
484	 steps: training loss - 0.41260	, testing loss - 0.51652	
485	 steps: training loss - 0.57853	, testing loss - 0.51633	
486	 steps: training loss - 0.45686	, testing loss - 0.51642	
487	 steps: training loss - 0.36487	, testing loss - 0.51654	
488	 steps: training loss - 0.43606	, testing loss - 0.51625	
489	 steps: training loss - 0.49973	, testing loss - 0.51586	
490	 steps: training loss - 0.62550	, testing loss - 0.51566	
491	 steps: training loss - 0.50557	, testing loss - 0.51572	
492	 steps: training loss - 0.56622	, testing loss - 0.51548	
493	 steps: training loss - 0.43158	, testing loss - 0.51546	
494	 steps: training loss - 0.52470	, testing loss - 0.51539	
495	 steps: training loss - 0.50830	, testing loss - 0.51537	
496	 steps: training loss - 0.38301	, testing loss - 0.51550	
497	 steps: training loss - 0.36429	, testing loss - 0.51526	
498	 steps: training loss - 0.52943	, testing loss - 0.51493	
499	 steps: training loss - 0.54157	, testing loss - 0.51465	
500	 steps: training loss - 0.54616	, testing loss - 0.51448	
501	 steps: training loss - 0.59099	, testing loss - 0.51419	
502	 steps: training loss - 0.29488	, testing loss - 0.51430	
503	 steps: training loss - 0.51858	, testing loss - 0.51435	
504	 steps: training loss - 0.52654	, testing loss - 0.51408	
505	 steps: training loss - 0.46720	, testing loss - 0.51344	
506	 steps: training loss - 0.40583	, testing loss - 0.51274	
507	 steps: training loss - 0.57771	, testing loss - 0.51190	
508	 steps: training loss - 0.60649	, testing loss - 0.51126	
509	 steps: training loss - 0.35567	, testing loss - 0.51072	
510	 steps: training loss - 0.51970	, testing loss - 0.51026	
511	 steps: training loss - 0.49635	, testing loss - 0.50972	
512	 steps: training loss - 0.49628	, testing loss - 0.50924	
513	 steps: training loss - 0.64491	, testing loss - 0.50865	
514	 steps: training loss - 0.54119	, testing loss - 0.50812	
515	 steps: training loss - 0.45373	, testing loss - 0.50752	
516	 steps: training loss - 0.48150	, testing loss - 0.50676	
517	 steps: training loss - 0.50935	, testing loss - 0.50596	
518	 steps: training loss - 0.47867	, testing loss - 0.50531	
519	 steps: training loss - 0.40392	, testing loss - 0.50477	
520	 steps: training loss - 0.43600	, testing loss - 0.50448	
521	 steps: training loss - 0.44251	, testing loss - 0.50409	
522	 steps: training loss - 0.56609	, testing loss - 0.50414	
523	 steps: training loss - 0.33884	, testing loss - 0.50413	
524	 steps: training loss - 0.40055	, testing loss - 0.50396	
525	 steps: training loss - 0.51498	, testing loss - 0.50353	
526	 steps: training loss - 0.39627	, testing loss - 0.50320	
527	 steps: training loss - 0.49958	, testing loss - 0.50315	
528	 steps: training loss - 0.38737	, testing loss - 0.50335	
529	 steps: training loss - 0.57140	, testing loss - 0.50333	
530	 steps: training loss - 0.53410	, testing loss - 0.50356	
531	 steps: training loss - 0.55262	, testing loss - 0.50360	
532	 steps: training loss - 0.69079	, testing loss - 0.50363	
533	 steps: training loss - 0.53438	, testing loss - 0.50398	
534	 steps: training loss - 0.46877	, testing loss - 0.50444	
535	 steps: training loss - 0.52193	, testing loss - 0.50446	
536	 steps: training loss - 0.56583	, testing loss - 0.50456	
537	 steps: training loss - 0.59074	, testing loss - 0.50450	
538	 steps: training loss - 0.54875	, testing loss - 0.50471	
539	 steps: training loss - 0.43519	, testing loss - 0.50476	
540	 steps: training loss - 0.43773	, testing loss - 0.50434	
541	 steps: training loss - 0.58080	, testing loss - 0.50418	
542	 steps: training loss - 0.41293	, testing loss - 0.50441	
543	 steps: training loss - 0.44362	, testing loss - 0.50479	
544	 steps: training loss - 0.63605	, testing loss - 0.50546	
545	 steps: training loss - 0.38932	, testing loss - 0.50624	
546	 steps: training loss - 0.45577	, testing loss - 0.50672	
547	 steps: training loss - 0.59814	, testing loss - 0.50696	
548	 steps: training loss - 0.45075	, testing loss - 0.50745	
549	 steps: training loss - 0.62762	, testing loss - 0.50827	
550	 steps: training loss - 0.51070	, testing loss - 0.50919	
551	 steps: training loss - 0.48796	, testing loss - 0.51005	
552	 steps: training loss - 0.41913	, testing loss - 0.51090	
553	 steps: training loss - 0.42345	, testing loss - 0.51159	
554	 steps: training loss - 0.47934	, testing loss - 0.51197	
555	 steps: training loss - 0.29820	, testing loss - 0.51223	
556	 steps: training loss - 0.53411	, testing loss - 0.51232	
557	 steps: training loss - 0.62827	, testing loss - 0.51246	
558	 steps: training loss - 0.42887	, testing loss - 0.51256	
559	 steps: training loss - 0.51693	, testing loss - 0.51240	
560	 steps: training loss - 0.47209	, testing loss - 0.51245	
561	 steps: training loss - 0.49433	, testing loss - 0.51233	
562	 steps: training loss - 0.39627	, testing loss - 0.51205	
563	 steps: training loss - 0.46246	, testing loss - 0.51191	
564	 steps: training loss - 0.46014	, testing loss - 0.51176	
565	 steps: training loss - 0.60949	, testing loss - 0.51139	
566	 steps: training loss - 0.41951	, testing loss - 0.51127	
567	 steps: training loss - 0.49853	, testing loss - 0.51146	
568	 steps: training loss - 0.44394	, testing loss - 0.51177	
569	 steps: training loss - 0.52398	, testing loss - 0.51223	
570	 steps: training loss - 0.48605	, testing loss - 0.51343	
571	 steps: training loss - 0.47021	, testing loss - 0.51464	
572	 steps: training loss - 0.51262	, testing loss - 0.51591	
573	 steps: training loss - 0.61417	, testing loss - 0.51695	
574	 steps: training loss - 0.45837	, testing loss - 0.51783	
575	 steps: training loss - 0.52130	, testing loss - 0.51878	
576	 steps: training loss - 0.36705	, testing loss - 0.52043	
577	 steps: training loss - 0.31601	, testing loss - 0.52194	
578	 steps: training loss - 0.43150	, testing loss - 0.52293	
579	 steps: training loss - 0.35320	, testing loss - 0.52353	
580	 steps: training loss - 0.42548	, testing loss - 0.52419	
581	 steps: training loss - 0.43599	, testing loss - 0.52464	
582	 steps: training loss - 0.56459	, testing loss - 0.52493	
583	 steps: training loss - 0.46440	, testing loss - 0.52490	
584	 steps: training loss - 0.68222	, testing loss - 0.52523	
585	 steps: training loss - 0.46301	, testing loss - 0.52570	
586	 steps: training loss - 0.35705	, testing loss - 0.52642	
587	 steps: training loss - 0.45082	, testing loss - 0.52702	
588	 steps: training loss - 0.48934	, testing loss - 0.52744	
589	 steps: training loss - 0.42018	, testing loss - 0.52762	
590	 steps: training loss - 0.42495	, testing loss - 0.52788	
591	 steps: training loss - 0.49612	, testing loss - 0.52787	
592	 steps: training loss - 0.49463	, testing loss - 0.52769	
593	 steps: training loss - 0.49384	, testing loss - 0.52790	
594	 steps: training loss - 0.39378	, testing loss - 0.52823	
595	 steps: training loss - 0.48311	, testing loss - 0.52819	
596	 steps: training loss - 0.67940	, testing loss - 0.52795	
597	 steps: training loss - 0.37458	, testing loss - 0.52774	
598	 steps: training loss - 0.31107	, testing loss - 0.52762	
599	 steps: training loss - 0.45403	, testing loss - 0.52729	
600	 steps: training loss - 0.38417	, testing loss - 0.52695	
601	 steps: training loss - 0.58465	, testing loss - 0.52677	
602	 steps: training loss - 0.54914	, testing loss - 0.52667	
603	 steps: training loss - 0.57287	, testing loss - 0.52601	
604	 steps: training loss - 0.60845	, testing loss - 0.52535	
605	 steps: training loss - 0.49864	, testing loss - 0.52530	
606	 steps: training loss - 0.42549	, testing loss - 0.52559	
607	 steps: training loss - 0.60240	, testing loss - 0.52549	
608	 steps: training loss - 0.30175	, testing loss - 0.52518	
609	 steps: training loss - 0.55683	, testing loss - 0.52495	
610	 steps: training loss - 0.52846	, testing loss - 0.52466	
611	 steps: training loss - 0.56682	, testing loss - 0.52525	
612	 steps: training loss - 0.44696	, testing loss - 0.52560	
613	 steps: training loss - 0.33334	, testing loss - 0.52609	
614	 steps: training loss - 0.43594	, testing loss - 0.52634	
615	 steps: training loss - 0.36842	, testing loss - 0.52610	
616	 steps: training loss - 0.44011	, testing loss - 0.52525	
617	 steps: training loss - 0.35888	, testing loss - 0.52478	
618	 steps: training loss - 0.36298	, testing loss - 0.52436	
619	 steps: training loss - 0.45508	, testing loss - 0.52392	
620	 steps: training loss - 0.38012	, testing loss - 0.52338	
621	 steps: training loss - 0.47168	, testing loss - 0.52249	
622	 steps: training loss - 0.65740	, testing loss - 0.52111	
623	 steps: training loss - 0.45586	, testing loss - 0.51997	
624	 steps: training loss - 0.51469	, testing loss - 0.51919	
625	 steps: training loss - 0.44937	, testing loss - 0.51879	
626	 steps: training loss - 0.40966	, testing loss - 0.51825	
627	 steps: training loss - 0.53771	, testing loss - 0.51793	
628	 steps: training loss - 0.43909	, testing loss - 0.51728	
629	 steps: training loss - 0.51489	, testing loss - 0.51675	
630	 steps: training loss - 0.50569	, testing loss - 0.51683	
631	 steps: training loss - 0.43111	, testing loss - 0.51656	
632	 steps: training loss - 0.42936	, testing loss - 0.51605	
633	 steps: training loss - 0.40669	, testing loss - 0.51558	
634	 steps: training loss - 0.44840	, testing loss - 0.51531	
635	 steps: training loss - 0.46829	, testing loss - 0.51552	
636	 steps: training loss - 0.48514	, testing loss - 0.51581	
637	 steps: training loss - 0.47169	, testing loss - 0.51570	
638	 steps: training loss - 0.38976	, testing loss - 0.51549	
639	 steps: training loss - 0.44068	, testing loss - 0.51538	
640	 steps: training loss - 0.34408	, testing loss - 0.51558	
641	 steps: training loss - 0.39627	, testing loss - 0.51596	
642	 steps: training loss - 0.54606	, testing loss - 0.51620	
643	 steps: training loss - 0.40151	, testing loss - 0.51613	
644	 steps: training loss - 0.37920	, testing loss - 0.51602	
645	 steps: training loss - 0.44762	, testing loss - 0.51592	
646	 steps: training loss - 0.43822	, testing loss - 0.51594	
647	 steps: training loss - 0.47646	, testing loss - 0.51612	
648	 steps: training loss - 0.55986	, testing loss - 0.51627	
649	 steps: training loss - 0.41189	, testing loss - 0.51619	
650	 steps: training loss - 0.50963	, testing loss - 0.51594	
651	 steps: training loss - 0.34408	, testing loss - 0.51574	
652	 steps: training loss - 0.53783	, testing loss - 0.51577	
653	 steps: training loss - 0.43333	, testing loss - 0.51558	
654	 steps: training loss - 0.50243	, testing loss - 0.51504	
655	 steps: training loss - 0.28865	, testing loss - 0.51466	
656	 steps: training loss - 0.38937	, testing loss - 0.51427	
657	 steps: training loss - 0.40336	, testing loss - 0.51400	
658	 steps: training loss - 0.45481	, testing loss - 0.51395	
659	 steps: training loss - 0.42309	, testing loss - 0.51334	
660	 steps: training loss - 0.54847	, testing loss - 0.51273	
661	 steps: training loss - 0.47244	, testing loss - 0.51241	
662	 steps: training loss - 0.51551	, testing loss - 0.51211	
663	 steps: training loss - 0.42276	, testing loss - 0.51194	
664	 steps: training loss - 0.59792	, testing loss - 0.51155	
665	 steps: training loss - 0.32040	, testing loss - 0.51104	
666	 steps: training loss - 0.44790	, testing loss - 0.51064	
667	 steps: training loss - 0.55987	, testing loss - 0.51058	
668	 steps: training loss - 0.39952	, testing loss - 0.51046	
669	 steps: training loss - 0.41576	, testing loss - 0.51017	
670	 steps: training loss - 0.53031	, testing loss - 0.51000	
671	 steps: training loss - 0.62033	, testing loss - 0.50997	
672	 steps: training loss - 0.51453	, testing loss - 0.50991	
673	 steps: training loss - 0.36309	, testing loss - 0.50989	
674	 steps: training loss - 0.45007	, testing loss - 0.50942	
675	 steps: training loss - 0.66049	, testing loss - 0.50882	
676	 steps: training loss - 0.39984	, testing loss - 0.50856	
677	 steps: training loss - 0.55531	, testing loss - 0.50820	
678	 steps: training loss - 0.32489	, testing loss - 0.50745	
679	 steps: training loss - 0.58737	, testing loss - 0.50674	
680	 steps: training loss - 0.40897	, testing loss - 0.50616	
681	 steps: training loss - 0.46416	, testing loss - 0.50549	
682	 steps: training loss - 0.35854	, testing loss - 0.50447	
683	 steps: training loss - 0.39129	, testing loss - 0.50359	
684	 steps: training loss - 0.45715	, testing loss - 0.50273	
685	 steps: training loss - 0.42207	, testing loss - 0.50195	
686	 steps: training loss - 0.42389	, testing loss - 0.50132	
687	 steps: training loss - 0.51230	, testing loss - 0.50065	
688	 steps: training loss - 0.56213	, testing loss - 0.49965	
689	 steps: training loss - 0.35916	, testing loss - 0.49848	
690	 steps: training loss - 0.57932	, testing loss - 0.49752	
691	 steps: training loss - 0.42614	, testing loss - 0.49696	
692	 steps: training loss - 0.52136	, testing loss - 0.49674	
693	 steps: training loss - 0.38703	, testing loss - 0.49627	
694	 steps: training loss - 0.36415	, testing loss - 0.49558	
695	 steps: training loss - 0.46481	, testing loss - 0.49493	
696	 steps: training loss - 0.58823	, testing loss - 0.49452	
697	 steps: training loss - 0.65637	, testing loss - 0.49460	
698	 steps: training loss - 0.41659	, testing loss - 0.49469	
699	 steps: training loss - 0.48573	, testing loss - 0.49492	
700	 steps: training loss - 0.39160	, testing loss - 0.49514	
701	 steps: training loss - 0.48979	, testing loss - 0.49554	
702	 steps: training loss - 0.45116	, testing loss - 0.49588	
703	 steps: training loss - 0.55641	, testing loss - 0.49561	
704	 steps: training loss - 0.26472	, testing loss - 0.49510	
705	 steps: training loss - 0.45845	, testing loss - 0.49454	
706	 steps: training loss - 0.48382	, testing loss - 0.49391	
707	 steps: training loss - 0.42291	, testing loss - 0.49298	
708	 steps: training loss - 0.39146	, testing loss - 0.49201	
709	 steps: training loss - 0.56065	, testing loss - 0.49087	
710	 steps: training loss - 0.37129	, testing loss - 0.48977	
711	 steps: training loss - 0.52956	, testing loss - 0.48892	
712	 steps: training loss - 0.45418	, testing loss - 0.48841	
713	 steps: training loss - 0.44918	, testing loss - 0.48787	
714	 steps: training loss - 0.44925	, testing loss - 0.48709	
715	 steps: training loss - 0.52807	, testing loss - 0.48647	
716	 steps: training loss - 0.40946	, testing loss - 0.48594	
717	 steps: training loss - 0.63084	, testing loss - 0.48584	
718	 steps: training loss - 0.54376	, testing loss - 0.48599	
719	 steps: training loss - 0.55125	, testing loss - 0.48608	
720	 steps: training loss - 0.50709	, testing loss - 0.48635	
721	 steps: training loss - 0.55144	, testing loss - 0.48711	
722	 steps: training loss - 0.37091	, testing loss - 0.48809	
723	 steps: training loss - 0.43462	, testing loss - 0.48891	
724	 steps: training loss - 0.40272	, testing loss - 0.48956	
725	 steps: training loss - 0.54037	, testing loss - 0.49029	
726	 steps: training loss - 0.43647	, testing loss - 0.49111	
727	 steps: training loss - 0.55200	, testing loss - 0.49193	
728	 steps: training loss - 0.39158	, testing loss - 0.49288	
729	 steps: training loss - 0.56915	, testing loss - 0.49372	
730	 steps: training loss - 0.55514	, testing loss - 0.49471	
731	 steps: training loss - 0.32653	, testing loss - 0.49548	
732	 steps: training loss - 0.42660	, testing loss - 0.49603	
733	 steps: training loss - 0.57879	, testing loss - 0.49633	
734	 steps: training loss - 0.63358	, testing loss - 0.49691	
735	 steps: training loss - 0.44767	, testing loss - 0.49760	
736	 steps: training loss - 0.41437	, testing loss - 0.49862	
737	 steps: training loss - 0.49286	, testing loss - 0.50003	
738	 steps: training loss - 0.37008	, testing loss - 0.50146	
739	 steps: training loss - 0.37372	, testing loss - 0.50271	
740	 steps: training loss - 0.44261	, testing loss - 0.50352	
741	 steps: training loss - 0.52405	, testing loss - 0.50435	
742	 steps: training loss - 0.45137	, testing loss - 0.50519	
743	 steps: training loss - 0.52423	, testing loss - 0.50591	
744	 steps: training loss - 0.38618	, testing loss - 0.50667	
745	 steps: training loss - 0.34597	, testing loss - 0.50736	
746	 steps: training loss - 0.56267	, testing loss - 0.50784	
747	 steps: training loss - 0.65155	, testing loss - 0.50802	
748	 steps: training loss - 0.43197	, testing loss - 0.50823	
749	 steps: training loss - 0.60233	, testing loss - 0.50839	
750	 steps: training loss - 0.48371	, testing loss - 0.50893	
751	 steps: training loss - 0.39393	, testing loss - 0.50905	
752	 steps: training loss - 0.39056	, testing loss - 0.50877	
753	 steps: training loss - 0.34619	, testing loss - 0.50871	
754	 steps: training loss - 0.46586	, testing loss - 0.50875	
755	 steps: training loss - 0.51083	, testing loss - 0.50915	
756	 steps: training loss - 0.44164	, testing loss - 0.50959	
757	 steps: training loss - 0.50355	, testing loss - 0.50984	
758	 steps: training loss - 0.56211	, testing loss - 0.51014	
759	 steps: training loss - 0.47306	, testing loss - 0.51083	
760	 steps: training loss - 0.32909	, testing loss - 0.51159	
761	 steps: training loss - 0.45384	, testing loss - 0.51227	
762	 steps: training loss - 0.41595	, testing loss - 0.51282	
763	 steps: training loss - 0.52796	, testing loss - 0.51372	
764	 steps: training loss - 0.40574	, testing loss - 0.51414	
765	 steps: training loss - 0.40652	, testing loss - 0.51402	
766	 steps: training loss - 0.60957	, testing loss - 0.51394	
767	 steps: training loss - 0.49678	, testing loss - 0.51385	
768	 steps: training loss - 0.65941	, testing loss - 0.51361	
769	 steps: training loss - 0.28276	, testing loss - 0.51357	
770	 steps: training loss - 0.34835	, testing loss - 0.51355	
771	 steps: training loss - 0.46941	, testing loss - 0.51322	
772	 steps: training loss - 0.42363	, testing loss - 0.51263	
773	 steps: training loss - 0.32335	, testing loss - 0.51195	
774	 steps: training loss - 0.46917	, testing loss - 0.51147	
775	 steps: training loss - 0.44830	, testing loss - 0.51107	
776	 steps: training loss - 0.54202	, testing loss - 0.51064	
777	 steps: training loss - 0.42735	, testing loss - 0.51028	
778	 steps: training loss - 0.48853	, testing loss - 0.51007	
779	 steps: training loss - 0.51164	, testing loss - 0.51004	
780	 steps: training loss - 0.31668	, testing loss - 0.50982	
781	 steps: training loss - 0.38252	, testing loss - 0.50972	
782	 steps: training loss - 0.39265	, testing loss - 0.50985	
783	 steps: training loss - 0.41951	, testing loss - 0.50995	
784	 steps: training loss - 0.62505	, testing loss - 0.51036	
785	 steps: training loss - 0.59780	, testing loss - 0.51083	
786	 steps: training loss - 0.58409	, testing loss - 0.51101	
787	 steps: training loss - 0.50851	, testing loss - 0.51128	
788	 steps: training loss - 0.47768	, testing loss - 0.51150	
789	 steps: training loss - 0.52823	, testing loss - 0.51175	
790	 steps: training loss - 0.52571	, testing loss - 0.51161	
791	 steps: training loss - 0.59975	, testing loss - 0.51119	
792	 steps: training loss - 0.46346	, testing loss - 0.51076	
793	 steps: training loss - 0.42791	, testing loss - 0.51035	
794	 steps: training loss - 0.58593	, testing loss - 0.50977	
795	 steps: training loss - 0.55495	, testing loss - 0.50882	
796	 steps: training loss - 0.42396	, testing loss - 0.50810	
797	 steps: training loss - 0.41323	, testing loss - 0.50743	
798	 steps: training loss - 0.52160	, testing loss - 0.50664	
799	 steps: training loss - 0.31321	, testing loss - 0.50626	
800	 steps: training loss - 0.39822	, testing loss - 0.50559	
801	 steps: training loss - 0.52977	, testing loss - 0.50524	
802	 steps: training loss - 0.41236	, testing loss - 0.50491	
803	 steps: training loss - 0.32617	, testing loss - 0.50464	
804	 steps: training loss - 0.60112	, testing loss - 0.50405	
805	 steps: training loss - 0.52110	, testing loss - 0.50341	
806	 steps: training loss - 0.34076	, testing loss - 0.50292	
807	 steps: training loss - 0.49845	, testing loss - 0.50219	
808	 steps: training loss - 0.32852	, testing loss - 0.50167	
809	 steps: training loss - 0.35007	, testing loss - 0.50145	
810	 steps: training loss - 0.43582	, testing loss - 0.50128	
811	 steps: training loss - 0.61519	, testing loss - 0.50116	
812	 steps: training loss - 0.36240	, testing loss - 0.50097	
813	 steps: training loss - 0.44829	, testing loss - 0.50059	
814	 steps: training loss - 0.44812	, testing loss - 0.50018	
815	 steps: training loss - 0.41153	, testing loss - 0.49989	
816	 steps: training loss - 0.46075	, testing loss - 0.49972	
817	 steps: training loss - 0.40000	, testing loss - 0.49910	
818	 steps: training loss - 0.33366	, testing loss - 0.49851	
819	 steps: training loss - 0.39172	, testing loss - 0.49803	
820	 steps: training loss - 0.67352	, testing loss - 0.49743	
821	 steps: training loss - 0.59164	, testing loss - 0.49709	
822	 steps: training loss - 0.53599	, testing loss - 0.49724	
823	 steps: training loss - 0.42070	, testing loss - 0.49775	
824	 steps: training loss - 0.39574	, testing loss - 0.49827	
825	 steps: training loss - 0.59362	, testing loss - 0.49858	
826	 steps: training loss - 0.51606	, testing loss - 0.49870	
827	 steps: training loss - 0.47800	, testing loss - 0.49854	
828	 steps: training loss - 0.53938	, testing loss - 0.49843	
829	 steps: training loss - 0.29923	, testing loss - 0.49888	
830	 steps: training loss - 0.50652	, testing loss - 0.49944	
831	 steps: training loss - 0.49249	, testing loss - 0.50011	
832	 steps: training loss - 0.49496	, testing loss - 0.50016	
833	 steps: training loss - 0.32237	, testing loss - 0.50052	
834	 steps: training loss - 0.41064	, testing loss - 0.50113	
835	 steps: training loss - 0.46602	, testing loss - 0.50162	
836	 steps: training loss - 0.45096	, testing loss - 0.50164	
837	 steps: training loss - 0.29341	, testing loss - 0.50134	
838	 steps: training loss - 0.38863	, testing loss - 0.50103	
839	 steps: training loss - 0.59452	, testing loss - 0.50072	
840	 steps: training loss - 0.47139	, testing loss - 0.50053	
841	 steps: training loss - 0.55931	, testing loss - 0.50036	
842	 steps: training loss - 0.36693	, testing loss - 0.50001	
843	 steps: training loss - 0.31591	, testing loss - 0.49966	
844	 steps: training loss - 0.52520	, testing loss - 0.49940	
845	 steps: training loss - 0.62165	, testing loss - 0.49925	
846	 steps: training loss - 0.73523	, testing loss - 0.49916	
847	 steps: training loss - 0.54767	, testing loss - 0.49932	
848	 steps: training loss - 0.39654	, testing loss - 0.49963	
849	 steps: training loss - 0.48472	, testing loss - 0.49931	
850	 steps: training loss - 0.23641	, testing loss - 0.49884	
851	 steps: training loss - 0.58378	, testing loss - 0.49823	
852	 steps: training loss - 0.56021	, testing loss - 0.49747	
853	 steps: training loss - 0.47460	, testing loss - 0.49702	
854	 steps: training loss - 0.31508	, testing loss - 0.49644	
855	 steps: training loss - 0.44357	, testing loss - 0.49557	
856	 steps: training loss - 0.26503	, testing loss - 0.49466	
857	 steps: training loss - 0.44584	, testing loss - 0.49383	
858	 steps: training loss - 0.34817	, testing loss - 0.49320	
859	 steps: training loss - 0.42148	, testing loss - 0.49235	
860	 steps: training loss - 0.42162	, testing loss - 0.49161	
861	 steps: training loss - 0.34283	, testing loss - 0.49061	
862	 steps: training loss - 0.47503	, testing loss - 0.48961	
863	 steps: training loss - 0.38762	, testing loss - 0.48893	
864	 steps: training loss - 0.50773	, testing loss - 0.48849	
865	 steps: training loss - 0.60139	, testing loss - 0.48826	
866	 steps: training loss - 0.48458	, testing loss - 0.48824	
867	 steps: training loss - 0.29750	, testing loss - 0.48888	
868	 steps: training loss - 0.42772	, testing loss - 0.48956	
869	 steps: training loss - 0.42923	, testing loss - 0.48973	
870	 steps: training loss - 0.46544	, testing loss - 0.48966	
871	 steps: training loss - 0.49953	, testing loss - 0.48924	
872	 steps: training loss - 0.57964	, testing loss - 0.48890	
873	 steps: training loss - 0.35980	, testing loss - 0.48870	
874	 steps: training loss - 0.53275	, testing loss - 0.48872	
875	 steps: training loss - 0.43756	, testing loss - 0.48908	
876	 steps: training loss - 0.41943	, testing loss - 0.48910	
877	 steps: training loss - 0.41145	, testing loss - 0.48868	
878	 steps: training loss - 0.46403	, testing loss - 0.48824	
879	 steps: training loss - 0.39360	, testing loss - 0.48784	
880	 steps: training loss - 0.45286	, testing loss - 0.48744	
881	 steps: training loss - 0.51384	, testing loss - 0.48748	
882	 steps: training loss - 0.47946	, testing loss - 0.48758	
883	 steps: training loss - 0.57873	, testing loss - 0.48781	
884	 steps: training loss - 0.28140	, testing loss - 0.48804	
885	 steps: training loss - 0.48730	, testing loss - 0.48817	
886	 steps: training loss - 0.62360	, testing loss - 0.48847	
887	 steps: training loss - 0.26436	, testing loss - 0.48879	
888	 steps: training loss - 0.44674	, testing loss - 0.48901	
889	 steps: training loss - 0.50809	, testing loss - 0.48939	
890	 steps: training loss - 0.56231	, testing loss - 0.48987	
891	 steps: training loss - 0.38780	, testing loss - 0.49029	
892	 steps: training loss - 0.30843	, testing loss - 0.49070	
893	 steps: training loss - 0.35388	, testing loss - 0.49111	
894	 steps: training loss - 0.44279	, testing loss - 0.49172	
895	 steps: training loss - 0.52128	, testing loss - 0.49269	
896	 steps: training loss - 0.58593	, testing loss - 0.49377	
897	 steps: training loss - 0.41830	, testing loss - 0.49492	
898	 steps: training loss - 0.62709	, testing loss - 0.49629	
899	 steps: training loss - 0.34786	, testing loss - 0.49740	
900	 steps: training loss - 0.43333	, testing loss - 0.49856	
901	 steps: training loss - 0.54659	, testing loss - 0.49935	
902	 steps: training loss - 0.21865	, testing loss - 0.50010	
903	 steps: training loss - 0.43687	, testing loss - 0.50057	
904	 steps: training loss - 0.41143	, testing loss - 0.50123	
905	 steps: training loss - 0.55796	, testing loss - 0.50171	
906	 steps: training loss - 0.40760	, testing loss - 0.50213	
907	 steps: training loss - 0.34437	, testing loss - 0.50274	
908	 steps: training loss - 0.55555	, testing loss - 0.50365	
909	 steps: training loss - 0.52339	, testing loss - 0.50502	
910	 steps: training loss - 0.49640	, testing loss - 0.50646	
911	 steps: training loss - 0.36661	, testing loss - 0.50769	
912	 steps: training loss - 0.46327	, testing loss - 0.50855	
913	 steps: training loss - 0.25651	, testing loss - 0.50889	
914	 steps: training loss - 0.50637	, testing loss - 0.50903	
915	 steps: training loss - 0.60731	, testing loss - 0.50875	
916	 steps: training loss - 0.33829	, testing loss - 0.50842	
917	 steps: training loss - 0.38108	, testing loss - 0.50845	
918	 steps: training loss - 0.55116	, testing loss - 0.50890	
919	 steps: training loss - 0.58828	, testing loss - 0.50920	
920	 steps: training loss - 0.56190	, testing loss - 0.50928	
921	 steps: training loss - 0.64783	, testing loss - 0.50921	
922	 steps: training loss - 0.52229	, testing loss - 0.50910	
923	 steps: training loss - 0.44761	, testing loss - 0.50910	
924	 steps: training loss - 0.52058	, testing loss - 0.50856	
925	 steps: training loss - 0.52708	, testing loss - 0.50804	
926	 steps: training loss - 0.29990	, testing loss - 0.50785	
927	 steps: training loss - 0.67927	, testing loss - 0.50780	
928	 steps: training loss - 0.32825	, testing loss - 0.50781	
929	 steps: training loss - 0.49391	, testing loss - 0.50771	
930	 steps: training loss - 0.52307	, testing loss - 0.50759	
931	 steps: training loss - 0.48789	, testing loss - 0.50786	
932	 steps: training loss - 0.44869	, testing loss - 0.50795	
933	 steps: training loss - 0.42922	, testing loss - 0.50793	
934	 steps: training loss - 0.40635	, testing loss - 0.50789	
935	 steps: training loss - 0.36442	, testing loss - 0.50772	
936	 steps: training loss - 0.51649	, testing loss - 0.50789	
937	 steps: training loss - 0.44676	, testing loss - 0.50780	
938	 steps: training loss - 0.44667	, testing loss - 0.50712	
939	 steps: training loss - 0.48155	, testing loss - 0.50636	
940	 steps: training loss - 0.43137	, testing loss - 0.50524	
941	 steps: training loss - 0.40986	, testing loss - 0.50395	
942	 steps: training loss - 0.33069	, testing loss - 0.50262	
943	 steps: training loss - 0.43404	, testing loss - 0.50144	
944	 steps: training loss - 0.47840	, testing loss - 0.50034	
945	 steps: training loss - 0.72240	, testing loss - 0.49967	
946	 steps: training loss - 0.55367	, testing loss - 0.49946	
947	 steps: training loss - 0.58483	, testing loss - 0.49977	
948	 steps: training loss - 0.56952	, testing loss - 0.49997	
949	 steps: training loss - 0.38663	, testing loss - 0.50029	
950	 steps: training loss - 0.31867	, testing loss - 0.50050	
951	 steps: training loss - 0.56097	, testing loss - 0.50091	
952	 steps: training loss - 0.46038	, testing loss - 0.50125	
953	 steps: training loss - 0.47694	, testing loss - 0.50121	
954	 steps: training loss - 0.41412	, testing loss - 0.50123	
955	 steps: training loss - 0.58265	, testing loss - 0.50154	
956	 steps: training loss - 0.48769	, testing loss - 0.50243	
957	 steps: training loss - 0.56484	, testing loss - 0.50293	
958	 steps: training loss - 0.47014	, testing loss - 0.50351	
959	 steps: training loss - 0.41026	, testing loss - 0.50374	
960	 steps: training loss - 0.32110	, testing loss - 0.50425	
961	 steps: training loss - 0.38286	, testing loss - 0.50445	
962	 steps: training loss - 0.49277	, testing loss - 0.50496	
963	 steps: training loss - 0.40033	, testing loss - 0.50557	
964	 steps: training loss - 0.46405	, testing loss - 0.50599	
965	 steps: training loss - 0.32806	, testing loss - 0.50633	
966	 steps: training loss - 0.46205	, testing loss - 0.50642	
967	 steps: training loss - 0.32049	, testing loss - 0.50597	
968	 steps: training loss - 0.38485	, testing loss - 0.50551	
969	 steps: training loss - 0.50838	, testing loss - 0.50539	
970	 steps: training loss - 0.42883	, testing loss - 0.50551	
971	 steps: training loss - 0.49244	, testing loss - 0.50607	
972	 steps: training loss - 0.34702	, testing loss - 0.50658	
973	 steps: training loss - 0.49844	, testing loss - 0.50747	
974	 steps: training loss - 0.34047	, testing loss - 0.50890	
975	 steps: training loss - 0.46533	, testing loss - 0.50971	
976	 steps: training loss - 0.65096	, testing loss - 0.51069	
977	 steps: training loss - 0.34788	, testing loss - 0.51158	
978	 steps: training loss - 0.35052	, testing loss - 0.51190	
979	 steps: training loss - 0.26667	, testing loss - 0.51159	
980	 steps: training loss - 0.43421	, testing loss - 0.51113	
981	 steps: training loss - 0.48222	, testing loss - 0.51087	
982	 steps: training loss - 0.40328	, testing loss - 0.51058	
983	 steps: training loss - 0.32488	, testing loss - 0.51023	
984	 steps: training loss - 0.56867	, testing loss - 0.50971	
985	 steps: training loss - 0.47961	, testing loss - 0.50891	
986	 steps: training loss - 0.48685	, testing loss - 0.50814	
987	 steps: training loss - 0.49825	, testing loss - 0.50732	
988	 steps: training loss - 0.39913	, testing loss - 0.50680	
989	 steps: training loss - 0.56478	, testing loss - 0.50630	
990	 steps: training loss - 0.52510	, testing loss - 0.50599	
991	 steps: training loss - 0.55511	, testing loss - 0.50569	
992	 steps: training loss - 0.42093	, testing loss - 0.50569	
993	 steps: training loss - 0.49572	, testing loss - 0.50589	
994	 steps: training loss - 0.52105	, testing loss - 0.50637	
995	 steps: training loss - 0.54408	, testing loss - 0.50760	
996	 steps: training loss - 0.48747	, testing loss - 0.50869	
997	 steps: training loss - 0.51558	, testing loss - 0.50960	
998	 steps: training loss - 0.46800	, testing loss - 0.51036	
999	 steps: training loss - 0.39321	, testing loss - 0.51057	
EVALUATION
----------
Test loss: 0.45410
MIMO Accuracies: 1.00000

LOOCV TRAINING INFO - is_lstm? True
LOOCV? -  True
-------------
TRAINING USERS -  ['a', 'b', 'c', 'e', 'h', 'i']
LEFT OUT -  g
-------------
actions ['bike', 'sit']
devices ['samsungold_1', 'samsungold_2']
step size 10
num_epochs 1000
batch size 12
feature size (x,y,z) 3
hidden size 20
number recurrent layers 2
number of classes 2
writing pickle to run9_model.p
writing accuracy + pickle to acc_run9_model.p
------------------------------------------------
0	 steps: training loss - 0.67224	, testing loss - 0.68444	
1	 steps: training loss - 0.70253	, testing loss - 0.68421	
2	 steps: training loss - 0.69327	, testing loss - 0.68369	
3	 steps: training loss - 0.65102	, testing loss - 0.68314	
4	 steps: training loss - 0.67958	, testing loss - 0.68269	
5	 steps: training loss - 0.70701	, testing loss - 0.68223	
6	 steps: training loss - 0.68405	, testing loss - 0.68172	
7	 steps: training loss - 0.68811	, testing loss - 0.68123	
8	 steps: training loss - 0.67903	, testing loss - 0.68071	
9	 steps: training loss - 0.66634	, testing loss - 0.68018	
10	 steps: training loss - 0.65472	, testing loss - 0.67965	
11	 steps: training loss - 0.70296	, testing loss - 0.67913	
12	 steps: training loss - 0.67789	, testing loss - 0.67860	
13	 steps: training loss - 0.71992	, testing loss - 0.67808	
14	 steps: training loss - 0.67183	, testing loss - 0.67756	
15	 steps: training loss - 0.69011	, testing loss - 0.67703	
16	 steps: training loss - 0.67719	, testing loss - 0.67648	
17	 steps: training loss - 0.67788	, testing loss - 0.67591	
18	 steps: training loss - 0.68615	, testing loss - 0.67534	
19	 steps: training loss - 0.67703	, testing loss - 0.67476	
20	 steps: training loss - 0.70426	, testing loss - 0.67420	
21	 steps: training loss - 0.66947	, testing loss - 0.67367	
22	 steps: training loss - 0.65434	, testing loss - 0.67313	
23	 steps: training loss - 0.66251	, testing loss - 0.67261	
24	 steps: training loss - 0.70546	, testing loss - 0.67210	
25	 steps: training loss - 0.67427	, testing loss - 0.67162	
26	 steps: training loss - 0.67408	, testing loss - 0.67115	
27	 steps: training loss - 0.68264	, testing loss - 0.67067	
28	 steps: training loss - 0.65351	, testing loss - 0.67023	
29	 steps: training loss - 0.65816	, testing loss - 0.66982	
30	 steps: training loss - 0.66054	, testing loss - 0.66939	
31	 steps: training loss - 0.69593	, testing loss - 0.66897	
32	 steps: training loss - 0.67222	, testing loss - 0.66857	
33	 steps: training loss - 0.65794	, testing loss - 0.66816	
34	 steps: training loss - 0.66927	, testing loss - 0.66774	
35	 steps: training loss - 0.68486	, testing loss - 0.66731	
36	 steps: training loss - 0.68825	, testing loss - 0.66683	
37	 steps: training loss - 0.70445	, testing loss - 0.66633	
38	 steps: training loss - 0.68731	, testing loss - 0.66582	
39	 steps: training loss - 0.66228	, testing loss - 0.66532	
40	 steps: training loss - 0.68094	, testing loss - 0.66487	
41	 steps: training loss - 0.66564	, testing loss - 0.66439	
42	 steps: training loss - 0.67790	, testing loss - 0.66398	
43	 steps: training loss - 0.69714	, testing loss - 0.66360	
44	 steps: training loss - 0.68852	, testing loss - 0.66319	
45	 steps: training loss - 0.67720	, testing loss - 0.66278	
46	 steps: training loss - 0.68234	, testing loss - 0.66233	
47	 steps: training loss - 0.67125	, testing loss - 0.66186	
48	 steps: training loss - 0.67364	, testing loss - 0.66134	
49	 steps: training loss - 0.63101	, testing loss - 0.66084	
50	 steps: training loss - 0.63724	, testing loss - 0.66036	
51	 steps: training loss - 0.65553	, testing loss - 0.65993	
52	 steps: training loss - 0.66238	, testing loss - 0.65954	
53	 steps: training loss - 0.66788	, testing loss - 0.65914	
54	 steps: training loss - 0.65621	, testing loss - 0.65867	
55	 steps: training loss - 0.65547	, testing loss - 0.65821	
56	 steps: training loss - 0.67587	, testing loss - 0.65775	
57	 steps: training loss - 0.64220	, testing loss - 0.65725	
58	 steps: training loss - 0.65776	, testing loss - 0.65674	
59	 steps: training loss - 0.64312	, testing loss - 0.65629	
60	 steps: training loss - 0.66508	, testing loss - 0.65585	
61	 steps: training loss - 0.63972	, testing loss - 0.65540	
62	 steps: training loss - 0.66565	, testing loss - 0.65496	
63	 steps: training loss - 0.65037	, testing loss - 0.65452	
64	 steps: training loss - 0.66937	, testing loss - 0.65412	
65	 steps: training loss - 0.70860	, testing loss - 0.65375	
66	 steps: training loss - 0.64973	, testing loss - 0.65336	
67	 steps: training loss - 0.70177	, testing loss - 0.65301	
68	 steps: training loss - 0.68799	, testing loss - 0.65260	
69	 steps: training loss - 0.64970	, testing loss - 0.65216	
70	 steps: training loss - 0.66594	, testing loss - 0.65176	
71	 steps: training loss - 0.64796	, testing loss - 0.65138	
72	 steps: training loss - 0.63090	, testing loss - 0.65103	
73	 steps: training loss - 0.66523	, testing loss - 0.65076	
74	 steps: training loss - 0.66206	, testing loss - 0.65048	
75	 steps: training loss - 0.64406	, testing loss - 0.65019	
76	 steps: training loss - 0.60855	, testing loss - 0.64990	
77	 steps: training loss - 0.66640	, testing loss - 0.64969	
78	 steps: training loss - 0.66957	, testing loss - 0.64949	
79	 steps: training loss - 0.67614	, testing loss - 0.64927	
80	 steps: training loss - 0.67744	, testing loss - 0.64897	
81	 steps: training loss - 0.64684	, testing loss - 0.64857	
82	 steps: training loss - 0.71877	, testing loss - 0.64820	
83	 steps: training loss - 0.70462	, testing loss - 0.64770	
84	 steps: training loss - 0.66267	, testing loss - 0.64710	
85	 steps: training loss - 0.65494	, testing loss - 0.64652	
86	 steps: training loss - 0.64220	, testing loss - 0.64596	
87	 steps: training loss - 0.65415	, testing loss - 0.64547	
88	 steps: training loss - 0.62685	, testing loss - 0.64496	
89	 steps: training loss - 0.70206	, testing loss - 0.64454	
90	 steps: training loss - 0.63820	, testing loss - 0.64408	
91	 steps: training loss - 0.63465	, testing loss - 0.64363	
92	 steps: training loss - 0.69328	, testing loss - 0.64321	
93	 steps: training loss - 0.65191	, testing loss - 0.64281	
94	 steps: training loss - 0.59034	, testing loss - 0.64237	
95	 steps: training loss - 0.61498	, testing loss - 0.64208	
96	 steps: training loss - 0.66287	, testing loss - 0.64180	
97	 steps: training loss - 0.67278	, testing loss - 0.64145	
98	 steps: training loss - 0.66322	, testing loss - 0.64111	
99	 steps: training loss - 0.68328	, testing loss - 0.64079	
100	 steps: training loss - 0.62243	, testing loss - 0.64042	
101	 steps: training loss - 0.64966	, testing loss - 0.64006	
102	 steps: training loss - 0.65349	, testing loss - 0.63966	
103	 steps: training loss - 0.65018	, testing loss - 0.63932	
104	 steps: training loss - 0.69343	, testing loss - 0.63899	
105	 steps: training loss - 0.66241	, testing loss - 0.63865	
106	 steps: training loss - 0.67200	, testing loss - 0.63831	
107	 steps: training loss - 0.65688	, testing loss - 0.63792	
108	 steps: training loss - 0.63735	, testing loss - 0.63752	
109	 steps: training loss - 0.68043	, testing loss - 0.63711	
110	 steps: training loss - 0.70429	, testing loss - 0.63664	
111	 steps: training loss - 0.60865	, testing loss - 0.63607	
112	 steps: training loss - 0.69743	, testing loss - 0.63556	
113	 steps: training loss - 0.62199	, testing loss - 0.63509	
114	 steps: training loss - 0.63641	, testing loss - 0.63464	
115	 steps: training loss - 0.66393	, testing loss - 0.63432	
116	 steps: training loss - 0.65437	, testing loss - 0.63394	
117	 steps: training loss - 0.66507	, testing loss - 0.63348	
118	 steps: training loss - 0.63517	, testing loss - 0.63304	
119	 steps: training loss - 0.66215	, testing loss - 0.63266	
120	 steps: training loss - 0.66155	, testing loss - 0.63223	
121	 steps: training loss - 0.67420	, testing loss - 0.63172	
122	 steps: training loss - 0.63894	, testing loss - 0.63119	
123	 steps: training loss - 0.67753	, testing loss - 0.63063	
124	 steps: training loss - 0.62029	, testing loss - 0.63006	
125	 steps: training loss - 0.62496	, testing loss - 0.62960	
126	 steps: training loss - 0.71009	, testing loss - 0.62912	
127	 steps: training loss - 0.65019	, testing loss - 0.62861	
128	 steps: training loss - 0.63030	, testing loss - 0.62811	
129	 steps: training loss - 0.64810	, testing loss - 0.62760	
130	 steps: training loss - 0.63628	, testing loss - 0.62709	
131	 steps: training loss - 0.65651	, testing loss - 0.62665	
132	 steps: training loss - 0.65547	, testing loss - 0.62627	
133	 steps: training loss - 0.67317	, testing loss - 0.62592	
134	 steps: training loss - 0.62001	, testing loss - 0.62555	
135	 steps: training loss - 0.60927	, testing loss - 0.62511	
136	 steps: training loss - 0.65783	, testing loss - 0.62471	
137	 steps: training loss - 0.66936	, testing loss - 0.62435	
138	 steps: training loss - 0.64731	, testing loss - 0.62388	
139	 steps: training loss - 0.67748	, testing loss - 0.62340	
140	 steps: training loss - 0.64563	, testing loss - 0.62293	
141	 steps: training loss - 0.64659	, testing loss - 0.62247	
142	 steps: training loss - 0.61688	, testing loss - 0.62210	
143	 steps: training loss - 0.64753	, testing loss - 0.62175	
144	 steps: training loss - 0.67134	, testing loss - 0.62136	
145	 steps: training loss - 0.67753	, testing loss - 0.62094	
146	 steps: training loss - 0.65102	, testing loss - 0.62044	
147	 steps: training loss - 0.65073	, testing loss - 0.61986	
148	 steps: training loss - 0.60838	, testing loss - 0.61927	
149	 steps: training loss - 0.66230	, testing loss - 0.61876	
150	 steps: training loss - 0.61508	, testing loss - 0.61825	
151	 steps: training loss - 0.61406	, testing loss - 0.61771	
152	 steps: training loss - 0.68181	, testing loss - 0.61725	
153	 steps: training loss - 0.59828	, testing loss - 0.61682	
154	 steps: training loss - 0.61839	, testing loss - 0.61637	
155	 steps: training loss - 0.61954	, testing loss - 0.61589	
156	 steps: training loss - 0.63677	, testing loss - 0.61544	
157	 steps: training loss - 0.65729	, testing loss - 0.61502	
158	 steps: training loss - 0.67163	, testing loss - 0.61455	
159	 steps: training loss - 0.64244	, testing loss - 0.61409	
160	 steps: training loss - 0.63486	, testing loss - 0.61365	
161	 steps: training loss - 0.60572	, testing loss - 0.61322	
162	 steps: training loss - 0.70867	, testing loss - 0.61286	
163	 steps: training loss - 0.63370	, testing loss - 0.61250	
164	 steps: training loss - 0.65454	, testing loss - 0.61217	
165	 steps: training loss - 0.61619	, testing loss - 0.61180	
166	 steps: training loss - 0.65880	, testing loss - 0.61137	
167	 steps: training loss - 0.63589	, testing loss - 0.61090	
168	 steps: training loss - 0.61456	, testing loss - 0.61049	
169	 steps: training loss - 0.64071	, testing loss - 0.61007	
170	 steps: training loss - 0.68406	, testing loss - 0.60957	
171	 steps: training loss - 0.60856	, testing loss - 0.60903	
172	 steps: training loss - 0.60282	, testing loss - 0.60857	
173	 steps: training loss - 0.64540	, testing loss - 0.60816	
174	 steps: training loss - 0.63106	, testing loss - 0.60781	
175	 steps: training loss - 0.64668	, testing loss - 0.60746	
176	 steps: training loss - 0.62728	, testing loss - 0.60707	
177	 steps: training loss - 0.58707	, testing loss - 0.60660	
178	 steps: training loss - 0.62040	, testing loss - 0.60618	
179	 steps: training loss - 0.60454	, testing loss - 0.60581	
180	 steps: training loss - 0.67147	, testing loss - 0.60552	
181	 steps: training loss - 0.60494	, testing loss - 0.60521	
182	 steps: training loss - 0.65779	, testing loss - 0.60491	
183	 steps: training loss - 0.67117	, testing loss - 0.60464	
184	 steps: training loss - 0.64248	, testing loss - 0.60432	
185	 steps: training loss - 0.67234	, testing loss - 0.60401	
186	 steps: training loss - 0.62344	, testing loss - 0.60355	
187	 steps: training loss - 0.66474	, testing loss - 0.60303	
188	 steps: training loss - 0.69146	, testing loss - 0.60246	
189	 steps: training loss - 0.63492	, testing loss - 0.60193	
190	 steps: training loss - 0.64443	, testing loss - 0.60144	
191	 steps: training loss - 0.62173	, testing loss - 0.60092	
192	 steps: training loss - 0.60391	, testing loss - 0.60040	
193	 steps: training loss - 0.62555	, testing loss - 0.59986	
194	 steps: training loss - 0.60341	, testing loss - 0.59939	
195	 steps: training loss - 0.60392	, testing loss - 0.59897	
196	 steps: training loss - 0.61850	, testing loss - 0.59854	
197	 steps: training loss - 0.68525	, testing loss - 0.59816	
198	 steps: training loss - 0.59118	, testing loss - 0.59774	
199	 steps: training loss - 0.59104	, testing loss - 0.59739	
200	 steps: training loss - 0.62404	, testing loss - 0.59711	
201	 steps: training loss - 0.64395	, testing loss - 0.59694	
202	 steps: training loss - 0.62377	, testing loss - 0.59672	
203	 steps: training loss - 0.67428	, testing loss - 0.59646	
204	 steps: training loss - 0.57464	, testing loss - 0.59603	
205	 steps: training loss - 0.66396	, testing loss - 0.59554	
206	 steps: training loss - 0.61507	, testing loss - 0.59505	
207	 steps: training loss - 0.60487	, testing loss - 0.59455	
208	 steps: training loss - 0.63295	, testing loss - 0.59411	
209	 steps: training loss - 0.61790	, testing loss - 0.59362	
210	 steps: training loss - 0.67116	, testing loss - 0.59319	
211	 steps: training loss - 0.58138	, testing loss - 0.59272	
212	 steps: training loss - 0.56121	, testing loss - 0.59230	
213	 steps: training loss - 0.63139	, testing loss - 0.59193	
214	 steps: training loss - 0.62498	, testing loss - 0.59152	
215	 steps: training loss - 0.60640	, testing loss - 0.59112	
216	 steps: training loss - 0.62970	, testing loss - 0.59062	
217	 steps: training loss - 0.63452	, testing loss - 0.59006	
218	 steps: training loss - 0.64547	, testing loss - 0.58940	
219	 steps: training loss - 0.65052	, testing loss - 0.58873	
220	 steps: training loss - 0.68691	, testing loss - 0.58800	
221	 steps: training loss - 0.67639	, testing loss - 0.58734	
222	 steps: training loss - 0.59501	, testing loss - 0.58672	
223	 steps: training loss - 0.63339	, testing loss - 0.58612	
224	 steps: training loss - 0.58956	, testing loss - 0.58555	
225	 steps: training loss - 0.68110	, testing loss - 0.58506	
226	 steps: training loss - 0.65283	, testing loss - 0.58463	
227	 steps: training loss - 0.63020	, testing loss - 0.58424	
228	 steps: training loss - 0.63076	, testing loss - 0.58385	
229	 steps: training loss - 0.59018	, testing loss - 0.58347	
230	 steps: training loss - 0.61116	, testing loss - 0.58313	
231	 steps: training loss - 0.66497	, testing loss - 0.58281	
232	 steps: training loss - 0.61729	, testing loss - 0.58248	
233	 steps: training loss - 0.61841	, testing loss - 0.58220	
234	 steps: training loss - 0.59958	, testing loss - 0.58196	
235	 steps: training loss - 0.65045	, testing loss - 0.58172	
236	 steps: training loss - 0.60608	, testing loss - 0.58149	
237	 steps: training loss - 0.61610	, testing loss - 0.58131	
238	 steps: training loss - 0.62605	, testing loss - 0.58108	
239	 steps: training loss - 0.60143	, testing loss - 0.58077	
240	 steps: training loss - 0.62608	, testing loss - 0.58041	
241	 steps: training loss - 0.59170	, testing loss - 0.58001	
242	 steps: training loss - 0.59998	, testing loss - 0.57962	
243	 steps: training loss - 0.62439	, testing loss - 0.57926	
244	 steps: training loss - 0.61678	, testing loss - 0.57893	
245	 steps: training loss - 0.57749	, testing loss - 0.57860	
246	 steps: training loss - 0.61902	, testing loss - 0.57827	
247	 steps: training loss - 0.65670	, testing loss - 0.57793	
248	 steps: training loss - 0.65548	, testing loss - 0.57756	
249	 steps: training loss - 0.64296	, testing loss - 0.57707	
250	 steps: training loss - 0.62112	, testing loss - 0.57663	
251	 steps: training loss - 0.63120	, testing loss - 0.57624	
252	 steps: training loss - 0.61689	, testing loss - 0.57582	
253	 steps: training loss - 0.66687	, testing loss - 0.57546	
254	 steps: training loss - 0.61934	, testing loss - 0.57512	
255	 steps: training loss - 0.62555	, testing loss - 0.57487	
256	 steps: training loss - 0.59438	, testing loss - 0.57463	
257	 steps: training loss - 0.61640	, testing loss - 0.57430	
258	 steps: training loss - 0.61595	, testing loss - 0.57398	
259	 steps: training loss - 0.64134	, testing loss - 0.57366	
260	 steps: training loss - 0.57967	, testing loss - 0.57340	
261	 steps: training loss - 0.62337	, testing loss - 0.57312	
262	 steps: training loss - 0.65041	, testing loss - 0.57266	
263	 steps: training loss - 0.64558	, testing loss - 0.57222	
264	 steps: training loss - 0.59769	, testing loss - 0.57172	
265	 steps: training loss - 0.65237	, testing loss - 0.57121	
266	 steps: training loss - 0.66028	, testing loss - 0.57077	
267	 steps: training loss - 0.65164	, testing loss - 0.57036	
268	 steps: training loss - 0.65711	, testing loss - 0.56992	
269	 steps: training loss - 0.66312	, testing loss - 0.56952	
270	 steps: training loss - 0.58989	, testing loss - 0.56919	
271	 steps: training loss - 0.59533	, testing loss - 0.56890	
272	 steps: training loss - 0.62532	, testing loss - 0.56858	
273	 steps: training loss - 0.61727	, testing loss - 0.56827	
274	 steps: training loss - 0.58470	, testing loss - 0.56788	
275	 steps: training loss - 0.66595	, testing loss - 0.56745	
276	 steps: training loss - 0.62775	, testing loss - 0.56697	
277	 steps: training loss - 0.56464	, testing loss - 0.56645	
278	 steps: training loss - 0.62165	, testing loss - 0.56596	
279	 steps: training loss - 0.58743	, testing loss - 0.56551	
280	 steps: training loss - 0.57248	, testing loss - 0.56509	
281	 steps: training loss - 0.60192	, testing loss - 0.56465	
282	 steps: training loss - 0.54609	, testing loss - 0.56424	
283	 steps: training loss - 0.62682	, testing loss - 0.56385	
284	 steps: training loss - 0.65188	, testing loss - 0.56346	
285	 steps: training loss - 0.62233	, testing loss - 0.56307	
286	 steps: training loss - 0.62764	, testing loss - 0.56269	
287	 steps: training loss - 0.61918	, testing loss - 0.56234	
288	 steps: training loss - 0.61904	, testing loss - 0.56203	
289	 steps: training loss - 0.61341	, testing loss - 0.56172	
290	 steps: training loss - 0.58973	, testing loss - 0.56139	
291	 steps: training loss - 0.61606	, testing loss - 0.56104	
292	 steps: training loss - 0.57988	, testing loss - 0.56062	
293	 steps: training loss - 0.61725	, testing loss - 0.56015	
294	 steps: training loss - 0.63238	, testing loss - 0.55973	
295	 steps: training loss - 0.62157	, testing loss - 0.55936	
296	 steps: training loss - 0.58614	, testing loss - 0.55895	
297	 steps: training loss - 0.59241	, testing loss - 0.55859	
298	 steps: training loss - 0.60332	, testing loss - 0.55823	
299	 steps: training loss - 0.59122	, testing loss - 0.55786	
300	 steps: training loss - 0.58028	, testing loss - 0.55748	
301	 steps: training loss - 0.63809	, testing loss - 0.55712	
302	 steps: training loss - 0.63622	, testing loss - 0.55678	
303	 steps: training loss - 0.59998	, testing loss - 0.55646	
304	 steps: training loss - 0.61801	, testing loss - 0.55612	
305	 steps: training loss - 0.56441	, testing loss - 0.55578	
306	 steps: training loss - 0.62342	, testing loss - 0.55544	
307	 steps: training loss - 0.65434	, testing loss - 0.55512	
308	 steps: training loss - 0.60368	, testing loss - 0.55483	
309	 steps: training loss - 0.62271	, testing loss - 0.55447	
310	 steps: training loss - 0.61874	, testing loss - 0.55402	
311	 steps: training loss - 0.57954	, testing loss - 0.55352	
312	 steps: training loss - 0.57128	, testing loss - 0.55304	
313	 steps: training loss - 0.58651	, testing loss - 0.55267	
314	 steps: training loss - 0.57402	, testing loss - 0.55235	
315	 steps: training loss - 0.59896	, testing loss - 0.55204	
316	 steps: training loss - 0.59415	, testing loss - 0.55181	
317	 steps: training loss - 0.58455	, testing loss - 0.55158	
318	 steps: training loss - 0.54450	, testing loss - 0.55136	
319	 steps: training loss - 0.66806	, testing loss - 0.55108	
320	 steps: training loss - 0.57258	, testing loss - 0.55083	
321	 steps: training loss - 0.59808	, testing loss - 0.55068	
322	 steps: training loss - 0.56896	, testing loss - 0.55050	
323	 steps: training loss - 0.64611	, testing loss - 0.55041	
324	 steps: training loss - 0.61154	, testing loss - 0.55022	
325	 steps: training loss - 0.58311	, testing loss - 0.54987	
326	 steps: training loss - 0.56816	, testing loss - 0.54951	
327	 steps: training loss - 0.61695	, testing loss - 0.54916	
328	 steps: training loss - 0.62750	, testing loss - 0.54877	
329	 steps: training loss - 0.62978	, testing loss - 0.54829	
330	 steps: training loss - 0.61794	, testing loss - 0.54778	
331	 steps: training loss - 0.60037	, testing loss - 0.54726	
332	 steps: training loss - 0.66552	, testing loss - 0.54677	
333	 steps: training loss - 0.51037	, testing loss - 0.54633	
334	 steps: training loss - 0.57126	, testing loss - 0.54588	
335	 steps: training loss - 0.59174	, testing loss - 0.54540	
336	 steps: training loss - 0.60556	, testing loss - 0.54501	
337	 steps: training loss - 0.67084	, testing loss - 0.54474	
338	 steps: training loss - 0.55814	, testing loss - 0.54446	
339	 steps: training loss - 0.64693	, testing loss - 0.54416	
340	 steps: training loss - 0.54535	, testing loss - 0.54384	
341	 steps: training loss - 0.54001	, testing loss - 0.54344	
342	 steps: training loss - 0.58731	, testing loss - 0.54307	
343	 steps: training loss - 0.63201	, testing loss - 0.54272	
344	 steps: training loss - 0.57759	, testing loss - 0.54238	
345	 steps: training loss - 0.61669	, testing loss - 0.54196	
346	 steps: training loss - 0.57409	, testing loss - 0.54151	
347	 steps: training loss - 0.53597	, testing loss - 0.54105	
348	 steps: training loss - 0.62773	, testing loss - 0.54070	
349	 steps: training loss - 0.54249	, testing loss - 0.54032	
350	 steps: training loss - 0.58642	, testing loss - 0.53998	
351	 steps: training loss - 0.57658	, testing loss - 0.53968	
352	 steps: training loss - 0.59315	, testing loss - 0.53935	
353	 steps: training loss - 0.62300	, testing loss - 0.53903	
354	 steps: training loss - 0.60581	, testing loss - 0.53868	
355	 steps: training loss - 0.61358	, testing loss - 0.53830	
356	 steps: training loss - 0.58984	, testing loss - 0.53798	
357	 steps: training loss - 0.62004	, testing loss - 0.53764	
358	 steps: training loss - 0.60466	, testing loss - 0.53730	
359	 steps: training loss - 0.61353	, testing loss - 0.53698	
360	 steps: training loss - 0.62436	, testing loss - 0.53670	
361	 steps: training loss - 0.53699	, testing loss - 0.53649	
362	 steps: training loss - 0.59261	, testing loss - 0.53628	
363	 steps: training loss - 0.64185	, testing loss - 0.53604	
364	 steps: training loss - 0.61883	, testing loss - 0.53579	
365	 steps: training loss - 0.66372	, testing loss - 0.53557	
366	 steps: training loss - 0.54097	, testing loss - 0.53525	
367	 steps: training loss - 0.57335	, testing loss - 0.53492	
368	 steps: training loss - 0.54166	, testing loss - 0.53463	
369	 steps: training loss - 0.56257	, testing loss - 0.53433	
370	 steps: training loss - 0.57199	, testing loss - 0.53404	
371	 steps: training loss - 0.57791	, testing loss - 0.53376	
372	 steps: training loss - 0.56930	, testing loss - 0.53347	
373	 steps: training loss - 0.59343	, testing loss - 0.53325	
374	 steps: training loss - 0.60587	, testing loss - 0.53298	
375	 steps: training loss - 0.60744	, testing loss - 0.53268	
376	 steps: training loss - 0.64129	, testing loss - 0.53233	
377	 steps: training loss - 0.57936	, testing loss - 0.53190	
378	 steps: training loss - 0.62629	, testing loss - 0.53151	
379	 steps: training loss - 0.59335	, testing loss - 0.53127	
380	 steps: training loss - 0.57619	, testing loss - 0.53106	
381	 steps: training loss - 0.61020	, testing loss - 0.53081	
382	 steps: training loss - 0.55409	, testing loss - 0.53058	
383	 steps: training loss - 0.62179	, testing loss - 0.53037	
384	 steps: training loss - 0.63081	, testing loss - 0.53004	
385	 steps: training loss - 0.55904	, testing loss - 0.52969	
386	 steps: training loss - 0.51661	, testing loss - 0.52929	
387	 steps: training loss - 0.55821	, testing loss - 0.52890	
388	 steps: training loss - 0.61380	, testing loss - 0.52856	
389	 steps: training loss - 0.52531	, testing loss - 0.52827	
390	 steps: training loss - 0.55916	, testing loss - 0.52789	
391	 steps: training loss - 0.63778	, testing loss - 0.52741	
392	 steps: training loss - 0.51905	, testing loss - 0.52699	
393	 steps: training loss - 0.57162	, testing loss - 0.52662	
394	 steps: training loss - 0.61197	, testing loss - 0.52630	
395	 steps: training loss - 0.55962	, testing loss - 0.52601	
396	 steps: training loss - 0.58276	, testing loss - 0.52570	
397	 steps: training loss - 0.57912	, testing loss - 0.52534	
398	 steps: training loss - 0.62314	, testing loss - 0.52495	
399	 steps: training loss - 0.63123	, testing loss - 0.52452	
400	 steps: training loss - 0.65285	, testing loss - 0.52407	
401	 steps: training loss - 0.59000	, testing loss - 0.52364	
402	 steps: training loss - 0.54896	, testing loss - 0.52327	
403	 steps: training loss - 0.58177	, testing loss - 0.52294	
404	 steps: training loss - 0.59316	, testing loss - 0.52269	
405	 steps: training loss - 0.63492	, testing loss - 0.52243	
406	 steps: training loss - 0.59660	, testing loss - 0.52221	
407	 steps: training loss - 0.52485	, testing loss - 0.52209	
408	 steps: training loss - 0.65780	, testing loss - 0.52204	
409	 steps: training loss - 0.58869	, testing loss - 0.52196	
410	 steps: training loss - 0.56648	, testing loss - 0.52177	
411	 steps: training loss - 0.61452	, testing loss - 0.52148	
412	 steps: training loss - 0.64860	, testing loss - 0.52111	
413	 steps: training loss - 0.58397	, testing loss - 0.52073	
414	 steps: training loss - 0.65698	, testing loss - 0.52034	
415	 steps: training loss - 0.64405	, testing loss - 0.51994	
416	 steps: training loss - 0.57409	, testing loss - 0.51956	
417	 steps: training loss - 0.53148	, testing loss - 0.51920	
418	 steps: training loss - 0.57180	, testing loss - 0.51882	
419	 steps: training loss - 0.61121	, testing loss - 0.51840	
420	 steps: training loss - 0.65110	, testing loss - 0.51792	
421	 steps: training loss - 0.57046	, testing loss - 0.51741	
422	 steps: training loss - 0.56391	, testing loss - 0.51698	
423	 steps: training loss - 0.53577	, testing loss - 0.51662	
424	 steps: training loss - 0.60832	, testing loss - 0.51625	
425	 steps: training loss - 0.60759	, testing loss - 0.51590	
426	 steps: training loss - 0.64042	, testing loss - 0.51557	
427	 steps: training loss - 0.55959	, testing loss - 0.51520	
428	 steps: training loss - 0.61964	, testing loss - 0.51475	
429	 steps: training loss - 0.62968	, testing loss - 0.51440	
430	 steps: training loss - 0.57417	, testing loss - 0.51412	
431	 steps: training loss - 0.60581	, testing loss - 0.51386	
432	 steps: training loss - 0.57259	, testing loss - 0.51364	
433	 steps: training loss - 0.61146	, testing loss - 0.51345	
434	 steps: training loss - 0.56277	, testing loss - 0.51323	
435	 steps: training loss - 0.60332	, testing loss - 0.51304	
436	 steps: training loss - 0.65344	, testing loss - 0.51290	
437	 steps: training loss - 0.58977	, testing loss - 0.51275	
438	 steps: training loss - 0.62857	, testing loss - 0.51259	
439	 steps: training loss - 0.57650	, testing loss - 0.51243	
440	 steps: training loss - 0.56158	, testing loss - 0.51224	
441	 steps: training loss - 0.56029	, testing loss - 0.51197	
442	 steps: training loss - 0.61534	, testing loss - 0.51168	
443	 steps: training loss - 0.51985	, testing loss - 0.51144	
444	 steps: training loss - 0.53925	, testing loss - 0.51124	
445	 steps: training loss - 0.55321	, testing loss - 0.51105	
446	 steps: training loss - 0.53790	, testing loss - 0.51082	
447	 steps: training loss - 0.53994	, testing loss - 0.51054	
448	 steps: training loss - 0.67441	, testing loss - 0.51018	
449	 steps: training loss - 0.59838	, testing loss - 0.50983	
450	 steps: training loss - 0.65289	, testing loss - 0.50936	
451	 steps: training loss - 0.60095	, testing loss - 0.50893	
452	 steps: training loss - 0.58037	, testing loss - 0.50860	
453	 steps: training loss - 0.57236	, testing loss - 0.50820	
454	 steps: training loss - 0.61585	, testing loss - 0.50782	
455	 steps: training loss - 0.61902	, testing loss - 0.50737	
456	 steps: training loss - 0.56233	, testing loss - 0.50695	
457	 steps: training loss - 0.60678	, testing loss - 0.50663	
458	 steps: training loss - 0.58804	, testing loss - 0.50627	
459	 steps: training loss - 0.56059	, testing loss - 0.50592	
460	 steps: training loss - 0.57702	, testing loss - 0.50557	
461	 steps: training loss - 0.57637	, testing loss - 0.50523	
462	 steps: training loss - 0.49949	, testing loss - 0.50483	
463	 steps: training loss - 0.57552	, testing loss - 0.50443	
464	 steps: training loss - 0.57667	, testing loss - 0.50407	
465	 steps: training loss - 0.64509	, testing loss - 0.50377	
466	 steps: training loss - 0.50950	, testing loss - 0.50341	
467	 steps: training loss - 0.58963	, testing loss - 0.50304	
468	 steps: training loss - 0.59634	, testing loss - 0.50274	
469	 steps: training loss - 0.59939	, testing loss - 0.50243	
470	 steps: training loss - 0.59005	, testing loss - 0.50210	
471	 steps: training loss - 0.60120	, testing loss - 0.50181	
472	 steps: training loss - 0.51218	, testing loss - 0.50160	
473	 steps: training loss - 0.64190	, testing loss - 0.50141	
474	 steps: training loss - 0.59804	, testing loss - 0.50124	
475	 steps: training loss - 0.57509	, testing loss - 0.50105	
476	 steps: training loss - 0.55454	, testing loss - 0.50075	
477	 steps: training loss - 0.64409	, testing loss - 0.50041	
478	 steps: training loss - 0.63954	, testing loss - 0.50007	
479	 steps: training loss - 0.56027	, testing loss - 0.49973	
480	 steps: training loss - 0.56460	, testing loss - 0.49934	
481	 steps: training loss - 0.52415	, testing loss - 0.49894	
482	 steps: training loss - 0.53199	, testing loss - 0.49857	
483	 steps: training loss - 0.56612	, testing loss - 0.49826	
484	 steps: training loss - 0.65325	, testing loss - 0.49798	
485	 steps: training loss - 0.62258	, testing loss - 0.49769	
486	 steps: training loss - 0.62182	, testing loss - 0.49739	
487	 steps: training loss - 0.56412	, testing loss - 0.49705	
488	 steps: training loss - 0.55877	, testing loss - 0.49669	
489	 steps: training loss - 0.52716	, testing loss - 0.49635	
490	 steps: training loss - 0.54334	, testing loss - 0.49600	
491	 steps: training loss - 0.60592	, testing loss - 0.49571	
492	 steps: training loss - 0.60184	, testing loss - 0.49545	
493	 steps: training loss - 0.54824	, testing loss - 0.49522	
494	 steps: training loss - 0.57827	, testing loss - 0.49497	
495	 steps: training loss - 0.57245	, testing loss - 0.49470	
496	 steps: training loss - 0.54982	, testing loss - 0.49443	
497	 steps: training loss - 0.63951	, testing loss - 0.49418	
498	 steps: training loss - 0.55349	, testing loss - 0.49388	
499	 steps: training loss - 0.60437	, testing loss - 0.49353	
500	 steps: training loss - 0.55694	, testing loss - 0.49320	
501	 steps: training loss - 0.58652	, testing loss - 0.49287	
502	 steps: training loss - 0.55112	, testing loss - 0.49253	
503	 steps: training loss - 0.62384	, testing loss - 0.49221	
504	 steps: training loss - 0.65681	, testing loss - 0.49194	
505	 steps: training loss - 0.55192	, testing loss - 0.49168	
506	 steps: training loss - 0.53871	, testing loss - 0.49144	
507	 steps: training loss - 0.52644	, testing loss - 0.49115	
508	 steps: training loss - 0.56804	, testing loss - 0.49089	
509	 steps: training loss - 0.54321	, testing loss - 0.49064	
510	 steps: training loss - 0.49465	, testing loss - 0.49035	
511	 steps: training loss - 0.60217	, testing loss - 0.49006	
512	 steps: training loss - 0.58367	, testing loss - 0.48983	
513	 steps: training loss - 0.61145	, testing loss - 0.48958	
514	 steps: training loss - 0.59608	, testing loss - 0.48931	
515	 steps: training loss - 0.54137	, testing loss - 0.48894	
516	 steps: training loss - 0.52689	, testing loss - 0.48854	
517	 steps: training loss - 0.49576	, testing loss - 0.48815	
518	 steps: training loss - 0.58181	, testing loss - 0.48774	
519	 steps: training loss - 0.58927	, testing loss - 0.48738	
520	 steps: training loss - 0.52703	, testing loss - 0.48704	
521	 steps: training loss - 0.54569	, testing loss - 0.48673	
522	 steps: training loss - 0.56492	, testing loss - 0.48645	
523	 steps: training loss - 0.55210	, testing loss - 0.48618	
524	 steps: training loss - 0.58341	, testing loss - 0.48588	
525	 steps: training loss - 0.61175	, testing loss - 0.48558	
526	 steps: training loss - 0.51826	, testing loss - 0.48528	
527	 steps: training loss - 0.51166	, testing loss - 0.48503	
528	 steps: training loss - 0.55329	, testing loss - 0.48475	
529	 steps: training loss - 0.60092	, testing loss - 0.48440	
530	 steps: training loss - 0.54978	, testing loss - 0.48416	
531	 steps: training loss - 0.57619	, testing loss - 0.48392	
532	 steps: training loss - 0.56756	, testing loss - 0.48376	
533	 steps: training loss - 0.59907	, testing loss - 0.48358	
534	 steps: training loss - 0.55858	, testing loss - 0.48342	
535	 steps: training loss - 0.57531	, testing loss - 0.48325	
536	 steps: training loss - 0.50848	, testing loss - 0.48310	
537	 steps: training loss - 0.51682	, testing loss - 0.48291	
538	 steps: training loss - 0.59196	, testing loss - 0.48267	
539	 steps: training loss - 0.56622	, testing loss - 0.48240	
540	 steps: training loss - 0.56821	, testing loss - 0.48211	
541	 steps: training loss - 0.59857	, testing loss - 0.48178	
542	 steps: training loss - 0.67758	, testing loss - 0.48140	
543	 steps: training loss - 0.62109	, testing loss - 0.48104	
544	 steps: training loss - 0.48334	, testing loss - 0.48073	
545	 steps: training loss - 0.55626	, testing loss - 0.48044	
546	 steps: training loss - 0.62989	, testing loss - 0.48017	
547	 steps: training loss - 0.64483	, testing loss - 0.47992	
548	 steps: training loss - 0.57053	, testing loss - 0.47962	
549	 steps: training loss - 0.61234	, testing loss - 0.47940	
550	 steps: training loss - 0.57498	, testing loss - 0.47915	
551	 steps: training loss - 0.58344	, testing loss - 0.47884	
552	 steps: training loss - 0.56593	, testing loss - 0.47855	
553	 steps: training loss - 0.52240	, testing loss - 0.47828	
554	 steps: training loss - 0.55242	, testing loss - 0.47805	
555	 steps: training loss - 0.53309	, testing loss - 0.47783	
556	 steps: training loss - 0.58445	, testing loss - 0.47764	
557	 steps: training loss - 0.49503	, testing loss - 0.47741	
558	 steps: training loss - 0.51282	, testing loss - 0.47717	
559	 steps: training loss - 0.61152	, testing loss - 0.47691	
560	 steps: training loss - 0.57100	, testing loss - 0.47662	
561	 steps: training loss - 0.57706	, testing loss - 0.47634	
562	 steps: training loss - 0.57067	, testing loss - 0.47606	
563	 steps: training loss - 0.56534	, testing loss - 0.47581	
564	 steps: training loss - 0.60466	, testing loss - 0.47557	
565	 steps: training loss - 0.60086	, testing loss - 0.47539	
566	 steps: training loss - 0.62616	, testing loss - 0.47524	
567	 steps: training loss - 0.58593	, testing loss - 0.47503	
568	 steps: training loss - 0.56855	, testing loss - 0.47481	
569	 steps: training loss - 0.60033	, testing loss - 0.47458	
570	 steps: training loss - 0.56100	, testing loss - 0.47440	
571	 steps: training loss - 0.57833	, testing loss - 0.47425	
572	 steps: training loss - 0.57071	, testing loss - 0.47410	
573	 steps: training loss - 0.53950	, testing loss - 0.47392	
574	 steps: training loss - 0.59216	, testing loss - 0.47371	
575	 steps: training loss - 0.54948	, testing loss - 0.47339	
576	 steps: training loss - 0.64253	, testing loss - 0.47304	
577	 steps: training loss - 0.53579	, testing loss - 0.47277	
578	 steps: training loss - 0.52955	, testing loss - 0.47256	
579	 steps: training loss - 0.60882	, testing loss - 0.47238	
580	 steps: training loss - 0.63212	, testing loss - 0.47217	
581	 steps: training loss - 0.62699	, testing loss - 0.47201	
582	 steps: training loss - 0.60496	, testing loss - 0.47189	
583	 steps: training loss - 0.59215	, testing loss - 0.47178	
584	 steps: training loss - 0.59821	, testing loss - 0.47167	
585	 steps: training loss - 0.54402	, testing loss - 0.47153	
586	 steps: training loss - 0.53858	, testing loss - 0.47140	
587	 steps: training loss - 0.54649	, testing loss - 0.47128	
588	 steps: training loss - 0.50386	, testing loss - 0.47122	
589	 steps: training loss - 0.55703	, testing loss - 0.47122	
590	 steps: training loss - 0.57505	, testing loss - 0.47124	
591	 steps: training loss - 0.46519	, testing loss - 0.47106	
592	 steps: training loss - 0.54398	, testing loss - 0.47079	
593	 steps: training loss - 0.57893	, testing loss - 0.47055	
594	 steps: training loss - 0.55921	, testing loss - 0.47031	
595	 steps: training loss - 0.57374	, testing loss - 0.47008	
596	 steps: training loss - 0.59846	, testing loss - 0.46994	
597	 steps: training loss - 0.59696	, testing loss - 0.46986	
598	 steps: training loss - 0.52308	, testing loss - 0.46976	
599	 steps: training loss - 0.57189	, testing loss - 0.46966	
600	 steps: training loss - 0.57903	, testing loss - 0.46937	
601	 steps: training loss - 0.56940	, testing loss - 0.46908	
602	 steps: training loss - 0.56713	, testing loss - 0.46879	
603	 steps: training loss - 0.53476	, testing loss - 0.46845	
604	 steps: training loss - 0.55901	, testing loss - 0.46807	
605	 steps: training loss - 0.51507	, testing loss - 0.46778	
606	 steps: training loss - 0.55920	, testing loss - 0.46748	
607	 steps: training loss - 0.53666	, testing loss - 0.46716	
608	 steps: training loss - 0.52375	, testing loss - 0.46684	
609	 steps: training loss - 0.57169	, testing loss - 0.46646	
610	 steps: training loss - 0.50700	, testing loss - 0.46605	
611	 steps: training loss - 0.59881	, testing loss - 0.46568	
612	 steps: training loss - 0.55646	, testing loss - 0.46536	
613	 steps: training loss - 0.50589	, testing loss - 0.46509	
614	 steps: training loss - 0.60493	, testing loss - 0.46477	
615	 steps: training loss - 0.59527	, testing loss - 0.46442	
616	 steps: training loss - 0.50216	, testing loss - 0.46409	
617	 steps: training loss - 0.63001	, testing loss - 0.46372	
618	 steps: training loss - 0.56375	, testing loss - 0.46344	
619	 steps: training loss - 0.59388	, testing loss - 0.46317	
620	 steps: training loss - 0.53804	, testing loss - 0.46289	
621	 steps: training loss - 0.59267	, testing loss - 0.46256	
622	 steps: training loss - 0.49369	, testing loss - 0.46215	
623	 steps: training loss - 0.55304	, testing loss - 0.46177	
624	 steps: training loss - 0.60725	, testing loss - 0.46139	
625	 steps: training loss - 0.55744	, testing loss - 0.46099	
626	 steps: training loss - 0.52485	, testing loss - 0.46055	
627	 steps: training loss - 0.52373	, testing loss - 0.46011	
628	 steps: training loss - 0.54144	, testing loss - 0.45970	
629	 steps: training loss - 0.53295	, testing loss - 0.45935	
630	 steps: training loss - 0.68537	, testing loss - 0.45900	
631	 steps: training loss - 0.64588	, testing loss - 0.45865	
632	 steps: training loss - 0.50842	, testing loss - 0.45832	
633	 steps: training loss - 0.47565	, testing loss - 0.45802	
634	 steps: training loss - 0.51700	, testing loss - 0.45774	
635	 steps: training loss - 0.57120	, testing loss - 0.45747	
636	 steps: training loss - 0.57096	, testing loss - 0.45718	
637	 steps: training loss - 0.49132	, testing loss - 0.45686	
638	 steps: training loss - 0.56301	, testing loss - 0.45651	
639	 steps: training loss - 0.66342	, testing loss - 0.45624	
640	 steps: training loss - 0.56825	, testing loss - 0.45600	
641	 steps: training loss - 0.55130	, testing loss - 0.45580	
642	 steps: training loss - 0.56778	, testing loss - 0.45563	
643	 steps: training loss - 0.58352	, testing loss - 0.45546	
644	 steps: training loss - 0.44415	, testing loss - 0.45525	
645	 steps: training loss - 0.56248	, testing loss - 0.45497	
646	 steps: training loss - 0.61580	, testing loss - 0.45467	
647	 steps: training loss - 0.62126	, testing loss - 0.45434	
648	 steps: training loss - 0.52933	, testing loss - 0.45403	
649	 steps: training loss - 0.47935	, testing loss - 0.45376	
650	 steps: training loss - 0.52082	, testing loss - 0.45352	
651	 steps: training loss - 0.48221	, testing loss - 0.45331	
652	 steps: training loss - 0.53873	, testing loss - 0.45311	
653	 steps: training loss - 0.55982	, testing loss - 0.45290	
654	 steps: training loss - 0.53374	, testing loss - 0.45269	
655	 steps: training loss - 0.59642	, testing loss - 0.45249	
656	 steps: training loss - 0.54829	, testing loss - 0.45226	
657	 steps: training loss - 0.58777	, testing loss - 0.45203	
658	 steps: training loss - 0.53403	, testing loss - 0.45170	
659	 steps: training loss - 0.52465	, testing loss - 0.45141	
660	 steps: training loss - 0.58146	, testing loss - 0.45115	
661	 steps: training loss - 0.53341	, testing loss - 0.45095	
662	 steps: training loss - 0.55716	, testing loss - 0.45076	
663	 steps: training loss - 0.51602	, testing loss - 0.45059	
664	 steps: training loss - 0.55539	, testing loss - 0.45046	
665	 steps: training loss - 0.60109	, testing loss - 0.45032	
666	 steps: training loss - 0.57921	, testing loss - 0.45021	
667	 steps: training loss - 0.55066	, testing loss - 0.45009	
668	 steps: training loss - 0.53341	, testing loss - 0.44995	
669	 steps: training loss - 0.50582	, testing loss - 0.44982	
670	 steps: training loss - 0.64035	, testing loss - 0.44976	
671	 steps: training loss - 0.56177	, testing loss - 0.44967	
672	 steps: training loss - 0.60043	, testing loss - 0.44949	
673	 steps: training loss - 0.50876	, testing loss - 0.44926	
674	 steps: training loss - 0.54886	, testing loss - 0.44897	
675	 steps: training loss - 0.57345	, testing loss - 0.44867	
676	 steps: training loss - 0.58419	, testing loss - 0.44847	
677	 steps: training loss - 0.59212	, testing loss - 0.44832	
678	 steps: training loss - 0.55435	, testing loss - 0.44822	
679	 steps: training loss - 0.53412	, testing loss - 0.44810	
680	 steps: training loss - 0.53262	, testing loss - 0.44798	
681	 steps: training loss - 0.60453	, testing loss - 0.44796	
682	 steps: training loss - 0.57503	, testing loss - 0.44792	
683	 steps: training loss - 0.54848	, testing loss - 0.44785	
684	 steps: training loss - 0.54876	, testing loss - 0.44773	
685	 steps: training loss - 0.51738	, testing loss - 0.44755	
686	 steps: training loss - 0.61762	, testing loss - 0.44733	
687	 steps: training loss - 0.53966	, testing loss - 0.44714	
688	 steps: training loss - 0.58886	, testing loss - 0.44696	
689	 steps: training loss - 0.55900	, testing loss - 0.44675	
690	 steps: training loss - 0.61978	, testing loss - 0.44654	
691	 steps: training loss - 0.57392	, testing loss - 0.44630	
692	 steps: training loss - 0.59047	, testing loss - 0.44605	
693	 steps: training loss - 0.66420	, testing loss - 0.44586	
694	 steps: training loss - 0.49441	, testing loss - 0.44573	
695	 steps: training loss - 0.48270	, testing loss - 0.44556	
696	 steps: training loss - 0.55190	, testing loss - 0.44533	
697	 steps: training loss - 0.58501	, testing loss - 0.44513	
698	 steps: training loss - 0.57203	, testing loss - 0.44495	
699	 steps: training loss - 0.56047	, testing loss - 0.44480	
700	 steps: training loss - 0.51973	, testing loss - 0.44472	
701	 steps: training loss - 0.53908	, testing loss - 0.44459	
702	 steps: training loss - 0.58936	, testing loss - 0.44441	
703	 steps: training loss - 0.53496	, testing loss - 0.44420	
704	 steps: training loss - 0.55046	, testing loss - 0.44392	
705	 steps: training loss - 0.67180	, testing loss - 0.44366	
706	 steps: training loss - 0.49915	, testing loss - 0.44341	
707	 steps: training loss - 0.57954	, testing loss - 0.44312	
708	 steps: training loss - 0.61516	, testing loss - 0.44284	
709	 steps: training loss - 0.55817	, testing loss - 0.44258	
710	 steps: training loss - 0.49388	, testing loss - 0.44235	
711	 steps: training loss - 0.57105	, testing loss - 0.44216	
712	 steps: training loss - 0.52424	, testing loss - 0.44200	
713	 steps: training loss - 0.63901	, testing loss - 0.44189	
714	 steps: training loss - 0.62211	, testing loss - 0.44185	
715	 steps: training loss - 0.56713	, testing loss - 0.44177	
716	 steps: training loss - 0.49729	, testing loss - 0.44170	
717	 steps: training loss - 0.55718	, testing loss - 0.44167	
718	 steps: training loss - 0.48415	, testing loss - 0.44151	
719	 steps: training loss - 0.51215	, testing loss - 0.44130	
720	 steps: training loss - 0.56871	, testing loss - 0.44104	
721	 steps: training loss - 0.59015	, testing loss - 0.44070	
722	 steps: training loss - 0.58159	, testing loss - 0.44038	
723	 steps: training loss - 0.49014	, testing loss - 0.44015	
724	 steps: training loss - 0.49994	, testing loss - 0.43990	
725	 steps: training loss - 0.55004	, testing loss - 0.43968	
726	 steps: training loss - 0.56998	, testing loss - 0.43936	
727	 steps: training loss - 0.58170	, testing loss - 0.43903	
728	 steps: training loss - 0.57434	, testing loss - 0.43866	
729	 steps: training loss - 0.55156	, testing loss - 0.43829	
730	 steps: training loss - 0.41655	, testing loss - 0.43802	
731	 steps: training loss - 0.59124	, testing loss - 0.43770	
732	 steps: training loss - 0.58313	, testing loss - 0.43727	
733	 steps: training loss - 0.44584	, testing loss - 0.43679	
734	 steps: training loss - 0.55565	, testing loss - 0.43635	
735	 steps: training loss - 0.60790	, testing loss - 0.43601	
736	 steps: training loss - 0.55004	, testing loss - 0.43575	
737	 steps: training loss - 0.63237	, testing loss - 0.43553	
738	 steps: training loss - 0.50716	, testing loss - 0.43535	
739	 steps: training loss - 0.51202	, testing loss - 0.43512	
740	 steps: training loss - 0.51575	, testing loss - 0.43485	
741	 steps: training loss - 0.45614	, testing loss - 0.43458	
742	 steps: training loss - 0.57353	, testing loss - 0.43435	
743	 steps: training loss - 0.54394	, testing loss - 0.43413	
744	 steps: training loss - 0.56404	, testing loss - 0.43391	
745	 steps: training loss - 0.58732	, testing loss - 0.43372	
746	 steps: training loss - 0.61252	, testing loss - 0.43356	
747	 steps: training loss - 0.56388	, testing loss - 0.43345	
748	 steps: training loss - 0.52426	, testing loss - 0.43331	
749	 steps: training loss - 0.55546	, testing loss - 0.43317	
750	 steps: training loss - 0.55911	, testing loss - 0.43295	
751	 steps: training loss - 0.53673	, testing loss - 0.43269	
752	 steps: training loss - 0.52896	, testing loss - 0.43251	
753	 steps: training loss - 0.49872	, testing loss - 0.43234	
754	 steps: training loss - 0.50144	, testing loss - 0.43216	
755	 steps: training loss - 0.57682	, testing loss - 0.43197	
756	 steps: training loss - 0.50712	, testing loss - 0.43177	
757	 steps: training loss - 0.47136	, testing loss - 0.43157	
758	 steps: training loss - 0.64638	, testing loss - 0.43138	
759	 steps: training loss - 0.51073	, testing loss - 0.43112	
760	 steps: training loss - 0.54120	, testing loss - 0.43085	
761	 steps: training loss - 0.53878	, testing loss - 0.43053	
762	 steps: training loss - 0.51825	, testing loss - 0.43017	
763	 steps: training loss - 0.48116	, testing loss - 0.42981	
764	 steps: training loss - 0.51303	, testing loss - 0.42941	
765	 steps: training loss - 0.49446	, testing loss - 0.42899	
766	 steps: training loss - 0.63100	, testing loss - 0.42854	
767	 steps: training loss - 0.54032	, testing loss - 0.42809	
768	 steps: training loss - 0.45594	, testing loss - 0.42772	
769	 steps: training loss - 0.60571	, testing loss - 0.42742	
770	 steps: training loss - 0.57311	, testing loss - 0.42716	
771	 steps: training loss - 0.54887	, testing loss - 0.42696	
772	 steps: training loss - 0.44551	, testing loss - 0.42678	
773	 steps: training loss - 0.58175	, testing loss - 0.42657	
774	 steps: training loss - 0.54346	, testing loss - 0.42638	
775	 steps: training loss - 0.56929	, testing loss - 0.42615	
776	 steps: training loss - 0.55943	, testing loss - 0.42591	
777	 steps: training loss - 0.58551	, testing loss - 0.42569	
778	 steps: training loss - 0.53856	, testing loss - 0.42551	
779	 steps: training loss - 0.49934	, testing loss - 0.42534	
780	 steps: training loss - 0.66537	, testing loss - 0.42512	
781	 steps: training loss - 0.52384	, testing loss - 0.42493	
782	 steps: training loss - 0.48956	, testing loss - 0.42475	
783	 steps: training loss - 0.58107	, testing loss - 0.42457	
784	 steps: training loss - 0.50249	, testing loss - 0.42441	
785	 steps: training loss - 0.67005	, testing loss - 0.42428	
786	 steps: training loss - 0.56276	, testing loss - 0.42419	
787	 steps: training loss - 0.54982	, testing loss - 0.42409	
788	 steps: training loss - 0.45828	, testing loss - 0.42395	
789	 steps: training loss - 0.51325	, testing loss - 0.42376	
790	 steps: training loss - 0.47815	, testing loss - 0.42351	
791	 steps: training loss - 0.52438	, testing loss - 0.42322	
792	 steps: training loss - 0.56397	, testing loss - 0.42298	
793	 steps: training loss - 0.48562	, testing loss - 0.42272	
794	 steps: training loss - 0.54149	, testing loss - 0.42242	
795	 steps: training loss - 0.49184	, testing loss - 0.42215	
796	 steps: training loss - 0.53795	, testing loss - 0.42189	
797	 steps: training loss - 0.59621	, testing loss - 0.42166	
798	 steps: training loss - 0.54200	, testing loss - 0.42142	
799	 steps: training loss - 0.60514	, testing loss - 0.42117	
800	 steps: training loss - 0.49189	, testing loss - 0.42091	
801	 steps: training loss - 0.57754	, testing loss - 0.42068	
802	 steps: training loss - 0.56989	, testing loss - 0.42044	
803	 steps: training loss - 0.54754	, testing loss - 0.42023	
804	 steps: training loss - 0.58935	, testing loss - 0.42005	
805	 steps: training loss - 0.55951	, testing loss - 0.41988	
806	 steps: training loss - 0.52082	, testing loss - 0.41973	
807	 steps: training loss - 0.51401	, testing loss - 0.41956	
808	 steps: training loss - 0.49480	, testing loss - 0.41936	
809	 steps: training loss - 0.56731	, testing loss - 0.41915	
810	 steps: training loss - 0.55726	, testing loss - 0.41896	
811	 steps: training loss - 0.49788	, testing loss - 0.41877	
812	 steps: training loss - 0.55595	, testing loss - 0.41856	
813	 steps: training loss - 0.51365	, testing loss - 0.41837	
814	 steps: training loss - 0.50507	, testing loss - 0.41817	
815	 steps: training loss - 0.53937	, testing loss - 0.41797	
816	 steps: training loss - 0.58173	, testing loss - 0.41776	
817	 steps: training loss - 0.60921	, testing loss - 0.41760	
818	 steps: training loss - 0.51830	, testing loss - 0.41749	
819	 steps: training loss - 0.57552	, testing loss - 0.41737	
820	 steps: training loss - 0.56677	, testing loss - 0.41729	
821	 steps: training loss - 0.54748	, testing loss - 0.41721	
822	 steps: training loss - 0.47976	, testing loss - 0.41710	
823	 steps: training loss - 0.60399	, testing loss - 0.41693	
824	 steps: training loss - 0.48693	, testing loss - 0.41677	
825	 steps: training loss - 0.61763	, testing loss - 0.41660	
826	 steps: training loss - 0.46165	, testing loss - 0.41645	
827	 steps: training loss - 0.47768	, testing loss - 0.41628	
828	 steps: training loss - 0.40989	, testing loss - 0.41605	
829	 steps: training loss - 0.52869	, testing loss - 0.41581	
830	 steps: training loss - 0.53910	, testing loss - 0.41562	
831	 steps: training loss - 0.57164	, testing loss - 0.41547	
832	 steps: training loss - 0.58859	, testing loss - 0.41536	
833	 steps: training loss - 0.58335	, testing loss - 0.41533	
834	 steps: training loss - 0.57065	, testing loss - 0.41528	
835	 steps: training loss - 0.58644	, testing loss - 0.41516	
836	 steps: training loss - 0.57088	, testing loss - 0.41506	
837	 steps: training loss - 0.53464	, testing loss - 0.41502	
838	 steps: training loss - 0.63168	, testing loss - 0.41493	
839	 steps: training loss - 0.51554	, testing loss - 0.41479	
840	 steps: training loss - 0.55282	, testing loss - 0.41457	
841	 steps: training loss - 0.61295	, testing loss - 0.41434	
842	 steps: training loss - 0.55992	, testing loss - 0.41414	
843	 steps: training loss - 0.61426	, testing loss - 0.41395	
844	 steps: training loss - 0.53769	, testing loss - 0.41379	
845	 steps: training loss - 0.55392	, testing loss - 0.41367	
846	 steps: training loss - 0.56902	, testing loss - 0.41356	
847	 steps: training loss - 0.50425	, testing loss - 0.41341	
848	 steps: training loss - 0.56223	, testing loss - 0.41324	
849	 steps: training loss - 0.43483	, testing loss - 0.41305	
850	 steps: training loss - 0.50130	, testing loss - 0.41290	
851	 steps: training loss - 0.59091	, testing loss - 0.41273	
852	 steps: training loss - 0.58446	, testing loss - 0.41254	
853	 steps: training loss - 0.55623	, testing loss - 0.41242	
854	 steps: training loss - 0.59250	, testing loss - 0.41233	
855	 steps: training loss - 0.42274	, testing loss - 0.41220	
856	 steps: training loss - 0.61276	, testing loss - 0.41206	
857	 steps: training loss - 0.46490	, testing loss - 0.41192	
858	 steps: training loss - 0.53852	, testing loss - 0.41173	
859	 steps: training loss - 0.49193	, testing loss - 0.41144	
860	 steps: training loss - 0.55097	, testing loss - 0.41116	
861	 steps: training loss - 0.58510	, testing loss - 0.41095	
862	 steps: training loss - 0.46927	, testing loss - 0.41076	
863	 steps: training loss - 0.51956	, testing loss - 0.41057	
864	 steps: training loss - 0.47026	, testing loss - 0.41037	
865	 steps: training loss - 0.52620	, testing loss - 0.41016	
866	 steps: training loss - 0.55350	, testing loss - 0.40999	
867	 steps: training loss - 0.48960	, testing loss - 0.40985	
868	 steps: training loss - 0.54521	, testing loss - 0.40968	
869	 steps: training loss - 0.44334	, testing loss - 0.40954	
870	 steps: training loss - 0.51949	, testing loss - 0.40933	
871	 steps: training loss - 0.49269	, testing loss - 0.40908	
872	 steps: training loss - 0.43957	, testing loss - 0.40888	
873	 steps: training loss - 0.55511	, testing loss - 0.40865	
874	 steps: training loss - 0.52116	, testing loss - 0.40843	
875	 steps: training loss - 0.49276	, testing loss - 0.40822	
876	 steps: training loss - 0.52626	, testing loss - 0.40809	
877	 steps: training loss - 0.53633	, testing loss - 0.40802	
878	 steps: training loss - 0.55873	, testing loss - 0.40795	
879	 steps: training loss - 0.64185	, testing loss - 0.40792	
880	 steps: training loss - 0.48387	, testing loss - 0.40788	
881	 steps: training loss - 0.62713	, testing loss - 0.40782	
882	 steps: training loss - 0.52439	, testing loss - 0.40781	
883	 steps: training loss - 0.55326	, testing loss - 0.40790	
884	 steps: training loss - 0.43896	, testing loss - 0.40792	
885	 steps: training loss - 0.45794	, testing loss - 0.40786	
886	 steps: training loss - 0.60334	, testing loss - 0.40777	
887	 steps: training loss - 0.47175	, testing loss - 0.40771	
888	 steps: training loss - 0.53869	, testing loss - 0.40776	
889	 steps: training loss - 0.49891	, testing loss - 0.40781	
890	 steps: training loss - 0.52914	, testing loss - 0.40780	
891	 steps: training loss - 0.45361	, testing loss - 0.40785	
892	 steps: training loss - 0.55595	, testing loss - 0.40787	
893	 steps: training loss - 0.56669	, testing loss - 0.40781	
894	 steps: training loss - 0.51666	, testing loss - 0.40772	
895	 steps: training loss - 0.61369	, testing loss - 0.40759	
896	 steps: training loss - 0.55859	, testing loss - 0.40732	
897	 steps: training loss - 0.59645	, testing loss - 0.40692	
898	 steps: training loss - 0.54470	, testing loss - 0.40654	
899	 steps: training loss - 0.61281	, testing loss - 0.40613	
900	 steps: training loss - 0.61667	, testing loss - 0.40557	
901	 steps: training loss - 0.56007	, testing loss - 0.40500	
902	 steps: training loss - 0.55944	, testing loss - 0.40461	
903	 steps: training loss - 0.55212	, testing loss - 0.40428	
904	 steps: training loss - 0.39991	, testing loss - 0.40392	
905	 steps: training loss - 0.52745	, testing loss - 0.40353	
906	 steps: training loss - 0.64788	, testing loss - 0.40320	
907	 steps: training loss - 0.50805	, testing loss - 0.40297	
908	 steps: training loss - 0.52079	, testing loss - 0.40279	
909	 steps: training loss - 0.43037	, testing loss - 0.40259	
910	 steps: training loss - 0.49939	, testing loss - 0.40230	
911	 steps: training loss - 0.54568	, testing loss - 0.40206	
912	 steps: training loss - 0.45346	, testing loss - 0.40191	
913	 steps: training loss - 0.61920	, testing loss - 0.40176	
914	 steps: training loss - 0.51614	, testing loss - 0.40151	
915	 steps: training loss - 0.46251	, testing loss - 0.40131	
916	 steps: training loss - 0.65950	, testing loss - 0.40118	
917	 steps: training loss - 0.63847	, testing loss - 0.40109	
918	 steps: training loss - 0.52313	, testing loss - 0.40086	
919	 steps: training loss - 0.61013	, testing loss - 0.40068	
920	 steps: training loss - 0.48929	, testing loss - 0.40048	
921	 steps: training loss - 0.55229	, testing loss - 0.40031	
922	 steps: training loss - 0.45600	, testing loss - 0.40019	
923	 steps: training loss - 0.43468	, testing loss - 0.40000	
924	 steps: training loss - 0.47408	, testing loss - 0.39978	
925	 steps: training loss - 0.50611	, testing loss - 0.39955	
926	 steps: training loss - 0.42005	, testing loss - 0.39935	
927	 steps: training loss - 0.50406	, testing loss - 0.39909	
928	 steps: training loss - 0.53316	, testing loss - 0.39874	
929	 steps: training loss - 0.54369	, testing loss - 0.39837	
930	 steps: training loss - 0.53999	, testing loss - 0.39804	
931	 steps: training loss - 0.65535	, testing loss - 0.39778	
932	 steps: training loss - 0.48572	, testing loss - 0.39753	
933	 steps: training loss - 0.56358	, testing loss - 0.39730	
934	 steps: training loss - 0.55298	, testing loss - 0.39703	
935	 steps: training loss - 0.47801	, testing loss - 0.39677	
936	 steps: training loss - 0.52932	, testing loss - 0.39650	
937	 steps: training loss - 0.61388	, testing loss - 0.39628	
938	 steps: training loss - 0.60319	, testing loss - 0.39611	
939	 steps: training loss - 0.57636	, testing loss - 0.39599	
940	 steps: training loss - 0.59181	, testing loss - 0.39593	
941	 steps: training loss - 0.62351	, testing loss - 0.39588	
942	 steps: training loss - 0.50827	, testing loss - 0.39578	
943	 steps: training loss - 0.58616	, testing loss - 0.39573	
944	 steps: training loss - 0.45822	, testing loss - 0.39571	
945	 steps: training loss - 0.57540	, testing loss - 0.39571	
946	 steps: training loss - 0.45389	, testing loss - 0.39575	
947	 steps: training loss - 0.47029	, testing loss - 0.39579	
948	 steps: training loss - 0.57663	, testing loss - 0.39587	
949	 steps: training loss - 0.49573	, testing loss - 0.39601	
950	 steps: training loss - 0.52996	, testing loss - 0.39611	
951	 steps: training loss - 0.48931	, testing loss - 0.39618	
952	 steps: training loss - 0.44285	, testing loss - 0.39624	
953	 steps: training loss - 0.64485	, testing loss - 0.39633	
954	 steps: training loss - 0.41189	, testing loss - 0.39635	
955	 steps: training loss - 0.55960	, testing loss - 0.39639	
956	 steps: training loss - 0.56992	, testing loss - 0.39630	
957	 steps: training loss - 0.53872	, testing loss - 0.39604	
958	 steps: training loss - 0.58115	, testing loss - 0.39578	
959	 steps: training loss - 0.58367	, testing loss - 0.39535	
960	 steps: training loss - 0.43291	, testing loss - 0.39505	
961	 steps: training loss - 0.49227	, testing loss - 0.39483	
962	 steps: training loss - 0.59177	, testing loss - 0.39464	
963	 steps: training loss - 0.58734	, testing loss - 0.39442	
964	 steps: training loss - 0.54966	, testing loss - 0.39421	
965	 steps: training loss - 0.51274	, testing loss - 0.39397	
966	 steps: training loss - 0.55905	, testing loss - 0.39373	
967	 steps: training loss - 0.44439	, testing loss - 0.39352	
968	 steps: training loss - 0.50534	, testing loss - 0.39327	
969	 steps: training loss - 0.49066	, testing loss - 0.39293	
970	 steps: training loss - 0.58916	, testing loss - 0.39258	
971	 steps: training loss - 0.48325	, testing loss - 0.39229	
972	 steps: training loss - 0.51250	, testing loss - 0.39193	
973	 steps: training loss - 0.45815	, testing loss - 0.39166	
974	 steps: training loss - 0.45408	, testing loss - 0.39141	
975	 steps: training loss - 0.47932	, testing loss - 0.39115	
976	 steps: training loss - 0.54503	, testing loss - 0.39086	
977	 steps: training loss - 0.61253	, testing loss - 0.39057	
978	 steps: training loss - 0.46704	, testing loss - 0.39031	
979	 steps: training loss - 0.53674	, testing loss - 0.39020	
980	 steps: training loss - 0.44091	, testing loss - 0.39013	
981	 steps: training loss - 0.61480	, testing loss - 0.39001	
982	 steps: training loss - 0.49764	, testing loss - 0.38991	
983	 steps: training loss - 0.55756	, testing loss - 0.38988	
984	 steps: training loss - 0.61808	, testing loss - 0.38980	
985	 steps: training loss - 0.49299	, testing loss - 0.38978	
986	 steps: training loss - 0.48490	, testing loss - 0.38976	
987	 steps: training loss - 0.43822	, testing loss - 0.38973	
988	 steps: training loss - 0.56985	, testing loss - 0.38970	
989	 steps: training loss - 0.52463	, testing loss - 0.38976	
990	 steps: training loss - 0.51715	, testing loss - 0.38982	
991	 steps: training loss - 0.52765	, testing loss - 0.38988	
992	 steps: training loss - 0.46813	, testing loss - 0.38992	
993	 steps: training loss - 0.44104	, testing loss - 0.38992	
994	 steps: training loss - 0.51082	, testing loss - 0.38991	
995	 steps: training loss - 0.68623	, testing loss - 0.38989	
996	 steps: training loss - 0.67176	, testing loss - 0.38984	
997	 steps: training loss - 0.45830	, testing loss - 0.38987	
998	 steps: training loss - 0.45375	, testing loss - 0.38986	
999	 steps: training loss - 0.56124	, testing loss - 0.38994	
EVALUATION
----------
Test loss: 0.55250
MIMO Accuracies: 0.99921

LOOCV TRAINING INFO - is_lstm? True
LOOCV? -  True
-------------
TRAINING USERS -  ['a', 'b', 'c', 'e', 'g', 'i']
LEFT OUT -  h
-------------
actions ['bike', 'sit']
devices ['samsungold_1', 'samsungold_2']
step size 10
num_epochs 1000
batch size 12
feature size (x,y,z) 3
hidden size 20
number recurrent layers 2
number of classes 2
writing pickle to run9_model.p
writing accuracy + pickle to acc_run9_model.p
------------------------------------------------
0	 steps: training loss - 0.70532	, testing loss - 0.70766	
1	 steps: training loss - 0.68516	, testing loss - 0.70708	
2	 steps: training loss - 0.70940	, testing loss - 0.70652	
3	 steps: training loss - 0.69753	, testing loss - 0.70609	
4	 steps: training loss - 0.70557	, testing loss - 0.70562	
5	 steps: training loss - 0.71660	, testing loss - 0.70513	
6	 steps: training loss - 0.68884	, testing loss - 0.70465	
7	 steps: training loss - 0.69621	, testing loss - 0.70418	
8	 steps: training loss - 0.70551	, testing loss - 0.70368	
9	 steps: training loss - 0.69088	, testing loss - 0.70318	
10	 steps: training loss - 0.68298	, testing loss - 0.70268	
11	 steps: training loss - 0.66359	, testing loss - 0.70217	
12	 steps: training loss - 0.71618	, testing loss - 0.70166	
13	 steps: training loss - 0.71498	, testing loss - 0.70119	
14	 steps: training loss - 0.71530	, testing loss - 0.70072	
15	 steps: training loss - 0.69522	, testing loss - 0.70026	
16	 steps: training loss - 0.67530	, testing loss - 0.69979	
17	 steps: training loss - 0.68766	, testing loss - 0.69931	
18	 steps: training loss - 0.67479	, testing loss - 0.69884	
19	 steps: training loss - 0.68665	, testing loss - 0.69836	
20	 steps: training loss - 0.72546	, testing loss - 0.69788	
21	 steps: training loss - 0.66975	, testing loss - 0.69742	
22	 steps: training loss - 0.66655	, testing loss - 0.69697	
23	 steps: training loss - 0.65247	, testing loss - 0.69655	
24	 steps: training loss - 0.71228	, testing loss - 0.69619	
25	 steps: training loss - 0.70391	, testing loss - 0.69582	
26	 steps: training loss - 0.70070	, testing loss - 0.69542	
27	 steps: training loss - 0.66575	, testing loss - 0.69500	
28	 steps: training loss - 0.70387	, testing loss - 0.69461	
29	 steps: training loss - 0.67630	, testing loss - 0.69419	
30	 steps: training loss - 0.70940	, testing loss - 0.69376	
31	 steps: training loss - 0.71257	, testing loss - 0.69331	
32	 steps: training loss - 0.69408	, testing loss - 0.69284	
33	 steps: training loss - 0.64149	, testing loss - 0.69236	
34	 steps: training loss - 0.67775	, testing loss - 0.69192	
35	 steps: training loss - 0.67315	, testing loss - 0.69150	
36	 steps: training loss - 0.63666	, testing loss - 0.69109	
37	 steps: training loss - 0.65409	, testing loss - 0.69074	
38	 steps: training loss - 0.64781	, testing loss - 0.69047	
39	 steps: training loss - 0.64715	, testing loss - 0.69024	
40	 steps: training loss - 0.67099	, testing loss - 0.69007	
41	 steps: training loss - 0.67769	, testing loss - 0.68991	
42	 steps: training loss - 0.67379	, testing loss - 0.68972	
43	 steps: training loss - 0.63072	, testing loss - 0.68949	
44	 steps: training loss - 0.69956	, testing loss - 0.68932	
45	 steps: training loss - 0.64379	, testing loss - 0.68911	
46	 steps: training loss - 0.71045	, testing loss - 0.68893	
47	 steps: training loss - 0.69892	, testing loss - 0.68867	
48	 steps: training loss - 0.64923	, testing loss - 0.68834	
49	 steps: training loss - 0.65229	, testing loss - 0.68803	
50	 steps: training loss - 0.62909	, testing loss - 0.68779	
51	 steps: training loss - 0.64240	, testing loss - 0.68762	
52	 steps: training loss - 0.66269	, testing loss - 0.68750	
53	 steps: training loss - 0.65935	, testing loss - 0.68738	
54	 steps: training loss - 0.65734	, testing loss - 0.68727	
55	 steps: training loss - 0.67085	, testing loss - 0.68715	
56	 steps: training loss - 0.64441	, testing loss - 0.68699	
57	 steps: training loss - 0.65576	, testing loss - 0.68686	
58	 steps: training loss - 0.64990	, testing loss - 0.68670	
59	 steps: training loss - 0.62077	, testing loss - 0.68651	
60	 steps: training loss - 0.66614	, testing loss - 0.68643	
61	 steps: training loss - 0.64082	, testing loss - 0.68633	
62	 steps: training loss - 0.67957	, testing loss - 0.68629	
63	 steps: training loss - 0.67145	, testing loss - 0.68619	
64	 steps: training loss - 0.67400	, testing loss - 0.68597	
65	 steps: training loss - 0.59838	, testing loss - 0.68567	
66	 steps: training loss - 0.62869	, testing loss - 0.68550	
67	 steps: training loss - 0.63634	, testing loss - 0.68545	
68	 steps: training loss - 0.66633	, testing loss - 0.68544	
69	 steps: training loss - 0.64218	, testing loss - 0.68541	
70	 steps: training loss - 0.62684	, testing loss - 0.68537	
71	 steps: training loss - 0.66189	, testing loss - 0.68541	
72	 steps: training loss - 0.61370	, testing loss - 0.68538	
73	 steps: training loss - 0.59192	, testing loss - 0.68537	
74	 steps: training loss - 0.59983	, testing loss - 0.68554	
75	 steps: training loss - 0.66939	, testing loss - 0.68586	
76	 steps: training loss - 0.72112	, testing loss - 0.68607	
77	 steps: training loss - 0.61698	, testing loss - 0.68596	
78	 steps: training loss - 0.72065	, testing loss - 0.68584	
79	 steps: training loss - 0.63957	, testing loss - 0.68547	
80	 steps: training loss - 0.64599	, testing loss - 0.68504	
81	 steps: training loss - 0.60630	, testing loss - 0.68459	
82	 steps: training loss - 0.70628	, testing loss - 0.68431	
83	 steps: training loss - 0.69163	, testing loss - 0.68391	
84	 steps: training loss - 0.60564	, testing loss - 0.68338	
85	 steps: training loss - 0.60651	, testing loss - 0.68294	
86	 steps: training loss - 0.60626	, testing loss - 0.68260	
87	 steps: training loss - 0.67689	, testing loss - 0.68243	
88	 steps: training loss - 0.67706	, testing loss - 0.68218	
89	 steps: training loss - 0.60123	, testing loss - 0.68180	
90	 steps: training loss - 0.70792	, testing loss - 0.68150	
91	 steps: training loss - 0.60816	, testing loss - 0.68104	
92	 steps: training loss - 0.56535	, testing loss - 0.68071	
93	 steps: training loss - 0.68388	, testing loss - 0.68072	
94	 steps: training loss - 0.60454	, testing loss - 0.68061	
95	 steps: training loss - 0.74340	, testing loss - 0.68058	
96	 steps: training loss - 0.71259	, testing loss - 0.68024	
97	 steps: training loss - 0.58419	, testing loss - 0.67959	
98	 steps: training loss - 0.68829	, testing loss - 0.67913	
99	 steps: training loss - 0.63217	, testing loss - 0.67863	
100	 steps: training loss - 0.58315	, testing loss - 0.67820	
101	 steps: training loss - 0.62916	, testing loss - 0.67799	
102	 steps: training loss - 0.58637	, testing loss - 0.67789	
103	 steps: training loss - 0.58085	, testing loss - 0.67790	
104	 steps: training loss - 0.58071	, testing loss - 0.67807	
105	 steps: training loss - 0.62963	, testing loss - 0.67839	
106	 steps: training loss - 0.64638	, testing loss - 0.67863	
107	 steps: training loss - 0.62015	, testing loss - 0.67877	
108	 steps: training loss - 0.64211	, testing loss - 0.67887	
109	 steps: training loss - 0.68418	, testing loss - 0.67890	
110	 steps: training loss - 0.64750	, testing loss - 0.67872	
111	 steps: training loss - 0.57558	, testing loss - 0.67845	
112	 steps: training loss - 0.65487	, testing loss - 0.67838	
113	 steps: training loss - 0.71493	, testing loss - 0.67821	
114	 steps: training loss - 0.53364	, testing loss - 0.67781	
115	 steps: training loss - 0.66572	, testing loss - 0.67767	
116	 steps: training loss - 0.51042	, testing loss - 0.67754	
117	 steps: training loss - 0.70099	, testing loss - 0.67774	
118	 steps: training loss - 0.64036	, testing loss - 0.67783	
119	 steps: training loss - 0.61981	, testing loss - 0.67780	
120	 steps: training loss - 0.60310	, testing loss - 0.67771	
121	 steps: training loss - 0.60737	, testing loss - 0.67769	
122	 steps: training loss - 0.60602	, testing loss - 0.67774	
123	 steps: training loss - 0.54855	, testing loss - 0.67784	
124	 steps: training loss - 0.72575	, testing loss - 0.67815	
125	 steps: training loss - 0.70728	, testing loss - 0.67821	
126	 steps: training loss - 0.59367	, testing loss - 0.67792	
127	 steps: training loss - 0.60258	, testing loss - 0.67765	
128	 steps: training loss - 0.68531	, testing loss - 0.67750	
129	 steps: training loss - 0.55186	, testing loss - 0.67714	
130	 steps: training loss - 0.65667	, testing loss - 0.67694	
131	 steps: training loss - 0.70255	, testing loss - 0.67675	
132	 steps: training loss - 0.62734	, testing loss - 0.67634	
133	 steps: training loss - 0.54496	, testing loss - 0.67593	
134	 steps: training loss - 0.57753	, testing loss - 0.67585	
135	 steps: training loss - 0.64003	, testing loss - 0.67598	
136	 steps: training loss - 0.71132	, testing loss - 0.67608	
137	 steps: training loss - 0.68226	, testing loss - 0.67576	
138	 steps: training loss - 0.63535	, testing loss - 0.67520	
139	 steps: training loss - 0.62189	, testing loss - 0.67462	
140	 steps: training loss - 0.63417	, testing loss - 0.67412	
141	 steps: training loss - 0.56720	, testing loss - 0.67359	
142	 steps: training loss - 0.62585	, testing loss - 0.67329	
143	 steps: training loss - 0.70618	, testing loss - 0.67312	
144	 steps: training loss - 0.59729	, testing loss - 0.67263	
145	 steps: training loss - 0.68109	, testing loss - 0.67212	
146	 steps: training loss - 0.74506	, testing loss - 0.67149	
147	 steps: training loss - 0.59419	, testing loss - 0.67046	
148	 steps: training loss - 0.61697	, testing loss - 0.66948	
149	 steps: training loss - 0.56029	, testing loss - 0.66867	
150	 steps: training loss - 0.61817	, testing loss - 0.66820	
151	 steps: training loss - 0.66752	, testing loss - 0.66784	
152	 steps: training loss - 0.63199	, testing loss - 0.66732	
153	 steps: training loss - 0.69706	, testing loss - 0.66679	
154	 steps: training loss - 0.57358	, testing loss - 0.66610	
155	 steps: training loss - 0.66151	, testing loss - 0.66558	
156	 steps: training loss - 0.74585	, testing loss - 0.66503	
157	 steps: training loss - 0.62002	, testing loss - 0.66419	
158	 steps: training loss - 0.52798	, testing loss - 0.66343	
159	 steps: training loss - 0.62343	, testing loss - 0.66300	
160	 steps: training loss - 0.57903	, testing loss - 0.66264	
161	 steps: training loss - 0.67158	, testing loss - 0.66236	
162	 steps: training loss - 0.66142	, testing loss - 0.66190	
163	 steps: training loss - 0.56107	, testing loss - 0.66120	
164	 steps: training loss - 0.69231	, testing loss - 0.66067	
165	 steps: training loss - 0.55960	, testing loss - 0.65999	
166	 steps: training loss - 0.61012	, testing loss - 0.65949	
167	 steps: training loss - 0.61638	, testing loss - 0.65909	
168	 steps: training loss - 0.51164	, testing loss - 0.65875	
169	 steps: training loss - 0.61913	, testing loss - 0.65872	
170	 steps: training loss - 0.66159	, testing loss - 0.65879	
171	 steps: training loss - 0.58182	, testing loss - 0.65868	
172	 steps: training loss - 0.62430	, testing loss - 0.65861	
173	 steps: training loss - 0.60200	, testing loss - 0.65859	
174	 steps: training loss - 0.59348	, testing loss - 0.65850	
175	 steps: training loss - 0.62196	, testing loss - 0.65848	
176	 steps: training loss - 0.64788	, testing loss - 0.65840	
177	 steps: training loss - 0.65558	, testing loss - 0.65815	
178	 steps: training loss - 0.67247	, testing loss - 0.65769	
179	 steps: training loss - 0.59034	, testing loss - 0.65703	
180	 steps: training loss - 0.63614	, testing loss - 0.65649	
181	 steps: training loss - 0.63284	, testing loss - 0.65596	
182	 steps: training loss - 0.64274	, testing loss - 0.65544	
183	 steps: training loss - 0.64457	, testing loss - 0.65496	
184	 steps: training loss - 0.63179	, testing loss - 0.65437	
185	 steps: training loss - 0.61312	, testing loss - 0.65373	
186	 steps: training loss - 0.66026	, testing loss - 0.65311	
187	 steps: training loss - 0.62649	, testing loss - 0.65243	
188	 steps: training loss - 0.58152	, testing loss - 0.65174	
189	 steps: training loss - 0.62528	, testing loss - 0.65124	
190	 steps: training loss - 0.65892	, testing loss - 0.65081	
191	 steps: training loss - 0.51800	, testing loss - 0.65036	
192	 steps: training loss - 0.57878	, testing loss - 0.65018	
193	 steps: training loss - 0.67170	, testing loss - 0.65015	
194	 steps: training loss - 0.61304	, testing loss - 0.64983	
195	 steps: training loss - 0.61957	, testing loss - 0.64936	
196	 steps: training loss - 0.55509	, testing loss - 0.64890	
197	 steps: training loss - 0.56950	, testing loss - 0.64873	
198	 steps: training loss - 0.65971	, testing loss - 0.64872	
199	 steps: training loss - 0.56619	, testing loss - 0.64846	
200	 steps: training loss - 0.62868	, testing loss - 0.64827	
201	 steps: training loss - 0.56362	, testing loss - 0.64802	
202	 steps: training loss - 0.54031	, testing loss - 0.64789	
203	 steps: training loss - 0.63568	, testing loss - 0.64799	
204	 steps: training loss - 0.63084	, testing loss - 0.64808	
205	 steps: training loss - 0.59138	, testing loss - 0.64796	
206	 steps: training loss - 0.64188	, testing loss - 0.64791	
207	 steps: training loss - 0.68140	, testing loss - 0.64777	
208	 steps: training loss - 0.59863	, testing loss - 0.64744	
209	 steps: training loss - 0.62899	, testing loss - 0.64705	
210	 steps: training loss - 0.61591	, testing loss - 0.64665	
211	 steps: training loss - 0.61012	, testing loss - 0.64623	
212	 steps: training loss - 0.53116	, testing loss - 0.64584	
213	 steps: training loss - 0.65442	, testing loss - 0.64560	
214	 steps: training loss - 0.62877	, testing loss - 0.64520	
215	 steps: training loss - 0.57220	, testing loss - 0.64468	
216	 steps: training loss - 0.74208	, testing loss - 0.64429	
217	 steps: training loss - 0.51562	, testing loss - 0.64355	
218	 steps: training loss - 0.68194	, testing loss - 0.64306	
219	 steps: training loss - 0.68637	, testing loss - 0.64236	
220	 steps: training loss - 0.63081	, testing loss - 0.64137	
221	 steps: training loss - 0.63553	, testing loss - 0.64031	
222	 steps: training loss - 0.63643	, testing loss - 0.63923	
223	 steps: training loss - 0.65701	, testing loss - 0.63818	
224	 steps: training loss - 0.60927	, testing loss - 0.63721	
225	 steps: training loss - 0.60142	, testing loss - 0.63628	
226	 steps: training loss - 0.66101	, testing loss - 0.63553	
227	 steps: training loss - 0.66014	, testing loss - 0.63475	
228	 steps: training loss - 0.62808	, testing loss - 0.63390	
229	 steps: training loss - 0.56698	, testing loss - 0.63308	
230	 steps: training loss - 0.60247	, testing loss - 0.63241	
231	 steps: training loss - 0.54786	, testing loss - 0.63178	
232	 steps: training loss - 0.58796	, testing loss - 0.63140	
233	 steps: training loss - 0.60177	, testing loss - 0.63099	
234	 steps: training loss - 0.62086	, testing loss - 0.63043	
235	 steps: training loss - 0.53768	, testing loss - 0.62995	
236	 steps: training loss - 0.60590	, testing loss - 0.62969	
237	 steps: training loss - 0.59102	, testing loss - 0.62944	
238	 steps: training loss - 0.60588	, testing loss - 0.62936	
239	 steps: training loss - 0.62425	, testing loss - 0.62926	
240	 steps: training loss - 0.59612	, testing loss - 0.62908	
241	 steps: training loss - 0.64121	, testing loss - 0.62882	
242	 steps: training loss - 0.53877	, testing loss - 0.62843	
243	 steps: training loss - 0.57752	, testing loss - 0.62817	
244	 steps: training loss - 0.56209	, testing loss - 0.62804	
245	 steps: training loss - 0.61539	, testing loss - 0.62799	
246	 steps: training loss - 0.64360	, testing loss - 0.62790	
247	 steps: training loss - 0.56724	, testing loss - 0.62766	
248	 steps: training loss - 0.56243	, testing loss - 0.62748	
249	 steps: training loss - 0.59840	, testing loss - 0.62734	
250	 steps: training loss - 0.56288	, testing loss - 0.62719	
251	 steps: training loss - 0.53856	, testing loss - 0.62713	
252	 steps: training loss - 0.62307	, testing loss - 0.62735	
253	 steps: training loss - 0.57621	, testing loss - 0.62750	
254	 steps: training loss - 0.60959	, testing loss - 0.62771	
255	 steps: training loss - 0.57181	, testing loss - 0.62788	
256	 steps: training loss - 0.52023	, testing loss - 0.62797	
257	 steps: training loss - 0.59606	, testing loss - 0.62816	
258	 steps: training loss - 0.59097	, testing loss - 0.62830	
259	 steps: training loss - 0.58067	, testing loss - 0.62833	
260	 steps: training loss - 0.57884	, testing loss - 0.62842	
261	 steps: training loss - 0.65208	, testing loss - 0.62836	
262	 steps: training loss - 0.67810	, testing loss - 0.62815	
263	 steps: training loss - 0.57815	, testing loss - 0.62747	
264	 steps: training loss - 0.59226	, testing loss - 0.62672	
265	 steps: training loss - 0.60066	, testing loss - 0.62609	
266	 steps: training loss - 0.57608	, testing loss - 0.62535	
267	 steps: training loss - 0.55907	, testing loss - 0.62450	
268	 steps: training loss - 0.59069	, testing loss - 0.62375	
269	 steps: training loss - 0.49867	, testing loss - 0.62325	
270	 steps: training loss - 0.58628	, testing loss - 0.62329	
271	 steps: training loss - 0.51174	, testing loss - 0.62353	
272	 steps: training loss - 0.62112	, testing loss - 0.62402	
273	 steps: training loss - 0.56170	, testing loss - 0.62435	
274	 steps: training loss - 0.56615	, testing loss - 0.62466	
275	 steps: training loss - 0.61083	, testing loss - 0.62502	
276	 steps: training loss - 0.58388	, testing loss - 0.62523	
277	 steps: training loss - 0.60091	, testing loss - 0.62520	
278	 steps: training loss - 0.65367	, testing loss - 0.62498	
279	 steps: training loss - 0.64958	, testing loss - 0.62455	
280	 steps: training loss - 0.53338	, testing loss - 0.62391	
281	 steps: training loss - 0.63763	, testing loss - 0.62347	
282	 steps: training loss - 0.60632	, testing loss - 0.62301	
283	 steps: training loss - 0.61381	, testing loss - 0.62260	
284	 steps: training loss - 0.61406	, testing loss - 0.62206	
285	 steps: training loss - 0.59049	, testing loss - 0.62146	
286	 steps: training loss - 0.63163	, testing loss - 0.62077	
287	 steps: training loss - 0.52703	, testing loss - 0.61997	
288	 steps: training loss - 0.65539	, testing loss - 0.61959	
289	 steps: training loss - 0.59615	, testing loss - 0.61905	
290	 steps: training loss - 0.53206	, testing loss - 0.61840	
291	 steps: training loss - 0.56118	, testing loss - 0.61786	
292	 steps: training loss - 0.58698	, testing loss - 0.61737	
293	 steps: training loss - 0.59524	, testing loss - 0.61696	
294	 steps: training loss - 0.59006	, testing loss - 0.61661	
295	 steps: training loss - 0.52458	, testing loss - 0.61628	
296	 steps: training loss - 0.56564	, testing loss - 0.61607	
297	 steps: training loss - 0.59958	, testing loss - 0.61595	
298	 steps: training loss - 0.57852	, testing loss - 0.61568	
299	 steps: training loss - 0.52243	, testing loss - 0.61544	
300	 steps: training loss - 0.62681	, testing loss - 0.61524	
301	 steps: training loss - 0.58028	, testing loss - 0.61483	
302	 steps: training loss - 0.60013	, testing loss - 0.61444	
303	 steps: training loss - 0.55930	, testing loss - 0.61406	
304	 steps: training loss - 0.61230	, testing loss - 0.61367	
305	 steps: training loss - 0.60114	, testing loss - 0.61335	
306	 steps: training loss - 0.61559	, testing loss - 0.61311	
307	 steps: training loss - 0.57907	, testing loss - 0.61271	
308	 steps: training loss - 0.61551	, testing loss - 0.61244	
309	 steps: training loss - 0.55788	, testing loss - 0.61214	
310	 steps: training loss - 0.52982	, testing loss - 0.61194	
311	 steps: training loss - 0.60967	, testing loss - 0.61192	
312	 steps: training loss - 0.57165	, testing loss - 0.61173	
313	 steps: training loss - 0.59638	, testing loss - 0.61151	
314	 steps: training loss - 0.59413	, testing loss - 0.61098	
315	 steps: training loss - 0.53860	, testing loss - 0.61025	
316	 steps: training loss - 0.63757	, testing loss - 0.60958	
317	 steps: training loss - 0.53471	, testing loss - 0.60893	
318	 steps: training loss - 0.61207	, testing loss - 0.60859	
319	 steps: training loss - 0.58677	, testing loss - 0.60828	
320	 steps: training loss - 0.48243	, testing loss - 0.60800	
321	 steps: training loss - 0.55427	, testing loss - 0.60803	
322	 steps: training loss - 0.70827	, testing loss - 0.60819	
323	 steps: training loss - 0.54161	, testing loss - 0.60788	
324	 steps: training loss - 0.71219	, testing loss - 0.60748	
325	 steps: training loss - 0.62665	, testing loss - 0.60667	
326	 steps: training loss - 0.61524	, testing loss - 0.60568	
327	 steps: training loss - 0.61115	, testing loss - 0.60458	
328	 steps: training loss - 0.57405	, testing loss - 0.60364	
329	 steps: training loss - 0.57340	, testing loss - 0.60275	
330	 steps: training loss - 0.70535	, testing loss - 0.60176	
331	 steps: training loss - 0.56452	, testing loss - 0.60063	
332	 steps: training loss - 0.51027	, testing loss - 0.59968	
333	 steps: training loss - 0.57283	, testing loss - 0.59912	
334	 steps: training loss - 0.63473	, testing loss - 0.59864	
335	 steps: training loss - 0.50941	, testing loss - 0.59802	
336	 steps: training loss - 0.56910	, testing loss - 0.59755	
337	 steps: training loss - 0.60199	, testing loss - 0.59721	
338	 steps: training loss - 0.57601	, testing loss - 0.59682	
339	 steps: training loss - 0.57361	, testing loss - 0.59660	
340	 steps: training loss - 0.58936	, testing loss - 0.59631	
341	 steps: training loss - 0.54728	, testing loss - 0.59574	
342	 steps: training loss - 0.63301	, testing loss - 0.59527	
343	 steps: training loss - 0.57124	, testing loss - 0.59472	
344	 steps: training loss - 0.58102	, testing loss - 0.59422	
345	 steps: training loss - 0.67150	, testing loss - 0.59383	
346	 steps: training loss - 0.61516	, testing loss - 0.59320	
347	 steps: training loss - 0.54354	, testing loss - 0.59252	
348	 steps: training loss - 0.55318	, testing loss - 0.59203	
349	 steps: training loss - 0.48939	, testing loss - 0.59160	
350	 steps: training loss - 0.58856	, testing loss - 0.59148	
351	 steps: training loss - 0.61433	, testing loss - 0.59143	
352	 steps: training loss - 0.56860	, testing loss - 0.59139	
353	 steps: training loss - 0.55594	, testing loss - 0.59122	
354	 steps: training loss - 0.57302	, testing loss - 0.59110	
355	 steps: training loss - 0.68115	, testing loss - 0.59093	
356	 steps: training loss - 0.47981	, testing loss - 0.59045	
357	 steps: training loss - 0.53690	, testing loss - 0.59026	
358	 steps: training loss - 0.54679	, testing loss - 0.59033	
359	 steps: training loss - 0.56634	, testing loss - 0.59040	
360	 steps: training loss - 0.53557	, testing loss - 0.59062	
361	 steps: training loss - 0.59845	, testing loss - 0.59082	
362	 steps: training loss - 0.51389	, testing loss - 0.59082	
363	 steps: training loss - 0.66557	, testing loss - 0.59106	
364	 steps: training loss - 0.64089	, testing loss - 0.59116	
365	 steps: training loss - 0.55459	, testing loss - 0.59107	
366	 steps: training loss - 0.58957	, testing loss - 0.59118	
367	 steps: training loss - 0.53632	, testing loss - 0.59116	
368	 steps: training loss - 0.63662	, testing loss - 0.59109	
369	 steps: training loss - 0.62093	, testing loss - 0.59089	
370	 steps: training loss - 0.62161	, testing loss - 0.59065	
371	 steps: training loss - 0.56330	, testing loss - 0.59020	
372	 steps: training loss - 0.52969	, testing loss - 0.58974	
373	 steps: training loss - 0.59278	, testing loss - 0.58939	
374	 steps: training loss - 0.55924	, testing loss - 0.58895	
375	 steps: training loss - 0.54138	, testing loss - 0.58857	
376	 steps: training loss - 0.51800	, testing loss - 0.58843	
377	 steps: training loss - 0.57554	, testing loss - 0.58834	
378	 steps: training loss - 0.55477	, testing loss - 0.58830	
379	 steps: training loss - 0.54875	, testing loss - 0.58843	
380	 steps: training loss - 0.59375	, testing loss - 0.58855	
381	 steps: training loss - 0.58713	, testing loss - 0.58852	
382	 steps: training loss - 0.57030	, testing loss - 0.58846	
383	 steps: training loss - 0.55147	, testing loss - 0.58835	
384	 steps: training loss - 0.57924	, testing loss - 0.58831	
385	 steps: training loss - 0.54033	, testing loss - 0.58814	
386	 steps: training loss - 0.62014	, testing loss - 0.58800	
387	 steps: training loss - 0.56774	, testing loss - 0.58787	
388	 steps: training loss - 0.55597	, testing loss - 0.58763	
389	 steps: training loss - 0.60912	, testing loss - 0.58739	
390	 steps: training loss - 0.62024	, testing loss - 0.58716	
391	 steps: training loss - 0.62073	, testing loss - 0.58682	
392	 steps: training loss - 0.52714	, testing loss - 0.58639	
393	 steps: training loss - 0.64310	, testing loss - 0.58613	
394	 steps: training loss - 0.60884	, testing loss - 0.58547	
395	 steps: training loss - 0.58900	, testing loss - 0.58454	
396	 steps: training loss - 0.67229	, testing loss - 0.58348	
397	 steps: training loss - 0.52268	, testing loss - 0.58239	
398	 steps: training loss - 0.67649	, testing loss - 0.58132	
399	 steps: training loss - 0.55228	, testing loss - 0.58027	
400	 steps: training loss - 0.59256	, testing loss - 0.57944	
401	 steps: training loss - 0.57190	, testing loss - 0.57875	
402	 steps: training loss - 0.57717	, testing loss - 0.57819	
403	 steps: training loss - 0.58792	, testing loss - 0.57771	
404	 steps: training loss - 0.60051	, testing loss - 0.57752	
405	 steps: training loss - 0.54147	, testing loss - 0.57725	
406	 steps: training loss - 0.60631	, testing loss - 0.57715	
407	 steps: training loss - 0.59419	, testing loss - 0.57708	
408	 steps: training loss - 0.49824	, testing loss - 0.57704	
409	 steps: training loss - 0.59379	, testing loss - 0.57702	
410	 steps: training loss - 0.62294	, testing loss - 0.57704	
411	 steps: training loss - 0.52290	, testing loss - 0.57689	
412	 steps: training loss - 0.57901	, testing loss - 0.57675	
413	 steps: training loss - 0.49976	, testing loss - 0.57646	
414	 steps: training loss - 0.49832	, testing loss - 0.57635	
415	 steps: training loss - 0.59221	, testing loss - 0.57651	
416	 steps: training loss - 0.57193	, testing loss - 0.57667	
417	 steps: training loss - 0.63710	, testing loss - 0.57675	
418	 steps: training loss - 0.56242	, testing loss - 0.57679	
419	 steps: training loss - 0.58126	, testing loss - 0.57674	
420	 steps: training loss - 0.53456	, testing loss - 0.57649	
421	 steps: training loss - 0.59499	, testing loss - 0.57628	
422	 steps: training loss - 0.60902	, testing loss - 0.57585	
423	 steps: training loss - 0.66021	, testing loss - 0.57544	
424	 steps: training loss - 0.59514	, testing loss - 0.57488	
425	 steps: training loss - 0.55281	, testing loss - 0.57443	
426	 steps: training loss - 0.60767	, testing loss - 0.57410	
427	 steps: training loss - 0.52040	, testing loss - 0.57394	
428	 steps: training loss - 0.59098	, testing loss - 0.57413	
429	 steps: training loss - 0.57286	, testing loss - 0.57410	
430	 steps: training loss - 0.51926	, testing loss - 0.57416	
431	 steps: training loss - 0.52631	, testing loss - 0.57455	
432	 steps: training loss - 0.56579	, testing loss - 0.57517	
433	 steps: training loss - 0.66357	, testing loss - 0.57570	
434	 steps: training loss - 0.50467	, testing loss - 0.57568	
435	 steps: training loss - 0.57781	, testing loss - 0.57536	
436	 steps: training loss - 0.56754	, testing loss - 0.57493	
437	 steps: training loss - 0.54256	, testing loss - 0.57451	
438	 steps: training loss - 0.52621	, testing loss - 0.57431	
439	 steps: training loss - 0.55332	, testing loss - 0.57428	
440	 steps: training loss - 0.55819	, testing loss - 0.57427	
441	 steps: training loss - 0.49426	, testing loss - 0.57437	
442	 steps: training loss - 0.55640	, testing loss - 0.57465	
443	 steps: training loss - 0.56431	, testing loss - 0.57511	
444	 steps: training loss - 0.58056	, testing loss - 0.57544	
445	 steps: training loss - 0.54614	, testing loss - 0.57563	
446	 steps: training loss - 0.53973	, testing loss - 0.57565	
447	 steps: training loss - 0.44918	, testing loss - 0.57564	
448	 steps: training loss - 0.72461	, testing loss - 0.57567	
449	 steps: training loss - 0.61625	, testing loss - 0.57515	
450	 steps: training loss - 0.59006	, testing loss - 0.57430	
451	 steps: training loss - 0.69134	, testing loss - 0.57333	
452	 steps: training loss - 0.54661	, testing loss - 0.57202	
453	 steps: training loss - 0.50994	, testing loss - 0.57063	
454	 steps: training loss - 0.50820	, testing loss - 0.56938	
455	 steps: training loss - 0.63638	, testing loss - 0.56841	
456	 steps: training loss - 0.59001	, testing loss - 0.56738	
457	 steps: training loss - 0.58786	, testing loss - 0.56641	
458	 steps: training loss - 0.58904	, testing loss - 0.56560	
459	 steps: training loss - 0.51015	, testing loss - 0.56489	
460	 steps: training loss - 0.57108	, testing loss - 0.56442	
461	 steps: training loss - 0.52345	, testing loss - 0.56414	
462	 steps: training loss - 0.61966	, testing loss - 0.56395	
463	 steps: training loss - 0.53319	, testing loss - 0.56358	
464	 steps: training loss - 0.55844	, testing loss - 0.56307	
465	 steps: training loss - 0.55664	, testing loss - 0.56258	
466	 steps: training loss - 0.52941	, testing loss - 0.56229	
467	 steps: training loss - 0.58903	, testing loss - 0.56200	
468	 steps: training loss - 0.50671	, testing loss - 0.56147	
469	 steps: training loss - 0.49758	, testing loss - 0.56112	
470	 steps: training loss - 0.58604	, testing loss - 0.56104	
471	 steps: training loss - 0.60172	, testing loss - 0.56099	
472	 steps: training loss - 0.54582	, testing loss - 0.56087	
473	 steps: training loss - 0.52048	, testing loss - 0.56060	
474	 steps: training loss - 0.51182	, testing loss - 0.56032	
475	 steps: training loss - 0.49435	, testing loss - 0.56015	
476	 steps: training loss - 0.60215	, testing loss - 0.56001	
477	 steps: training loss - 0.57384	, testing loss - 0.55989	
478	 steps: training loss - 0.59674	, testing loss - 0.55964	
479	 steps: training loss - 0.50391	, testing loss - 0.55938	
480	 steps: training loss - 0.58338	, testing loss - 0.55918	
481	 steps: training loss - 0.57271	, testing loss - 0.55911	
482	 steps: training loss - 0.49199	, testing loss - 0.55901	
483	 steps: training loss - 0.61104	, testing loss - 0.55886	
484	 steps: training loss - 0.52358	, testing loss - 0.55864	
485	 steps: training loss - 0.54020	, testing loss - 0.55837	
486	 steps: training loss - 0.60410	, testing loss - 0.55807	
487	 steps: training loss - 0.67904	, testing loss - 0.55772	
488	 steps: training loss - 0.59899	, testing loss - 0.55700	
489	 steps: training loss - 0.61855	, testing loss - 0.55634	
490	 steps: training loss - 0.49322	, testing loss - 0.55575	
491	 steps: training loss - 0.45413	, testing loss - 0.55540	
492	 steps: training loss - 0.61026	, testing loss - 0.55537	
493	 steps: training loss - 0.50268	, testing loss - 0.55528	
494	 steps: training loss - 0.54390	, testing loss - 0.55543	
495	 steps: training loss - 0.68347	, testing loss - 0.55534	
496	 steps: training loss - 0.46720	, testing loss - 0.55488	
497	 steps: training loss - 0.50661	, testing loss - 0.55445	
498	 steps: training loss - 0.52362	, testing loss - 0.55428	
499	 steps: training loss - 0.65449	, testing loss - 0.55431	
500	 steps: training loss - 0.55635	, testing loss - 0.55391	
501	 steps: training loss - 0.51202	, testing loss - 0.55359	
502	 steps: training loss - 0.62451	, testing loss - 0.55310	
503	 steps: training loss - 0.60409	, testing loss - 0.55257	
504	 steps: training loss - 0.46954	, testing loss - 0.55200	
505	 steps: training loss - 0.53186	, testing loss - 0.55177	
506	 steps: training loss - 0.55999	, testing loss - 0.55162	
507	 steps: training loss - 0.47379	, testing loss - 0.55126	
508	 steps: training loss - 0.48921	, testing loss - 0.55101	
509	 steps: training loss - 0.50180	, testing loss - 0.55096	
510	 steps: training loss - 0.53087	, testing loss - 0.55095	
511	 steps: training loss - 0.54228	, testing loss - 0.55099	
512	 steps: training loss - 0.51926	, testing loss - 0.55113	
513	 steps: training loss - 0.54663	, testing loss - 0.55102	
514	 steps: training loss - 0.60531	, testing loss - 0.55084	
515	 steps: training loss - 0.60313	, testing loss - 0.55060	
516	 steps: training loss - 0.54914	, testing loss - 0.55040	
517	 steps: training loss - 0.53227	, testing loss - 0.55024	
518	 steps: training loss - 0.54341	, testing loss - 0.55014	
519	 steps: training loss - 0.56694	, testing loss - 0.55024	
520	 steps: training loss - 0.57377	, testing loss - 0.55025	
521	 steps: training loss - 0.52106	, testing loss - 0.55015	
522	 steps: training loss - 0.51053	, testing loss - 0.55029	
523	 steps: training loss - 0.59420	, testing loss - 0.55086	
524	 steps: training loss - 0.58693	, testing loss - 0.55130	
525	 steps: training loss - 0.58051	, testing loss - 0.55135	
526	 steps: training loss - 0.57881	, testing loss - 0.55137	
527	 steps: training loss - 0.49599	, testing loss - 0.55138	
528	 steps: training loss - 0.45518	, testing loss - 0.55149	
529	 steps: training loss - 0.53438	, testing loss - 0.55189	
530	 steps: training loss - 0.56222	, testing loss - 0.55214	
531	 steps: training loss - 0.56683	, testing loss - 0.55230	
532	 steps: training loss - 0.54286	, testing loss - 0.55241	
533	 steps: training loss - 0.55488	, testing loss - 0.55254	
534	 steps: training loss - 0.63412	, testing loss - 0.55232	
535	 steps: training loss - 0.52125	, testing loss - 0.55144	
536	 steps: training loss - 0.57457	, testing loss - 0.55070	
537	 steps: training loss - 0.51860	, testing loss - 0.55000	
538	 steps: training loss - 0.61539	, testing loss - 0.54963	
539	 steps: training loss - 0.54967	, testing loss - 0.54900	
540	 steps: training loss - 0.53210	, testing loss - 0.54842	
541	 steps: training loss - 0.55610	, testing loss - 0.54779	
542	 steps: training loss - 0.61170	, testing loss - 0.54728	
543	 steps: training loss - 0.61044	, testing loss - 0.54655	
544	 steps: training loss - 0.53938	, testing loss - 0.54577	
545	 steps: training loss - 0.61058	, testing loss - 0.54524	
546	 steps: training loss - 0.50022	, testing loss - 0.54451	
547	 steps: training loss - 0.57612	, testing loss - 0.54383	
548	 steps: training loss - 0.46667	, testing loss - 0.54296	
549	 steps: training loss - 0.50036	, testing loss - 0.54225	
550	 steps: training loss - 0.55761	, testing loss - 0.54174	
551	 steps: training loss - 0.59821	, testing loss - 0.54091	
552	 steps: training loss - 0.56961	, testing loss - 0.54024	
553	 steps: training loss - 0.55847	, testing loss - 0.53969	
554	 steps: training loss - 0.48965	, testing loss - 0.53937	
555	 steps: training loss - 0.43658	, testing loss - 0.53943	
556	 steps: training loss - 0.49491	, testing loss - 0.53969	
557	 steps: training loss - 0.61310	, testing loss - 0.54003	
558	 steps: training loss - 0.59737	, testing loss - 0.53986	
559	 steps: training loss - 0.54046	, testing loss - 0.53955	
560	 steps: training loss - 0.56170	, testing loss - 0.53927	
561	 steps: training loss - 0.57835	, testing loss - 0.53922	
562	 steps: training loss - 0.50294	, testing loss - 0.53933	
563	 steps: training loss - 0.60140	, testing loss - 0.53960	
564	 steps: training loss - 0.60241	, testing loss - 0.53975	
565	 steps: training loss - 0.50124	, testing loss - 0.53959	
566	 steps: training loss - 0.50759	, testing loss - 0.53932	
567	 steps: training loss - 0.53846	, testing loss - 0.53913	
568	 steps: training loss - 0.64497	, testing loss - 0.53907	
569	 steps: training loss - 0.60537	, testing loss - 0.53869	
570	 steps: training loss - 0.40813	, testing loss - 0.53827	
571	 steps: training loss - 0.63753	, testing loss - 0.53805	
572	 steps: training loss - 0.52710	, testing loss - 0.53769	
573	 steps: training loss - 0.58030	, testing loss - 0.53734	
574	 steps: training loss - 0.55063	, testing loss - 0.53707	
575	 steps: training loss - 0.60515	, testing loss - 0.53707	
576	 steps: training loss - 0.46723	, testing loss - 0.53716	
577	 steps: training loss - 0.53153	, testing loss - 0.53734	
578	 steps: training loss - 0.57961	, testing loss - 0.53749	
579	 steps: training loss - 0.43571	, testing loss - 0.53748	
580	 steps: training loss - 0.59686	, testing loss - 0.53749	
581	 steps: training loss - 0.50008	, testing loss - 0.53713	
582	 steps: training loss - 0.48330	, testing loss - 0.53667	
583	 steps: training loss - 0.49861	, testing loss - 0.53639	
584	 steps: training loss - 0.54352	, testing loss - 0.53627	
585	 steps: training loss - 0.57525	, testing loss - 0.53609	
586	 steps: training loss - 0.50380	, testing loss - 0.53538	
587	 steps: training loss - 0.50705	, testing loss - 0.53445	
588	 steps: training loss - 0.51273	, testing loss - 0.53362	
589	 steps: training loss - 0.50322	, testing loss - 0.53294	
590	 steps: training loss - 0.46470	, testing loss - 0.53259	
591	 steps: training loss - 0.55922	, testing loss - 0.53251	
592	 steps: training loss - 0.51924	, testing loss - 0.53256	
593	 steps: training loss - 0.62947	, testing loss - 0.53261	
594	 steps: training loss - 0.56392	, testing loss - 0.53241	
595	 steps: training loss - 0.42957	, testing loss - 0.53222	
596	 steps: training loss - 0.52566	, testing loss - 0.53215	
597	 steps: training loss - 0.57374	, testing loss - 0.53225	
598	 steps: training loss - 0.53523	, testing loss - 0.53218	
599	 steps: training loss - 0.48769	, testing loss - 0.53188	
600	 steps: training loss - 0.58443	, testing loss - 0.53163	
601	 steps: training loss - 0.50464	, testing loss - 0.53103	
602	 steps: training loss - 0.56912	, testing loss - 0.53041	
603	 steps: training loss - 0.50043	, testing loss - 0.52994	
604	 steps: training loss - 0.58050	, testing loss - 0.52962	
605	 steps: training loss - 0.55242	, testing loss - 0.52909	
606	 steps: training loss - 0.63171	, testing loss - 0.52866	
607	 steps: training loss - 0.50433	, testing loss - 0.52833	
608	 steps: training loss - 0.53465	, testing loss - 0.52783	
609	 steps: training loss - 0.52298	, testing loss - 0.52749	
610	 steps: training loss - 0.47643	, testing loss - 0.52708	
611	 steps: training loss - 0.54773	, testing loss - 0.52691	
612	 steps: training loss - 0.58834	, testing loss - 0.52673	
613	 steps: training loss - 0.51542	, testing loss - 0.52627	
614	 steps: training loss - 0.46064	, testing loss - 0.52590	
615	 steps: training loss - 0.60094	, testing loss - 0.52590	
616	 steps: training loss - 0.57375	, testing loss - 0.52590	
617	 steps: training loss - 0.47084	, testing loss - 0.52598	
618	 steps: training loss - 0.50478	, testing loss - 0.52594	
619	 steps: training loss - 0.52334	, testing loss - 0.52611	
620	 steps: training loss - 0.51190	, testing loss - 0.52658	
621	 steps: training loss - 0.52356	, testing loss - 0.52696	
622	 steps: training loss - 0.50952	, testing loss - 0.52756	
623	 steps: training loss - 0.54132	, testing loss - 0.52803	
624	 steps: training loss - 0.49368	, testing loss - 0.52844	
625	 steps: training loss - 0.55585	, testing loss - 0.52869	
626	 steps: training loss - 0.45888	, testing loss - 0.52859	
627	 steps: training loss - 0.50462	, testing loss - 0.52839	
628	 steps: training loss - 0.56181	, testing loss - 0.52823	
629	 steps: training loss - 0.55624	, testing loss - 0.52795	
630	 steps: training loss - 0.51200	, testing loss - 0.52766	
631	 steps: training loss - 0.57827	, testing loss - 0.52760	
632	 steps: training loss - 0.54852	, testing loss - 0.52751	
633	 steps: training loss - 0.58528	, testing loss - 0.52720	
634	 steps: training loss - 0.55166	, testing loss - 0.52705	
635	 steps: training loss - 0.44791	, testing loss - 0.52696	
636	 steps: training loss - 0.52833	, testing loss - 0.52722	
637	 steps: training loss - 0.54199	, testing loss - 0.52745	
638	 steps: training loss - 0.53021	, testing loss - 0.52747	
639	 steps: training loss - 0.51672	, testing loss - 0.52770	
640	 steps: training loss - 0.53948	, testing loss - 0.52797	
641	 steps: training loss - 0.51982	, testing loss - 0.52793	
642	 steps: training loss - 0.58833	, testing loss - 0.52804	
643	 steps: training loss - 0.60646	, testing loss - 0.52801	
644	 steps: training loss - 0.50189	, testing loss - 0.52762	
645	 steps: training loss - 0.44834	, testing loss - 0.52697	
646	 steps: training loss - 0.59353	, testing loss - 0.52657	
647	 steps: training loss - 0.45859	, testing loss - 0.52642	
648	 steps: training loss - 0.59640	, testing loss - 0.52651	
649	 steps: training loss - 0.50184	, testing loss - 0.52652	
650	 steps: training loss - 0.50629	, testing loss - 0.52667	
651	 steps: training loss - 0.60547	, testing loss - 0.52677	
652	 steps: training loss - 0.54018	, testing loss - 0.52651	
653	 steps: training loss - 0.51610	, testing loss - 0.52588	
654	 steps: training loss - 0.48978	, testing loss - 0.52544	
655	 steps: training loss - 0.53867	, testing loss - 0.52496	
656	 steps: training loss - 0.53910	, testing loss - 0.52420	
657	 steps: training loss - 0.48225	, testing loss - 0.52326	
658	 steps: training loss - 0.48770	, testing loss - 0.52251	
659	 steps: training loss - 0.63567	, testing loss - 0.52186	
660	 steps: training loss - 0.48366	, testing loss - 0.52137	
661	 steps: training loss - 0.58173	, testing loss - 0.52115	
662	 steps: training loss - 0.46526	, testing loss - 0.52082	
663	 steps: training loss - 0.48546	, testing loss - 0.52083	
664	 steps: training loss - 0.55329	, testing loss - 0.52079	
665	 steps: training loss - 0.59045	, testing loss - 0.52080	
666	 steps: training loss - 0.49652	, testing loss - 0.52092	
667	 steps: training loss - 0.45741	, testing loss - 0.52071	
668	 steps: training loss - 0.53032	, testing loss - 0.52060	
669	 steps: training loss - 0.54458	, testing loss - 0.52052	
670	 steps: training loss - 0.59967	, testing loss - 0.52071	
671	 steps: training loss - 0.54140	, testing loss - 0.52025	
672	 steps: training loss - 0.51673	, testing loss - 0.51947	
673	 steps: training loss - 0.52379	, testing loss - 0.51894	
674	 steps: training loss - 0.64440	, testing loss - 0.51873	
675	 steps: training loss - 0.56133	, testing loss - 0.51829	
676	 steps: training loss - 0.55258	, testing loss - 0.51768	
677	 steps: training loss - 0.48640	, testing loss - 0.51724	
678	 steps: training loss - 0.61511	, testing loss - 0.51716	
679	 steps: training loss - 0.60727	, testing loss - 0.51676	
680	 steps: training loss - 0.52043	, testing loss - 0.51623	
681	 steps: training loss - 0.47794	, testing loss - 0.51600	
682	 steps: training loss - 0.57402	, testing loss - 0.51575	
683	 steps: training loss - 0.55059	, testing loss - 0.51550	
684	 steps: training loss - 0.49529	, testing loss - 0.51521	
685	 steps: training loss - 0.64836	, testing loss - 0.51525	
686	 steps: training loss - 0.58851	, testing loss - 0.51525	
687	 steps: training loss - 0.48064	, testing loss - 0.51532	
688	 steps: training loss - 0.46921	, testing loss - 0.51579	
689	 steps: training loss - 0.46753	, testing loss - 0.51624	
690	 steps: training loss - 0.55748	, testing loss - 0.51673	
691	 steps: training loss - 0.65059	, testing loss - 0.51711	
692	 steps: training loss - 0.52764	, testing loss - 0.51695	
693	 steps: training loss - 0.64747	, testing loss - 0.51660	
694	 steps: training loss - 0.50287	, testing loss - 0.51632	
695	 steps: training loss - 0.51274	, testing loss - 0.51622	
696	 steps: training loss - 0.50965	, testing loss - 0.51609	
697	 steps: training loss - 0.58145	, testing loss - 0.51608	
698	 steps: training loss - 0.46960	, testing loss - 0.51601	
699	 steps: training loss - 0.53649	, testing loss - 0.51605	
700	 steps: training loss - 0.50312	, testing loss - 0.51594	
701	 steps: training loss - 0.54104	, testing loss - 0.51593	
702	 steps: training loss - 0.46407	, testing loss - 0.51603	
703	 steps: training loss - 0.58161	, testing loss - 0.51649	
704	 steps: training loss - 0.48157	, testing loss - 0.51685	
705	 steps: training loss - 0.63528	, testing loss - 0.51716	
706	 steps: training loss - 0.55947	, testing loss - 0.51702	
707	 steps: training loss - 0.50595	, testing loss - 0.51653	
708	 steps: training loss - 0.52276	, testing loss - 0.51573	
709	 steps: training loss - 0.53503	, testing loss - 0.51477	
710	 steps: training loss - 0.47969	, testing loss - 0.51392	
711	 steps: training loss - 0.50145	, testing loss - 0.51325	
712	 steps: training loss - 0.46513	, testing loss - 0.51267	
713	 steps: training loss - 0.58512	, testing loss - 0.51251	
714	 steps: training loss - 0.50426	, testing loss - 0.51231	
715	 steps: training loss - 0.60090	, testing loss - 0.51219	
716	 steps: training loss - 0.60938	, testing loss - 0.51180	
717	 steps: training loss - 0.55673	, testing loss - 0.51112	
718	 steps: training loss - 0.61628	, testing loss - 0.51046	
719	 steps: training loss - 0.52424	, testing loss - 0.51002	
720	 steps: training loss - 0.55014	, testing loss - 0.50958	
721	 steps: training loss - 0.55510	, testing loss - 0.50922	
722	 steps: training loss - 0.55416	, testing loss - 0.50901	
723	 steps: training loss - 0.48989	, testing loss - 0.50858	
724	 steps: training loss - 0.54721	, testing loss - 0.50811	
725	 steps: training loss - 0.50469	, testing loss - 0.50733	
726	 steps: training loss - 0.44361	, testing loss - 0.50649	
727	 steps: training loss - 0.46663	, testing loss - 0.50569	
728	 steps: training loss - 0.51237	, testing loss - 0.50509	
729	 steps: training loss - 0.45255	, testing loss - 0.50471	
730	 steps: training loss - 0.39446	, testing loss - 0.50430	
731	 steps: training loss - 0.50345	, testing loss - 0.50409	
732	 steps: training loss - 0.50529	, testing loss - 0.50400	
733	 steps: training loss - 0.53555	, testing loss - 0.50405	
734	 steps: training loss - 0.49020	, testing loss - 0.50412	
735	 steps: training loss - 0.63113	, testing loss - 0.50413	
736	 steps: training loss - 0.52963	, testing loss - 0.50376	
737	 steps: training loss - 0.56958	, testing loss - 0.50318	
738	 steps: training loss - 0.48310	, testing loss - 0.50231	
739	 steps: training loss - 0.56316	, testing loss - 0.50183	
740	 steps: training loss - 0.52164	, testing loss - 0.50161	
741	 steps: training loss - 0.57024	, testing loss - 0.50127	
742	 steps: training loss - 0.48872	, testing loss - 0.50113	
743	 steps: training loss - 0.59749	, testing loss - 0.50115	
744	 steps: training loss - 0.45484	, testing loss - 0.50092	
745	 steps: training loss - 0.55177	, testing loss - 0.50088	
746	 steps: training loss - 0.45746	, testing loss - 0.50061	
747	 steps: training loss - 0.57380	, testing loss - 0.50035	
748	 steps: training loss - 0.53642	, testing loss - 0.50008	
749	 steps: training loss - 0.55563	, testing loss - 0.49991	
750	 steps: training loss - 0.55698	, testing loss - 0.49960	
751	 steps: training loss - 0.47334	, testing loss - 0.49933	
752	 steps: training loss - 0.44367	, testing loss - 0.49908	
753	 steps: training loss - 0.51144	, testing loss - 0.49910	
754	 steps: training loss - 0.53535	, testing loss - 0.49923	
755	 steps: training loss - 0.46175	, testing loss - 0.49886	
756	 steps: training loss - 0.51626	, testing loss - 0.49850	
757	 steps: training loss - 0.50647	, testing loss - 0.49831	
758	 steps: training loss - 0.43231	, testing loss - 0.49827	
759	 steps: training loss - 0.56771	, testing loss - 0.49851	
760	 steps: training loss - 0.46779	, testing loss - 0.49881	
761	 steps: training loss - 0.47242	, testing loss - 0.49914	
762	 steps: training loss - 0.53658	, testing loss - 0.49956	
763	 steps: training loss - 0.56264	, testing loss - 0.49967	
764	 steps: training loss - 0.51853	, testing loss - 0.49969	
765	 steps: training loss - 0.44473	, testing loss - 0.49980	
766	 steps: training loss - 0.43290	, testing loss - 0.50025	
767	 steps: training loss - 0.55576	, testing loss - 0.50095	
768	 steps: training loss - 0.50163	, testing loss - 0.50143	
769	 steps: training loss - 0.52715	, testing loss - 0.50169	
770	 steps: training loss - 0.47868	, testing loss - 0.50194	
771	 steps: training loss - 0.55097	, testing loss - 0.50209	
772	 steps: training loss - 0.53305	, testing loss - 0.50210	
773	 steps: training loss - 0.55864	, testing loss - 0.50196	
774	 steps: training loss - 0.46603	, testing loss - 0.50205	
775	 steps: training loss - 0.49387	, testing loss - 0.50207	
776	 steps: training loss - 0.43368	, testing loss - 0.50211	
777	 steps: training loss - 0.47482	, testing loss - 0.50218	
778	 steps: training loss - 0.57876	, testing loss - 0.50192	
779	 steps: training loss - 0.42955	, testing loss - 0.50150	
780	 steps: training loss - 0.61578	, testing loss - 0.50125	
781	 steps: training loss - 0.45432	, testing loss - 0.50061	
782	 steps: training loss - 0.47458	, testing loss - 0.49980	
783	 steps: training loss - 0.63494	, testing loss - 0.49930	
784	 steps: training loss - 0.55841	, testing loss - 0.49900	
785	 steps: training loss - 0.55928	, testing loss - 0.49883	
786	 steps: training loss - 0.53545	, testing loss - 0.49884	
787	 steps: training loss - 0.45344	, testing loss - 0.49884	
788	 steps: training loss - 0.60044	, testing loss - 0.49879	
789	 steps: training loss - 0.54899	, testing loss - 0.49876	
790	 steps: training loss - 0.57463	, testing loss - 0.49843	
791	 steps: training loss - 0.48721	, testing loss - 0.49799	
792	 steps: training loss - 0.45899	, testing loss - 0.49762	
793	 steps: training loss - 0.58924	, testing loss - 0.49738	
794	 steps: training loss - 0.45008	, testing loss - 0.49696	
795	 steps: training loss - 0.55270	, testing loss - 0.49684	
796	 steps: training loss - 0.50856	, testing loss - 0.49695	
797	 steps: training loss - 0.46022	, testing loss - 0.49706	
798	 steps: training loss - 0.53318	, testing loss - 0.49704	
799	 steps: training loss - 0.53104	, testing loss - 0.49707	
800	 steps: training loss - 0.56875	, testing loss - 0.49676	
801	 steps: training loss - 0.52808	, testing loss - 0.49619	
802	 steps: training loss - 0.45586	, testing loss - 0.49580	
803	 steps: training loss - 0.48794	, testing loss - 0.49583	
804	 steps: training loss - 0.57314	, testing loss - 0.49620	
805	 steps: training loss - 0.42083	, testing loss - 0.49641	
806	 steps: training loss - 0.58393	, testing loss - 0.49665	
807	 steps: training loss - 0.60284	, testing loss - 0.49658	
808	 steps: training loss - 0.51119	, testing loss - 0.49635	
809	 steps: training loss - 0.48883	, testing loss - 0.49622	
810	 steps: training loss - 0.47671	, testing loss - 0.49615	
811	 steps: training loss - 0.60790	, testing loss - 0.49618	
812	 steps: training loss - 0.59218	, testing loss - 0.49614	
813	 steps: training loss - 0.60483	, testing loss - 0.49603	
814	 steps: training loss - 0.40159	, testing loss - 0.49552	
815	 steps: training loss - 0.50948	, testing loss - 0.49486	
816	 steps: training loss - 0.57337	, testing loss - 0.49415	
817	 steps: training loss - 0.52391	, testing loss - 0.49315	
818	 steps: training loss - 0.60306	, testing loss - 0.49201	
819	 steps: training loss - 0.51114	, testing loss - 0.49082	
820	 steps: training loss - 0.46687	, testing loss - 0.48960	
821	 steps: training loss - 0.50918	, testing loss - 0.48852	
822	 steps: training loss - 0.54266	, testing loss - 0.48752	
823	 steps: training loss - 0.55792	, testing loss - 0.48697	
824	 steps: training loss - 0.56082	, testing loss - 0.48609	
825	 steps: training loss - 0.51507	, testing loss - 0.48524	
826	 steps: training loss - 0.49510	, testing loss - 0.48417	
827	 steps: training loss - 0.46939	, testing loss - 0.48319	
828	 steps: training loss - 0.55717	, testing loss - 0.48238	